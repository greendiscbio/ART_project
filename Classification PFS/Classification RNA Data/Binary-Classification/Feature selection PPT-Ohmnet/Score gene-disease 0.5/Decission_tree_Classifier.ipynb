{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model using Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>EPAS1</th>\n",
       "      <th>NF2</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>TSC1</th>\n",
       "      <th>VHL</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33.677294</td>\n",
       "      <td>37.95811</td>\n",
       "      <td>33.96080</td>\n",
       "      <td>36.73944</td>\n",
       "      <td>32.93402</td>\n",
       "      <td>32.30615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.643149</td>\n",
       "      <td>38.83281</td>\n",
       "      <td>33.69899</td>\n",
       "      <td>37.13114</td>\n",
       "      <td>33.16630</td>\n",
       "      <td>32.19988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32.368866</td>\n",
       "      <td>37.19345</td>\n",
       "      <td>34.07472</td>\n",
       "      <td>37.91878</td>\n",
       "      <td>33.63282</td>\n",
       "      <td>31.49147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31.895400</td>\n",
       "      <td>39.46713</td>\n",
       "      <td>33.14612</td>\n",
       "      <td>37.77827</td>\n",
       "      <td>32.88250</td>\n",
       "      <td>32.11538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33.968348</td>\n",
       "      <td>38.49884</td>\n",
       "      <td>32.58079</td>\n",
       "      <td>37.99008</td>\n",
       "      <td>33.44515</td>\n",
       "      <td>33.33646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       BAP1     EPAS1       NF2      PTEN      TSC1       VHL  Y\n",
       "0           0  33.677294  37.95811  33.96080  36.73944  32.93402  32.30615  1\n",
       "1           1  32.643149  38.83281  33.69899  37.13114  33.16630  32.19988  1\n",
       "2           2  32.368866  37.19345  34.07472  37.91878  33.63282  31.49147  1\n",
       "3           3  31.895400  39.46713  33.14612  37.77827  32.88250  32.11538  0\n",
       "4           4  33.968348  38.49884  32.58079  37.99008  33.44515  33.33646  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='C:/Users/sandr/Documents/ART_project/GNN model/Data/PPT-Ohmnet/mRCC_big_pool/Second big pool/mrcc_protein_matrix_16_genes_6_nodes.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BAP1     EPAS1       NF2      PTEN      TSC1       VHL\n",
      "0    33.677294  37.95811  33.96080  36.73944  32.93402  32.30615\n",
      "1    32.643149  38.83281  33.69899  37.13114  33.16630  32.19988\n",
      "2    32.368866  37.19345  34.07472  37.91878  33.63282  31.49147\n",
      "3    31.895400  39.46713  33.14612  37.77827  32.88250  32.11538\n",
      "4    33.968348  38.49884  32.58079  37.99008  33.44515  33.33646\n",
      "..         ...       ...       ...       ...       ...       ...\n",
      "176  33.843872  39.13826  33.58214  37.99666  32.93248  31.79913\n",
      "177  32.519967  35.86338  33.10420  34.65038  32.62658  31.66344\n",
      "178  33.115209  37.91340  33.80118  36.77314  32.81059  32.39461\n",
      "179  32.895151  37.96870  33.51366  36.08937  34.04810  32.34561\n",
      "180  33.404526  38.75226  33.67890  36.87734  33.82576  30.34566\n",
      "\n",
      "[181 rows x 6 columns]\n",
      "Numero de pacientes:  181\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,1:7  ] \n",
    "Y = []\n",
    "for i in range (len(data)):\n",
    "    if data.Y[i]==0: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
    "        Y.append(0)\n",
    "    else:\n",
    "        Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
    "print(X)\n",
    "print('Numero de pacientes: ',len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 144\n",
      "Target column size of the training set: 144\n",
      "Test set size: 37\n",
      "Target column size of the test set: 37\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125, stratify=Y)\n",
    "\n",
    "# Convert sets to arrays\n",
    "XTrain = XTrain.values\n",
    "XTest = XTest.values\n",
    "\n",
    "print('Training set size:', len(XTrain))\n",
    "print('Target column size of the training set:', len(yTrain))\n",
    "print('Test set size:', len(XTest))\n",
    "print('Target column size of the test set:', len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select the parameters of the model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': [2, 5, 10, 12],\n",
       "                         'min_samples_leaf': [2, 5, 7],\n",
       "                         'min_samples_split': [2, 5], 'random_state': [125],\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'min_samples_leaf': [2,5,7],\n",
    "              'min_samples_split': [2, 5],\n",
    "              'max_depth':[2,5,10,12],\n",
    "              'criterion':['entropy','gini'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'random_state':[125]}\n",
    "\n",
    "\n",
    "# I created a GridSearchCV which allows us to systematically evaluate and select the parameters of our model.\n",
    "# By indicating a model and the parameters to test, you can evaluate the performance of the first one based on the\n",
    "# seconds through cross validation.\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = 5)\n",
    "\n",
    "clf.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimate of parameters according to GridSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2,\n",
       "                       random_state=125, splitter='random')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best estimate of parameters according to GridSearchCV:\")\n",
    "model = clf.best_estimator_\n",
    "# Fit the model with the best parameters\n",
    "model.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result of the cross validation of the model with the best paramters:0.5411330049261084\n"
     ]
    }
   ],
   "source": [
    "print(\"Best result of the cross validation of the model with the best paramters:\" +str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the training dataset\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTrain),1) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training dataset:0.7777777777777778\n",
      "Final accuracy on the testing dataset: 0.5135135135135135\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy on the training dataset:' + str(contTrain/len(yTrain)))\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Training)------------------\n",
      "[[61  7]\n",
      " [25 51]]\n",
      "Input data:  [1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1]\n",
      "Prediction:        [1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1\n",
      " 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0\n",
      " 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Confusion Matrix (Training)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Input data:  ' + str(np.array(yTrain)))\n",
    "print('Prediction:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79        68\n",
      "           1       0.88      0.67      0.76        76\n",
      "\n",
      "    accuracy                           0.78       144\n",
      "   macro avg       0.79      0.78      0.78       144\n",
      "weighted avg       0.80      0.78      0.78       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[12  5]\n",
      " [13  7]]\n",
      "Input data:  [0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0]\n",
      "Prediction:        [0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Input data:  ' + str(np.array(yTest)))\n",
    "print('Prediction:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57        17\n",
      "           1       0.58      0.35      0.44        20\n",
      "\n",
      "    accuracy                           0.51        37\n",
      "   macro avg       0.53      0.53      0.50        37\n",
      "weighted avg       0.54      0.51      0.50        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8be240dc937e61b542e412c89351978950720d3fde5a0c37c158fb19f149fb89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
