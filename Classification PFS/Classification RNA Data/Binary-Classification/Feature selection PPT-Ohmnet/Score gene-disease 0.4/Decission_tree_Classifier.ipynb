{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model using Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>EPAS1</th>\n",
       "      <th>MTOR</th>\n",
       "      <th>NF2</th>\n",
       "      <th>PIK3CA</th>\n",
       "      <th>PTEN</th>\n",
       "      <th>PTGS2</th>\n",
       "      <th>RNF139</th>\n",
       "      <th>SETD2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>TSC1</th>\n",
       "      <th>VHL</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33.677294</td>\n",
       "      <td>37.95811</td>\n",
       "      <td>33.01718</td>\n",
       "      <td>33.96080</td>\n",
       "      <td>32.42544</td>\n",
       "      <td>36.73944</td>\n",
       "      <td>31.08504</td>\n",
       "      <td>32.46554</td>\n",
       "      <td>32.58565</td>\n",
       "      <td>33.83518</td>\n",
       "      <td>32.93402</td>\n",
       "      <td>32.30615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.643149</td>\n",
       "      <td>38.83281</td>\n",
       "      <td>33.17883</td>\n",
       "      <td>33.69899</td>\n",
       "      <td>33.21465</td>\n",
       "      <td>37.13114</td>\n",
       "      <td>30.16993</td>\n",
       "      <td>32.27190</td>\n",
       "      <td>33.19915</td>\n",
       "      <td>34.44810</td>\n",
       "      <td>33.16630</td>\n",
       "      <td>32.19988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32.368866</td>\n",
       "      <td>37.19345</td>\n",
       "      <td>34.06093</td>\n",
       "      <td>34.07472</td>\n",
       "      <td>32.46705</td>\n",
       "      <td>37.91878</td>\n",
       "      <td>30.76766</td>\n",
       "      <td>32.55514</td>\n",
       "      <td>32.84628</td>\n",
       "      <td>35.41980</td>\n",
       "      <td>33.63282</td>\n",
       "      <td>31.49147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31.895400</td>\n",
       "      <td>39.46713</td>\n",
       "      <td>33.50445</td>\n",
       "      <td>33.14612</td>\n",
       "      <td>33.87549</td>\n",
       "      <td>37.77827</td>\n",
       "      <td>30.54053</td>\n",
       "      <td>33.19823</td>\n",
       "      <td>33.68316</td>\n",
       "      <td>34.18862</td>\n",
       "      <td>32.88250</td>\n",
       "      <td>32.11538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33.968348</td>\n",
       "      <td>38.49884</td>\n",
       "      <td>34.22502</td>\n",
       "      <td>32.58079</td>\n",
       "      <td>34.24976</td>\n",
       "      <td>37.99008</td>\n",
       "      <td>30.95478</td>\n",
       "      <td>30.89813</td>\n",
       "      <td>34.63036</td>\n",
       "      <td>34.91241</td>\n",
       "      <td>33.44515</td>\n",
       "      <td>33.33646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       BAP1     EPAS1      MTOR       NF2    PIK3CA      PTEN  \\\n",
       "0           0  33.677294  37.95811  33.01718  33.96080  32.42544  36.73944   \n",
       "1           1  32.643149  38.83281  33.17883  33.69899  33.21465  37.13114   \n",
       "2           2  32.368866  37.19345  34.06093  34.07472  32.46705  37.91878   \n",
       "3           3  31.895400  39.46713  33.50445  33.14612  33.87549  37.77827   \n",
       "4           4  33.968348  38.49884  34.22502  32.58079  34.24976  37.99008   \n",
       "\n",
       "      PTGS2    RNF139     SETD2      TP53      TSC1       VHL  Y  \n",
       "0  31.08504  32.46554  32.58565  33.83518  32.93402  32.30615  1  \n",
       "1  30.16993  32.27190  33.19915  34.44810  33.16630  32.19988  1  \n",
       "2  30.76766  32.55514  32.84628  35.41980  33.63282  31.49147  1  \n",
       "3  30.54053  33.19823  33.68316  34.18862  32.88250  32.11538  0  \n",
       "4  30.95478  30.89813  34.63036  34.91241  33.44515  33.33646  1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='C:/Users/sandr/Documents/ART_project/GNN model/Data/PPT-Ohmnet/mRCC_big_pool/Second big pool/mrcc_protein_matrix_24_genes_12_nodes.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BAP1     EPAS1      MTOR       NF2    PIK3CA      PTEN     PTGS2  \\\n",
      "0    33.677294  37.95811  33.01718  33.96080  32.42544  36.73944  31.08504   \n",
      "1    32.643149  38.83281  33.17883  33.69899  33.21465  37.13114  30.16993   \n",
      "2    32.368866  37.19345  34.06093  34.07472  32.46705  37.91878  30.76766   \n",
      "3    31.895400  39.46713  33.50445  33.14612  33.87549  37.77827  30.54053   \n",
      "4    33.968348  38.49884  34.22502  32.58079  34.24976  37.99008  30.95478   \n",
      "..         ...       ...       ...       ...       ...       ...       ...   \n",
      "176  33.843872  39.13826  33.84510  33.58214  32.89218  37.99666  30.11854   \n",
      "177  32.519967  35.86338  32.98942  33.10420  33.35177  34.65038  31.17902   \n",
      "178  33.115209  37.91340  34.30048  33.80118  32.93922  36.77314  33.02287   \n",
      "179  32.895151  37.96870  32.81197  33.51366  32.59420  36.08937  31.14709   \n",
      "180  33.404526  38.75226  33.43997  33.67890  32.98728  36.87734  34.94678   \n",
      "\n",
      "       RNF139     SETD2      TP53      TSC1       VHL  \n",
      "0    32.46554  32.58565  33.83518  32.93402  32.30615  \n",
      "1    32.27190  33.19915  34.44810  33.16630  32.19988  \n",
      "2    32.55514  32.84628  35.41980  33.63282  31.49147  \n",
      "3    33.19823  33.68316  34.18862  32.88250  32.11538  \n",
      "4    30.89813  34.63036  34.91241  33.44515  33.33646  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "176  32.12573  33.34867  35.39631  32.93248  31.79913  \n",
      "177  34.27276  32.16275  32.04003  32.62658  31.66344  \n",
      "178  32.92305  34.01015  33.34126  32.81059  32.39461  \n",
      "179  31.87160  33.23246  34.98283  34.04810  32.34561  \n",
      "180  32.47268  32.81781  33.82151  33.82576  30.34566  \n",
      "\n",
      "[181 rows x 12 columns]\n",
      "Numero de pacientes:  181\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,1:13  ] \n",
    "Y = []\n",
    "for i in range (len(data)):\n",
    "    if data.Y[i]==0: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
    "        Y.append(0)\n",
    "    else:\n",
    "        Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
    "print(X)\n",
    "print('Numero de pacientes: ',len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 144\n",
      "Target column size of the training set: 144\n",
      "Test set size: 37\n",
      "Target column size of the test set: 37\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125, stratify=Y)\n",
    "\n",
    "# Convert sets to arrays\n",
    "XTrain = XTrain.values\n",
    "XTest = XTest.values\n",
    "\n",
    "print('Training set size:', len(XTrain))\n",
    "print('Target column size of the training set:', len(yTrain))\n",
    "print('Test set size:', len(XTest))\n",
    "print('Target column size of the test set:', len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select the parameters of the model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': [2, 5, 10, 12],\n",
       "                         'min_samples_leaf': [2, 5, 7],\n",
       "                         'min_samples_split': [2, 5], 'random_state': [125],\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'min_samples_leaf': [2,5,7],\n",
    "              'min_samples_split': [2, 5],\n",
    "              'max_depth':[2,5,10,12],\n",
    "              'criterion':['entropy','gini'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'random_state':[125]}\n",
    "\n",
    "\n",
    "# I created a GridSearchCV which allows us to systematically evaluate and select the parameters of our model.\n",
    "# By indicating a model and the parameters to test, you can evaluate the performance of the first one based on the\n",
    "# seconds through cross validation.\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = 5)\n",
    "\n",
    "clf.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimate of parameters according to GridSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=12, min_samples_leaf=2, min_samples_split=5,\n",
       "                       random_state=125, splitter='random')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best estimate of parameters according to GridSearchCV:\")\n",
    "model = clf.best_estimator_\n",
    "# Fit the model with the best parameters\n",
    "model.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result of the cross validation of the model with the best paramters:0.5556650246305418\n"
     ]
    }
   ],
   "source": [
    "print(\"Best result of the cross validation of the model with the best paramters:\" +str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the training dataset\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTrain),1) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training dataset:0.8680555555555556\n",
      "Final accuracy on the testing dataset: 0.4864864864864865\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy on the training dataset:' + str(contTrain/len(yTrain)))\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Training)------------------\n",
      "[[66  2]\n",
      " [17 59]]\n",
      "Input data:  [1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1]\n",
      "Prediction:        [0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1\n",
      " 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Confusion Matrix (Training)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Input data:  ' + str(np.array(yTrain)))\n",
    "print('Prediction:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87        68\n",
      "           1       0.97      0.78      0.86        76\n",
      "\n",
      "    accuracy                           0.87       144\n",
      "   macro avg       0.88      0.87      0.87       144\n",
      "weighted avg       0.89      0.87      0.87       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[12  5]\n",
      " [14  6]]\n",
      "Input data:  [0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0]\n",
      "Prediction:        [1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Input data:  ' + str(np.array(yTest)))\n",
    "print('Prediction:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.71      0.56        17\n",
      "           1       0.55      0.30      0.39        20\n",
      "\n",
      "    accuracy                           0.49        37\n",
      "   macro avg       0.50      0.50      0.47        37\n",
      "weighted avg       0.51      0.49      0.47        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8be240dc937e61b542e412c89351978950720d3fde5a0c37c158fb19f149fb89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
