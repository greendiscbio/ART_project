{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model using Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload Clinic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RNA_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sarc</th>\n",
       "      <th>Rhab</th>\n",
       "      <th>Number_of_Prior_Therapies</th>\n",
       "      <th>Days_from_TumorSample_Collection_and_Start_of_Trial_Therapy</th>\n",
       "      <th>Tumor_Shrinkage</th>\n",
       "      <th>PFS</th>\n",
       "      <th>TM_TC_Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>MSKCC_NA</th>\n",
       "      <th>MSKCC_POOR</th>\n",
       "      <th>IMDC_FAVORABLE</th>\n",
       "      <th>IMDC_INTERMEDIATE</th>\n",
       "      <th>IMDC_NOT_REPORTED</th>\n",
       "      <th>IMDC_POOR</th>\n",
       "      <th>ImmunoPhenotype_Desert</th>\n",
       "      <th>ImmunoPhenotype_Excluded</th>\n",
       "      <th>ImmunoPhenotype_Infiltrated</th>\n",
       "      <th>ImmunoPhenotype_NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.545205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.419178</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.413699</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394521</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.158904</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RNA_ID  Age  Sarc  Rhab  Number_of_Prior_Therapies  \\\n",
       "0           0     NaN   73   0.0   0.0                        2.0   \n",
       "1           1     NaN   55   0.0   0.0                        2.0   \n",
       "2           2     NaN   51   0.0   0.0                        1.0   \n",
       "3           3     NaN   70   0.0   0.0                        3.0   \n",
       "4           4     NaN   59   0.0   0.0                        3.0   \n",
       "\n",
       "   Days_from_TumorSample_Collection_and_Start_of_Trial_Therapy  \\\n",
       "0                                                808             \n",
       "1                                               1826             \n",
       "2                                               1541             \n",
       "3                                                 -1             \n",
       "4                                                376             \n",
       "\n",
       "   Tumor_Shrinkage        PFS  TM_TC_Ratio  ...  MSKCC_NA  MSKCC_POOR  \\\n",
       "0              0.0   1.545205         -1.0  ...         0           0   \n",
       "1              0.0   3.419178         -1.0  ...         0           0   \n",
       "2              0.0   1.413699         -1.0  ...         0           0   \n",
       "3              0.0   0.394521         -1.0  ...         0           1   \n",
       "4              0.0  10.158904         -1.0  ...         0           1   \n",
       "\n",
       "   IMDC_FAVORABLE  IMDC_INTERMEDIATE  IMDC_NOT_REPORTED  IMDC_POOR  \\\n",
       "0               0                  0                  1          0   \n",
       "1               0                  0                  1          0   \n",
       "2               0                  0                  1          0   \n",
       "3               0                  0                  1          0   \n",
       "4               0                  0                  1          0   \n",
       "\n",
       "   ImmunoPhenotype_Desert  ImmunoPhenotype_Excluded  \\\n",
       "0                       0                         0   \n",
       "1                       1                         0   \n",
       "2                       0                         0   \n",
       "3                       0                         0   \n",
       "4                       0                         0   \n",
       "\n",
       "   ImmunoPhenotype_Infiltrated  ImmunoPhenotype_NA  \n",
       "0                            1                   0  \n",
       "1                            0                   0  \n",
       "2                            1                   0  \n",
       "3                            0                   1  \n",
       "4                            1                   0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='../../../Data_preprocessing/Prediction PFS/Clinical_data_categorized_PFS.csv' \n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Sarc  Rhab  Number_of_Prior_Therapies  \\\n",
      "0     73   0.0   0.0                        2.0   \n",
      "1     55   0.0   0.0                        2.0   \n",
      "2     51   0.0   0.0                        1.0   \n",
      "3     70   0.0   0.0                        3.0   \n",
      "4     59   0.0   0.0                        3.0   \n",
      "..   ...   ...   ...                        ...   \n",
      "285   54   0.0   0.0                        3.0   \n",
      "286   56   0.0   0.0                        2.0   \n",
      "287   65   0.0   0.0                        2.0   \n",
      "288   48   0.0   0.0                        1.0   \n",
      "289   76   0.0   0.0                        2.0   \n",
      "\n",
      "     Days_from_TumorSample_Collection_and_Start_of_Trial_Therapy  \\\n",
      "0                                                  808             \n",
      "1                                                 1826             \n",
      "2                                                 1541             \n",
      "3                                                   -1             \n",
      "4                                                  376             \n",
      "..                                                 ...             \n",
      "285                                               2096             \n",
      "286                                                 -1             \n",
      "287                                               8092             \n",
      "288                                               1018             \n",
      "289                                               2762             \n",
      "\n",
      "     Tumor_Shrinkage  TM_TC_Ratio  Cohort_CM-010  Cohort_CM-025  Sex_Female  \\\n",
      "0                0.0         -1.0              1              0           0   \n",
      "1                0.0         -1.0              1              0           0   \n",
      "2                0.0         -1.0              1              0           0   \n",
      "3                0.0         -1.0              1              0           0   \n",
      "4                0.0         -1.0              1              0           0   \n",
      "..               ...          ...            ...            ...         ...   \n",
      "285              0.0         -1.0              0              1           0   \n",
      "286              0.0         -1.0              0              1           0   \n",
      "287              0.0         -1.0              0              1           0   \n",
      "288              0.0         -1.0              0              1           1   \n",
      "289              0.0         -1.0              0              1           1   \n",
      "\n",
      "     ...  MSKCC_NA  MSKCC_POOR  IMDC_FAVORABLE  IMDC_INTERMEDIATE  \\\n",
      "0    ...         0           0               0                  0   \n",
      "1    ...         0           0               0                  0   \n",
      "2    ...         0           0               0                  0   \n",
      "3    ...         0           1               0                  0   \n",
      "4    ...         0           1               0                  0   \n",
      "..   ...       ...         ...             ...                ...   \n",
      "285  ...         0           0               0                  1   \n",
      "286  ...         0           0               0                  1   \n",
      "287  ...         0           0               0                  1   \n",
      "288  ...         0           1               0                  1   \n",
      "289  ...         0           0               0                  1   \n",
      "\n",
      "     IMDC_NOT_REPORTED  IMDC_POOR  ImmunoPhenotype_Desert  \\\n",
      "0                    1          0                       0   \n",
      "1                    1          0                       1   \n",
      "2                    1          0                       0   \n",
      "3                    1          0                       0   \n",
      "4                    1          0                       0   \n",
      "..                 ...        ...                     ...   \n",
      "285                  0          0                       0   \n",
      "286                  0          0                       0   \n",
      "287                  0          0                       0   \n",
      "288                  0          0                       0   \n",
      "289                  0          0                       0   \n",
      "\n",
      "     ImmunoPhenotype_Excluded  ImmunoPhenotype_Infiltrated  ImmunoPhenotype_NA  \n",
      "0                           0                            1                   0  \n",
      "1                           0                            0                   0  \n",
      "2                           0                            1                   0  \n",
      "3                           0                            0                   1  \n",
      "4                           0                            1                   0  \n",
      "..                        ...                          ...                 ...  \n",
      "285                         0                            0                   1  \n",
      "286                         0                            0                   1  \n",
      "287                         0                            0                   1  \n",
      "288                         0                            0                   1  \n",
      "289                         0                            0                   1  \n",
      "\n",
      "[290 rows x 23 columns]\n",
      "Numero de pacientes:  290\n"
     ]
    }
   ],
   "source": [
    "Y = [] # Target column\n",
    "# For each entry I classified it by its PFS value.\n",
    "for i in range (len(data)):\n",
    "    if data.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
    "        Y.append(0)\n",
    "    elif data.PFS[i]<6: # If PFS is over 6 months, I will consider it as Responder (R)\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(2) # If PFS is between 3 and 6 months, I will consider it as SemiResponder (SR)\n",
    "        \n",
    "data = data.drop('PFS', axis=1) # As we won't need this column any more, I deleted it.\n",
    "\n",
    "X = data.iloc[:,2:26] \n",
    "# I selected all the columns by removing the Unnamed column (row id) and the Target column.\n",
    "print(X)\n",
    "print('Numero de pacientes: ',len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 232\n",
      "Target column size of the training set: 232\n",
      "Test set size: 58\n",
      "Target column size of the test set: 58\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=125)\n",
    "\n",
    "\n",
    "print('Training set size:', len(X_train))\n",
    "print('Target column size of the training set:', len(y_train))\n",
    "print('Test set size:', len(X_test))\n",
    "print('Target column size of the test set:', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select the parameters of the model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 2, 5, 7, 10],\n",
       "                         'max_iter': [25, 50, 100, 200, 500, 1000],\n",
       "                         'random_state': [125], 'solver': ['liblinear']})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [1,2,5,7,10],\n",
    "            'solver': ['liblinear'], # No escogemos â€˜lbfgsâ€™, â€˜sagâ€™ ni â€˜sagaâ€™ porque no termina de \n",
    "                                                 # ejecutarse debido a: \"TOTAL NO. of ITERATIONS REACHED LIMIT\"\n",
    "            'max_iter':[25,50,100,200,500,1000],\n",
    "            'random_state':[125]}\n",
    "\n",
    "# I created a GridSearchCV which allows us to systematically evaluate and select the parameters of our model.\n",
    "# By indicating a model and the parameters to test, you can evaluate the performance of the first one based on the\n",
    "# seconds through cross validation.\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv = 5)\n",
    "clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimate of parameters according to GridSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, max_iter=25, random_state=125, solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best estimate of parameters according to GridSearchCV:\")\n",
    "model = clf.best_estimator_\n",
    "# Fit the model with the best parameters\n",
    "model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result of the cross validation of the model with the best paramters:0.4225716928769658\n"
     ]
    }
   ],
   "source": [
    "print(\"Best result of the cross validation of the model with the best paramters:\" +str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the training dataset\n",
    "yhatTrain = model.predict(X_train)\n",
    "contTrain = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(y_train),1) :\n",
    "    if (yhatTrain[i] == y_train[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(X_test)\n",
    "contTest = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(y_test),1) :\n",
    "    if (yhatTest[i] == y_test[i]):\n",
    "        contTest = contTest + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training dataset:0.5\n",
      "Final accuracy on the testing dataset: 0.4827586206896552\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy on the training dataset:' + str(contTrain/len(y_train)))\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Training)------------------\n",
      "[[78  6 21]\n",
      " [33  8 13]\n",
      " [41  2 30]]\n",
      "Input data:  [2 0 1 2 0 2 1 2 2 1 1 0 1 0 2 2 2 2 1 2 1 2 1 0 0 2 1 1 0 0 0 2 0 0 1 2 2\n",
      " 2 0 0 2 0 2 2 0 2 1 2 0 0 2 0 2 0 0 0 0 0 1 0 2 1 2 0 2 0 2 2 2 2 2 2 0 2\n",
      " 1 2 0 0 0 0 2 0 0 2 2 2 0 0 1 1 1 2 2 1 1 2 0 0 0 0 2 2 1 0 0 0 1 1 2 2 2\n",
      " 2 0 0 2 0 0 0 0 2 0 1 2 1 2 2 0 1 0 0 0 0 0 0 0 1 0 2 2 1 0 0 0 0 2 2 2 0\n",
      " 1 1 0 2 0 2 2 2 0 0 0 0 1 1 2 0 2 0 0 1 0 0 0 1 2 0 2 1 2 0 2 0 0 0 1 2 1\n",
      " 1 0 1 0 1 1 1 0 0 2 1 0 2 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 2 1 1\n",
      " 0 2 0 0 2 0 1 1 0 0]\n",
      "Prediction:        [0 0 2 0 0 2 1 0 0 0 2 0 0 2 0 0 2 2 0 2 0 2 1 2 0 0 0 2 0 2 1 2 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 2 0 2 2 0 0 0 0 2 1 0 0 2 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 2\n",
      " 0 0 0 0 0 2 2 0 2 0 0 2 0 0 0 2 0 0 0 1 0 1 2 0 0 1 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 0 0 2 0 0 0 0 0 0 2 2 0 2 0 2 1 0 0 0 0 0 2 2 1 2 2 1 0 2 0 0 2 0 0 0 0\n",
      " 0 1 0 2 2 0 0 2 2 0 1 0 0 0 0 0 0 0 0 2 2 0 0 0 2 0 2 0 0 0 2 0 0 0 2 2 0\n",
      " 0 0 0 2 0 0 0 0 0 2 2 0 2 1 0 0 0 0 1 2 0 2 0 0 0 0 0 0 0 0 0 0 0 2 2 1 2\n",
      " 0 2 0 0 2 0 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Confusion Matrix (Training)------------------')\n",
    "print(confusion_matrix(y_train,yhatTrain))\n",
    "print('Input data:  ' + str(np.array(y_train)))\n",
    "print('Prediction:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.74      0.61       105\n",
      "           1       0.50      0.15      0.23        54\n",
      "           2       0.47      0.41      0.44        73\n",
      "\n",
      "    accuracy                           0.50       232\n",
      "   macro avg       0.49      0.43      0.42       232\n",
      "weighted avg       0.50      0.50      0.47       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[20  3  2]\n",
      " [13  0  2]\n",
      " [ 8  2  8]]\n",
      "Input data:  [2 2 1 2 0 1 1 2 2 2 0 0 2 0 1 0 0 2 0 2 2 0 2 2 1 0 0 1 1 0 0 2 1 0 0 0 1\n",
      " 1 1 1 2 2 0 1 0 0 0 0 1 0 2 0 2 1 0 2 0 0]\n",
      "Prediction:        [2 2 2 0 0 0 0 0 2 2 0 0 2 0 0 0 1 0 0 2 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 2 2 2 0 0 0 0 2 0 1 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(y_test,yhatTest))\n",
    "print('Input data:  ' + str(np.array(y_test)))\n",
    "print('Prediction:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.80      0.61        25\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.48        58\n",
      "   macro avg       0.38      0.41      0.38        58\n",
      "weighted avg       0.42      0.48      0.43        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhatTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Everolimus test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../../../Data_preprocessing/Testing with everolimus/Clinical_data_categorized_everolimus.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "Y = [] # Target column\n",
    "# For each entry I classified it by its PFS value.\n",
    "for i in range (len(data)):\n",
    "    if data.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
    "        Y.append(0)\n",
    "    elif data.PFS[i]<6:\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
    "data=data.drop(['Unnamed: 0', 'PFS', 'RNA_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the testing dataset: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(data)\n",
    "contTest = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(Y),1) :\n",
    "    if (yhatTest[i] == Y[i]):\n",
    "        contTest = contTest + 1\n",
    "\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[44  2 19]\n",
      " [55 12 36]\n",
      " [ 0  0  0]]\n",
      "Input data:  [1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1\n",
      " 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 0]\n",
      "Prediction:        [0 2 2 1 2 0 0 2 0 0 0 0 0 0 0 0 0 1 0 2 0 2 0 0 0 2 0 0 2 2 2 2 0 0 0 2 1\n",
      " 0 2 0 0 0 0 0 0 0 0 0 2 0 0 2 2 2 0 1 2 1 0 0 2 2 2 1 2 2 0 2 0 2 0 2 1 0\n",
      " 0 0 1 0 0 2 0 2 2 2 0 0 0 2 2 0 0 2 1 2 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 2\n",
      " 0 0 2 2 2 0 0 0 2 0 0 2 1 0 2 2 2 2 0 0 0 2 2 0 0 0 2 0 0 0 0 2 2 0 2 0 1\n",
      " 0 0 1 0 0 0 0 1 0 2 0 2 0 2 0 2 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.68      0.54        65\n",
      "           1       0.86      0.12      0.21       103\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33       168\n",
      "   macro avg       0.43      0.26      0.25       168\n",
      "weighted avg       0.70      0.33      0.33       168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sandr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sandr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(Y,yhatTest))\n",
    "print('Input data:  ' + str(np.array(Y)))\n",
    "print('Prediction:        ' +str(yhatTest))\n",
    "print(classification_report(Y,yhatTest))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "173607e09da2ffe2d433f1218cab6faa8c4cbe5c89eb01ef45bf4a279737dd84"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
