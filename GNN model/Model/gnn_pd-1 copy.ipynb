{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# # !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "# !pip install -q captum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gene matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACPP</th>\n",
       "      <th>FOLH1</th>\n",
       "      <th>FRAT1</th>\n",
       "      <th>FRAT2</th>\n",
       "      <th>ICOS</th>\n",
       "      <th>ICOSLG</th>\n",
       "      <th>ITK</th>\n",
       "      <th>MTCP1</th>\n",
       "      <th>NFATC1</th>\n",
       "      <th>NFATC2</th>\n",
       "      <th>...</th>\n",
       "      <th>TCF7L1</th>\n",
       "      <th>TCIRG1</th>\n",
       "      <th>TCL1A</th>\n",
       "      <th>TCL1B</th>\n",
       "      <th>TLX1</th>\n",
       "      <th>TLX2</th>\n",
       "      <th>TLX3</th>\n",
       "      <th>WT1</th>\n",
       "      <th>WTAP</th>\n",
       "      <th>WTIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.643264</td>\n",
       "      <td>33.06366</td>\n",
       "      <td>22.86623</td>\n",
       "      <td>25.14807</td>\n",
       "      <td>23.66478</td>\n",
       "      <td>31.25529</td>\n",
       "      <td>31.97483</td>\n",
       "      <td>32.68788</td>\n",
       "      <td>32.00358</td>\n",
       "      <td>31.98820</td>\n",
       "      <td>...</td>\n",
       "      <td>29.73447</td>\n",
       "      <td>33.92966</td>\n",
       "      <td>21.65301</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>25.58066</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>27.25894</td>\n",
       "      <td>32.30986</td>\n",
       "      <td>30.89343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.478681</td>\n",
       "      <td>33.34812</td>\n",
       "      <td>27.58122</td>\n",
       "      <td>27.19051</td>\n",
       "      <td>27.81065</td>\n",
       "      <td>29.88798</td>\n",
       "      <td>32.85944</td>\n",
       "      <td>34.62906</td>\n",
       "      <td>30.96356</td>\n",
       "      <td>31.94520</td>\n",
       "      <td>...</td>\n",
       "      <td>31.39434</td>\n",
       "      <td>33.85213</td>\n",
       "      <td>21.65301</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>24.61959</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>22.90940</td>\n",
       "      <td>33.64920</td>\n",
       "      <td>32.19936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.556110</td>\n",
       "      <td>32.20052</td>\n",
       "      <td>25.38929</td>\n",
       "      <td>26.69664</td>\n",
       "      <td>26.66294</td>\n",
       "      <td>30.92857</td>\n",
       "      <td>31.09956</td>\n",
       "      <td>33.46376</td>\n",
       "      <td>31.30038</td>\n",
       "      <td>31.04482</td>\n",
       "      <td>...</td>\n",
       "      <td>30.94080</td>\n",
       "      <td>33.53312</td>\n",
       "      <td>26.38498</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>22.90940</td>\n",
       "      <td>35.26323</td>\n",
       "      <td>29.13798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.253267</td>\n",
       "      <td>34.48359</td>\n",
       "      <td>28.10294</td>\n",
       "      <td>26.49687</td>\n",
       "      <td>23.66478</td>\n",
       "      <td>29.47329</td>\n",
       "      <td>31.18813</td>\n",
       "      <td>33.10176</td>\n",
       "      <td>31.65882</td>\n",
       "      <td>32.62476</td>\n",
       "      <td>...</td>\n",
       "      <td>31.69465</td>\n",
       "      <td>32.51771</td>\n",
       "      <td>24.98799</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>26.34435</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>30.72576</td>\n",
       "      <td>33.85052</td>\n",
       "      <td>32.61099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.643264</td>\n",
       "      <td>34.68356</td>\n",
       "      <td>27.09929</td>\n",
       "      <td>22.82728</td>\n",
       "      <td>23.66478</td>\n",
       "      <td>32.22363</td>\n",
       "      <td>33.25193</td>\n",
       "      <td>32.65197</td>\n",
       "      <td>32.94580</td>\n",
       "      <td>33.70037</td>\n",
       "      <td>...</td>\n",
       "      <td>30.41687</td>\n",
       "      <td>33.75841</td>\n",
       "      <td>21.65301</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>31.55831</td>\n",
       "      <td>33.25769</td>\n",
       "      <td>29.29437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>29.643765</td>\n",
       "      <td>33.58120</td>\n",
       "      <td>26.78622</td>\n",
       "      <td>27.10293</td>\n",
       "      <td>22.97275</td>\n",
       "      <td>30.82689</td>\n",
       "      <td>26.57659</td>\n",
       "      <td>33.91039</td>\n",
       "      <td>31.93211</td>\n",
       "      <td>31.61476</td>\n",
       "      <td>...</td>\n",
       "      <td>31.55301</td>\n",
       "      <td>32.80839</td>\n",
       "      <td>20.32437</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>21.18281</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>33.76553</td>\n",
       "      <td>32.92597</td>\n",
       "      <td>33.36054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>32.256558</td>\n",
       "      <td>31.42896</td>\n",
       "      <td>21.76825</td>\n",
       "      <td>26.01421</td>\n",
       "      <td>29.53775</td>\n",
       "      <td>27.72514</td>\n",
       "      <td>30.11127</td>\n",
       "      <td>34.06419</td>\n",
       "      <td>29.13034</td>\n",
       "      <td>29.95589</td>\n",
       "      <td>...</td>\n",
       "      <td>27.36919</td>\n",
       "      <td>33.87425</td>\n",
       "      <td>25.58961</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>21.18281</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>29.72826</td>\n",
       "      <td>35.27110</td>\n",
       "      <td>27.34363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>26.275234</td>\n",
       "      <td>34.13379</td>\n",
       "      <td>26.74567</td>\n",
       "      <td>26.15839</td>\n",
       "      <td>28.98194</td>\n",
       "      <td>31.82216</td>\n",
       "      <td>33.03207</td>\n",
       "      <td>32.87564</td>\n",
       "      <td>32.10593</td>\n",
       "      <td>32.57213</td>\n",
       "      <td>...</td>\n",
       "      <td>31.82891</td>\n",
       "      <td>33.58358</td>\n",
       "      <td>20.32437</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>26.68332</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>24.56089</td>\n",
       "      <td>33.08478</td>\n",
       "      <td>32.23764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>31.822287</td>\n",
       "      <td>32.24862</td>\n",
       "      <td>25.46541</td>\n",
       "      <td>22.81349</td>\n",
       "      <td>27.50438</td>\n",
       "      <td>31.74571</td>\n",
       "      <td>31.83385</td>\n",
       "      <td>33.71362</td>\n",
       "      <td>31.09448</td>\n",
       "      <td>32.49485</td>\n",
       "      <td>...</td>\n",
       "      <td>30.01069</td>\n",
       "      <td>34.20252</td>\n",
       "      <td>20.32437</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>21.18281</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>29.86003</td>\n",
       "      <td>32.15581</td>\n",
       "      <td>32.35205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>32.443022</td>\n",
       "      <td>26.45839</td>\n",
       "      <td>26.21286</td>\n",
       "      <td>26.00386</td>\n",
       "      <td>29.33309</td>\n",
       "      <td>29.34334</td>\n",
       "      <td>32.18353</td>\n",
       "      <td>32.85734</td>\n",
       "      <td>30.93542</td>\n",
       "      <td>30.80994</td>\n",
       "      <td>...</td>\n",
       "      <td>30.86975</td>\n",
       "      <td>35.10128</td>\n",
       "      <td>26.59326</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>27.56092</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>34.54019</td>\n",
       "      <td>32.88606</td>\n",
       "      <td>27.34363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACPP     FOLH1     FRAT1     FRAT2      ICOS    ICOSLG       ITK  \\\n",
       "0    24.643264  33.06366  22.86623  25.14807  23.66478  31.25529  31.97483   \n",
       "1    30.478681  33.34812  27.58122  27.19051  27.81065  29.88798  32.85944   \n",
       "2    30.556110  32.20052  25.38929  26.69664  26.66294  30.92857  31.09956   \n",
       "3    30.253267  34.48359  28.10294  26.49687  23.66478  29.47329  31.18813   \n",
       "4    24.643264  34.68356  27.09929  22.82728  23.66478  32.22363  33.25193   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "176  29.643765  33.58120  26.78622  27.10293  22.97275  30.82689  26.57659   \n",
       "177  32.256558  31.42896  21.76825  26.01421  29.53775  27.72514  30.11127   \n",
       "178  26.275234  34.13379  26.74567  26.15839  28.98194  31.82216  33.03207   \n",
       "179  31.822287  32.24862  25.46541  22.81349  27.50438  31.74571  31.83385   \n",
       "180  32.443022  26.45839  26.21286  26.00386  29.33309  29.34334  32.18353   \n",
       "\n",
       "        MTCP1    NFATC1    NFATC2  ...    TCF7L1    TCIRG1     TCL1A  \\\n",
       "0    32.68788  32.00358  31.98820  ...  29.73447  33.92966  21.65301   \n",
       "1    34.62906  30.96356  31.94520  ...  31.39434  33.85213  21.65301   \n",
       "2    33.46376  31.30038  31.04482  ...  30.94080  33.53312  26.38498   \n",
       "3    33.10176  31.65882  32.62476  ...  31.69465  32.51771  24.98799   \n",
       "4    32.65197  32.94580  33.70037  ...  30.41687  33.75841  21.65301   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  33.91039  31.93211  31.61476  ...  31.55301  32.80839  20.32437   \n",
       "177  34.06419  29.13034  29.95589  ...  27.36919  33.87425  25.58961   \n",
       "178  32.87564  32.10593  32.57213  ...  31.82891  33.58358  20.32437   \n",
       "179  33.71362  31.09448  32.49485  ...  30.01069  34.20252  20.32437   \n",
       "180  32.85734  30.93542  30.80994  ...  30.86975  35.10128  26.59326   \n",
       "\n",
       "        TCL1B      TLX1      TLX2      TLX3       WT1      WTAP      WTIP  \n",
       "0    21.31325  25.58066  21.09375  21.21067  27.25894  32.30986  30.89343  \n",
       "1    21.31325  21.06706  24.61959  21.21067  22.90940  33.64920  32.19936  \n",
       "2    21.31325  21.06706  21.09375  21.21067  22.90940  35.26323  29.13798  \n",
       "3    21.31325  21.06706  26.34435  21.21067  30.72576  33.85052  32.61099  \n",
       "4    21.31325  21.06706  21.09375  21.21067  31.55831  33.25769  29.29437  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "176  21.31293  21.09326  21.18281  21.37595  33.76553  32.92597  33.36054  \n",
       "177  21.31293  21.09326  21.18281  21.37595  29.72826  35.27110  27.34363  \n",
       "178  21.31293  21.09326  26.68332  21.37595  24.56089  33.08478  32.23764  \n",
       "179  21.31293  21.09326  21.18281  21.37595  29.86003  32.15581  32.35205  \n",
       "180  21.31293  21.09326  27.56092  21.37595  34.54019  32.88606  27.34363  \n",
       "\n",
       "[181 rows x 38 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = pd.read_csv('../Data/Programmed cell death protein/Programmed_cell_death_protein_matrix.csv')\n",
    "Y = genes.Y\n",
    "\n",
    "genes = genes.iloc[:,1:39] \n",
    "genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../Data/Programmed cell death protein/network_edges_pd-1.tsv'\n",
    "data = pd.read_csv(path, delimiter='\\t')\n",
    "edge_index1=data['#node1'].to_numpy()\n",
    "edge_index2=data['node2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(edge_index1)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = le.transform(edge_index1)\n",
    "edge_index2 = le.transform(edge_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [edge_index1]+[edge_index2]\n",
    "edge_index = np.array(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  5,  5,  1,  1,  2,  3,  4,  4,  4,  4,  6,  7,  7,  8,\n",
       "         8,  8,  8,  9,  9,  9,  9, 10, 11, 11, 11, 12, 12, 13, 13, 13,\n",
       "        14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17,\n",
       "        17, 18, 18, 19, 20, 21, 22, 22, 22, 22, 22, 22, 23, 23, 24, 24,\n",
       "        25, 25, 25, 25, 26, 26, 27, 27, 27, 28, 29, 30, 30, 31, 31, 32,\n",
       "        32, 32, 33, 34, 34, 35, 35, 35, 36, 37],\n",
       "       [22, 19,  4, 17, 24, 22,  3,  2, 18,  6, 17,  5,  4, 31, 30, 29,\n",
       "        11, 17,  9, 11, 10, 12,  8,  9, 12,  8,  9, 11,  9, 16, 14, 15,\n",
       "        22, 13, 15, 16, 22, 13, 14, 16, 22, 13, 14, 15,  4,  8, 27,  5,\n",
       "        18,  4, 17,  0, 21, 20,  1, 24, 15, 14,  0, 16, 25, 27,  1, 22,\n",
       "        33, 23, 34, 32, 34, 32, 28, 17, 23, 27,  8, 31,  7,  7, 30, 25,\n",
       "        35, 26, 25, 25, 26, 32, 37, 36, 35, 35]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  5,  5,  1,  1,  2,  3,  4,  4,  4,  4,  6,  7,  7,  8,  8,  8,\n",
       "          8,  9,  9,  9,  9, 10, 11, 11, 11, 12, 12, 13, 13, 13, 14, 14, 14, 14,\n",
       "         15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18, 19, 20, 21,\n",
       "         22, 22, 22, 22, 22, 22, 23, 23, 24, 24, 25, 25, 25, 25, 26, 26, 27, 27,\n",
       "         27, 28, 29, 30, 30, 31, 31, 32, 32, 32, 33, 34, 34, 35, 35, 35, 36, 37],\n",
       "        [22, 19,  4, 17, 24, 22,  3,  2, 18,  6, 17,  5,  4, 31, 30, 29, 11, 17,\n",
       "          9, 11, 10, 12,  8,  9, 12,  8,  9, 11,  9, 16, 14, 15, 22, 13, 15, 16,\n",
       "         22, 13, 14, 16, 22, 13, 14, 15,  4,  8, 27,  5, 18,  4, 17,  0, 21, 20,\n",
       "          1, 24, 15, 14,  0, 16, 25, 27,  1, 22, 33, 23, 34, 32, 34, 32, 28, 17,\n",
       "         23, 27,  8, 31,  7,  7, 30, 25, 35, 26, 25, 25, 26, 32, 37, 36, 35, 35]])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[38], edge_index=[2, 90], y=[1, 1])\n"
     ]
    }
   ],
   "source": [
    "list_data_0=[]\n",
    "list_data_1=[]\n",
    "\n",
    "for g in range(len(genes)):\n",
    "  b=[]\n",
    "  for i in genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    a.append(i*10)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.float).reshape([-1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y.iloc[g]], dtype=torch.float).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  if y == 0:\n",
    "    list_data_0.append(data)\n",
    "  else:\n",
    "    list_data_1.append(data)\n",
    "\n",
    "print(list_data_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Patient sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 38\n",
      "Number of charcateristics per node: 1\n",
      "Number of edges: 90\n",
      "Average node degree: 2.37\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "data = list_data_0[0]\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of charcateristics per node: {data.num_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 153\n",
      "Number of test graphs: 28\n",
      "Negative cases from train: 72 of 153 = 0.47058823529411764\n",
      "Negative cases from test: 13 of 28 = 0.4642857142857143\n",
      "It should be 46.9\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(125)\n",
    "random.shuffle(list_data_0)\n",
    "random.shuffle(list_data_1)\n",
    "\n",
    "train_dataset = list_data_0[0:72]\n",
    "test_dataset = list_data_0[72:86]\n",
    "train_dataset = train_dataset + list_data_1[0:81]\n",
    "test_dataset = test_dataset + list_data_1[81:97]\n",
    "random.shuffle(train_dataset)\n",
    "random.shuffle(test_dataset)\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "cont = 0\n",
    "cont1=0\n",
    "for i in train_dataset:\n",
    "    if i.y == 0:\n",
    "        cont+=1\n",
    "for i in test_dataset:\n",
    "    if i.y == 0:\n",
    "        cont1+=1\n",
    "print(\"Negative cases from train: \" + str(cont) + \" of \" + str(len(train_dataset)) + \" = \" + str(cont/len(train_dataset)))\n",
    "print(\"Negative cases from test: \" + str(cont1) + \" of \" + str(len(test_dataset)) + \" = \" + str(cont1/len(test_dataset)))\n",
    "print(\"It should be 46.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# random.shuffle(list_data)\n",
    "# train_dataset = list_data[0:124]\n",
    "# test_dataset = list_data[124:182]\n",
    "# print(f'Number of training graphs: {len(train_dataset)}')\n",
    "# print(f'Number of test graphs: {len(test_dataset)}')\n",
    "# cont = 0\n",
    "# cont1=0\n",
    "# for i in train_dataset:\n",
    "#     if i.y == 0:\n",
    "#         cont+=1\n",
    "# for i in test_dataset:\n",
    "#     if i.y == 0:\n",
    "#         cont1+=1\n",
    "# print(\"Negative cases from train: \" + str(cont) + \" of \" + str(len(train_dataset)) + \" = \" + str(cont/len(train_dataset)))\n",
    "# print(\"Negative cases from test: \" + str(cont1) + \" of \" + str(len(test_dataset)) + \" = \" + str(cont1/len(test_dataset)))\n",
    "# print(\"It should be 46.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[1216], edge_index=[2, 2880], y=[32, 1], batch=[1216], ptr=[33])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[1216], edge_index=[2, 2880], y=[32, 1], batch=[1216], ptr=[33])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[1216], edge_index=[2, 2880], y=[32, 1], batch=[1216], ptr=[33])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(x=[1216], edge_index=[2, 2880], y=[32, 1], batch=[1216], ptr=[33])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 25\n",
      "DataBatch(x=[950], edge_index=[2, 2250], y=[25, 1], batch=[950], ptr=[26])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv, global_add_pool\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch import nn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 38\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dim = dim\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GraphConv(embed_dim, dim)\n",
    "        self.pool1 = TopKPooling(dim, ratio=0.8)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.pool2 = TopKPooling(dim, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=368, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(38, 19)\n",
    "        self.lin3 = torch.nn.Linear(19, 1)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        print(self)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = torch.tensor(x).to(torch.int)\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # x = F.relu(self.conv2(x, edge_index))\n",
    "        # x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        # x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 #+ x2\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(output, data.y.squeeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        for i in range(len(output)):\n",
    "            if output[i]>0.5:\n",
    "                output[i]=1\n",
    "            else:\n",
    "                output[i]=0\n",
    "            if output[i]==data.y[i]:\n",
    "                correct=correct+1\n",
    "    # print(\"Correct: \"+str(correct) +\" of \"+str(len(loader.dataset)))\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GraphConv(38, 19)\n",
      "  (pool1): TopKPooling(19, ratio=0.8, multiplier=1.0)\n",
      "  (conv2): GraphConv(19, 19)\n",
      "  (pool2): TopKPooling(19, ratio=0.8, multiplier=1.0)\n",
      "  (item_embedding): Embedding(368, 38)\n",
      "  (lin1): Linear(in_features=38, out_features=19, bias=True)\n",
      "  (lin3): Linear(in_features=19, out_features=1, bias=True)\n",
      "  (act1): ReLU()\n",
      ")\n",
      "Epoch: 001, Loss: 0.6933, Train Acc: 0.5294, Test Acc: 0.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_4644/3374044401.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(torch.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.6894, Train Acc: 0.5294, Test Acc: 0.5357\n",
      "Epoch: 003, Loss: 0.6816, Train Acc: 0.5294, Test Acc: 0.5357\n",
      "Epoch: 004, Loss: 0.6763, Train Acc: 0.5359, Test Acc: 0.5357\n",
      "Epoch: 005, Loss: 0.6819, Train Acc: 0.5359, Test Acc: 0.5357\n",
      "Epoch: 006, Loss: 0.6770, Train Acc: 0.5359, Test Acc: 0.5357\n",
      "Epoch: 007, Loss: 0.6783, Train Acc: 0.5359, Test Acc: 0.5357\n",
      "Epoch: 008, Loss: 0.6668, Train Acc: 0.5425, Test Acc: 0.5357\n",
      "Epoch: 009, Loss: 0.6589, Train Acc: 0.5621, Test Acc: 0.5357\n",
      "Epoch: 010, Loss: 0.6510, Train Acc: 0.6078, Test Acc: 0.5714\n",
      "Epoch: 011, Loss: 0.6613, Train Acc: 0.6928, Test Acc: 0.6429\n",
      "Epoch: 012, Loss: 0.6559, Train Acc: 0.7386, Test Acc: 0.6786\n",
      "Epoch: 013, Loss: 0.6353, Train Acc: 0.7451, Test Acc: 0.6786\n",
      "Epoch: 014, Loss: 0.6299, Train Acc: 0.7451, Test Acc: 0.7143\n",
      "Epoch: 015, Loss: 0.6123, Train Acc: 0.7778, Test Acc: 0.7143\n",
      "Epoch: 016, Loss: 0.6253, Train Acc: 0.7908, Test Acc: 0.7857\n",
      "Epoch: 017, Loss: 0.5949, Train Acc: 0.8105, Test Acc: 0.7500\n",
      "Epoch: 018, Loss: 0.5789, Train Acc: 0.8170, Test Acc: 0.7143\n",
      "Epoch: 019, Loss: 0.5869, Train Acc: 0.8235, Test Acc: 0.7500\n",
      "Epoch: 020, Loss: 0.5531, Train Acc: 0.8497, Test Acc: 0.8214\n",
      "Epoch: 021, Loss: 0.5469, Train Acc: 0.8627, Test Acc: 0.8214\n",
      "Epoch: 022, Loss: 0.5516, Train Acc: 0.8693, Test Acc: 0.8214\n",
      "Epoch: 023, Loss: 0.5351, Train Acc: 0.8758, Test Acc: 0.8214\n",
      "Epoch: 024, Loss: 0.5184, Train Acc: 0.9020, Test Acc: 0.8214\n",
      "Epoch: 025, Loss: 0.4848, Train Acc: 0.9150, Test Acc: 0.8214\n",
      "Epoch: 026, Loss: 0.4549, Train Acc: 0.9281, Test Acc: 0.8214\n",
      "Epoch: 027, Loss: 0.4549, Train Acc: 0.9346, Test Acc: 0.7857\n",
      "Epoch: 028, Loss: 0.4296, Train Acc: 0.9477, Test Acc: 0.7857\n",
      "Epoch: 029, Loss: 0.4070, Train Acc: 0.9477, Test Acc: 0.7857\n",
      "Epoch: 030, Loss: 0.3995, Train Acc: 0.9608, Test Acc: 0.7143\n",
      "Epoch: 031, Loss: 0.3773, Train Acc: 0.9608, Test Acc: 0.7857\n",
      "Epoch: 032, Loss: 0.3529, Train Acc: 0.9542, Test Acc: 0.7857\n",
      "Epoch: 033, Loss: 0.3385, Train Acc: 0.9739, Test Acc: 0.7500\n",
      "Epoch: 034, Loss: 0.2908, Train Acc: 0.9804, Test Acc: 0.7500\n",
      "Epoch: 035, Loss: 0.2928, Train Acc: 0.9869, Test Acc: 0.7500\n",
      "Epoch: 036, Loss: 0.2812, Train Acc: 0.9869, Test Acc: 0.7500\n",
      "Epoch: 037, Loss: 0.2462, Train Acc: 0.9869, Test Acc: 0.7500\n",
      "Epoch: 038, Loss: 0.2661, Train Acc: 0.9869, Test Acc: 0.7500\n",
      "Epoch: 039, Loss: 0.2108, Train Acc: 0.9869, Test Acc: 0.7500\n",
      "Epoch: 040, Loss: 0.1963, Train Acc: 0.9869, Test Acc: 0.7857\n",
      "Epoch: 041, Loss: 0.1995, Train Acc: 0.9935, Test Acc: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2007f4ab130>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = Net(dim=19)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_epoch=[]\n",
    "test_epoch=[]\n",
    "epoch = 1\n",
    "train_acc=0\n",
    "while train_acc < 0.99 and epoch < 100:\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_epoch.append(train_acc)\n",
    "    test_epoch.append(test_acc)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "          f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    epoch +=1\n",
    "\n",
    "plt.plot(train_epoch, color=\"red\", label='Train')\n",
    "plt.plot(test_epoch, color=\"blue\", label = 'Test')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
