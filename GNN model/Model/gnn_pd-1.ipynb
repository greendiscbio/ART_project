{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cpu\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\sandr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\sandr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.6.15)\n",
      "Requirement already satisfied: scipy in c:\\users\\sandr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch-sparse) (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\sandr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scipy->torch-sparse) (1.21.2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gene matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACPP</th>\n",
       "      <th>FOLH1</th>\n",
       "      <th>FRAT1</th>\n",
       "      <th>FRAT2</th>\n",
       "      <th>ICOS</th>\n",
       "      <th>ICOSLG</th>\n",
       "      <th>ITK</th>\n",
       "      <th>MTCP1</th>\n",
       "      <th>NFATC1</th>\n",
       "      <th>NFATC2</th>\n",
       "      <th>...</th>\n",
       "      <th>TCIRG1</th>\n",
       "      <th>TCL1A</th>\n",
       "      <th>TCL1B</th>\n",
       "      <th>TLX1</th>\n",
       "      <th>TLX2</th>\n",
       "      <th>TLX3</th>\n",
       "      <th>WT1</th>\n",
       "      <th>WTAP</th>\n",
       "      <th>WTIP</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.643264</td>\n",
       "      <td>33.06366</td>\n",
       "      <td>22.86623</td>\n",
       "      <td>25.14807</td>\n",
       "      <td>23.66478</td>\n",
       "      <td>31.25529</td>\n",
       "      <td>31.97483</td>\n",
       "      <td>32.68788</td>\n",
       "      <td>32.00358</td>\n",
       "      <td>31.98820</td>\n",
       "      <td>...</td>\n",
       "      <td>33.92966</td>\n",
       "      <td>21.65301</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>25.58066</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>27.25894</td>\n",
       "      <td>32.30986</td>\n",
       "      <td>30.89343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.478681</td>\n",
       "      <td>33.34812</td>\n",
       "      <td>27.58122</td>\n",
       "      <td>27.19051</td>\n",
       "      <td>27.81065</td>\n",
       "      <td>29.88798</td>\n",
       "      <td>32.85944</td>\n",
       "      <td>34.62906</td>\n",
       "      <td>30.96356</td>\n",
       "      <td>31.94520</td>\n",
       "      <td>...</td>\n",
       "      <td>33.85213</td>\n",
       "      <td>21.65301</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>24.61959</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>22.90940</td>\n",
       "      <td>33.64920</td>\n",
       "      <td>32.19936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.556110</td>\n",
       "      <td>32.20052</td>\n",
       "      <td>25.38929</td>\n",
       "      <td>26.69664</td>\n",
       "      <td>26.66294</td>\n",
       "      <td>30.92857</td>\n",
       "      <td>31.09956</td>\n",
       "      <td>33.46376</td>\n",
       "      <td>31.30038</td>\n",
       "      <td>31.04482</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53312</td>\n",
       "      <td>26.38498</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>22.90940</td>\n",
       "      <td>35.26323</td>\n",
       "      <td>29.13798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.253267</td>\n",
       "      <td>34.48359</td>\n",
       "      <td>28.10294</td>\n",
       "      <td>26.49687</td>\n",
       "      <td>23.66478</td>\n",
       "      <td>29.47329</td>\n",
       "      <td>31.18813</td>\n",
       "      <td>33.10176</td>\n",
       "      <td>31.65882</td>\n",
       "      <td>32.62476</td>\n",
       "      <td>...</td>\n",
       "      <td>32.51771</td>\n",
       "      <td>24.98799</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>26.34435</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>30.72576</td>\n",
       "      <td>33.85052</td>\n",
       "      <td>32.61099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.643264</td>\n",
       "      <td>34.68356</td>\n",
       "      <td>27.09929</td>\n",
       "      <td>22.82728</td>\n",
       "      <td>23.66478</td>\n",
       "      <td>32.22363</td>\n",
       "      <td>33.25193</td>\n",
       "      <td>32.65197</td>\n",
       "      <td>32.94580</td>\n",
       "      <td>33.70037</td>\n",
       "      <td>...</td>\n",
       "      <td>33.75841</td>\n",
       "      <td>21.65301</td>\n",
       "      <td>21.31325</td>\n",
       "      <td>21.06706</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>21.21067</td>\n",
       "      <td>31.55831</td>\n",
       "      <td>33.25769</td>\n",
       "      <td>29.29437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>29.643765</td>\n",
       "      <td>33.58120</td>\n",
       "      <td>26.78622</td>\n",
       "      <td>27.10293</td>\n",
       "      <td>22.97275</td>\n",
       "      <td>30.82689</td>\n",
       "      <td>26.57659</td>\n",
       "      <td>33.91039</td>\n",
       "      <td>31.93211</td>\n",
       "      <td>31.61476</td>\n",
       "      <td>...</td>\n",
       "      <td>32.80839</td>\n",
       "      <td>20.32437</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>21.18281</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>33.76553</td>\n",
       "      <td>32.92597</td>\n",
       "      <td>33.36054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>32.256558</td>\n",
       "      <td>31.42896</td>\n",
       "      <td>21.76825</td>\n",
       "      <td>26.01421</td>\n",
       "      <td>29.53775</td>\n",
       "      <td>27.72514</td>\n",
       "      <td>30.11127</td>\n",
       "      <td>34.06419</td>\n",
       "      <td>29.13034</td>\n",
       "      <td>29.95589</td>\n",
       "      <td>...</td>\n",
       "      <td>33.87425</td>\n",
       "      <td>25.58961</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>21.18281</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>29.72826</td>\n",
       "      <td>35.27110</td>\n",
       "      <td>27.34363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>26.275234</td>\n",
       "      <td>34.13379</td>\n",
       "      <td>26.74567</td>\n",
       "      <td>26.15839</td>\n",
       "      <td>28.98194</td>\n",
       "      <td>31.82216</td>\n",
       "      <td>33.03207</td>\n",
       "      <td>32.87564</td>\n",
       "      <td>32.10593</td>\n",
       "      <td>32.57213</td>\n",
       "      <td>...</td>\n",
       "      <td>33.58358</td>\n",
       "      <td>20.32437</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>26.68332</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>24.56089</td>\n",
       "      <td>33.08478</td>\n",
       "      <td>32.23764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>31.822287</td>\n",
       "      <td>32.24862</td>\n",
       "      <td>25.46541</td>\n",
       "      <td>22.81349</td>\n",
       "      <td>27.50438</td>\n",
       "      <td>31.74571</td>\n",
       "      <td>31.83385</td>\n",
       "      <td>33.71362</td>\n",
       "      <td>31.09448</td>\n",
       "      <td>32.49485</td>\n",
       "      <td>...</td>\n",
       "      <td>34.20252</td>\n",
       "      <td>20.32437</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>21.18281</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>29.86003</td>\n",
       "      <td>32.15581</td>\n",
       "      <td>32.35205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>32.443022</td>\n",
       "      <td>26.45839</td>\n",
       "      <td>26.21286</td>\n",
       "      <td>26.00386</td>\n",
       "      <td>29.33309</td>\n",
       "      <td>29.34334</td>\n",
       "      <td>32.18353</td>\n",
       "      <td>32.85734</td>\n",
       "      <td>30.93542</td>\n",
       "      <td>30.80994</td>\n",
       "      <td>...</td>\n",
       "      <td>35.10128</td>\n",
       "      <td>26.59326</td>\n",
       "      <td>21.31293</td>\n",
       "      <td>21.09326</td>\n",
       "      <td>27.56092</td>\n",
       "      <td>21.37595</td>\n",
       "      <td>34.54019</td>\n",
       "      <td>32.88606</td>\n",
       "      <td>27.34363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACPP     FOLH1     FRAT1     FRAT2      ICOS    ICOSLG       ITK  \\\n",
       "0    24.643264  33.06366  22.86623  25.14807  23.66478  31.25529  31.97483   \n",
       "1    30.478681  33.34812  27.58122  27.19051  27.81065  29.88798  32.85944   \n",
       "2    30.556110  32.20052  25.38929  26.69664  26.66294  30.92857  31.09956   \n",
       "3    30.253267  34.48359  28.10294  26.49687  23.66478  29.47329  31.18813   \n",
       "4    24.643264  34.68356  27.09929  22.82728  23.66478  32.22363  33.25193   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "176  29.643765  33.58120  26.78622  27.10293  22.97275  30.82689  26.57659   \n",
       "177  32.256558  31.42896  21.76825  26.01421  29.53775  27.72514  30.11127   \n",
       "178  26.275234  34.13379  26.74567  26.15839  28.98194  31.82216  33.03207   \n",
       "179  31.822287  32.24862  25.46541  22.81349  27.50438  31.74571  31.83385   \n",
       "180  32.443022  26.45839  26.21286  26.00386  29.33309  29.34334  32.18353   \n",
       "\n",
       "        MTCP1    NFATC1    NFATC2  ...    TCIRG1     TCL1A     TCL1B  \\\n",
       "0    32.68788  32.00358  31.98820  ...  33.92966  21.65301  21.31325   \n",
       "1    34.62906  30.96356  31.94520  ...  33.85213  21.65301  21.31325   \n",
       "2    33.46376  31.30038  31.04482  ...  33.53312  26.38498  21.31325   \n",
       "3    33.10176  31.65882  32.62476  ...  32.51771  24.98799  21.31325   \n",
       "4    32.65197  32.94580  33.70037  ...  33.75841  21.65301  21.31325   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  33.91039  31.93211  31.61476  ...  32.80839  20.32437  21.31293   \n",
       "177  34.06419  29.13034  29.95589  ...  33.87425  25.58961  21.31293   \n",
       "178  32.87564  32.10593  32.57213  ...  33.58358  20.32437  21.31293   \n",
       "179  33.71362  31.09448  32.49485  ...  34.20252  20.32437  21.31293   \n",
       "180  32.85734  30.93542  30.80994  ...  35.10128  26.59326  21.31293   \n",
       "\n",
       "         TLX1      TLX2      TLX3       WT1      WTAP      WTIP  Y  \n",
       "0    25.58066  21.09375  21.21067  27.25894  32.30986  30.89343  1  \n",
       "1    21.06706  24.61959  21.21067  22.90940  33.64920  32.19936  1  \n",
       "2    21.06706  21.09375  21.21067  22.90940  35.26323  29.13798  1  \n",
       "3    21.06706  26.34435  21.21067  30.72576  33.85052  32.61099  0  \n",
       "4    21.06706  21.09375  21.21067  31.55831  33.25769  29.29437  1  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "176  21.09326  21.18281  21.37595  33.76553  32.92597  33.36054  0  \n",
       "177  21.09326  21.18281  21.37595  29.72826  35.27110  27.34363  0  \n",
       "178  21.09326  26.68332  21.37595  24.56089  33.08478  32.23764  1  \n",
       "179  21.09326  21.18281  21.37595  29.86003  32.15581  32.35205  0  \n",
       "180  21.09326  27.56092  21.37595  34.54019  32.88606  27.34363  0  \n",
       "\n",
       "[181 rows x 39 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = pd.read_csv('../Data/Programmed cell death protein/Programmed_cell_death_protein_matrix.csv')\n",
    "Y = genes.Y\n",
    "\n",
    "genes = genes.iloc[:,1:40] \n",
    "genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../Data/Programmed cell death protein/network_edges_pd-1.tsv'\n",
    "data = pd.read_csv(path, delimiter='\\t')\n",
    "edge_index1=data['#node1'].to_numpy()\n",
    "edge_index2=data['node2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(edge_index1)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = le.transform(edge_index1)\n",
    "edge_index2 = le.transform(edge_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [edge_index1]+[edge_index2]\n",
    "edge_index = np.array(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  5,  5,  1,  1,  2,  3,  4,  4,  4,  4,  6,  7,  7,  8,\n",
       "         8,  8,  8,  9,  9,  9,  9, 10, 11, 11, 11, 12, 12, 13, 13, 13,\n",
       "        14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17,\n",
       "        17, 18, 18, 19, 20, 21, 22, 22, 22, 22, 22, 22, 23, 23, 24, 24,\n",
       "        25, 25, 25, 25, 26, 26, 27, 27, 27, 28, 29, 30, 30, 31, 31, 32,\n",
       "        32, 32, 33, 34, 34, 35, 35, 35, 36, 37],\n",
       "       [22, 19,  4, 17, 24, 22,  3,  2, 18,  6, 17,  5,  4, 31, 30, 29,\n",
       "        11, 17,  9, 11, 10, 12,  8,  9, 12,  8,  9, 11,  9, 16, 14, 15,\n",
       "        22, 13, 15, 16, 22, 13, 14, 16, 22, 13, 14, 15,  4,  8, 27,  5,\n",
       "        18,  4, 17,  0, 21, 20,  1, 24, 15, 14,  0, 16, 25, 27,  1, 22,\n",
       "        33, 23, 34, 32, 34, 32, 28, 17, 23, 27,  8, 31,  7,  7, 30, 25,\n",
       "        35, 26, 25, 25, 26, 32, 37, 36, 35, 35]])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  5,  5,  1,  1,  2,  3,  4,  4,  4,  4,  6,  7,  7,  8,  8,  8,\n",
       "          8,  9,  9,  9,  9, 10, 11, 11, 11, 12, 12, 13, 13, 13, 14, 14, 14, 14,\n",
       "         15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17, 17, 18, 18, 19, 20, 21,\n",
       "         22, 22, 22, 22, 22, 22, 23, 23, 24, 24, 25, 25, 25, 25, 26, 26, 27, 27,\n",
       "         27, 28, 29, 30, 30, 31, 31, 32, 32, 32, 33, 34, 34, 35, 35, 35, 36, 37],\n",
       "        [22, 19,  4, 17, 24, 22,  3,  2, 18,  6, 17,  5,  4, 31, 30, 29, 11, 17,\n",
       "          9, 11, 10, 12,  8,  9, 12,  8,  9, 11,  9, 16, 14, 15, 22, 13, 15, 16,\n",
       "         22, 13, 14, 16, 22, 13, 14, 15,  4,  8, 27,  5, 18,  4, 17,  0, 21, 20,\n",
       "          1, 24, 15, 14,  0, 16, 25, 27,  1, 22, 33, 23, 34, 32, 34, 32, 28, 17,\n",
       "         23, 27,  8, 31,  7,  7, 30, 25, 35, 26, 25, 25, 26, 32, 37, 36, 35, 35]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[39], edge_index=[2, 90], y=[1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_20544/3352282437.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor([b], dtype=torch.long).reshape([-1])\n"
     ]
    }
   ],
   "source": [
    "list_data=[]\n",
    "\n",
    "for g in range(len(genes)):\n",
    "  b=[]\n",
    "  for i in genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    a.append(i)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.long).reshape([-1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y.iloc[g]], dtype=torch.float).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  list_data.append(data)\n",
    "\n",
    "print(list_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Patient sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 39\n",
      "Number of charcateristics per node: 1\n",
      "Number of edges: 90\n",
      "Average node degree: 2.31\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "data = list_data[0]\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of charcateristics per node: {data.num_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 144\n",
      "Number of test graphs: 37\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "random.shuffle(list_data)\n",
    "train_dataset = list_data[0:144]\n",
    "test_dataset = list_data[144:182]\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2496], edge_index=[2, 5760], y=[64, 1], batch=[2496], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(x=[2496], edge_index=[2, 5760], y=[64, 1], batch=[2496], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 16\n",
      "DataBatch(x=[624], edge_index=[2, 1440], y=[16, 1], batch=[624], ptr=[17])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv, global_add_pool\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch import nn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 78\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dim = dim\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GraphConv(embed_dim, dim)\n",
    "        self.pool1 = TopKPooling(dim, ratio=0.8)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.pool2 = TopKPooling(dim, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=390, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(78, 39)\n",
    "        self.lin3 = torch.nn.Linear(39, 1)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        print(self)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = torch.tensor(x).to(torch.int)\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        # print(\"OUTPUT\")\n",
    "        # print(output)\n",
    "        loss = criterion(output, data.y.squeeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # print(loss.item())\n",
    "        # print(data.num_graphs)\n",
    "        # print(loss_all)\n",
    "        optimizer.step()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        for i in range(len(output)):\n",
    "            if output[i]>0.5:\n",
    "                output[i]=1\n",
    "            else:\n",
    "                output[i]=0\n",
    "            if output[i]==data.y[i]:\n",
    "                correct=correct+1\n",
    "    # print(\"Correct: \"+str(correct) +\" of \"+str(len(loader.dataset)))\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GraphConv(78, 39)\n",
      "  (pool1): TopKPooling(39, ratio=0.8, multiplier=1.0)\n",
      "  (conv2): GraphConv(39, 39)\n",
      "  (pool2): TopKPooling(39, ratio=0.8, multiplier=1.0)\n",
      "  (item_embedding): Embedding(390, 78)\n",
      "  (lin1): Linear(in_features=78, out_features=39, bias=True)\n",
      "  (lin3): Linear(in_features=39, out_features=1, bias=True)\n",
      "  (act1): ReLU()\n",
      ")\n",
      "Epoch: 001, Loss: 0.7137, Train Acc: 0.5625, Test Acc: 0.5405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_20544/2242749262.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(torch.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.6921, Train Acc: 0.5903, Test Acc: 0.4865\n",
      "Epoch: 003, Loss: 0.6804, Train Acc: 0.5833, Test Acc: 0.5135\n",
      "Epoch: 004, Loss: 0.6635, Train Acc: 0.5417, Test Acc: 0.5135\n",
      "Epoch: 005, Loss: 0.6640, Train Acc: 0.5903, Test Acc: 0.5135\n",
      "Epoch: 006, Loss: 0.6717, Train Acc: 0.6181, Test Acc: 0.5676\n",
      "Epoch: 007, Loss: 0.6630, Train Acc: 0.6389, Test Acc: 0.5135\n",
      "Epoch: 008, Loss: 0.6442, Train Acc: 0.6944, Test Acc: 0.5405\n",
      "Epoch: 009, Loss: 0.6379, Train Acc: 0.6806, Test Acc: 0.5405\n",
      "Epoch: 010, Loss: 0.6227, Train Acc: 0.7292, Test Acc: 0.5946\n",
      "Epoch: 011, Loss: 0.5996, Train Acc: 0.7778, Test Acc: 0.6757\n",
      "Epoch: 012, Loss: 0.5674, Train Acc: 0.8125, Test Acc: 0.6757\n",
      "Epoch: 013, Loss: 0.5443, Train Acc: 0.8542, Test Acc: 0.7027\n",
      "Epoch: 014, Loss: 0.5261, Train Acc: 0.8750, Test Acc: 0.7838\n",
      "Epoch: 015, Loss: 0.4686, Train Acc: 0.9097, Test Acc: 0.7838\n",
      "Epoch: 016, Loss: 0.4432, Train Acc: 0.9375, Test Acc: 0.7568\n",
      "Epoch: 017, Loss: 0.3973, Train Acc: 0.9653, Test Acc: 0.8378\n",
      "Epoch: 018, Loss: 0.3602, Train Acc: 0.9861, Test Acc: 0.8108\n",
      "Epoch: 019, Loss: 0.3182, Train Acc: 0.9931, Test Acc: 0.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c1ed2bea90>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model = Net(dim=39)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_epoch=[]\n",
    "test_epoch=[]\n",
    "epoch = 1\n",
    "train_acc=0\n",
    "while train_acc < 0.99 and epoch < 100:\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    train_epoch.append(train_acc)\n",
    "    test_epoch.append(test_acc)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "          f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    epoch +=1\n",
    "\n",
    "plt.plot(train_epoch, color=\"red\", label='Train')\n",
    "plt.plot(test_epoch, color=\"blue\", label = 'Test')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
