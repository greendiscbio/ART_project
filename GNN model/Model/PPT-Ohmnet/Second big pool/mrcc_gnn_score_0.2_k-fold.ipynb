{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gene matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANXA1</th>\n",
       "      <th>ANXA2</th>\n",
       "      <th>APAF1</th>\n",
       "      <th>ARID1A</th>\n",
       "      <th>ATM</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>CASP2</th>\n",
       "      <th>CDKN2A</th>\n",
       "      <th>CRADD</th>\n",
       "      <th>CRYAB</th>\n",
       "      <th>...</th>\n",
       "      <th>RNF139</th>\n",
       "      <th>SETD2</th>\n",
       "      <th>SLC2A1</th>\n",
       "      <th>SOD2</th>\n",
       "      <th>TGM2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>TSC1</th>\n",
       "      <th>TSC2</th>\n",
       "      <th>VEGFA</th>\n",
       "      <th>VHL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.868001</td>\n",
       "      <td>37.396638</td>\n",
       "      <td>32.668769</td>\n",
       "      <td>33.848026</td>\n",
       "      <td>35.942429</td>\n",
       "      <td>33.677294</td>\n",
       "      <td>33.689015</td>\n",
       "      <td>33.329382</td>\n",
       "      <td>34.20040</td>\n",
       "      <td>39.95791</td>\n",
       "      <td>...</td>\n",
       "      <td>32.46554</td>\n",
       "      <td>32.58565</td>\n",
       "      <td>33.38586</td>\n",
       "      <td>38.67433</td>\n",
       "      <td>38.50142</td>\n",
       "      <td>33.83518</td>\n",
       "      <td>32.93402</td>\n",
       "      <td>34.93520</td>\n",
       "      <td>37.79678</td>\n",
       "      <td>32.30615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.085434</td>\n",
       "      <td>36.570671</td>\n",
       "      <td>32.337493</td>\n",
       "      <td>33.843513</td>\n",
       "      <td>35.988225</td>\n",
       "      <td>32.643149</td>\n",
       "      <td>33.946812</td>\n",
       "      <td>32.503791</td>\n",
       "      <td>33.33414</td>\n",
       "      <td>39.76850</td>\n",
       "      <td>...</td>\n",
       "      <td>32.27190</td>\n",
       "      <td>33.19915</td>\n",
       "      <td>33.69538</td>\n",
       "      <td>38.64559</td>\n",
       "      <td>34.33752</td>\n",
       "      <td>34.44810</td>\n",
       "      <td>33.16630</td>\n",
       "      <td>35.08304</td>\n",
       "      <td>40.09193</td>\n",
       "      <td>32.19988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.908372</td>\n",
       "      <td>38.443020</td>\n",
       "      <td>31.818198</td>\n",
       "      <td>33.516005</td>\n",
       "      <td>36.193587</td>\n",
       "      <td>32.368866</td>\n",
       "      <td>33.752815</td>\n",
       "      <td>32.561812</td>\n",
       "      <td>31.15063</td>\n",
       "      <td>40.93124</td>\n",
       "      <td>...</td>\n",
       "      <td>32.55514</td>\n",
       "      <td>32.84628</td>\n",
       "      <td>36.23588</td>\n",
       "      <td>40.50559</td>\n",
       "      <td>35.50178</td>\n",
       "      <td>35.41980</td>\n",
       "      <td>33.63282</td>\n",
       "      <td>34.79244</td>\n",
       "      <td>38.22308</td>\n",
       "      <td>31.49147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.290124</td>\n",
       "      <td>37.244829</td>\n",
       "      <td>32.601293</td>\n",
       "      <td>34.197698</td>\n",
       "      <td>36.578348</td>\n",
       "      <td>31.895400</td>\n",
       "      <td>34.064332</td>\n",
       "      <td>30.368889</td>\n",
       "      <td>32.93107</td>\n",
       "      <td>40.02236</td>\n",
       "      <td>...</td>\n",
       "      <td>33.19823</td>\n",
       "      <td>33.68316</td>\n",
       "      <td>34.41938</td>\n",
       "      <td>38.99231</td>\n",
       "      <td>35.77236</td>\n",
       "      <td>34.18862</td>\n",
       "      <td>32.88250</td>\n",
       "      <td>35.02014</td>\n",
       "      <td>39.94908</td>\n",
       "      <td>32.11538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.863272</td>\n",
       "      <td>36.871693</td>\n",
       "      <td>33.593121</td>\n",
       "      <td>33.351460</td>\n",
       "      <td>36.807497</td>\n",
       "      <td>33.968348</td>\n",
       "      <td>33.501184</td>\n",
       "      <td>24.501619</td>\n",
       "      <td>33.49363</td>\n",
       "      <td>38.83921</td>\n",
       "      <td>...</td>\n",
       "      <td>30.89813</td>\n",
       "      <td>34.63036</td>\n",
       "      <td>34.59911</td>\n",
       "      <td>38.41437</td>\n",
       "      <td>33.47112</td>\n",
       "      <td>34.91241</td>\n",
       "      <td>33.44515</td>\n",
       "      <td>35.01310</td>\n",
       "      <td>39.31564</td>\n",
       "      <td>33.33646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>35.985233</td>\n",
       "      <td>37.436964</td>\n",
       "      <td>32.603769</td>\n",
       "      <td>34.133940</td>\n",
       "      <td>35.318612</td>\n",
       "      <td>33.843872</td>\n",
       "      <td>33.840555</td>\n",
       "      <td>31.982007</td>\n",
       "      <td>31.12858</td>\n",
       "      <td>37.79607</td>\n",
       "      <td>...</td>\n",
       "      <td>32.12573</td>\n",
       "      <td>33.34867</td>\n",
       "      <td>36.50807</td>\n",
       "      <td>35.15898</td>\n",
       "      <td>34.57504</td>\n",
       "      <td>35.39631</td>\n",
       "      <td>32.93248</td>\n",
       "      <td>35.12781</td>\n",
       "      <td>40.48054</td>\n",
       "      <td>31.79913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>37.586062</td>\n",
       "      <td>37.635004</td>\n",
       "      <td>33.619701</td>\n",
       "      <td>32.373330</td>\n",
       "      <td>35.771711</td>\n",
       "      <td>32.519967</td>\n",
       "      <td>31.854546</td>\n",
       "      <td>34.088487</td>\n",
       "      <td>34.93690</td>\n",
       "      <td>40.18790</td>\n",
       "      <td>...</td>\n",
       "      <td>34.27276</td>\n",
       "      <td>32.16275</td>\n",
       "      <td>33.97705</td>\n",
       "      <td>38.85295</td>\n",
       "      <td>32.38354</td>\n",
       "      <td>32.04003</td>\n",
       "      <td>32.62658</td>\n",
       "      <td>33.78873</td>\n",
       "      <td>37.41392</td>\n",
       "      <td>31.66344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>36.111194</td>\n",
       "      <td>37.953757</td>\n",
       "      <td>33.316811</td>\n",
       "      <td>34.118843</td>\n",
       "      <td>36.008091</td>\n",
       "      <td>33.115209</td>\n",
       "      <td>33.551305</td>\n",
       "      <td>31.567085</td>\n",
       "      <td>32.89828</td>\n",
       "      <td>38.70298</td>\n",
       "      <td>...</td>\n",
       "      <td>32.92305</td>\n",
       "      <td>34.01015</td>\n",
       "      <td>34.85694</td>\n",
       "      <td>37.96021</td>\n",
       "      <td>36.65499</td>\n",
       "      <td>33.34126</td>\n",
       "      <td>32.81059</td>\n",
       "      <td>35.24316</td>\n",
       "      <td>38.72091</td>\n",
       "      <td>32.39461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>35.120811</td>\n",
       "      <td>35.957212</td>\n",
       "      <td>33.046782</td>\n",
       "      <td>33.833796</td>\n",
       "      <td>37.008936</td>\n",
       "      <td>32.895151</td>\n",
       "      <td>33.903126</td>\n",
       "      <td>29.930698</td>\n",
       "      <td>31.87461</td>\n",
       "      <td>38.81342</td>\n",
       "      <td>...</td>\n",
       "      <td>31.87160</td>\n",
       "      <td>33.23246</td>\n",
       "      <td>34.24055</td>\n",
       "      <td>37.24924</td>\n",
       "      <td>36.84744</td>\n",
       "      <td>34.98283</td>\n",
       "      <td>34.04810</td>\n",
       "      <td>35.60526</td>\n",
       "      <td>40.53108</td>\n",
       "      <td>32.34561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>34.648929</td>\n",
       "      <td>38.196845</td>\n",
       "      <td>32.170042</td>\n",
       "      <td>33.739764</td>\n",
       "      <td>35.937812</td>\n",
       "      <td>33.404526</td>\n",
       "      <td>34.798860</td>\n",
       "      <td>31.741651</td>\n",
       "      <td>31.85580</td>\n",
       "      <td>34.50354</td>\n",
       "      <td>...</td>\n",
       "      <td>32.47268</td>\n",
       "      <td>32.81781</td>\n",
       "      <td>35.99620</td>\n",
       "      <td>38.54211</td>\n",
       "      <td>37.23935</td>\n",
       "      <td>33.82151</td>\n",
       "      <td>33.82576</td>\n",
       "      <td>35.13995</td>\n",
       "      <td>40.81516</td>\n",
       "      <td>30.34566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ANXA1      ANXA2      APAF1     ARID1A        ATM       BAP1  \\\n",
       "0    33.868001  37.396638  32.668769  33.848026  35.942429  33.677294   \n",
       "1    35.085434  36.570671  32.337493  33.843513  35.988225  32.643149   \n",
       "2    34.908372  38.443020  31.818198  33.516005  36.193587  32.368866   \n",
       "3    36.290124  37.244829  32.601293  34.197698  36.578348  31.895400   \n",
       "4    36.863272  36.871693  33.593121  33.351460  36.807497  33.968348   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "176  35.985233  37.436964  32.603769  34.133940  35.318612  33.843872   \n",
       "177  37.586062  37.635004  33.619701  32.373330  35.771711  32.519967   \n",
       "178  36.111194  37.953757  33.316811  34.118843  36.008091  33.115209   \n",
       "179  35.120811  35.957212  33.046782  33.833796  37.008936  32.895151   \n",
       "180  34.648929  38.196845  32.170042  33.739764  35.937812  33.404526   \n",
       "\n",
       "         CASP2     CDKN2A     CRADD     CRYAB  ...    RNF139     SETD2  \\\n",
       "0    33.689015  33.329382  34.20040  39.95791  ...  32.46554  32.58565   \n",
       "1    33.946812  32.503791  33.33414  39.76850  ...  32.27190  33.19915   \n",
       "2    33.752815  32.561812  31.15063  40.93124  ...  32.55514  32.84628   \n",
       "3    34.064332  30.368889  32.93107  40.02236  ...  33.19823  33.68316   \n",
       "4    33.501184  24.501619  33.49363  38.83921  ...  30.89813  34.63036   \n",
       "..         ...        ...       ...       ...  ...       ...       ...   \n",
       "176  33.840555  31.982007  31.12858  37.79607  ...  32.12573  33.34867   \n",
       "177  31.854546  34.088487  34.93690  40.18790  ...  34.27276  32.16275   \n",
       "178  33.551305  31.567085  32.89828  38.70298  ...  32.92305  34.01015   \n",
       "179  33.903126  29.930698  31.87461  38.81342  ...  31.87160  33.23246   \n",
       "180  34.798860  31.741651  31.85580  34.50354  ...  32.47268  32.81781   \n",
       "\n",
       "       SLC2A1      SOD2      TGM2      TP53      TSC1      TSC2     VEGFA  \\\n",
       "0    33.38586  38.67433  38.50142  33.83518  32.93402  34.93520  37.79678   \n",
       "1    33.69538  38.64559  34.33752  34.44810  33.16630  35.08304  40.09193   \n",
       "2    36.23588  40.50559  35.50178  35.41980  33.63282  34.79244  38.22308   \n",
       "3    34.41938  38.99231  35.77236  34.18862  32.88250  35.02014  39.94908   \n",
       "4    34.59911  38.41437  33.47112  34.91241  33.44515  35.01310  39.31564   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  36.50807  35.15898  34.57504  35.39631  32.93248  35.12781  40.48054   \n",
       "177  33.97705  38.85295  32.38354  32.04003  32.62658  33.78873  37.41392   \n",
       "178  34.85694  37.96021  36.65499  33.34126  32.81059  35.24316  38.72091   \n",
       "179  34.24055  37.24924  36.84744  34.98283  34.04810  35.60526  40.53108   \n",
       "180  35.99620  38.54211  37.23935  33.82151  33.82576  35.13995  40.81516   \n",
       "\n",
       "          VHL  \n",
       "0    32.30615  \n",
       "1    32.19988  \n",
       "2    31.49147  \n",
       "3    32.11538  \n",
       "4    33.33646  \n",
       "..        ...  \n",
       "176  31.79913  \n",
       "177  31.66344  \n",
       "178  32.39461  \n",
       "179  32.34561  \n",
       "180  30.34566  \n",
       "\n",
       "[181 rows x 48 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = pd.read_csv('..\\..\\..\\Data\\PPT-Ohmnet\\mRCC_big_pool\\Second big pool/mrcc_protein_matrix_163_genes_48_nodes.csv')\n",
    "Y = genes.Y\n",
    "\n",
    "genes = genes.iloc[:,1:49] \n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANXA1</th>\n",
       "      <th>ANXA2</th>\n",
       "      <th>APAF1</th>\n",
       "      <th>ARID1A</th>\n",
       "      <th>ATM</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>CASP2</th>\n",
       "      <th>CDKN2A</th>\n",
       "      <th>CRADD</th>\n",
       "      <th>CRYAB</th>\n",
       "      <th>...</th>\n",
       "      <th>RNF139</th>\n",
       "      <th>SETD2</th>\n",
       "      <th>SLC2A1</th>\n",
       "      <th>SOD2</th>\n",
       "      <th>TGM2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>TSC1</th>\n",
       "      <th>TSC2</th>\n",
       "      <th>VEGFA</th>\n",
       "      <th>VHL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.275573</td>\n",
       "      <td>0.596683</td>\n",
       "      <td>0.610274</td>\n",
       "      <td>0.474298</td>\n",
       "      <td>0.551095</td>\n",
       "      <td>0.703386</td>\n",
       "      <td>0.622048</td>\n",
       "      <td>0.705692</td>\n",
       "      <td>0.846161</td>\n",
       "      <td>0.847331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547741</td>\n",
       "      <td>0.361620</td>\n",
       "      <td>0.420160</td>\n",
       "      <td>0.542412</td>\n",
       "      <td>0.945549</td>\n",
       "      <td>0.403803</td>\n",
       "      <td>0.411780</td>\n",
       "      <td>0.408244</td>\n",
       "      <td>0.439826</td>\n",
       "      <td>0.681580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512777</td>\n",
       "      <td>0.390935</td>\n",
       "      <td>0.536117</td>\n",
       "      <td>0.472846</td>\n",
       "      <td>0.561963</td>\n",
       "      <td>0.465055</td>\n",
       "      <td>0.669459</td>\n",
       "      <td>0.639694</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>0.824106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504091</td>\n",
       "      <td>0.518369</td>\n",
       "      <td>0.458930</td>\n",
       "      <td>0.538144</td>\n",
       "      <td>0.301997</td>\n",
       "      <td>0.538341</td>\n",
       "      <td>0.474109</td>\n",
       "      <td>0.451980</td>\n",
       "      <td>0.760074</td>\n",
       "      <td>0.664154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478279</td>\n",
       "      <td>0.857336</td>\n",
       "      <td>0.419872</td>\n",
       "      <td>0.367512</td>\n",
       "      <td>0.610698</td>\n",
       "      <td>0.401843</td>\n",
       "      <td>0.633782</td>\n",
       "      <td>0.644332</td>\n",
       "      <td>0.347778</td>\n",
       "      <td>0.966677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567938</td>\n",
       "      <td>0.428211</td>\n",
       "      <td>0.777154</td>\n",
       "      <td>0.814317</td>\n",
       "      <td>0.481939</td>\n",
       "      <td>0.751632</td>\n",
       "      <td>0.599295</td>\n",
       "      <td>0.366011</td>\n",
       "      <td>0.499309</td>\n",
       "      <td>0.547991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.747499</td>\n",
       "      <td>0.558867</td>\n",
       "      <td>0.595169</td>\n",
       "      <td>0.586761</td>\n",
       "      <td>0.702007</td>\n",
       "      <td>0.292727</td>\n",
       "      <td>0.691071</td>\n",
       "      <td>0.469030</td>\n",
       "      <td>0.638732</td>\n",
       "      <td>0.855233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712900</td>\n",
       "      <td>0.642034</td>\n",
       "      <td>0.549619</td>\n",
       "      <td>0.589625</td>\n",
       "      <td>0.523759</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.397955</td>\n",
       "      <td>0.433372</td>\n",
       "      <td>0.740142</td>\n",
       "      <td>0.650298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.859172</td>\n",
       "      <td>0.465919</td>\n",
       "      <td>0.817191</td>\n",
       "      <td>0.314590</td>\n",
       "      <td>0.756387</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.587505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730663</td>\n",
       "      <td>0.710160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194423</td>\n",
       "      <td>0.884044</td>\n",
       "      <td>0.572132</td>\n",
       "      <td>0.503813</td>\n",
       "      <td>0.168091</td>\n",
       "      <td>0.640258</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.651756</td>\n",
       "      <td>0.850528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.688094</td>\n",
       "      <td>0.606728</td>\n",
       "      <td>0.595723</td>\n",
       "      <td>0.566255</td>\n",
       "      <td>0.403055</td>\n",
       "      <td>0.741776</td>\n",
       "      <td>0.649917</td>\n",
       "      <td>0.597983</td>\n",
       "      <td>0.344175</td>\n",
       "      <td>0.582254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471142</td>\n",
       "      <td>0.556572</td>\n",
       "      <td>0.811248</td>\n",
       "      <td>0.020453</td>\n",
       "      <td>0.338707</td>\n",
       "      <td>0.746476</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.814298</td>\n",
       "      <td>0.598440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656060</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510581</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.284680</td>\n",
       "      <td>0.766375</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.875531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955115</td>\n",
       "      <td>0.253569</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.568933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.329281</td>\n",
       "      <td>0.069080</td>\n",
       "      <td>0.386405</td>\n",
       "      <td>0.576190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.712637</td>\n",
       "      <td>0.735461</td>\n",
       "      <td>0.755339</td>\n",
       "      <td>0.561399</td>\n",
       "      <td>0.566677</td>\n",
       "      <td>0.573847</td>\n",
       "      <td>0.596723</td>\n",
       "      <td>0.564814</td>\n",
       "      <td>0.633373</td>\n",
       "      <td>0.693456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650870</td>\n",
       "      <td>0.725580</td>\n",
       "      <td>0.604427</td>\n",
       "      <td>0.436379</td>\n",
       "      <td>0.660174</td>\n",
       "      <td>0.295386</td>\n",
       "      <td>0.378658</td>\n",
       "      <td>0.499349</td>\n",
       "      <td>0.568772</td>\n",
       "      <td>0.696085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.519670</td>\n",
       "      <td>0.238123</td>\n",
       "      <td>0.694893</td>\n",
       "      <td>0.469721</td>\n",
       "      <td>0.804191</td>\n",
       "      <td>0.523132</td>\n",
       "      <td>0.661425</td>\n",
       "      <td>0.434001</td>\n",
       "      <td>0.466089</td>\n",
       "      <td>0.706998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413858</td>\n",
       "      <td>0.526880</td>\n",
       "      <td>0.527218</td>\n",
       "      <td>0.330815</td>\n",
       "      <td>0.689918</td>\n",
       "      <td>0.655716</td>\n",
       "      <td>0.710731</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.821350</td>\n",
       "      <td>0.688050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.427729</td>\n",
       "      <td>0.796014</td>\n",
       "      <td>0.498633</td>\n",
       "      <td>0.439478</td>\n",
       "      <td>0.549999</td>\n",
       "      <td>0.640524</td>\n",
       "      <td>0.826155</td>\n",
       "      <td>0.578769</td>\n",
       "      <td>0.463015</td>\n",
       "      <td>0.178537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549350</td>\n",
       "      <td>0.420937</td>\n",
       "      <td>0.747131</td>\n",
       "      <td>0.522780</td>\n",
       "      <td>0.750490</td>\n",
       "      <td>0.400802</td>\n",
       "      <td>0.651068</td>\n",
       "      <td>0.468816</td>\n",
       "      <td>0.860988</td>\n",
       "      <td>0.360103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ANXA1     ANXA2     APAF1    ARID1A       ATM      BAP1     CASP2  \\\n",
       "0    0.275573  0.596683  0.610274  0.474298  0.551095  0.703386  0.622048   \n",
       "1    0.512777  0.390935  0.536117  0.472846  0.561963  0.465055  0.669459   \n",
       "2    0.478279  0.857336  0.419872  0.367512  0.610698  0.401843  0.633782   \n",
       "3    0.747499  0.558867  0.595169  0.586761  0.702007  0.292727  0.691071   \n",
       "4    0.859172  0.465919  0.817191  0.314590  0.756387  0.770463  0.587505   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  0.688094  0.606728  0.595723  0.566255  0.403055  0.741776  0.649917   \n",
       "177  1.000000  0.656060  0.823141  0.000000  0.510581  0.436667  0.284680   \n",
       "178  0.712637  0.735461  0.755339  0.561399  0.566677  0.573847  0.596723   \n",
       "179  0.519670  0.238123  0.694893  0.469721  0.804191  0.523132  0.661425   \n",
       "180  0.427729  0.796014  0.498633  0.439478  0.549999  0.640524  0.826155   \n",
       "\n",
       "       CDKN2A     CRADD     CRYAB  ...    RNF139     SETD2    SLC2A1  \\\n",
       "0    0.705692  0.846161  0.847331  ...  0.547741  0.361620  0.420160   \n",
       "1    0.639694  0.704600  0.824106  ...  0.504091  0.518369  0.458930   \n",
       "2    0.644332  0.347778  0.966677  ...  0.567938  0.428211  0.777154   \n",
       "3    0.469030  0.638732  0.855233  ...  0.712900  0.642034  0.549619   \n",
       "4    0.000000  0.730663  0.710160  ...  0.194423  0.884044  0.572132   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  0.597983  0.344175  0.582254  ...  0.471142  0.556572  0.811248   \n",
       "177  0.766375  0.966518  0.875531  ...  0.955115  0.253569  0.494212   \n",
       "178  0.564814  0.633373  0.693456  ...  0.650870  0.725580  0.604427   \n",
       "179  0.434001  0.466089  0.706998  ...  0.413858  0.526880  0.527218   \n",
       "180  0.578769  0.463015  0.178537  ...  0.549350  0.420937  0.747131   \n",
       "\n",
       "         SOD2      TGM2      TP53      TSC1      TSC2     VEGFA       VHL  \n",
       "0    0.542412  0.945549  0.403803  0.411780  0.408244  0.439826  0.681580  \n",
       "1    0.538144  0.301997  0.538341  0.474109  0.451980  0.760074  0.664154  \n",
       "2    0.814317  0.481939  0.751632  0.599295  0.366011  0.499309  0.547991  \n",
       "3    0.589625  0.523759  0.481384  0.397955  0.433372  0.740142  0.650298  \n",
       "4    0.503813  0.168091  0.640258  0.548936  0.431290  0.651756  0.850528  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "176  0.020453  0.338707  0.746476  0.411366  0.465225  0.814298  0.598440  \n",
       "177  0.568933  0.000000  0.009761  0.329281  0.069080  0.386405  0.576190  \n",
       "178  0.436379  0.660174  0.295386  0.378658  0.499349  0.568772  0.696085  \n",
       "179  0.330815  0.689918  0.655716  0.710731  0.606470  0.821350  0.688050  \n",
       "180  0.522780  0.750490  0.400802  0.651068  0.468816  0.860988  0.360103  \n",
       "\n",
       "[181 rows x 48 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = genes.columns\n",
    "d = scaler.fit_transform(genes)\n",
    "genes = pd.DataFrame(d, columns=names)\n",
    "genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../../../Data/PPT-Ohmnet/mRCC_big_pool/Second big pool/network_edges_mrcc_163_genes_48_nodes.tsv'\n",
    "data = pd.read_csv(path, delimiter='\\t')\n",
    "edge_index1=data[data.columns[1]].to_numpy()\n",
    "edge_index2=data[data.columns[2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = np.concatenate((edge_index1, edge_index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HSPD1', 'HSPD1', 'HSPD1', 'HSPD1', 'HSPD1', 'CRYAB', 'CRYAB',\n",
       "       'CRYAB', 'CRYAB', 'CRYAB', 'VHL', 'VHL', 'VHL', 'VHL', 'VHL',\n",
       "       'VHL', 'VHL', 'VHL', 'VHL', 'VHL', 'CDKN2A', 'CDKN2A', 'CDKN2A',\n",
       "       'CDKN2A', 'CDKN2A', 'GSTP1', 'GSTP1', 'MYC', 'MYC', 'MYC', 'MYC',\n",
       "       'MYC', 'MYC', 'TGM2', 'TGM2', 'TGM2', 'HNF1A', 'SETD2', 'ERBB2',\n",
       "       'ERBB2', 'ERBB2', 'FLT1', 'FLT1', 'FLT4', 'IGF1R', 'IGF1R',\n",
       "       'DNMT1', 'DNMT1', 'NDRG1', 'ERN1', 'CRADD', 'NF2', 'NF2', 'PIK3CA',\n",
       "       'MTOR', 'MTOR', 'ANXA1', 'ANXA1', 'ANXA1', 'ANXA2', 'ANXA2',\n",
       "       'LRRK2', 'APAF1', 'KDR', 'TSC1', 'RELA', 'RELA', 'RELA', 'RELA',\n",
       "       'ATM', 'MAPK8', 'PTEN', 'PTEN', 'ARID1A', 'PTGS1', 'PTGS2', 'IL6',\n",
       "       'HSPB1', 'HSPB1', 'TP53', 'HSPA9', 'HSPD1', 'LRRK2', 'HSPA9',\n",
       "       'MYC', 'ANXA1', 'PTEN', 'HSPB1', 'VEGFA', 'CRADD', 'TP53', 'CASP2',\n",
       "       'SLC2A1', 'RNF139', 'ANXA2', 'ATM', 'TGM2', 'TP53', 'SOD2',\n",
       "       'CDKN2A', 'MYC', 'EPAS1', 'RELA', 'MAPK8', 'HSPA9', 'TP53', 'MYC',\n",
       "       'TGM2', 'MAPK8', 'TP53', 'ANXA2', 'RELA', 'HSPB1', 'MAPK8',\n",
       "       'DNMT3A', 'RELA', 'ANXA1', 'PAK1', 'ANXA2', 'TP53', 'IGF1R', 'NF2',\n",
       "       'PAK1', 'VEGFA', 'KDR', 'KDR', 'BAP1', 'TP53', 'DNMT3A', 'TP53',\n",
       "       'TP53', 'TP53', 'CASP2', 'PAK1', 'TSC1', 'PTEN', 'TP53', 'MAPK8',\n",
       "       'ANXA2', 'HSPB1', 'RELA', 'TP53', 'PTEN', 'HSPA9', 'TP53', 'VEGFA',\n",
       "       'TSC2', 'IL6', 'TP53', 'ATM', 'HSPA9', 'TP53', 'TP53', 'TP53',\n",
       "       'BAP1', 'TP53', 'PTGS2', 'TP53', 'IL6R', 'TP53', 'HSPA9', 'HSPA9',\n",
       "       'BAP1', 'ANXA2'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(edge_index)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = le.transform(edge_index1)\n",
    "edge_index2 = le.transform(edge_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [edge_index1]+[edge_index2]\n",
    "edge_index = np.array(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 21, 21, 21, 21,  9,  9,  9,  9,  9, 47, 47, 47, 47, 47, 47,\n",
       "        47, 47, 47, 47,  7,  7,  7,  7,  7, 17, 17, 29, 29, 29, 29, 29,\n",
       "        29, 42, 42, 42, 18, 39, 13, 13, 13, 15, 15, 16, 22, 22, 10, 10,\n",
       "        30, 14,  8, 31, 31, 33, 28, 28,  0,  0,  0,  1,  1, 26,  2, 25,\n",
       "        44, 37, 37, 37, 37,  4, 27, 34, 34,  3, 35, 36, 23, 20, 20, 43,\n",
       "        19, 21],\n",
       "       [26, 19, 29,  0, 34, 20, 46,  8, 43,  6, 40, 38,  1,  4, 42, 43,\n",
       "        41,  7, 29, 12, 37, 27, 19, 43, 29, 42, 27, 43,  1, 37, 20, 27,\n",
       "        11, 37,  0, 32,  1, 43, 22, 31, 32, 46, 25, 25,  5, 43, 11, 43,\n",
       "        43, 43,  6, 32, 44, 34, 43, 27,  1, 20, 37, 43, 34, 19, 43, 46,\n",
       "        45, 23, 43,  4, 19, 43, 43, 43,  5, 43, 36, 43, 24, 43, 19, 19,\n",
       "         5,  1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 21, 21, 21, 21,  9,  9,  9,  9,  9, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "         47, 47,  7,  7,  7,  7,  7, 17, 17, 29, 29, 29, 29, 29, 29, 42, 42, 42,\n",
       "         18, 39, 13, 13, 13, 15, 15, 16, 22, 22, 10, 10, 30, 14,  8, 31, 31, 33,\n",
       "         28, 28,  0,  0,  0,  1,  1, 26,  2, 25, 44, 37, 37, 37, 37,  4, 27, 34,\n",
       "         34,  3, 35, 36, 23, 20, 20, 43, 19, 21],\n",
       "        [26, 19, 29,  0, 34, 20, 46,  8, 43,  6, 40, 38,  1,  4, 42, 43, 41,  7,\n",
       "         29, 12, 37, 27, 19, 43, 29, 42, 27, 43,  1, 37, 20, 27, 11, 37,  0, 32,\n",
       "          1, 43, 22, 31, 32, 46, 25, 25,  5, 43, 11, 43, 43, 43,  6, 32, 44, 34,\n",
       "         43, 27,  1, 20, 37, 43, 34, 19, 43, 46, 45, 23, 43,  4, 19, 43, 43, 43,\n",
       "          5, 43, 36, 43, 24, 43, 19, 19,  5,  1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[48], edge_index=[2, 82], y=[1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_8952/1747583445.py:11: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor([b], dtype=torch.long).reshape([-1])\n"
     ]
    }
   ],
   "source": [
    "list_data_0=[]\n",
    "list_data_1=[]\n",
    "total_data=[]\n",
    "for g in range(len(genes)):\n",
    "  b=[]\n",
    "  for i in genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    # a.append(Y[g])\n",
    "    a.append(i*100)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.long).reshape([-1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y.iloc[g]], dtype=torch.float).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  total_data.append(data)\n",
    "  if y == 0:\n",
    "    list_data_0.append(data)\n",
    "  else:\n",
    "    list_data_1.append(data)\n",
    "\n",
    "print(list_data_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Patient sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 48\n",
      "Number of charcateristics per node: 1\n",
      "Number of edges: 82\n",
      "Average node degree: 1.71\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "data = list_data_0[0]\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of charcateristics per node: {data.num_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 48\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dim = dim\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GraphConv(embed_dim, dim)\n",
    "        self.pool1 = SAGPooling(dim, ratio=0.5)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.pool2 = SAGPooling(dim, ratio=0.5)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=101, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(768, 50)\n",
    "        self.lin2 = torch.nn.Linear(500, 10)\n",
    "        self.lin3 = torch.nn.Linear(50, 1)\n",
    "        self.act1 = torch.nn.RReLU()\n",
    "        print(self)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = torch.tensor(x) #.to(torch.int)\n",
    "        # print(x.long())\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # x = F.relu(self.conv2(x, edge_index))\n",
    "        # x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        # x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 #+ x2\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        # x = self.lin2(x)\n",
    "        # x = self.act1(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(output, data.y.squeeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        for i in range(len(output)):\n",
    "            if output[i]>0.5:\n",
    "                output[i]=1\n",
    "            else:\n",
    "                output[i]=0\n",
    "            if output[i]==data.y[i]:\n",
    "                correct=correct+1\n",
    "    # print(\"Correct: \"+str(correct) +\" of \"+str(len(loader.dataset)))\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "kf=StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [ 30  32  33  34  40  41  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 35 36 37 38 39 42]\n",
      "144\n",
      "37\n",
      "Net(\n",
      "  (conv1): GraphConv(48, 384)\n",
      "  (pool1): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (conv2): GraphConv(384, 384)\n",
      "  (pool2): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 48)\n",
      "  (lin1): Linear(in_features=768, out_features=50, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_8952/308962947.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x) #.to(torch.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7204, Train Acc: 0.4722, Test Acc: 0.4595\n",
      "Epoch: 002, Loss: 0.6957, Train Acc: 0.5208, Test Acc: 0.5135\n",
      "Epoch: 003, Loss: 0.6858, Train Acc: 0.6458, Test Acc: 0.5676\n",
      "Epoch: 004, Loss: 0.6856, Train Acc: 0.6875, Test Acc: 0.5405\n",
      "Epoch: 005, Loss: 0.6770, Train Acc: 0.7014, Test Acc: 0.5135\n",
      "Epoch: 006, Loss: 0.6464, Train Acc: 0.4931, Test Acc: 0.4595\n",
      "Epoch: 007, Loss: 0.6702, Train Acc: 0.7083, Test Acc: 0.4865\n",
      "Epoch: 008, Loss: 0.6079, Train Acc: 0.6042, Test Acc: 0.5135\n",
      "Epoch: 009, Loss: 0.5866, Train Acc: 0.7708, Test Acc: 0.4595\n",
      "Epoch: 010, Loss: 0.5654, Train Acc: 0.7986, Test Acc: 0.4865\n",
      "Epoch: 011, Loss: 0.5318, Train Acc: 0.8194, Test Acc: 0.5135\n",
      "Epoch: 012, Loss: 0.5434, Train Acc: 0.7986, Test Acc: 0.5946\n",
      "Epoch: 013, Loss: 0.4595, Train Acc: 0.8333, Test Acc: 0.5135\n",
      "Epoch: 014, Loss: 0.4009, Train Acc: 0.6111, Test Acc: 0.4865\n",
      "Epoch: 015, Loss: 0.6993, Train Acc: 0.8403, Test Acc: 0.5405\n",
      "Epoch: 016, Loss: 0.3954, Train Acc: 0.8750, Test Acc: 0.5676\n",
      "Epoch: 017, Loss: 0.3130, Train Acc: 0.8819, Test Acc: 0.5405\n",
      "Epoch: 018, Loss: 0.3531, Train Acc: 0.8264, Test Acc: 0.5405\n",
      "Epoch: 019, Loss: 0.3861, Train Acc: 0.8958, Test Acc: 0.5676\n",
      "Epoch: 020, Loss: 0.3181, Train Acc: 0.9028, Test Acc: 0.5135\n",
      "Epoch: 021, Loss: 0.2758, Train Acc: 0.9236, Test Acc: 0.5135\n",
      "Epoch: 022, Loss: 0.2563, Train Acc: 0.9236, Test Acc: 0.5405\n",
      "Epoch: 023, Loss: 0.2335, Train Acc: 0.9306, Test Acc: 0.5135\n",
      "Epoch: 024, Loss: 0.2198, Train Acc: 0.9306, Test Acc: 0.4865\n",
      "Epoch: 025, Loss: 0.2137, Train Acc: 0.9306, Test Acc: 0.5135\n",
      "Epoch: 026, Loss: 0.2296, Train Acc: 0.9444, Test Acc: 0.5135\n",
      "Epoch: 027, Loss: 0.2264, Train Acc: 0.9306, Test Acc: 0.5405\n",
      "Epoch: 028, Loss: 0.2020, Train Acc: 0.9306, Test Acc: 0.5135\n",
      "Epoch: 029, Loss: 0.1998, Train Acc: 0.9306, Test Acc: 0.5135\n",
      "Epoch: 030, Loss: 0.2759, Train Acc: 0.7986, Test Acc: 0.4595\n",
      "Epoch: 031, Loss: 0.2881, Train Acc: 0.9444, Test Acc: 0.5405\n",
      "Epoch: 032, Loss: 0.1988, Train Acc: 0.9444, Test Acc: 0.5405\n",
      "Epoch: 033, Loss: 0.1797, Train Acc: 0.9444, Test Acc: 0.5676\n",
      "Epoch: 034, Loss: 0.1944, Train Acc: 0.9444, Test Acc: 0.5676\n",
      "Epoch: 035, Loss: 0.1747, Train Acc: 0.9514, Test Acc: 0.5135\n",
      "Epoch: 036, Loss: 0.1624, Train Acc: 0.9514, Test Acc: 0.5135\n",
      "Epoch: 037, Loss: 0.1640, Train Acc: 0.9514, Test Acc: 0.5135\n",
      "Epoch: 038, Loss: 0.2996, Train Acc: 0.9375, Test Acc: 0.5676\n",
      "Epoch: 039, Loss: 0.1992, Train Acc: 0.9375, Test Acc: 0.5405\n",
      "Epoch: 040, Loss: 0.1564, Train Acc: 0.9583, Test Acc: 0.5946\n",
      "Epoch: 041, Loss: 0.1441, Train Acc: 0.9583, Test Acc: 0.5946\n",
      "Epoch: 042, Loss: 0.1298, Train Acc: 0.9583, Test Acc: 0.5676\n",
      "Epoch: 043, Loss: 0.1476, Train Acc: 0.9583, Test Acc: 0.5405\n",
      "Epoch: 044, Loss: 0.1480, Train Acc: 0.9583, Test Acc: 0.5405\n",
      "Epoch: 045, Loss: 0.1240, Train Acc: 0.9583, Test Acc: 0.5135\n",
      "Epoch: 046, Loss: 0.1414, Train Acc: 0.9583, Test Acc: 0.5135\n",
      "Epoch: 047, Loss: 0.0969, Train Acc: 0.9653, Test Acc: 0.5135\n",
      "Epoch: 048, Loss: 0.1529, Train Acc: 0.9653, Test Acc: 0.5405\n",
      "Epoch: 049, Loss: 0.1129, Train Acc: 0.9653, Test Acc: 0.5405\n",
      "Epoch: 050, Loss: 0.0882, Train Acc: 0.9722, Test Acc: 0.5135\n",
      "Epoch: 051, Loss: 0.0985, Train Acc: 0.9722, Test Acc: 0.5135\n",
      "Epoch: 052, Loss: 0.1047, Train Acc: 0.9653, Test Acc: 0.5135\n",
      "Epoch: 053, Loss: 0.0978, Train Acc: 0.9653, Test Acc: 0.4865\n",
      "Epoch: 054, Loss: 0.0956, Train Acc: 0.9722, Test Acc: 0.5135\n",
      "Epoch: 055, Loss: 0.1039, Train Acc: 0.9653, Test Acc: 0.4865\n",
      "Epoch: 056, Loss: 0.1216, Train Acc: 0.9792, Test Acc: 0.4865\n",
      "Epoch: 057, Loss: 0.1235, Train Acc: 0.9861, Test Acc: 0.5676\n",
      "Epoch: 058, Loss: 0.0512, Train Acc: 0.9722, Test Acc: 0.5946\n",
      "Epoch: 059, Loss: 0.0615, Train Acc: 0.9792, Test Acc: 0.6216\n",
      "Epoch: 060, Loss: 0.0557, Train Acc: 0.9792, Test Acc: 0.6216\n",
      "Epoch: 061, Loss: 0.0559, Train Acc: 0.9792, Test Acc: 0.5946\n",
      "Epoch: 062, Loss: 0.0629, Train Acc: 0.9792, Test Acc: 0.6216\n",
      "Epoch: 063, Loss: 0.0579, Train Acc: 0.9792, Test Acc: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Loss: 0.0498, Train Acc: 0.9792, Test Acc: 0.6486\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  31  35  36  37  38  39\n",
      "  42  70  72  73  75  76  77  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180] TEST: [30 32 33 34 40 41 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\n",
      " 61 62 63 64 65 66 67 68 69 71 74 78]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(48, 384)\n",
      "  (pool1): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (conv2): GraphConv(384, 384)\n",
      "  (pool2): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 48)\n",
      "  (lin1): Linear(in_features=768, out_features=50, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 0.7411, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 002, Loss: 0.6931, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 003, Loss: 0.6916, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 004, Loss: 0.6857, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 005, Loss: 0.6814, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 006, Loss: 0.6685, Train Acc: 0.6138, Test Acc: 0.4444\n",
      "Epoch: 007, Loss: 0.6676, Train Acc: 0.6207, Test Acc: 0.4722\n",
      "Epoch: 008, Loss: 0.6659, Train Acc: 0.6345, Test Acc: 0.4444\n",
      "Epoch: 009, Loss: 0.6549, Train Acc: 0.6552, Test Acc: 0.4444\n",
      "Epoch: 010, Loss: 0.6364, Train Acc: 0.6345, Test Acc: 0.5000\n",
      "Epoch: 011, Loss: 0.6420, Train Acc: 0.6345, Test Acc: 0.5000\n",
      "Epoch: 012, Loss: 0.6074, Train Acc: 0.6828, Test Acc: 0.5556\n",
      "Epoch: 013, Loss: 0.5824, Train Acc: 0.7103, Test Acc: 0.5556\n",
      "Epoch: 014, Loss: 0.6439, Train Acc: 0.7310, Test Acc: 0.4722\n",
      "Epoch: 015, Loss: 0.7418, Train Acc: 0.6483, Test Acc: 0.5278\n",
      "Epoch: 016, Loss: 0.5668, Train Acc: 0.7862, Test Acc: 0.4444\n",
      "Epoch: 017, Loss: 0.4949, Train Acc: 0.8207, Test Acc: 0.4722\n",
      "Epoch: 018, Loss: 0.4761, Train Acc: 0.8552, Test Acc: 0.6111\n",
      "Epoch: 019, Loss: 0.5592, Train Acc: 0.6759, Test Acc: 0.5000\n",
      "Epoch: 020, Loss: 0.4943, Train Acc: 0.8345, Test Acc: 0.5833\n",
      "Epoch: 021, Loss: 0.4622, Train Acc: 0.8552, Test Acc: 0.5833\n",
      "Epoch: 022, Loss: 0.3944, Train Acc: 0.8897, Test Acc: 0.5556\n",
      "Epoch: 023, Loss: 0.3736, Train Acc: 0.8690, Test Acc: 0.5278\n",
      "Epoch: 024, Loss: 0.3820, Train Acc: 0.8759, Test Acc: 0.5556\n",
      "Epoch: 025, Loss: 0.3212, Train Acc: 0.9034, Test Acc: 0.5556\n",
      "Epoch: 026, Loss: 0.2924, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 027, Loss: 0.3010, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 028, Loss: 0.2670, Train Acc: 0.9241, Test Acc: 0.4722\n",
      "Epoch: 029, Loss: 0.2352, Train Acc: 0.9448, Test Acc: 0.5000\n",
      "Epoch: 030, Loss: 0.2412, Train Acc: 0.9517, Test Acc: 0.5278\n",
      "Epoch: 031, Loss: 0.2912, Train Acc: 0.9448, Test Acc: 0.5278\n",
      "Epoch: 032, Loss: 0.3900, Train Acc: 0.9241, Test Acc: 0.5556\n",
      "Epoch: 033, Loss: 0.2314, Train Acc: 0.9448, Test Acc: 0.4722\n",
      "Epoch: 034, Loss: 0.3118, Train Acc: 0.9310, Test Acc: 0.5556\n",
      "Epoch: 035, Loss: 0.2285, Train Acc: 0.9655, Test Acc: 0.5000\n",
      "Epoch: 036, Loss: 0.2271, Train Acc: 0.9379, Test Acc: 0.5000\n",
      "Epoch: 037, Loss: 0.4082, Train Acc: 0.9517, Test Acc: 0.5278\n",
      "Epoch: 038, Loss: 0.1609, Train Acc: 0.9655, Test Acc: 0.5000\n",
      "Epoch: 039, Loss: 0.1287, Train Acc: 0.9724, Test Acc: 0.5000\n",
      "Epoch: 040, Loss: 0.1315, Train Acc: 0.9724, Test Acc: 0.5000\n",
      "Epoch: 041, Loss: 0.0998, Train Acc: 0.9724, Test Acc: 0.5000\n",
      "Epoch: 042, Loss: 0.1189, Train Acc: 0.9724, Test Acc: 0.5278\n",
      "Epoch: 043, Loss: 0.1603, Train Acc: 0.9724, Test Acc: 0.6389\n",
      "Epoch: 044, Loss: 0.1005, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 045, Loss: 0.0720, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 046, Loss: 0.0691, Train Acc: 0.9793, Test Acc: 0.5833\n",
      "Epoch: 047, Loss: 0.0816, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 048, Loss: 0.0705, Train Acc: 0.9793, Test Acc: 0.5833\n",
      "Epoch: 049, Loss: 0.0848, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 050, Loss: 0.0682, Train Acc: 0.9793, Test Acc: 0.5833\n",
      "Epoch: 051, Loss: 0.0784, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 052, Loss: 0.0829, Train Acc: 0.9862, Test Acc: 0.5833\n",
      "Epoch: 053, Loss: 0.0473, Train Acc: 0.9931, Test Acc: 0.5833\n",
      "Epoch: 054, Loss: 0.9536, Train Acc: 0.7724, Test Acc: 0.5833\n",
      "Epoch: 055, Loss: 0.2472, Train Acc: 0.9793, Test Acc: 0.6389\n",
      "Epoch: 056, Loss: 0.0805, Train Acc: 0.9931, Test Acc: 0.5833\n",
      "Epoch: 057, Loss: 0.0517, Train Acc: 0.9931, Test Acc: 0.5833\n",
      "Epoch: 058, Loss: 0.0511, Train Acc: 0.9931, Test Acc: 0.6111\n",
      "Epoch: 059, Loss: 0.0418, Train Acc: 0.9931, Test Acc: 0.6111\n",
      "Epoch: 060, Loss: 0.0422, Train Acc: 0.9931, Test Acc: 0.6111\n",
      "Epoch: 061, Loss: 0.0556, Train Acc: 0.9931, Test Acc: 0.6111\n",
      "Epoch: 062, Loss: 0.0398, Train Acc: 0.9931, Test Acc: 0.5833\n",
      "Epoch: 063, Loss: 0.0395, Train Acc: 0.9931, Test Acc: 0.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Loss: 0.0355, Train Acc: 0.9931, Test Acc: 0.6111\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  71  74\n",
      "  78 107 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180] TEST: [ 70  72  73  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 108 109]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(48, 384)\n",
      "  (pool1): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (conv2): GraphConv(384, 384)\n",
      "  (pool2): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 48)\n",
      "  (lin1): Linear(in_features=768, out_features=50, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 0.9290, Train Acc: 0.5586, Test Acc: 0.5000\n",
      "Epoch: 002, Loss: 0.7029, Train Acc: 0.6000, Test Acc: 0.5278\n",
      "Epoch: 003, Loss: 0.6877, Train Acc: 0.6276, Test Acc: 0.4722\n",
      "Epoch: 004, Loss: 0.6803, Train Acc: 0.6483, Test Acc: 0.5000\n",
      "Epoch: 005, Loss: 0.6731, Train Acc: 0.6621, Test Acc: 0.4444\n",
      "Epoch: 006, Loss: 0.6616, Train Acc: 0.6483, Test Acc: 0.4444\n",
      "Epoch: 007, Loss: 0.6458, Train Acc: 0.6690, Test Acc: 0.4167\n",
      "Epoch: 008, Loss: 0.6387, Train Acc: 0.6690, Test Acc: 0.4167\n",
      "Epoch: 009, Loss: 0.6109, Train Acc: 0.6690, Test Acc: 0.4722\n",
      "Epoch: 010, Loss: 0.5744, Train Acc: 0.6414, Test Acc: 0.5278\n",
      "Epoch: 011, Loss: 0.6072, Train Acc: 0.7034, Test Acc: 0.4444\n",
      "Epoch: 012, Loss: 0.6008, Train Acc: 0.6690, Test Acc: 0.4722\n",
      "Epoch: 013, Loss: 0.5936, Train Acc: 0.6897, Test Acc: 0.4722\n",
      "Epoch: 014, Loss: 0.7251, Train Acc: 0.6966, Test Acc: 0.4722\n",
      "Epoch: 015, Loss: 0.5784, Train Acc: 0.7379, Test Acc: 0.4167\n",
      "Epoch: 016, Loss: 0.5525, Train Acc: 0.6690, Test Acc: 0.4444\n",
      "Epoch: 017, Loss: 0.5570, Train Acc: 0.7655, Test Acc: 0.4167\n",
      "Epoch: 018, Loss: 0.6063, Train Acc: 0.7310, Test Acc: 0.4722\n",
      "Epoch: 019, Loss: 0.5431, Train Acc: 0.7517, Test Acc: 0.4444\n",
      "Epoch: 020, Loss: 0.6106, Train Acc: 0.7655, Test Acc: 0.4444\n",
      "Epoch: 021, Loss: 0.4992, Train Acc: 0.8000, Test Acc: 0.4167\n",
      "Epoch: 022, Loss: 0.4725, Train Acc: 0.8069, Test Acc: 0.4722\n",
      "Epoch: 023, Loss: 0.4319, Train Acc: 0.5034, Test Acc: 0.5278\n",
      "Epoch: 024, Loss: 0.7180, Train Acc: 0.7655, Test Acc: 0.4722\n",
      "Epoch: 025, Loss: 0.4084, Train Acc: 0.7862, Test Acc: 0.5000\n",
      "Epoch: 026, Loss: 0.4915, Train Acc: 0.8621, Test Acc: 0.5000\n",
      "Epoch: 027, Loss: 0.4020, Train Acc: 0.8828, Test Acc: 0.5000\n",
      "Epoch: 028, Loss: 0.3309, Train Acc: 0.8897, Test Acc: 0.4444\n",
      "Epoch: 029, Loss: 0.3496, Train Acc: 0.8897, Test Acc: 0.4444\n",
      "Epoch: 030, Loss: 0.3030, Train Acc: 0.8621, Test Acc: 0.4444\n",
      "Epoch: 031, Loss: 0.3368, Train Acc: 0.8966, Test Acc: 0.4444\n",
      "Epoch: 032, Loss: 0.2992, Train Acc: 0.9034, Test Acc: 0.4444\n",
      "Epoch: 033, Loss: 0.2639, Train Acc: 0.8690, Test Acc: 0.4444\n",
      "Epoch: 034, Loss: 0.2724, Train Acc: 0.9310, Test Acc: 0.4167\n",
      "Epoch: 035, Loss: 0.2807, Train Acc: 0.8828, Test Acc: 0.4722\n",
      "Epoch: 036, Loss: 0.2443, Train Acc: 0.9310, Test Acc: 0.4444\n",
      "Epoch: 037, Loss: 0.2297, Train Acc: 0.9379, Test Acc: 0.3611\n",
      "Epoch: 038, Loss: 0.1763, Train Acc: 0.9517, Test Acc: 0.4167\n",
      "Epoch: 039, Loss: 0.1808, Train Acc: 0.9586, Test Acc: 0.4167\n",
      "Epoch: 040, Loss: 0.1633, Train Acc: 0.9586, Test Acc: 0.4167\n",
      "Epoch: 041, Loss: 0.1540, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 042, Loss: 0.1590, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 043, Loss: 0.1667, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 044, Loss: 0.1087, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 045, Loss: 0.1350, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 046, Loss: 0.1390, Train Acc: 0.9724, Test Acc: 0.4167\n",
      "Epoch: 047, Loss: 0.1225, Train Acc: 0.9379, Test Acc: 0.4167\n",
      "Epoch: 048, Loss: 0.1169, Train Acc: 0.9724, Test Acc: 0.4722\n",
      "Epoch: 049, Loss: 0.1063, Train Acc: 0.9724, Test Acc: 0.3889\n",
      "Epoch: 050, Loss: 0.1968, Train Acc: 0.9793, Test Acc: 0.3611\n",
      "Epoch: 051, Loss: 0.0806, Train Acc: 0.9793, Test Acc: 0.3611\n",
      "Epoch: 052, Loss: 0.0910, Train Acc: 0.9793, Test Acc: 0.3611\n",
      "Epoch: 053, Loss: 0.0816, Train Acc: 0.9793, Test Acc: 0.3611\n",
      "Epoch: 054, Loss: 0.0867, Train Acc: 0.9862, Test Acc: 0.3611\n",
      "Epoch: 055, Loss: 0.0577, Train Acc: 0.9862, Test Acc: 0.3611\n",
      "Epoch: 056, Loss: 0.0674, Train Acc: 0.9862, Test Acc: 0.3889\n",
      "Epoch: 057, Loss: 0.0469, Train Acc: 0.9862, Test Acc: 0.3889\n",
      "Epoch: 058, Loss: 0.0552, Train Acc: 0.9862, Test Acc: 0.3889\n",
      "Epoch: 059, Loss: 0.0963, Train Acc: 0.9793, Test Acc: 0.3611\n",
      "Epoch: 060, Loss: 0.1818, Train Acc: 0.9862, Test Acc: 0.3611\n",
      "Epoch: 061, Loss: 0.0564, Train Acc: 0.9862, Test Acc: 0.3333\n",
      "Epoch: 062, Loss: 0.0489, Train Acc: 0.9862, Test Acc: 0.3333\n",
      "Epoch: 063, Loss: 0.0458, Train Acc: 0.9862, Test Acc: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Loss: 0.0557, Train Acc: 0.9862, Test Acc: 0.3611\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 108\n",
      " 109 140 142 144 145 146 147 148 149 150 151 154 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180] TEST: [107 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 141 143 152 153 155]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(48, 384)\n",
      "  (pool1): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (conv2): GraphConv(384, 384)\n",
      "  (pool2): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 48)\n",
      "  (lin1): Linear(in_features=768, out_features=50, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 0.7634, Train Acc: 0.4897, Test Acc: 0.4722\n",
      "Epoch: 002, Loss: 0.6933, Train Acc: 0.5724, Test Acc: 0.5278\n",
      "Epoch: 003, Loss: 0.6850, Train Acc: 0.5931, Test Acc: 0.5000\n",
      "Epoch: 004, Loss: 0.6812, Train Acc: 0.6345, Test Acc: 0.5278\n",
      "Epoch: 005, Loss: 0.6606, Train Acc: 0.6828, Test Acc: 0.5278\n",
      "Epoch: 006, Loss: 0.6481, Train Acc: 0.7172, Test Acc: 0.5278\n",
      "Epoch: 007, Loss: 0.6471, Train Acc: 0.7172, Test Acc: 0.5000\n",
      "Epoch: 008, Loss: 0.6434, Train Acc: 0.7172, Test Acc: 0.5278\n",
      "Epoch: 009, Loss: 0.6013, Train Acc: 0.6897, Test Acc: 0.5278\n",
      "Epoch: 010, Loss: 0.5920, Train Acc: 0.7034, Test Acc: 0.5000\n",
      "Epoch: 011, Loss: 0.6488, Train Acc: 0.7379, Test Acc: 0.5278\n",
      "Epoch: 012, Loss: 0.5520, Train Acc: 0.7379, Test Acc: 0.5000\n",
      "Epoch: 013, Loss: 0.5367, Train Acc: 0.7448, Test Acc: 0.4722\n",
      "Epoch: 014, Loss: 0.4891, Train Acc: 0.7793, Test Acc: 0.5000\n",
      "Epoch: 015, Loss: 0.5980, Train Acc: 0.7793, Test Acc: 0.5000\n",
      "Epoch: 016, Loss: 0.4908, Train Acc: 0.8138, Test Acc: 0.4722\n",
      "Epoch: 017, Loss: 0.4440, Train Acc: 0.8276, Test Acc: 0.4722\n",
      "Epoch: 018, Loss: 0.4201, Train Acc: 0.8483, Test Acc: 0.5000\n",
      "Epoch: 019, Loss: 0.3843, Train Acc: 0.7862, Test Acc: 0.4444\n",
      "Epoch: 020, Loss: 0.4011, Train Acc: 0.8483, Test Acc: 0.4444\n",
      "Epoch: 021, Loss: 0.3871, Train Acc: 0.8621, Test Acc: 0.5000\n",
      "Epoch: 022, Loss: 0.4288, Train Acc: 0.8483, Test Acc: 0.5278\n",
      "Epoch: 023, Loss: 0.3269, Train Acc: 0.8690, Test Acc: 0.5278\n",
      "Epoch: 024, Loss: 0.3822, Train Acc: 0.8828, Test Acc: 0.5278\n",
      "Epoch: 025, Loss: 0.3095, Train Acc: 0.8897, Test Acc: 0.5278\n",
      "Epoch: 026, Loss: 0.2843, Train Acc: 0.8897, Test Acc: 0.5556\n",
      "Epoch: 027, Loss: 0.4166, Train Acc: 0.8759, Test Acc: 0.5278\n",
      "Epoch: 028, Loss: 0.2877, Train Acc: 0.9103, Test Acc: 0.5556\n",
      "Epoch: 029, Loss: 0.2528, Train Acc: 0.9103, Test Acc: 0.5556\n",
      "Epoch: 030, Loss: 0.2473, Train Acc: 0.9103, Test Acc: 0.5556\n",
      "Epoch: 031, Loss: 0.2530, Train Acc: 0.9103, Test Acc: 0.5556\n",
      "Epoch: 032, Loss: 0.2584, Train Acc: 0.9172, Test Acc: 0.5833\n",
      "Epoch: 033, Loss: 0.2440, Train Acc: 0.9103, Test Acc: 0.5833\n",
      "Epoch: 034, Loss: 0.3394, Train Acc: 0.8345, Test Acc: 0.5000\n",
      "Epoch: 035, Loss: 0.2828, Train Acc: 0.9379, Test Acc: 0.5833\n",
      "Epoch: 036, Loss: 0.1787, Train Acc: 0.9379, Test Acc: 0.5278\n",
      "Epoch: 037, Loss: 0.1856, Train Acc: 0.9379, Test Acc: 0.5278\n",
      "Epoch: 038, Loss: 0.1828, Train Acc: 0.9448, Test Acc: 0.5556\n",
      "Epoch: 039, Loss: 0.1777, Train Acc: 0.9379, Test Acc: 0.5556\n",
      "Epoch: 040, Loss: 0.1724, Train Acc: 0.9379, Test Acc: 0.5556\n",
      "Epoch: 041, Loss: 0.1848, Train Acc: 0.9379, Test Acc: 0.5278\n",
      "Epoch: 042, Loss: 0.1599, Train Acc: 0.9448, Test Acc: 0.5278\n",
      "Epoch: 043, Loss: 0.1807, Train Acc: 0.9379, Test Acc: 0.5833\n",
      "Epoch: 044, Loss: 0.1624, Train Acc: 0.9448, Test Acc: 0.5833\n",
      "Epoch: 045, Loss: 0.2820, Train Acc: 0.9241, Test Acc: 0.5833\n",
      "Epoch: 046, Loss: 0.2224, Train Acc: 0.9379, Test Acc: 0.5278\n",
      "Epoch: 047, Loss: 0.1423, Train Acc: 0.9448, Test Acc: 0.5833\n",
      "Epoch: 048, Loss: 0.1691, Train Acc: 0.9517, Test Acc: 0.5833\n",
      "Epoch: 049, Loss: 0.1219, Train Acc: 0.9586, Test Acc: 0.5833\n",
      "Epoch: 050, Loss: 0.1262, Train Acc: 0.9586, Test Acc: 0.5833\n",
      "Epoch: 051, Loss: 0.1153, Train Acc: 0.9586, Test Acc: 0.5833\n",
      "Epoch: 052, Loss: 0.1204, Train Acc: 0.9586, Test Acc: 0.5833\n",
      "Epoch: 053, Loss: 0.1403, Train Acc: 0.9655, Test Acc: 0.5556\n",
      "Epoch: 054, Loss: 0.1052, Train Acc: 0.9724, Test Acc: 0.5556\n",
      "Epoch: 055, Loss: 0.0958, Train Acc: 0.9724, Test Acc: 0.5556\n",
      "Epoch: 056, Loss: 0.1142, Train Acc: 0.9724, Test Acc: 0.5556\n",
      "Epoch: 057, Loss: 0.0839, Train Acc: 0.9724, Test Acc: 0.6111\n",
      "Epoch: 058, Loss: 0.0737, Train Acc: 0.9448, Test Acc: 0.5278\n",
      "Epoch: 059, Loss: 0.1010, Train Acc: 0.9724, Test Acc: 0.5278\n",
      "Epoch: 060, Loss: 0.0781, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 061, Loss: 0.0630, Train Acc: 0.9862, Test Acc: 0.5000\n",
      "Epoch: 062, Loss: 0.0516, Train Acc: 0.9862, Test Acc: 0.5556\n",
      "Epoch: 063, Loss: 0.0524, Train Acc: 0.9862, Test Acc: 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Loss: 0.0408, Train Acc: 0.9862, Test Acc: 0.5278\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 141 143 152 153\n",
      " 155] TEST: [140 142 144 145 146 147 148 149 150 151 154 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(48, 384)\n",
      "  (pool1): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (conv2): GraphConv(384, 384)\n",
      "  (pool2): SAGPooling(GraphConv, 384, ratio=0.5, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 48)\n",
      "  (lin1): Linear(in_features=768, out_features=50, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 0.6994, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 002, Loss: 0.6933, Train Acc: 0.5379, Test Acc: 0.5000\n",
      "Epoch: 003, Loss: 0.6905, Train Acc: 0.5448, Test Acc: 0.5000\n",
      "Epoch: 004, Loss: 0.6933, Train Acc: 0.5379, Test Acc: 0.5278\n",
      "Epoch: 005, Loss: 0.7076, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 006, Loss: 0.6889, Train Acc: 0.5655, Test Acc: 0.5278\n",
      "Epoch: 007, Loss: 0.6923, Train Acc: 0.6000, Test Acc: 0.5556\n",
      "Epoch: 008, Loss: 0.6738, Train Acc: 0.6552, Test Acc: 0.5556\n",
      "Epoch: 009, Loss: 0.6471, Train Acc: 0.4759, Test Acc: 0.4722\n",
      "Epoch: 010, Loss: 0.7723, Train Acc: 0.7034, Test Acc: 0.5556\n",
      "Epoch: 011, Loss: 0.6470, Train Acc: 0.7310, Test Acc: 0.5833\n",
      "Epoch: 012, Loss: 0.6089, Train Acc: 0.5793, Test Acc: 0.4167\n",
      "Epoch: 013, Loss: 0.6368, Train Acc: 0.7241, Test Acc: 0.5000\n",
      "Epoch: 014, Loss: 0.5920, Train Acc: 0.7517, Test Acc: 0.5000\n",
      "Epoch: 015, Loss: 0.5805, Train Acc: 0.7310, Test Acc: 0.5000\n",
      "Epoch: 016, Loss: 0.5186, Train Acc: 0.7793, Test Acc: 0.5000\n",
      "Epoch: 017, Loss: 0.5188, Train Acc: 0.8207, Test Acc: 0.5000\n",
      "Epoch: 018, Loss: 0.5893, Train Acc: 0.7379, Test Acc: 0.5278\n",
      "Epoch: 019, Loss: 0.4834, Train Acc: 0.8276, Test Acc: 0.5278\n",
      "Epoch: 020, Loss: 0.4428, Train Acc: 0.7862, Test Acc: 0.5000\n",
      "Epoch: 021, Loss: 0.4253, Train Acc: 0.8276, Test Acc: 0.5000\n",
      "Epoch: 022, Loss: 0.4271, Train Acc: 0.8276, Test Acc: 0.5000\n",
      "Epoch: 023, Loss: 0.4024, Train Acc: 0.8069, Test Acc: 0.5000\n",
      "Epoch: 024, Loss: 0.6079, Train Acc: 0.7586, Test Acc: 0.5278\n",
      "Epoch: 025, Loss: 0.4297, Train Acc: 0.8345, Test Acc: 0.4167\n",
      "Epoch: 026, Loss: 0.3793, Train Acc: 0.8414, Test Acc: 0.5000\n",
      "Epoch: 027, Loss: 0.3740, Train Acc: 0.8414, Test Acc: 0.5000\n",
      "Epoch: 028, Loss: 0.3691, Train Acc: 0.8414, Test Acc: 0.5000\n",
      "Epoch: 029, Loss: 0.3954, Train Acc: 0.8414, Test Acc: 0.5000\n",
      "Epoch: 030, Loss: 0.3820, Train Acc: 0.8690, Test Acc: 0.5278\n",
      "Epoch: 031, Loss: 0.3412, Train Acc: 0.8621, Test Acc: 0.5278\n",
      "Epoch: 032, Loss: 0.3191, Train Acc: 0.8828, Test Acc: 0.5278\n",
      "Epoch: 033, Loss: 0.3216, Train Acc: 0.8828, Test Acc: 0.5278\n",
      "Epoch: 034, Loss: 0.2999, Train Acc: 0.8897, Test Acc: 0.5556\n",
      "Epoch: 035, Loss: 0.3068, Train Acc: 0.8897, Test Acc: 0.5278\n",
      "Epoch: 036, Loss: 0.2849, Train Acc: 0.8897, Test Acc: 0.5278\n",
      "Epoch: 037, Loss: 0.3484, Train Acc: 0.8552, Test Acc: 0.5000\n",
      "Epoch: 038, Loss: 0.3895, Train Acc: 0.8966, Test Acc: 0.5833\n",
      "Epoch: 039, Loss: 0.2874, Train Acc: 0.8966, Test Acc: 0.6111\n",
      "Epoch: 040, Loss: 0.2743, Train Acc: 0.9034, Test Acc: 0.5556\n",
      "Epoch: 041, Loss: 0.2409, Train Acc: 0.9103, Test Acc: 0.5278\n",
      "Epoch: 042, Loss: 0.2691, Train Acc: 0.9103, Test Acc: 0.5278\n",
      "Epoch: 043, Loss: 0.2427, Train Acc: 0.9103, Test Acc: 0.5278\n",
      "Epoch: 044, Loss: 0.2485, Train Acc: 0.9103, Test Acc: 0.5278\n",
      "Epoch: 045, Loss: 0.2238, Train Acc: 0.9103, Test Acc: 0.5278\n",
      "Epoch: 046, Loss: 0.2440, Train Acc: 0.9103, Test Acc: 0.5000\n",
      "Epoch: 047, Loss: 0.3257, Train Acc: 0.9103, Test Acc: 0.5278\n",
      "Epoch: 048, Loss: 0.2327, Train Acc: 0.9103, Test Acc: 0.4722\n",
      "Epoch: 049, Loss: 0.2458, Train Acc: 0.9172, Test Acc: 0.4444\n",
      "Epoch: 050, Loss: 0.2283, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 051, Loss: 0.2062, Train Acc: 0.9172, Test Acc: 0.5278\n",
      "Epoch: 052, Loss: 0.2494, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 053, Loss: 0.2032, Train Acc: 0.9172, Test Acc: 0.5278\n",
      "Epoch: 054, Loss: 0.2224, Train Acc: 0.9172, Test Acc: 0.4722\n",
      "Epoch: 055, Loss: 0.1968, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 056, Loss: 0.1975, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 057, Loss: 0.1805, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 058, Loss: 0.1885, Train Acc: 0.9310, Test Acc: 0.5556\n",
      "Epoch: 059, Loss: 0.1739, Train Acc: 0.9310, Test Acc: 0.5000\n",
      "Epoch: 060, Loss: 0.1622, Train Acc: 0.9310, Test Acc: 0.5000\n",
      "Epoch: 061, Loss: 0.2455, Train Acc: 0.9379, Test Acc: 0.5000\n",
      "Epoch: 062, Loss: 0.1393, Train Acc: 0.9379, Test Acc: 0.4722\n",
      "Epoch: 063, Loss: 0.1533, Train Acc: 0.9379, Test Acc: 0.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Loss: 0.1489, Train Acc: 0.9379, Test Acc: 0.5000\n",
      "Test accuracy: 0.5297297297297298\n",
      "Test stv: 0.10008450829520316\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "test_avg = []\n",
    "for train_index, test_index in kf.split(total_data, Y):\n",
    "    train_dataset=[]\n",
    "    test_dataset=[]\n",
    "    print(\"TRAIN: \", train_index, \"TEST:\", test_index)\n",
    "    for i in train_index:\n",
    "        train_dataset.append(total_data[i])\n",
    "    for i in test_index:\n",
    "        test_dataset.append(total_data[i])\n",
    "\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    model = Net(dim=384)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.6)\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=0.7)\n",
    "\n",
    "    train_epoch=[]\n",
    "    test_epoch=[]\n",
    "    epoch = 1\n",
    "    train_acc=0\n",
    "    while epoch < 65:\n",
    "        loss = train(epoch)\n",
    "        train_acc = test(train_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        train_epoch.append(train_acc)\n",
    "        test_epoch.append(test_acc)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "            f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        epoch +=1\n",
    "\n",
    "    plt.plot(train_epoch, color=\"red\")\n",
    "    plt.plot(test_epoch, color=\"blue\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    test_avg.append(test_acc)\n",
    "\n",
    "print('Test accuracy: '+ str(np.array(test_avg).mean()))\n",
    "print('Test stv: '+ str(np.array(test_avg).std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
