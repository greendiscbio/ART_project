{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gene matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKT1</th>\n",
       "      <th>ANXA1</th>\n",
       "      <th>ANXA2</th>\n",
       "      <th>APAF1</th>\n",
       "      <th>APC</th>\n",
       "      <th>ARID1A</th>\n",
       "      <th>ATM</th>\n",
       "      <th>AXIN2</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>CARD11</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC2A1</th>\n",
       "      <th>SOD2</th>\n",
       "      <th>SRC</th>\n",
       "      <th>STK11</th>\n",
       "      <th>TGM2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>TSC1</th>\n",
       "      <th>TSC2</th>\n",
       "      <th>VEGFA</th>\n",
       "      <th>VHL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.434275</td>\n",
       "      <td>33.868001</td>\n",
       "      <td>37.396638</td>\n",
       "      <td>32.668769</td>\n",
       "      <td>32.860903</td>\n",
       "      <td>33.848026</td>\n",
       "      <td>35.942429</td>\n",
       "      <td>31.470999</td>\n",
       "      <td>33.677294</td>\n",
       "      <td>30.617112</td>\n",
       "      <td>...</td>\n",
       "      <td>33.38586</td>\n",
       "      <td>38.67433</td>\n",
       "      <td>32.25286</td>\n",
       "      <td>34.96649</td>\n",
       "      <td>38.50142</td>\n",
       "      <td>33.83518</td>\n",
       "      <td>32.93402</td>\n",
       "      <td>34.93520</td>\n",
       "      <td>37.79678</td>\n",
       "      <td>32.30615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.152701</td>\n",
       "      <td>35.085434</td>\n",
       "      <td>36.570671</td>\n",
       "      <td>32.337493</td>\n",
       "      <td>33.717568</td>\n",
       "      <td>33.843513</td>\n",
       "      <td>35.988225</td>\n",
       "      <td>29.614297</td>\n",
       "      <td>32.643149</td>\n",
       "      <td>29.714342</td>\n",
       "      <td>...</td>\n",
       "      <td>33.69538</td>\n",
       "      <td>38.64559</td>\n",
       "      <td>31.28699</td>\n",
       "      <td>33.69034</td>\n",
       "      <td>34.33752</td>\n",
       "      <td>34.44810</td>\n",
       "      <td>33.16630</td>\n",
       "      <td>35.08304</td>\n",
       "      <td>40.09193</td>\n",
       "      <td>32.19988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.449119</td>\n",
       "      <td>34.908372</td>\n",
       "      <td>38.443020</td>\n",
       "      <td>31.818198</td>\n",
       "      <td>34.023099</td>\n",
       "      <td>33.516005</td>\n",
       "      <td>36.193587</td>\n",
       "      <td>30.304642</td>\n",
       "      <td>32.368866</td>\n",
       "      <td>29.076142</td>\n",
       "      <td>...</td>\n",
       "      <td>36.23588</td>\n",
       "      <td>40.50559</td>\n",
       "      <td>32.18447</td>\n",
       "      <td>33.52524</td>\n",
       "      <td>35.50178</td>\n",
       "      <td>35.41980</td>\n",
       "      <td>33.63282</td>\n",
       "      <td>34.79244</td>\n",
       "      <td>38.22308</td>\n",
       "      <td>31.49147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.220278</td>\n",
       "      <td>36.290124</td>\n",
       "      <td>37.244829</td>\n",
       "      <td>32.601293</td>\n",
       "      <td>33.507711</td>\n",
       "      <td>34.197698</td>\n",
       "      <td>36.578348</td>\n",
       "      <td>29.398240</td>\n",
       "      <td>31.895400</td>\n",
       "      <td>27.783504</td>\n",
       "      <td>...</td>\n",
       "      <td>34.41938</td>\n",
       "      <td>38.99231</td>\n",
       "      <td>30.26144</td>\n",
       "      <td>33.20234</td>\n",
       "      <td>35.77236</td>\n",
       "      <td>34.18862</td>\n",
       "      <td>32.88250</td>\n",
       "      <td>35.02014</td>\n",
       "      <td>39.94908</td>\n",
       "      <td>32.11538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.973368</td>\n",
       "      <td>36.863272</td>\n",
       "      <td>36.871693</td>\n",
       "      <td>33.593121</td>\n",
       "      <td>34.607163</td>\n",
       "      <td>33.351460</td>\n",
       "      <td>36.807497</td>\n",
       "      <td>29.939456</td>\n",
       "      <td>33.968348</td>\n",
       "      <td>29.105024</td>\n",
       "      <td>...</td>\n",
       "      <td>34.59911</td>\n",
       "      <td>38.41437</td>\n",
       "      <td>33.05053</td>\n",
       "      <td>34.14981</td>\n",
       "      <td>33.47112</td>\n",
       "      <td>34.91241</td>\n",
       "      <td>33.44515</td>\n",
       "      <td>35.01310</td>\n",
       "      <td>39.31564</td>\n",
       "      <td>33.33646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>35.057571</td>\n",
       "      <td>35.985233</td>\n",
       "      <td>37.436964</td>\n",
       "      <td>32.603769</td>\n",
       "      <td>33.811200</td>\n",
       "      <td>34.133940</td>\n",
       "      <td>35.318612</td>\n",
       "      <td>30.153123</td>\n",
       "      <td>33.843872</td>\n",
       "      <td>28.896068</td>\n",
       "      <td>...</td>\n",
       "      <td>36.50807</td>\n",
       "      <td>35.15898</td>\n",
       "      <td>30.42359</td>\n",
       "      <td>34.28555</td>\n",
       "      <td>34.57504</td>\n",
       "      <td>35.39631</td>\n",
       "      <td>32.93248</td>\n",
       "      <td>35.12781</td>\n",
       "      <td>40.48054</td>\n",
       "      <td>31.79913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>32.553513</td>\n",
       "      <td>37.586062</td>\n",
       "      <td>37.635004</td>\n",
       "      <td>33.619701</td>\n",
       "      <td>32.786808</td>\n",
       "      <td>32.373330</td>\n",
       "      <td>35.771711</td>\n",
       "      <td>25.453485</td>\n",
       "      <td>32.519967</td>\n",
       "      <td>30.116288</td>\n",
       "      <td>...</td>\n",
       "      <td>33.97705</td>\n",
       "      <td>38.85295</td>\n",
       "      <td>29.93888</td>\n",
       "      <td>31.63124</td>\n",
       "      <td>32.38354</td>\n",
       "      <td>32.04003</td>\n",
       "      <td>32.62658</td>\n",
       "      <td>33.78873</td>\n",
       "      <td>37.41392</td>\n",
       "      <td>31.66344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>34.807825</td>\n",
       "      <td>36.111194</td>\n",
       "      <td>37.953757</td>\n",
       "      <td>33.316811</td>\n",
       "      <td>33.632929</td>\n",
       "      <td>34.118843</td>\n",
       "      <td>36.008091</td>\n",
       "      <td>32.452387</td>\n",
       "      <td>33.115209</td>\n",
       "      <td>31.295849</td>\n",
       "      <td>...</td>\n",
       "      <td>34.85694</td>\n",
       "      <td>37.96021</td>\n",
       "      <td>32.31498</td>\n",
       "      <td>33.10439</td>\n",
       "      <td>36.65499</td>\n",
       "      <td>33.34126</td>\n",
       "      <td>32.81059</td>\n",
       "      <td>35.24316</td>\n",
       "      <td>38.72091</td>\n",
       "      <td>32.39461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>34.787403</td>\n",
       "      <td>35.120811</td>\n",
       "      <td>35.957212</td>\n",
       "      <td>33.046782</td>\n",
       "      <td>34.048901</td>\n",
       "      <td>33.833796</td>\n",
       "      <td>37.008936</td>\n",
       "      <td>31.636474</td>\n",
       "      <td>32.895151</td>\n",
       "      <td>31.027394</td>\n",
       "      <td>...</td>\n",
       "      <td>34.24055</td>\n",
       "      <td>37.24924</td>\n",
       "      <td>32.62449</td>\n",
       "      <td>33.64364</td>\n",
       "      <td>36.84744</td>\n",
       "      <td>34.98283</td>\n",
       "      <td>34.04810</td>\n",
       "      <td>35.60526</td>\n",
       "      <td>40.53108</td>\n",
       "      <td>32.34561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>34.983826</td>\n",
       "      <td>34.648929</td>\n",
       "      <td>38.196845</td>\n",
       "      <td>32.170042</td>\n",
       "      <td>33.143095</td>\n",
       "      <td>33.739764</td>\n",
       "      <td>35.937812</td>\n",
       "      <td>29.126405</td>\n",
       "      <td>33.404526</td>\n",
       "      <td>31.920307</td>\n",
       "      <td>...</td>\n",
       "      <td>35.99620</td>\n",
       "      <td>38.54211</td>\n",
       "      <td>33.12709</td>\n",
       "      <td>32.58468</td>\n",
       "      <td>37.23935</td>\n",
       "      <td>33.82151</td>\n",
       "      <td>33.82576</td>\n",
       "      <td>35.13995</td>\n",
       "      <td>40.81516</td>\n",
       "      <td>30.34566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AKT1      ANXA1      ANXA2      APAF1        APC     ARID1A  \\\n",
       "0    34.434275  33.868001  37.396638  32.668769  32.860903  33.848026   \n",
       "1    34.152701  35.085434  36.570671  32.337493  33.717568  33.843513   \n",
       "2    35.449119  34.908372  38.443020  31.818198  34.023099  33.516005   \n",
       "3    34.220278  36.290124  37.244829  32.601293  33.507711  34.197698   \n",
       "4    33.973368  36.863272  36.871693  33.593121  34.607163  33.351460   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "176  35.057571  35.985233  37.436964  32.603769  33.811200  34.133940   \n",
       "177  32.553513  37.586062  37.635004  33.619701  32.786808  32.373330   \n",
       "178  34.807825  36.111194  37.953757  33.316811  33.632929  34.118843   \n",
       "179  34.787403  35.120811  35.957212  33.046782  34.048901  33.833796   \n",
       "180  34.983826  34.648929  38.196845  32.170042  33.143095  33.739764   \n",
       "\n",
       "           ATM      AXIN2       BAP1     CARD11  ...    SLC2A1      SOD2  \\\n",
       "0    35.942429  31.470999  33.677294  30.617112  ...  33.38586  38.67433   \n",
       "1    35.988225  29.614297  32.643149  29.714342  ...  33.69538  38.64559   \n",
       "2    36.193587  30.304642  32.368866  29.076142  ...  36.23588  40.50559   \n",
       "3    36.578348  29.398240  31.895400  27.783504  ...  34.41938  38.99231   \n",
       "4    36.807497  29.939456  33.968348  29.105024  ...  34.59911  38.41437   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "176  35.318612  30.153123  33.843872  28.896068  ...  36.50807  35.15898   \n",
       "177  35.771711  25.453485  32.519967  30.116288  ...  33.97705  38.85295   \n",
       "178  36.008091  32.452387  33.115209  31.295849  ...  34.85694  37.96021   \n",
       "179  37.008936  31.636474  32.895151  31.027394  ...  34.24055  37.24924   \n",
       "180  35.937812  29.126405  33.404526  31.920307  ...  35.99620  38.54211   \n",
       "\n",
       "          SRC     STK11      TGM2      TP53      TSC1      TSC2     VEGFA  \\\n",
       "0    32.25286  34.96649  38.50142  33.83518  32.93402  34.93520  37.79678   \n",
       "1    31.28699  33.69034  34.33752  34.44810  33.16630  35.08304  40.09193   \n",
       "2    32.18447  33.52524  35.50178  35.41980  33.63282  34.79244  38.22308   \n",
       "3    30.26144  33.20234  35.77236  34.18862  32.88250  35.02014  39.94908   \n",
       "4    33.05053  34.14981  33.47112  34.91241  33.44515  35.01310  39.31564   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  30.42359  34.28555  34.57504  35.39631  32.93248  35.12781  40.48054   \n",
       "177  29.93888  31.63124  32.38354  32.04003  32.62658  33.78873  37.41392   \n",
       "178  32.31498  33.10439  36.65499  33.34126  32.81059  35.24316  38.72091   \n",
       "179  32.62449  33.64364  36.84744  34.98283  34.04810  35.60526  40.53108   \n",
       "180  33.12709  32.58468  37.23935  33.82151  33.82576  35.13995  40.81516   \n",
       "\n",
       "          VHL  \n",
       "0    32.30615  \n",
       "1    32.19988  \n",
       "2    31.49147  \n",
       "3    32.11538  \n",
       "4    33.33646  \n",
       "..        ...  \n",
       "176  31.79913  \n",
       "177  31.66344  \n",
       "178  32.39461  \n",
       "179  32.34561  \n",
       "180  30.34566  \n",
       "\n",
       "[181 rows x 74 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = pd.read_csv('../../../Data\\PPT-Ohmnet/mRCC_big_pool/Second big pool/mrcc_protein_matrix_203_genes_74_nodes.csv')\n",
    "Y = genes.Y\n",
    "\n",
    "genes = genes.iloc[:,1:75] \n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKT1</th>\n",
       "      <th>ANXA1</th>\n",
       "      <th>ANXA2</th>\n",
       "      <th>APAF1</th>\n",
       "      <th>APC</th>\n",
       "      <th>ARID1A</th>\n",
       "      <th>ATM</th>\n",
       "      <th>AXIN2</th>\n",
       "      <th>BAP1</th>\n",
       "      <th>CARD11</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC2A1</th>\n",
       "      <th>SOD2</th>\n",
       "      <th>SRC</th>\n",
       "      <th>STK11</th>\n",
       "      <th>TGM2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>TSC1</th>\n",
       "      <th>TSC2</th>\n",
       "      <th>VEGFA</th>\n",
       "      <th>VHL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432669</td>\n",
       "      <td>0.275573</td>\n",
       "      <td>0.596683</td>\n",
       "      <td>0.610274</td>\n",
       "      <td>0.563291</td>\n",
       "      <td>0.474298</td>\n",
       "      <td>0.551095</td>\n",
       "      <td>0.775703</td>\n",
       "      <td>0.703386</td>\n",
       "      <td>0.643444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420160</td>\n",
       "      <td>0.542412</td>\n",
       "      <td>0.608390</td>\n",
       "      <td>0.940939</td>\n",
       "      <td>0.945549</td>\n",
       "      <td>0.403803</td>\n",
       "      <td>0.411780</td>\n",
       "      <td>0.408244</td>\n",
       "      <td>0.439826</td>\n",
       "      <td>0.681580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.367893</td>\n",
       "      <td>0.512777</td>\n",
       "      <td>0.390935</td>\n",
       "      <td>0.536117</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.472846</td>\n",
       "      <td>0.561963</td>\n",
       "      <td>0.639198</td>\n",
       "      <td>0.465055</td>\n",
       "      <td>0.537804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458930</td>\n",
       "      <td>0.538144</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.697760</td>\n",
       "      <td>0.301997</td>\n",
       "      <td>0.538341</td>\n",
       "      <td>0.474109</td>\n",
       "      <td>0.451980</td>\n",
       "      <td>0.760074</td>\n",
       "      <td>0.664154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666134</td>\n",
       "      <td>0.478279</td>\n",
       "      <td>0.857336</td>\n",
       "      <td>0.419872</td>\n",
       "      <td>0.807376</td>\n",
       "      <td>0.367512</td>\n",
       "      <td>0.610698</td>\n",
       "      <td>0.689952</td>\n",
       "      <td>0.401843</td>\n",
       "      <td>0.463124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777154</td>\n",
       "      <td>0.814317</td>\n",
       "      <td>0.596828</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.481939</td>\n",
       "      <td>0.751632</td>\n",
       "      <td>0.599295</td>\n",
       "      <td>0.366011</td>\n",
       "      <td>0.499309</td>\n",
       "      <td>0.547991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383439</td>\n",
       "      <td>0.747499</td>\n",
       "      <td>0.558867</td>\n",
       "      <td>0.595169</td>\n",
       "      <td>0.699134</td>\n",
       "      <td>0.586761</td>\n",
       "      <td>0.702007</td>\n",
       "      <td>0.623313</td>\n",
       "      <td>0.292727</td>\n",
       "      <td>0.311863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549619</td>\n",
       "      <td>0.589625</td>\n",
       "      <td>0.271721</td>\n",
       "      <td>0.604769</td>\n",
       "      <td>0.523759</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.397955</td>\n",
       "      <td>0.433372</td>\n",
       "      <td>0.740142</td>\n",
       "      <td>0.650298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326638</td>\n",
       "      <td>0.859172</td>\n",
       "      <td>0.465919</td>\n",
       "      <td>0.817191</td>\n",
       "      <td>0.930042</td>\n",
       "      <td>0.314590</td>\n",
       "      <td>0.756387</td>\n",
       "      <td>0.663103</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.466504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572132</td>\n",
       "      <td>0.503813</td>\n",
       "      <td>0.743244</td>\n",
       "      <td>0.785315</td>\n",
       "      <td>0.168091</td>\n",
       "      <td>0.640258</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.651756</td>\n",
       "      <td>0.850528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.576058</td>\n",
       "      <td>0.688094</td>\n",
       "      <td>0.606728</td>\n",
       "      <td>0.595723</td>\n",
       "      <td>0.762873</td>\n",
       "      <td>0.566255</td>\n",
       "      <td>0.403055</td>\n",
       "      <td>0.678812</td>\n",
       "      <td>0.741776</td>\n",
       "      <td>0.442052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811248</td>\n",
       "      <td>0.020453</td>\n",
       "      <td>0.299134</td>\n",
       "      <td>0.811181</td>\n",
       "      <td>0.338707</td>\n",
       "      <td>0.746476</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.814298</td>\n",
       "      <td>0.598440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656060</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.547729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510581</td>\n",
       "      <td>0.333294</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>0.584839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.568933</td>\n",
       "      <td>0.217189</td>\n",
       "      <td>0.305386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.329281</td>\n",
       "      <td>0.069080</td>\n",
       "      <td>0.386405</td>\n",
       "      <td>0.576190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.518604</td>\n",
       "      <td>0.712637</td>\n",
       "      <td>0.735461</td>\n",
       "      <td>0.755339</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.561399</td>\n",
       "      <td>0.566677</td>\n",
       "      <td>0.847854</td>\n",
       "      <td>0.573847</td>\n",
       "      <td>0.722867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604427</td>\n",
       "      <td>0.436379</td>\n",
       "      <td>0.618892</td>\n",
       "      <td>0.586104</td>\n",
       "      <td>0.660174</td>\n",
       "      <td>0.295386</td>\n",
       "      <td>0.378658</td>\n",
       "      <td>0.499349</td>\n",
       "      <td>0.568772</td>\n",
       "      <td>0.696085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.513906</td>\n",
       "      <td>0.519670</td>\n",
       "      <td>0.238123</td>\n",
       "      <td>0.694893</td>\n",
       "      <td>0.812795</td>\n",
       "      <td>0.469721</td>\n",
       "      <td>0.804191</td>\n",
       "      <td>0.787868</td>\n",
       "      <td>0.523132</td>\n",
       "      <td>0.691454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527218</td>\n",
       "      <td>0.330815</td>\n",
       "      <td>0.671218</td>\n",
       "      <td>0.688861</td>\n",
       "      <td>0.689918</td>\n",
       "      <td>0.655716</td>\n",
       "      <td>0.710731</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.821350</td>\n",
       "      <td>0.688050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.559093</td>\n",
       "      <td>0.427729</td>\n",
       "      <td>0.796014</td>\n",
       "      <td>0.498633</td>\n",
       "      <td>0.622557</td>\n",
       "      <td>0.439478</td>\n",
       "      <td>0.549999</td>\n",
       "      <td>0.603328</td>\n",
       "      <td>0.640524</td>\n",
       "      <td>0.795940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747131</td>\n",
       "      <td>0.522780</td>\n",
       "      <td>0.756187</td>\n",
       "      <td>0.487070</td>\n",
       "      <td>0.750490</td>\n",
       "      <td>0.400802</td>\n",
       "      <td>0.651068</td>\n",
       "      <td>0.468816</td>\n",
       "      <td>0.860988</td>\n",
       "      <td>0.360103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AKT1     ANXA1     ANXA2     APAF1       APC    ARID1A       ATM  \\\n",
       "0    0.432669  0.275573  0.596683  0.610274  0.563291  0.474298  0.551095   \n",
       "1    0.367893  0.512777  0.390935  0.536117  0.743208  0.472846  0.561963   \n",
       "2    0.666134  0.478279  0.857336  0.419872  0.807376  0.367512  0.610698   \n",
       "3    0.383439  0.747499  0.558867  0.595169  0.699134  0.586761  0.702007   \n",
       "4    0.326638  0.859172  0.465919  0.817191  0.930042  0.314590  0.756387   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  0.576058  0.688094  0.606728  0.595723  0.762873  0.566255  0.403055   \n",
       "177  0.000000  1.000000  0.656060  0.823141  0.547729  0.000000  0.510581   \n",
       "178  0.518604  0.712637  0.735461  0.755339  0.725432  0.561399  0.566677   \n",
       "179  0.513906  0.519670  0.238123  0.694893  0.812795  0.469721  0.804191   \n",
       "180  0.559093  0.427729  0.796014  0.498633  0.622557  0.439478  0.549999   \n",
       "\n",
       "        AXIN2      BAP1    CARD11  ...    SLC2A1      SOD2       SRC  \\\n",
       "0    0.775703  0.703386  0.643444  ...  0.420160  0.542412  0.608390   \n",
       "1    0.639198  0.465055  0.537804  ...  0.458930  0.538144  0.445100   \n",
       "2    0.689952  0.401843  0.463124  ...  0.777154  0.814317  0.596828   \n",
       "3    0.623313  0.292727  0.311863  ...  0.549619  0.589625  0.271721   \n",
       "4    0.663103  0.770463  0.466504  ...  0.572132  0.503813  0.743244   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  0.678812  0.741776  0.442052  ...  0.811248  0.020453  0.299134   \n",
       "177  0.333294  0.436667  0.584839  ...  0.494212  0.568933  0.217189   \n",
       "178  0.847854  0.573847  0.722867  ...  0.604427  0.436379  0.618892   \n",
       "179  0.787868  0.523132  0.691454  ...  0.527218  0.330815  0.671218   \n",
       "180  0.603328  0.640524  0.795940  ...  0.747131  0.522780  0.756187   \n",
       "\n",
       "        STK11      TGM2      TP53      TSC1      TSC2     VEGFA       VHL  \n",
       "0    0.940939  0.945549  0.403803  0.411780  0.408244  0.439826  0.681580  \n",
       "1    0.697760  0.301997  0.538341  0.474109  0.451980  0.760074  0.664154  \n",
       "2    0.666300  0.481939  0.751632  0.599295  0.366011  0.499309  0.547991  \n",
       "3    0.604769  0.523759  0.481384  0.397955  0.433372  0.740142  0.650298  \n",
       "4    0.785315  0.168091  0.640258  0.548936  0.431290  0.651756  0.850528  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "176  0.811181  0.338707  0.746476  0.411366  0.465225  0.814298  0.598440  \n",
       "177  0.305386  0.000000  0.009761  0.329281  0.069080  0.386405  0.576190  \n",
       "178  0.586104  0.660174  0.295386  0.378658  0.499349  0.568772  0.696085  \n",
       "179  0.688861  0.689918  0.655716  0.710731  0.606470  0.821350  0.688050  \n",
       "180  0.487070  0.750490  0.400802  0.651068  0.468816  0.860988  0.360103  \n",
       "\n",
       "[181 rows x 74 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = genes.columns\n",
    "d = scaler.fit_transform(genes)\n",
    "genes = pd.DataFrame(d, columns=names)\n",
    "genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../../../Data/PPT-Ohmnet/mRCC_big_pool/Second big pool/network_edges_mrcc_203_genes_74_nodes.tsv'\n",
    "data = pd.read_csv(path, delimiter='\\t')\n",
    "edge_index1=data[data.columns[1]].to_numpy()\n",
    "edge_index2=data[data.columns[2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = np.concatenate((edge_index1, edge_index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MYC', 'MYC', 'MYC', 'MYC', 'MYC', 'MYC', 'MYC', 'MYC', 'MYC',\n",
       "       'MYC', 'MYC', 'MYC', 'CDKN2A', 'CDKN2A', 'CDKN2A', 'CDKN2A',\n",
       "       'CDKN2A', 'CDKN2A', 'CDKN2A', 'ERBB2', 'ERBB2', 'ERBB2', 'ERBB2',\n",
       "       'ERBB2', 'ERN1', 'CRADD', 'CRADD', 'KIF1B', 'SRC', 'SRC', 'SRC',\n",
       "       'SRC', 'SRC', 'SRC', 'SRC', 'SRC', 'SRC', 'SRC', 'SRC', 'SRC',\n",
       "       'SRC', 'SRC', 'SRC', 'SRC', 'SRC', 'INSR', 'LRRK2', 'LRRK2',\n",
       "       'LRRK2', 'TSC1', 'TSC1', 'TSC1', 'TSC1', 'TSC2', 'TSC2', 'TSC2',\n",
       "       'CCND1', 'CCND1', 'CCND1', 'CCND1', 'PTEN', 'PTEN', 'PTEN', 'PTEN',\n",
       "       'PTEN', 'PTEN', 'PTEN', 'PTEN', 'ARID1A', 'HNF4A', 'HNF4A',\n",
       "       'HNF4A', 'PTGS1', 'PTGS2', 'PTGS2', 'AXIN2', 'AXIN2', 'BAP1',\n",
       "       'BAP1', 'STK11', 'STK11', 'STK11', 'JUN', 'JUN', 'JUN', 'JUN',\n",
       "       'JUN', 'JUN', 'JUN', 'JUN', 'JUNB', 'JUNB', 'JUND', 'JUND', 'JUND',\n",
       "       'DLC1', 'NDRG1', 'NDRG1', 'NF2', 'NF2', 'NF2', 'PIK3CA', 'NFE2L2',\n",
       "       'NFE2L2', 'NFE2L2', 'NFE2L2', 'NFE2L2', 'KDR', 'KDR', 'KDR', 'KDR',\n",
       "       'AKT1', 'AKT1', 'AKT1', 'AKT1', 'AKT1', 'AKT1', 'AKT1', 'AKT1',\n",
       "       'AKT1', 'HSPA9', 'HSPA9', 'HSPA9', 'HSPA9', 'HSPA9', 'HSPA9',\n",
       "       'HSPB1', 'HSPB1', 'HSPB1', 'HSPB1', 'HSPB1', 'SDHA', 'DNMT1',\n",
       "       'DNMT1', 'VEGFA', 'VEGFA', 'HSPD1', 'HSPD1', 'HSPD1', 'VHL', 'VHL',\n",
       "       'VHL', 'VHL', 'VHL', 'VHL', 'VHL', 'VHL', 'VHL', 'VHL', 'HNF1A',\n",
       "       'HNF1A', 'FLT1', 'SFRP2', 'FN1', 'FN1', 'FN1', 'FN1', 'FN1',\n",
       "       'ANXA1', 'ANXA1', 'ANXA1', 'ANXA2', 'APAF1', 'CASP2', 'APC', 'APC',\n",
       "       'APC', 'RELA', 'RELA', 'RELA', 'RELA', 'RET', 'RHEB', 'RHEB',\n",
       "       'CRYAB', 'CRYAB', 'GSTP1', 'GSTP1', 'TGM2', 'SETD2', 'IGF1R',\n",
       "       'MTOR', 'MTOR', 'PAK1', 'ATM', 'CTNNB1', 'CTNNB1', 'MAPK8',\n",
       "       'MAPK8', 'IL6', 'MYC', 'TP53', 'HSPD1', 'FN1', 'ANXA2', 'MAP2K1',\n",
       "       'RELA', 'HSPB1', 'MAPK8', 'CDKN2A', 'JUN', 'DNMT3A', 'VHL',\n",
       "       'CCND1', 'RELA', 'MAPK8', 'HSPA9', 'TP53', 'VHL', 'FN1', 'IGF1R',\n",
       "       'CTNNB1', 'SRC', 'NF2', 'PAK1', 'TP53', 'CASP2', 'CRYAB', 'JUN',\n",
       "       'TP53', 'ANXA2', 'IGF1R', 'FLT4', 'AKT1', 'HNF1A', 'FN1', 'HNF4A',\n",
       "       'INSR', 'CTNNB1', 'CCND1', 'L1CAM', 'IL6R', 'ANXA1', 'KDR', 'RET',\n",
       "       'TGM2', 'IGF1R', 'HSPD1', 'AKT1', 'HSPA9', 'AKT1', 'NF2', 'RHEB',\n",
       "       'TSC2', 'AKT1', 'CCND1', 'RHEB', 'RELA', 'CRYAB', 'CTNNB1',\n",
       "       'CARD11', 'TP53', 'AKT1', 'STK11', 'ANXA2', 'HSPD1', 'CTNNB1',\n",
       "       'BAP1', 'PIK3CA', 'TP53', 'TP53', 'HNF1A', 'CTNNB1', 'PTGS2',\n",
       "       'CTNNB1', 'TP53', 'CTNNB1', 'APC', 'IGF1R', 'HSPA9', 'TP53',\n",
       "       'PAK1', 'ATM', 'MAPK8', 'SHANK1', 'JUND', 'NFE2L2', 'FN1', 'FOSL2',\n",
       "       'RELA', 'EPAS1', 'MAPK8', 'FOSL2', 'NFE2L2', 'FOSL2', 'MAPK8',\n",
       "       'AKT1', 'TP53', 'CTNNB1', 'CTNNB1', 'PAK1', 'AKT1', 'AKT1',\n",
       "       'GSTP1', 'APC', 'MAP2K1', 'AKT1', 'MAPK8', 'VEGFA', 'CTNNB1',\n",
       "       'FLT4', 'FLT1', 'DNMT1', 'ATM', 'HSPA9', 'MTOR', 'MAPK8', 'CTNNB1',\n",
       "       'PAK1', 'RET', 'HSPB1', 'HSPD1', 'HSPB1', 'SDHA', 'RELA', 'TP53',\n",
       "       'FN1', 'TP53', 'CRYAB', 'SDHA', 'ANXA1', 'FN1', 'FN1', 'DNMT3A',\n",
       "       'TP53', 'CRYAB', 'FLT1', 'ANXA2', 'FN1', 'ANXA1', 'SLC2A1',\n",
       "       'RNF139', 'ANXA2', 'ATM', 'TGM2', 'TP53', 'CTNNB1', 'SOD2',\n",
       "       'EPAS1', 'FN1', 'CTNNB1', 'ANXA2', 'CTNNB1', 'FN1', 'ANXA2',\n",
       "       'ANXA1', 'TGM2', 'CTSD', 'GSTP1', 'TGM2', 'ANXA2', 'RELA', 'TP53',\n",
       "       'TP53', 'CRYAB', 'EPAS1', 'TP53', 'CTNNB1', 'TGM2', 'IL6', 'TP53',\n",
       "       'ATM', 'MAPK8', 'MTOR', 'ATM', 'CTNNB1', 'TP53', 'TGM2', 'MAPK8',\n",
       "       'PAK1', 'TP53', 'TP53', 'TP53', 'MAPK8', 'MAP2K1', 'TP53', 'EPAS1',\n",
       "       'MAPK8', 'MAP2K1', 'TP53', 'IL6R', 'NFE2L2'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(edge_index)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = le.transform(edge_index1)\n",
    "edge_index2 = le.transform(edge_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [edge_index1]+[edge_index2]\n",
    "edge_index = np.array(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 12, 12, 12, 12,\n",
       "        12, 12, 12, 21, 21, 21, 21, 21, 22, 13, 13, 41, 66, 66, 66, 66,\n",
       "        66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 36, 43, 43,\n",
       "        43, 70, 70, 70, 70, 71, 71, 71, 11, 11, 11, 11, 53, 53, 53, 53,\n",
       "        53, 53, 53, 53,  5, 29, 29, 29, 54, 55, 55,  7,  7,  8,  8, 67,\n",
       "        67, 67, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 39, 39, 39, 17,\n",
       "        48, 48, 49, 49, 49, 52, 50, 50, 50, 50, 50, 40, 40, 40, 40,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0, 30, 30, 30, 30, 30, 30, 31, 31,\n",
       "        31, 31, 31, 60, 18, 18, 72, 72, 32, 32, 32, 73, 73, 73, 73, 73,\n",
       "        73, 73, 73, 73, 73, 28, 28, 23, 62, 25, 25, 25, 25, 25,  1,  1,\n",
       "         1,  2,  3, 10,  4,  4,  4, 56, 56, 56, 56, 57, 58, 58, 14, 14,\n",
       "        27, 27, 68, 61, 33, 46, 46, 51,  6, 15, 15, 45, 45, 34, 47],\n",
       "       [69, 32, 25,  2, 44, 56, 31, 45, 12, 37, 19, 73, 11, 56, 45, 30,\n",
       "        69, 73, 25, 33, 15, 66, 49, 51, 69, 10, 14, 37, 69,  2, 33, 24,\n",
       "         0, 28, 25, 29, 36, 15, 11, 42, 35,  1, 40, 57, 68, 33, 32,  0,\n",
       "        30,  0, 49, 58, 71,  0, 11, 58, 56, 14, 15,  9, 69,  0, 67,  2,\n",
       "        32, 15,  8, 52, 69, 69, 28, 15, 55, 15, 69, 15,  4, 33, 30, 69,\n",
       "        51,  6, 45, 63, 39, 50, 25, 26, 56, 20, 45, 26, 50, 26, 45,  0,\n",
       "        69, 15, 15, 51,  0,  0, 27,  4, 44,  0, 45, 72, 15, 24, 23, 18,\n",
       "         6, 30, 46, 45, 15, 51, 57, 31, 32, 31, 60, 56, 69, 25, 69, 14,\n",
       "        60,  1, 25, 25, 19, 69, 14, 23,  2, 25,  1, 64, 59,  2,  6, 68,\n",
       "        69, 15, 65, 20, 25, 15,  2, 15, 25,  2,  1, 68, 16, 27, 68,  2,\n",
       "        56, 69, 69, 14, 20, 69, 15, 68, 34, 69,  6, 45, 46,  6, 15, 69,\n",
       "        68, 45, 51, 69, 69, 69, 45, 44, 69, 20, 45, 44, 69, 35, 50]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 12, 12, 12, 12, 12, 12,\n",
       "         12, 21, 21, 21, 21, 21, 22, 13, 13, 41, 66, 66, 66, 66, 66, 66, 66, 66,\n",
       "         66, 66, 66, 66, 66, 66, 66, 66, 66, 36, 43, 43, 43, 70, 70, 70, 70, 71,\n",
       "         71, 71, 11, 11, 11, 11, 53, 53, 53, 53, 53, 53, 53, 53,  5, 29, 29, 29,\n",
       "         54, 55, 55,  7,  7,  8,  8, 67, 67, 67, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "         38, 38, 39, 39, 39, 17, 48, 48, 49, 49, 49, 52, 50, 50, 50, 50, 50, 40,\n",
       "         40, 40, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0, 30, 30, 30, 30, 30, 30,\n",
       "         31, 31, 31, 31, 31, 60, 18, 18, 72, 72, 32, 32, 32, 73, 73, 73, 73, 73,\n",
       "         73, 73, 73, 73, 73, 28, 28, 23, 62, 25, 25, 25, 25, 25,  1,  1,  1,  2,\n",
       "          3, 10,  4,  4,  4, 56, 56, 56, 56, 57, 58, 58, 14, 14, 27, 27, 68, 61,\n",
       "         33, 46, 46, 51,  6, 15, 15, 45, 45, 34, 47],\n",
       "        [69, 32, 25,  2, 44, 56, 31, 45, 12, 37, 19, 73, 11, 56, 45, 30, 69, 73,\n",
       "         25, 33, 15, 66, 49, 51, 69, 10, 14, 37, 69,  2, 33, 24,  0, 28, 25, 29,\n",
       "         36, 15, 11, 42, 35,  1, 40, 57, 68, 33, 32,  0, 30,  0, 49, 58, 71,  0,\n",
       "         11, 58, 56, 14, 15,  9, 69,  0, 67,  2, 32, 15,  8, 52, 69, 69, 28, 15,\n",
       "         55, 15, 69, 15,  4, 33, 30, 69, 51,  6, 45, 63, 39, 50, 25, 26, 56, 20,\n",
       "         45, 26, 50, 26, 45,  0, 69, 15, 15, 51,  0,  0, 27,  4, 44,  0, 45, 72,\n",
       "         15, 24, 23, 18,  6, 30, 46, 45, 15, 51, 57, 31, 32, 31, 60, 56, 69, 25,\n",
       "         69, 14, 60,  1, 25, 25, 19, 69, 14, 23,  2, 25,  1, 64, 59,  2,  6, 68,\n",
       "         69, 15, 65, 20, 25, 15,  2, 15, 25,  2,  1, 68, 16, 27, 68,  2, 56, 69,\n",
       "         69, 14, 20, 69, 15, 68, 34, 69,  6, 45, 46,  6, 15, 69, 68, 45, 51, 69,\n",
       "         69, 69, 45, 44, 69, 20, 45, 44, 69, 35, 50]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[74], edge_index=[2, 191], y=[1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_17688/1747583445.py:11: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor([b], dtype=torch.long).reshape([-1])\n"
     ]
    }
   ],
   "source": [
    "list_data_0=[]\n",
    "list_data_1=[]\n",
    "total_data=[]\n",
    "for g in range(len(genes)):\n",
    "  b=[]\n",
    "  for i in genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    # a.append(Y[g])\n",
    "    a.append(i*100)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.long).reshape([-1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y.iloc[g]], dtype=torch.float).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  total_data.append(data)\n",
    "  if y == 0:\n",
    "    list_data_0.append(data)\n",
    "  else:\n",
    "    list_data_1.append(data)\n",
    "\n",
    "print(list_data_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Patient sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 74\n",
      "Number of charcateristics per node: 1\n",
      "Number of edges: 191\n",
      "Average node degree: 2.58\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "data = list_data_0[0]\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of charcateristics per node: {data.num_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 6\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dim = dim\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GraphConv(embed_dim, dim)\n",
    "        self.pool1 = SAGPooling(dim, ratio=0.1)\n",
    "        self.conv2 = GraphConv(dim, dim)\n",
    "        self.pool2 = SAGPooling(dim, ratio=0.1)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=101, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(1200, 500)\n",
    "        self.lin2 = torch.nn.Linear(500, 10)\n",
    "        self.lin3 = torch.nn.Linear(500, 1)\n",
    "        self.act1 = torch.nn.RReLU()\n",
    "        print(self)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = torch.tensor(x) #.to(torch.int)\n",
    "        # print(x.long())\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        # x = F.relu(self.conv2(x, edge_index))\n",
    "        # x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        # x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 #+ x2\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        # x = self.lin2(x)\n",
    "        # x = self.act1(x)\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(output, data.y.squeeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        for i in range(len(output)):\n",
    "            if output[i]>0.5:\n",
    "                output[i]=1\n",
    "            else:\n",
    "                output[i]=0\n",
    "            if output[i]==data.y[i]:\n",
    "                correct=correct+1\n",
    "    # print(\"Correct: \"+str(correct) +\" of \"+str(len(loader.dataset)))\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "kf=StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [ 30  32  33  34  40  41  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 35 36 37 38 39 42]\n",
      "144\n",
      "37\n",
      "Net(\n",
      "  (conv1): GraphConv(6, 600)\n",
      "  (pool1): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (conv2): GraphConv(600, 600)\n",
      "  (pool2): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 6)\n",
      "  (lin1): Linear(in_features=1200, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp/ipykernel_17688/922151203.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x) #.to(torch.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7101, Train Acc: 0.5486, Test Acc: 0.4595\n",
      "Epoch: 002, Loss: 0.6957, Train Acc: 0.5694, Test Acc: 0.4054\n",
      "Epoch: 003, Loss: 0.6983, Train Acc: 0.4722, Test Acc: 0.4595\n",
      "Epoch: 004, Loss: 0.7125, Train Acc: 0.4792, Test Acc: 0.4595\n",
      "Epoch: 005, Loss: 0.6905, Train Acc: 0.5903, Test Acc: 0.4054\n",
      "Epoch: 006, Loss: 0.6985, Train Acc: 0.5347, Test Acc: 0.3784\n",
      "Epoch: 007, Loss: 0.7019, Train Acc: 0.6181, Test Acc: 0.4054\n",
      "Epoch: 008, Loss: 0.7046, Train Acc: 0.5139, Test Acc: 0.4595\n",
      "Epoch: 009, Loss: 0.6946, Train Acc: 0.4861, Test Acc: 0.4865\n",
      "Epoch: 010, Loss: 0.6990, Train Acc: 0.5486, Test Acc: 0.5135\n",
      "Epoch: 011, Loss: 0.7120, Train Acc: 0.5278, Test Acc: 0.4595\n",
      "Epoch: 012, Loss: 0.6923, Train Acc: 0.5625, Test Acc: 0.4865\n",
      "Epoch: 013, Loss: 0.7099, Train Acc: 0.5347, Test Acc: 0.3784\n",
      "Epoch: 014, Loss: 0.7036, Train Acc: 0.4792, Test Acc: 0.4595\n",
      "Epoch: 015, Loss: 0.6987, Train Acc: 0.4792, Test Acc: 0.4324\n",
      "Epoch: 016, Loss: 0.7153, Train Acc: 0.5694, Test Acc: 0.5676\n",
      "Epoch: 017, Loss: 0.6981, Train Acc: 0.5208, Test Acc: 0.4595\n",
      "Epoch: 018, Loss: 0.7075, Train Acc: 0.5347, Test Acc: 0.3784\n",
      "Epoch: 019, Loss: 0.7041, Train Acc: 0.5208, Test Acc: 0.5676\n",
      "Epoch: 020, Loss: 0.6943, Train Acc: 0.4375, Test Acc: 0.3514\n",
      "Epoch: 021, Loss: 0.7143, Train Acc: 0.5000, Test Acc: 0.3784\n",
      "Epoch: 022, Loss: 0.7102, Train Acc: 0.4931, Test Acc: 0.4054\n",
      "Epoch: 023, Loss: 0.7022, Train Acc: 0.5556, Test Acc: 0.5405\n",
      "Epoch: 024, Loss: 0.6877, Train Acc: 0.5347, Test Acc: 0.5135\n",
      "Epoch: 025, Loss: 0.6871, Train Acc: 0.5486, Test Acc: 0.4324\n",
      "Epoch: 026, Loss: 0.6958, Train Acc: 0.5625, Test Acc: 0.5405\n",
      "Epoch: 027, Loss: 0.6925, Train Acc: 0.5347, Test Acc: 0.3784\n",
      "Epoch: 028, Loss: 0.6970, Train Acc: 0.5556, Test Acc: 0.4595\n",
      "Epoch: 029, Loss: 0.7130, Train Acc: 0.5486, Test Acc: 0.4324\n",
      "Epoch: 030, Loss: 0.7041, Train Acc: 0.5625, Test Acc: 0.5135\n",
      "Epoch: 031, Loss: 0.7018, Train Acc: 0.4583, Test Acc: 0.4054\n",
      "Epoch: 032, Loss: 0.7121, Train Acc: 0.5139, Test Acc: 0.4865\n",
      "Epoch: 033, Loss: 0.7086, Train Acc: 0.4722, Test Acc: 0.5135\n",
      "Epoch: 034, Loss: 0.7113, Train Acc: 0.5278, Test Acc: 0.5946\n",
      "Epoch: 035, Loss: 0.7116, Train Acc: 0.4792, Test Acc: 0.4595\n",
      "Epoch: 036, Loss: 0.6968, Train Acc: 0.4722, Test Acc: 0.4324\n",
      "Epoch: 037, Loss: 0.6894, Train Acc: 0.4792, Test Acc: 0.5405\n",
      "Epoch: 038, Loss: 0.6992, Train Acc: 0.4653, Test Acc: 0.4595\n",
      "Epoch: 039, Loss: 0.6990, Train Acc: 0.5556, Test Acc: 0.6216\n",
      "Epoch: 040, Loss: 0.6952, Train Acc: 0.4931, Test Acc: 0.4324\n",
      "Epoch: 041, Loss: 0.7058, Train Acc: 0.5833, Test Acc: 0.6216\n",
      "Epoch: 042, Loss: 0.7093, Train Acc: 0.5764, Test Acc: 0.5946\n",
      "Epoch: 043, Loss: 0.6956, Train Acc: 0.6111, Test Acc: 0.6216\n",
      "Epoch: 044, Loss: 0.6888, Train Acc: 0.5903, Test Acc: 0.5135\n",
      "Epoch: 045, Loss: 0.6927, Train Acc: 0.6319, Test Acc: 0.5676\n",
      "Epoch: 046, Loss: 0.6992, Train Acc: 0.5903, Test Acc: 0.5135\n",
      "Epoch: 047, Loss: 0.6921, Train Acc: 0.5625, Test Acc: 0.5135\n",
      "Epoch: 048, Loss: 0.6919, Train Acc: 0.6250, Test Acc: 0.5946\n",
      "Epoch: 049, Loss: 0.6903, Train Acc: 0.5556, Test Acc: 0.5135\n",
      "Epoch: 050, Loss: 0.6941, Train Acc: 0.6042, Test Acc: 0.5135\n",
      "Epoch: 051, Loss: 0.6908, Train Acc: 0.5694, Test Acc: 0.5135\n",
      "Epoch: 052, Loss: 0.6921, Train Acc: 0.5486, Test Acc: 0.4865\n",
      "Epoch: 053, Loss: 0.6907, Train Acc: 0.6181, Test Acc: 0.5676\n",
      "Epoch: 054, Loss: 0.6959, Train Acc: 0.6111, Test Acc: 0.5946\n",
      "Epoch: 055, Loss: 0.6954, Train Acc: 0.6111, Test Acc: 0.5676\n",
      "Epoch: 056, Loss: 0.6864, Train Acc: 0.6111, Test Acc: 0.5405\n",
      "Epoch: 057, Loss: 0.6866, Train Acc: 0.5903, Test Acc: 0.5405\n",
      "Epoch: 058, Loss: 0.6730, Train Acc: 0.6042, Test Acc: 0.5135\n",
      "Epoch: 059, Loss: 0.6927, Train Acc: 0.6458, Test Acc: 0.5405\n",
      "Epoch: 060, Loss: 0.6920, Train Acc: 0.5903, Test Acc: 0.5135\n",
      "Epoch: 061, Loss: 0.7036, Train Acc: 0.5903, Test Acc: 0.5405\n",
      "Epoch: 062, Loss: 0.6876, Train Acc: 0.5972, Test Acc: 0.5135\n",
      "Epoch: 063, Loss: 0.6881, Train Acc: 0.5278, Test Acc: 0.5135\n",
      "Epoch: 064, Loss: 0.6803, Train Acc: 0.6319, Test Acc: 0.5676\n",
      "Epoch: 065, Loss: 0.6926, Train Acc: 0.6389, Test Acc: 0.4865\n",
      "Epoch: 066, Loss: 0.6968, Train Acc: 0.6458, Test Acc: 0.6216\n",
      "Epoch: 067, Loss: 0.6891, Train Acc: 0.6389, Test Acc: 0.5135\n",
      "Epoch: 068, Loss: 0.6873, Train Acc: 0.6389, Test Acc: 0.5946\n",
      "Epoch: 069, Loss: 0.6922, Train Acc: 0.6389, Test Acc: 0.5135\n",
      "Epoch: 070, Loss: 0.6832, Train Acc: 0.6042, Test Acc: 0.5405\n",
      "Epoch: 071, Loss: 0.6964, Train Acc: 0.6319, Test Acc: 0.5946\n",
      "Epoch: 072, Loss: 0.6707, Train Acc: 0.6111, Test Acc: 0.5405\n",
      "Epoch: 073, Loss: 0.6868, Train Acc: 0.5833, Test Acc: 0.5135\n",
      "Epoch: 074, Loss: 0.6976, Train Acc: 0.6528, Test Acc: 0.5946\n",
      "Epoch: 075, Loss: 0.6714, Train Acc: 0.6181, Test Acc: 0.4865\n",
      "Epoch: 076, Loss: 0.6877, Train Acc: 0.5972, Test Acc: 0.5676\n",
      "Epoch: 077, Loss: 0.7010, Train Acc: 0.5972, Test Acc: 0.5946\n",
      "Epoch: 078, Loss: 0.6765, Train Acc: 0.6250, Test Acc: 0.4865\n",
      "Epoch: 079, Loss: 0.6708, Train Acc: 0.6111, Test Acc: 0.5405\n",
      "Epoch: 080, Loss: 0.6882, Train Acc: 0.5903, Test Acc: 0.5405\n",
      "Epoch: 081, Loss: 0.6871, Train Acc: 0.6389, Test Acc: 0.5676\n",
      "Epoch: 082, Loss: 0.6801, Train Acc: 0.5903, Test Acc: 0.5405\n",
      "Epoch: 083, Loss: 0.6958, Train Acc: 0.6111, Test Acc: 0.5676\n",
      "Epoch: 084, Loss: 0.6866, Train Acc: 0.5833, Test Acc: 0.5405\n",
      "Epoch: 085, Loss: 0.6809, Train Acc: 0.5833, Test Acc: 0.6216\n",
      "Epoch: 086, Loss: 0.6824, Train Acc: 0.5486, Test Acc: 0.5946\n",
      "Epoch: 087, Loss: 0.6845, Train Acc: 0.5694, Test Acc: 0.6486\n",
      "Epoch: 088, Loss: 0.6989, Train Acc: 0.5417, Test Acc: 0.5676\n",
      "Epoch: 089, Loss: 0.6991, Train Acc: 0.5417, Test Acc: 0.5676\n",
      "Epoch: 090, Loss: 0.6834, Train Acc: 0.6389, Test Acc: 0.4595\n",
      "Epoch: 091, Loss: 0.6726, Train Acc: 0.5486, Test Acc: 0.5946\n",
      "Epoch: 092, Loss: 0.6789, Train Acc: 0.6389, Test Acc: 0.4595\n",
      "Epoch: 093, Loss: 0.7043, Train Acc: 0.6181, Test Acc: 0.4595\n",
      "Epoch: 094, Loss: 0.7048, Train Acc: 0.5764, Test Acc: 0.6216\n",
      "Epoch: 095, Loss: 0.6840, Train Acc: 0.5972, Test Acc: 0.6486\n",
      "Epoch: 096, Loss: 0.6970, Train Acc: 0.6042, Test Acc: 0.6216\n",
      "Epoch: 097, Loss: 0.6680, Train Acc: 0.6181, Test Acc: 0.6216\n",
      "Epoch: 098, Loss: 0.7114, Train Acc: 0.6250, Test Acc: 0.6216\n",
      "Epoch: 099, Loss: 0.6842, Train Acc: 0.5694, Test Acc: 0.6216\n",
      "Epoch: 100, Loss: 0.6694, Train Acc: 0.6042, Test Acc: 0.4865\n",
      "Epoch: 101, Loss: 0.6859, Train Acc: 0.6458, Test Acc: 0.5135\n",
      "Epoch: 102, Loss: 0.6923, Train Acc: 0.6528, Test Acc: 0.4595\n",
      "Epoch: 103, Loss: 0.6953, Train Acc: 0.6181, Test Acc: 0.4865\n",
      "Epoch: 104, Loss: 0.6731, Train Acc: 0.5903, Test Acc: 0.4865\n",
      "Epoch: 105, Loss: 0.6777, Train Acc: 0.6319, Test Acc: 0.4324\n",
      "Epoch: 106, Loss: 0.6686, Train Acc: 0.6667, Test Acc: 0.4054\n",
      "Epoch: 107, Loss: 0.6709, Train Acc: 0.6667, Test Acc: 0.4865\n",
      "Epoch: 108, Loss: 0.6771, Train Acc: 0.6319, Test Acc: 0.4595\n",
      "Epoch: 109, Loss: 0.6910, Train Acc: 0.6667, Test Acc: 0.3784\n",
      "Epoch: 110, Loss: 0.6977, Train Acc: 0.5278, Test Acc: 0.5946\n",
      "Epoch: 111, Loss: 0.7180, Train Acc: 0.5486, Test Acc: 0.5676\n",
      "Epoch: 112, Loss: 0.6849, Train Acc: 0.6111, Test Acc: 0.4324\n",
      "Epoch: 113, Loss: 0.7136, Train Acc: 0.5486, Test Acc: 0.4865\n",
      "Epoch: 114, Loss: 0.6999, Train Acc: 0.5556, Test Acc: 0.4865\n",
      "Epoch: 115, Loss: 0.6966, Train Acc: 0.5556, Test Acc: 0.4865\n",
      "Epoch: 116, Loss: 0.6707, Train Acc: 0.5556, Test Acc: 0.5135\n",
      "Epoch: 117, Loss: 0.6518, Train Acc: 0.5556, Test Acc: 0.5405\n",
      "Epoch: 118, Loss: 0.7326, Train Acc: 0.5694, Test Acc: 0.4054\n",
      "Epoch: 119, Loss: 0.6964, Train Acc: 0.5833, Test Acc: 0.5135\n",
      "Epoch: 120, Loss: 0.6894, Train Acc: 0.5694, Test Acc: 0.4595\n",
      "Epoch: 121, Loss: 0.6926, Train Acc: 0.5417, Test Acc: 0.5135\n",
      "Epoch: 122, Loss: 0.6828, Train Acc: 0.5556, Test Acc: 0.5135\n",
      "Epoch: 123, Loss: 0.7063, Train Acc: 0.5625, Test Acc: 0.3514\n",
      "Epoch: 124, Loss: 0.6860, Train Acc: 0.5833, Test Acc: 0.4865\n",
      "Epoch: 125, Loss: 0.6842, Train Acc: 0.5764, Test Acc: 0.3514\n",
      "Epoch: 126, Loss: 0.6866, Train Acc: 0.5833, Test Acc: 0.4054\n",
      "Epoch: 127, Loss: 0.6866, Train Acc: 0.5625, Test Acc: 0.2973\n",
      "Epoch: 128, Loss: 0.6779, Train Acc: 0.5556, Test Acc: 0.2973\n",
      "Epoch: 129, Loss: 0.6906, Train Acc: 0.5486, Test Acc: 0.3514\n",
      "Epoch: 130, Loss: 0.6980, Train Acc: 0.5764, Test Acc: 0.4595\n",
      "Epoch: 131, Loss: 0.6963, Train Acc: 0.5625, Test Acc: 0.5676\n",
      "Epoch: 132, Loss: 0.6705, Train Acc: 0.5764, Test Acc: 0.5676\n",
      "Epoch: 133, Loss: 0.6906, Train Acc: 0.5625, Test Acc: 0.5676\n",
      "Epoch: 134, Loss: 0.6686, Train Acc: 0.5694, Test Acc: 0.5405\n",
      "Epoch: 135, Loss: 0.7100, Train Acc: 0.5903, Test Acc: 0.4324\n",
      "Epoch: 136, Loss: 0.6797, Train Acc: 0.5764, Test Acc: 0.4054\n",
      "Epoch: 137, Loss: 0.6756, Train Acc: 0.6319, Test Acc: 0.4324\n",
      "Epoch: 138, Loss: 0.6711, Train Acc: 0.5694, Test Acc: 0.4054\n",
      "Epoch: 139, Loss: 0.6856, Train Acc: 0.6042, Test Acc: 0.4054\n",
      "Epoch: 140, Loss: 0.6650, Train Acc: 0.5694, Test Acc: 0.4054\n",
      "Epoch: 141, Loss: 0.6826, Train Acc: 0.6181, Test Acc: 0.5135\n",
      "Epoch: 142, Loss: 0.6846, Train Acc: 0.6042, Test Acc: 0.4595\n",
      "Epoch: 143, Loss: 0.6882, Train Acc: 0.5625, Test Acc: 0.4054\n",
      "Epoch: 144, Loss: 0.6925, Train Acc: 0.5486, Test Acc: 0.4054\n",
      "Epoch: 145, Loss: 0.7166, Train Acc: 0.5417, Test Acc: 0.5405\n",
      "Epoch: 146, Loss: 0.6964, Train Acc: 0.5139, Test Acc: 0.4865\n",
      "Epoch: 147, Loss: 0.7051, Train Acc: 0.5417, Test Acc: 0.5135\n",
      "Epoch: 148, Loss: 0.6932, Train Acc: 0.5278, Test Acc: 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149, Loss: 0.7027, Train Acc: 0.5417, Test Acc: 0.5676\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  31  35  36  37  38  39\n",
      "  42  70  72  73  75  76  77  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180] TEST: [30 32 33 34 40 41 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\n",
      " 61 62 63 64 65 66 67 68 69 71 74 78]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(6, 600)\n",
      "  (pool1): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (conv2): GraphConv(600, 600)\n",
      "  (pool2): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 6)\n",
      "  (lin1): Linear(in_features=1200, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 0.7067, Train Acc: 0.5517, Test Acc: 0.5556\n",
      "Epoch: 002, Loss: 0.6953, Train Acc: 0.5724, Test Acc: 0.5833\n",
      "Epoch: 003, Loss: 0.6945, Train Acc: 0.5517, Test Acc: 0.5278\n",
      "Epoch: 004, Loss: 0.6943, Train Acc: 0.5724, Test Acc: 0.5833\n",
      "Epoch: 005, Loss: 0.6958, Train Acc: 0.5724, Test Acc: 0.6944\n",
      "Epoch: 006, Loss: 0.6963, Train Acc: 0.6000, Test Acc: 0.6111\n",
      "Epoch: 007, Loss: 0.6922, Train Acc: 0.5586, Test Acc: 0.5833\n",
      "Epoch: 008, Loss: 0.6962, Train Acc: 0.5793, Test Acc: 0.5278\n",
      "Epoch: 009, Loss: 0.6921, Train Acc: 0.5310, Test Acc: 0.5556\n",
      "Epoch: 010, Loss: 0.7136, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 011, Loss: 0.6964, Train Acc: 0.5241, Test Acc: 0.4167\n",
      "Epoch: 012, Loss: 0.7209, Train Acc: 0.6138, Test Acc: 0.5556\n",
      "Epoch: 013, Loss: 0.6905, Train Acc: 0.6138, Test Acc: 0.5278\n",
      "Epoch: 014, Loss: 0.6882, Train Acc: 0.6138, Test Acc: 0.5278\n",
      "Epoch: 015, Loss: 0.7139, Train Acc: 0.6138, Test Acc: 0.4722\n",
      "Epoch: 016, Loss: 0.7084, Train Acc: 0.5517, Test Acc: 0.4444\n",
      "Epoch: 017, Loss: 0.7020, Train Acc: 0.6069, Test Acc: 0.5000\n",
      "Epoch: 018, Loss: 0.6963, Train Acc: 0.5931, Test Acc: 0.5833\n",
      "Epoch: 019, Loss: 0.6928, Train Acc: 0.5724, Test Acc: 0.4722\n",
      "Epoch: 020, Loss: 0.6885, Train Acc: 0.6207, Test Acc: 0.4722\n",
      "Epoch: 021, Loss: 0.6768, Train Acc: 0.5517, Test Acc: 0.3889\n",
      "Epoch: 022, Loss: 0.7091, Train Acc: 0.6000, Test Acc: 0.6111\n",
      "Epoch: 023, Loss: 0.7004, Train Acc: 0.6138, Test Acc: 0.5278\n",
      "Epoch: 024, Loss: 0.6745, Train Acc: 0.5517, Test Acc: 0.4444\n",
      "Epoch: 025, Loss: 0.6894, Train Acc: 0.6138, Test Acc: 0.5556\n",
      "Epoch: 026, Loss: 0.7015, Train Acc: 0.6069, Test Acc: 0.5556\n",
      "Epoch: 027, Loss: 0.7009, Train Acc: 0.6069, Test Acc: 0.4444\n",
      "Epoch: 028, Loss: 0.6905, Train Acc: 0.6207, Test Acc: 0.5278\n",
      "Epoch: 029, Loss: 0.6779, Train Acc: 0.6276, Test Acc: 0.5278\n",
      "Epoch: 030, Loss: 0.6869, Train Acc: 0.5862, Test Acc: 0.4444\n",
      "Epoch: 031, Loss: 0.6951, Train Acc: 0.6276, Test Acc: 0.5556\n",
      "Epoch: 032, Loss: 0.6898, Train Acc: 0.6000, Test Acc: 0.5000\n",
      "Epoch: 033, Loss: 0.6682, Train Acc: 0.6276, Test Acc: 0.5556\n",
      "Epoch: 034, Loss: 0.6791, Train Acc: 0.6069, Test Acc: 0.5000\n",
      "Epoch: 035, Loss: 0.6760, Train Acc: 0.6069, Test Acc: 0.5000\n",
      "Epoch: 036, Loss: 0.6870, Train Acc: 0.5862, Test Acc: 0.5000\n",
      "Epoch: 037, Loss: 0.6866, Train Acc: 0.6000, Test Acc: 0.5278\n",
      "Epoch: 038, Loss: 0.6888, Train Acc: 0.6276, Test Acc: 0.4722\n",
      "Epoch: 039, Loss: 0.6653, Train Acc: 0.6207, Test Acc: 0.5000\n",
      "Epoch: 040, Loss: 0.7123, Train Acc: 0.5931, Test Acc: 0.5833\n",
      "Epoch: 041, Loss: 0.6744, Train Acc: 0.6414, Test Acc: 0.5000\n",
      "Epoch: 042, Loss: 0.6726, Train Acc: 0.6552, Test Acc: 0.5278\n",
      "Epoch: 043, Loss: 0.6930, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 044, Loss: 0.6853, Train Acc: 0.6345, Test Acc: 0.5833\n",
      "Epoch: 045, Loss: 0.6826, Train Acc: 0.6345, Test Acc: 0.5556\n",
      "Epoch: 046, Loss: 0.6823, Train Acc: 0.6345, Test Acc: 0.6111\n",
      "Epoch: 047, Loss: 0.6715, Train Acc: 0.6207, Test Acc: 0.5556\n",
      "Epoch: 048, Loss: 0.6710, Train Acc: 0.6552, Test Acc: 0.5556\n",
      "Epoch: 049, Loss: 0.6572, Train Acc: 0.6483, Test Acc: 0.4444\n",
      "Epoch: 050, Loss: 0.7591, Train Acc: 0.5862, Test Acc: 0.5000\n",
      "Epoch: 051, Loss: 0.6943, Train Acc: 0.6414, Test Acc: 0.5833\n",
      "Epoch: 052, Loss: 0.6715, Train Acc: 0.6483, Test Acc: 0.5833\n",
      "Epoch: 053, Loss: 0.6859, Train Acc: 0.6276, Test Acc: 0.5556\n",
      "Epoch: 054, Loss: 0.6688, Train Acc: 0.6345, Test Acc: 0.5278\n",
      "Epoch: 055, Loss: 0.6752, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 056, Loss: 0.6955, Train Acc: 0.6483, Test Acc: 0.5556\n",
      "Epoch: 057, Loss: 0.6624, Train Acc: 0.6552, Test Acc: 0.5833\n",
      "Epoch: 058, Loss: 0.7001, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 059, Loss: 0.6721, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 060, Loss: 0.6578, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 061, Loss: 0.6878, Train Acc: 0.6483, Test Acc: 0.5556\n",
      "Epoch: 062, Loss: 0.6887, Train Acc: 0.6276, Test Acc: 0.5833\n",
      "Epoch: 063, Loss: 0.6665, Train Acc: 0.6414, Test Acc: 0.5833\n",
      "Epoch: 064, Loss: 0.6988, Train Acc: 0.6828, Test Acc: 0.6389\n",
      "Epoch: 065, Loss: 0.6835, Train Acc: 0.6207, Test Acc: 0.5833\n",
      "Epoch: 066, Loss: 0.6674, Train Acc: 0.6759, Test Acc: 0.6389\n",
      "Epoch: 067, Loss: 0.6754, Train Acc: 0.6897, Test Acc: 0.6389\n",
      "Epoch: 068, Loss: 0.6644, Train Acc: 0.6414, Test Acc: 0.5278\n",
      "Epoch: 069, Loss: 0.6568, Train Acc: 0.5931, Test Acc: 0.5278\n",
      "Epoch: 070, Loss: 0.6578, Train Acc: 0.6552, Test Acc: 0.5556\n",
      "Epoch: 071, Loss: 0.6541, Train Acc: 0.6276, Test Acc: 0.5556\n",
      "Epoch: 072, Loss: 0.6527, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 073, Loss: 0.6653, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 074, Loss: 0.6512, Train Acc: 0.6483, Test Acc: 0.5833\n",
      "Epoch: 075, Loss: 0.6482, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 076, Loss: 0.6889, Train Acc: 0.6552, Test Acc: 0.6111\n",
      "Epoch: 077, Loss: 0.6518, Train Acc: 0.6483, Test Acc: 0.5556\n",
      "Epoch: 078, Loss: 0.6468, Train Acc: 0.6483, Test Acc: 0.5556\n",
      "Epoch: 079, Loss: 0.6534, Train Acc: 0.6483, Test Acc: 0.5556\n",
      "Epoch: 080, Loss: 0.6288, Train Acc: 0.6483, Test Acc: 0.5278\n",
      "Epoch: 081, Loss: 0.6382, Train Acc: 0.6552, Test Acc: 0.5278\n",
      "Epoch: 082, Loss: 0.6396, Train Acc: 0.6690, Test Acc: 0.5278\n",
      "Epoch: 083, Loss: 0.6379, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 084, Loss: 0.6495, Train Acc: 0.6276, Test Acc: 0.6389\n",
      "Epoch: 085, Loss: 0.6762, Train Acc: 0.6759, Test Acc: 0.5278\n",
      "Epoch: 086, Loss: 0.6455, Train Acc: 0.6690, Test Acc: 0.6111\n",
      "Epoch: 087, Loss: 0.6193, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 088, Loss: 0.6398, Train Acc: 0.6621, Test Acc: 0.5278\n",
      "Epoch: 089, Loss: 0.6452, Train Acc: 0.6690, Test Acc: 0.5278\n",
      "Epoch: 090, Loss: 0.6226, Train Acc: 0.6759, Test Acc: 0.5833\n",
      "Epoch: 091, Loss: 0.6334, Train Acc: 0.6552, Test Acc: 0.5556\n",
      "Epoch: 092, Loss: 0.6612, Train Acc: 0.6345, Test Acc: 0.6389\n",
      "Epoch: 093, Loss: 0.6418, Train Acc: 0.6345, Test Acc: 0.6389\n",
      "Epoch: 094, Loss: 0.6389, Train Acc: 0.6345, Test Acc: 0.6389\n",
      "Epoch: 095, Loss: 0.6773, Train Acc: 0.6414, Test Acc: 0.6111\n",
      "Epoch: 096, Loss: 0.6210, Train Acc: 0.6345, Test Acc: 0.6111\n",
      "Epoch: 097, Loss: 0.6281, Train Acc: 0.6414, Test Acc: 0.5833\n",
      "Epoch: 098, Loss: 0.6346, Train Acc: 0.6552, Test Acc: 0.5833\n",
      "Epoch: 099, Loss: 0.6268, Train Acc: 0.6276, Test Acc: 0.5556\n",
      "Epoch: 100, Loss: 0.6583, Train Acc: 0.6483, Test Acc: 0.5833\n",
      "Epoch: 101, Loss: 0.6391, Train Acc: 0.6345, Test Acc: 0.6111\n",
      "Epoch: 102, Loss: 0.6378, Train Acc: 0.6552, Test Acc: 0.6111\n",
      "Epoch: 103, Loss: 0.6359, Train Acc: 0.6621, Test Acc: 0.5833\n",
      "Epoch: 104, Loss: 0.6281, Train Acc: 0.6483, Test Acc: 0.6389\n",
      "Epoch: 105, Loss: 0.6252, Train Acc: 0.6897, Test Acc: 0.6111\n",
      "Epoch: 106, Loss: 0.6279, Train Acc: 0.6759, Test Acc: 0.6389\n",
      "Epoch: 107, Loss: 0.6011, Train Acc: 0.6483, Test Acc: 0.6389\n",
      "Epoch: 108, Loss: 0.6677, Train Acc: 0.6207, Test Acc: 0.6667\n",
      "Epoch: 109, Loss: 0.6293, Train Acc: 0.6483, Test Acc: 0.6667\n",
      "Epoch: 110, Loss: 0.5936, Train Acc: 0.6414, Test Acc: 0.6667\n",
      "Epoch: 111, Loss: 0.6378, Train Acc: 0.6690, Test Acc: 0.6111\n",
      "Epoch: 112, Loss: 0.6474, Train Acc: 0.6483, Test Acc: 0.4722\n",
      "Epoch: 113, Loss: 0.6625, Train Acc: 0.6759, Test Acc: 0.5000\n",
      "Epoch: 114, Loss: 0.6590, Train Acc: 0.6828, Test Acc: 0.4722\n",
      "Epoch: 115, Loss: 0.6371, Train Acc: 0.6897, Test Acc: 0.4722\n",
      "Epoch: 116, Loss: 0.6392, Train Acc: 0.6690, Test Acc: 0.4722\n",
      "Epoch: 117, Loss: 0.6190, Train Acc: 0.6759, Test Acc: 0.5278\n",
      "Epoch: 118, Loss: 0.6393, Train Acc: 0.6828, Test Acc: 0.5278\n",
      "Epoch: 119, Loss: 0.6372, Train Acc: 0.6759, Test Acc: 0.5278\n",
      "Epoch: 120, Loss: 0.6351, Train Acc: 0.6897, Test Acc: 0.5000\n",
      "Epoch: 121, Loss: 0.6287, Train Acc: 0.6621, Test Acc: 0.5000\n",
      "Epoch: 122, Loss: 0.6376, Train Acc: 0.6621, Test Acc: 0.5000\n",
      "Epoch: 123, Loss: 0.6049, Train Acc: 0.6552, Test Acc: 0.5278\n",
      "Epoch: 124, Loss: 0.5821, Train Acc: 0.6345, Test Acc: 0.4722\n",
      "Epoch: 125, Loss: 0.6354, Train Acc: 0.6483, Test Acc: 0.4722\n",
      "Epoch: 126, Loss: 0.6438, Train Acc: 0.6690, Test Acc: 0.5278\n",
      "Epoch: 127, Loss: 0.6170, Train Acc: 0.6552, Test Acc: 0.5556\n",
      "Epoch: 128, Loss: 0.5990, Train Acc: 0.6552, Test Acc: 0.5000\n",
      "Epoch: 129, Loss: 0.6439, Train Acc: 0.6759, Test Acc: 0.4722\n",
      "Epoch: 130, Loss: 0.5909, Train Acc: 0.6828, Test Acc: 0.5000\n",
      "Epoch: 131, Loss: 0.5957, Train Acc: 0.6690, Test Acc: 0.4722\n",
      "Epoch: 132, Loss: 0.6598, Train Acc: 0.6621, Test Acc: 0.4167\n",
      "Epoch: 133, Loss: 0.6340, Train Acc: 0.6414, Test Acc: 0.4722\n",
      "Epoch: 134, Loss: 0.6336, Train Acc: 0.6414, Test Acc: 0.4722\n",
      "Epoch: 135, Loss: 0.6167, Train Acc: 0.6828, Test Acc: 0.5000\n",
      "Epoch: 136, Loss: 0.6055, Train Acc: 0.6897, Test Acc: 0.5556\n",
      "Epoch: 137, Loss: 0.5969, Train Acc: 0.6828, Test Acc: 0.5278\n",
      "Epoch: 138, Loss: 0.5979, Train Acc: 0.6966, Test Acc: 0.5556\n",
      "Epoch: 139, Loss: 0.5948, Train Acc: 0.6966, Test Acc: 0.5556\n",
      "Epoch: 140, Loss: 0.5898, Train Acc: 0.6828, Test Acc: 0.5556\n",
      "Epoch: 141, Loss: 0.5695, Train Acc: 0.7103, Test Acc: 0.5833\n",
      "Epoch: 142, Loss: 0.6046, Train Acc: 0.7034, Test Acc: 0.6111\n",
      "Epoch: 143, Loss: 0.6019, Train Acc: 0.6690, Test Acc: 0.6111\n",
      "Epoch: 144, Loss: 0.5932, Train Acc: 0.6828, Test Acc: 0.5556\n",
      "Epoch: 145, Loss: 0.6045, Train Acc: 0.6828, Test Acc: 0.5556\n",
      "Epoch: 146, Loss: 0.5831, Train Acc: 0.6690, Test Acc: 0.5556\n",
      "Epoch: 147, Loss: 0.5932, Train Acc: 0.6759, Test Acc: 0.5556\n",
      "Epoch: 148, Loss: 0.6182, Train Acc: 0.6759, Test Acc: 0.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149, Loss: 0.6263, Train Acc: 0.7241, Test Acc: 0.5833\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  71  74\n",
      "  78 107 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180] TEST: [ 70  72  73  75  76  77  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 108 109]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(6, 600)\n",
      "  (pool1): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (conv2): GraphConv(600, 600)\n",
      "  (pool2): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 6)\n",
      "  (lin1): Linear(in_features=1200, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 1.2145, Train Acc: 0.4690, Test Acc: 0.4722\n",
      "Epoch: 002, Loss: 0.9482, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 003, Loss: 1.2667, Train Acc: 0.4690, Test Acc: 0.4722\n",
      "Epoch: 004, Loss: 0.9782, Train Acc: 0.4690, Test Acc: 0.4722\n",
      "Epoch: 005, Loss: 0.8737, Train Acc: 0.4690, Test Acc: 0.4722\n",
      "Epoch: 006, Loss: 0.8632, Train Acc: 0.5517, Test Acc: 0.6389\n",
      "Epoch: 007, Loss: 0.7333, Train Acc: 0.5172, Test Acc: 0.5278\n",
      "Epoch: 008, Loss: 0.7427, Train Acc: 0.5931, Test Acc: 0.6111\n",
      "Epoch: 009, Loss: 0.8475, Train Acc: 0.5931, Test Acc: 0.5833\n",
      "Epoch: 010, Loss: 0.7964, Train Acc: 0.6000, Test Acc: 0.5000\n",
      "Epoch: 011, Loss: 0.7318, Train Acc: 0.5448, Test Acc: 0.5556\n",
      "Epoch: 012, Loss: 0.7372, Train Acc: 0.5793, Test Acc: 0.4722\n",
      "Epoch: 013, Loss: 0.6943, Train Acc: 0.5862, Test Acc: 0.5556\n",
      "Epoch: 014, Loss: 0.7160, Train Acc: 0.5931, Test Acc: 0.4722\n",
      "Epoch: 015, Loss: 0.6849, Train Acc: 0.6069, Test Acc: 0.6111\n",
      "Epoch: 016, Loss: 0.7138, Train Acc: 0.6069, Test Acc: 0.3611\n",
      "Epoch: 017, Loss: 0.6923, Train Acc: 0.6000, Test Acc: 0.5278\n",
      "Epoch: 018, Loss: 0.6970, Train Acc: 0.6138, Test Acc: 0.5278\n",
      "Epoch: 019, Loss: 0.7122, Train Acc: 0.6207, Test Acc: 0.5278\n",
      "Epoch: 020, Loss: 0.7120, Train Acc: 0.6069, Test Acc: 0.4444\n",
      "Epoch: 021, Loss: 0.6861, Train Acc: 0.6276, Test Acc: 0.3611\n",
      "Epoch: 022, Loss: 0.6899, Train Acc: 0.6483, Test Acc: 0.4722\n",
      "Epoch: 023, Loss: 0.6431, Train Acc: 0.6207, Test Acc: 0.5000\n",
      "Epoch: 024, Loss: 0.6966, Train Acc: 0.6414, Test Acc: 0.5000\n",
      "Epoch: 025, Loss: 0.7047, Train Acc: 0.6483, Test Acc: 0.5278\n",
      "Epoch: 026, Loss: 0.6666, Train Acc: 0.6000, Test Acc: 0.3889\n",
      "Epoch: 027, Loss: 0.6506, Train Acc: 0.6345, Test Acc: 0.3889\n",
      "Epoch: 028, Loss: 0.6796, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 029, Loss: 0.7093, Train Acc: 0.6414, Test Acc: 0.5278\n",
      "Epoch: 030, Loss: 0.6862, Train Acc: 0.6207, Test Acc: 0.4444\n",
      "Epoch: 031, Loss: 0.6698, Train Acc: 0.6552, Test Acc: 0.4722\n",
      "Epoch: 032, Loss: 0.7035, Train Acc: 0.6414, Test Acc: 0.5000\n",
      "Epoch: 033, Loss: 0.7293, Train Acc: 0.6483, Test Acc: 0.4167\n",
      "Epoch: 034, Loss: 0.6401, Train Acc: 0.6276, Test Acc: 0.5278\n",
      "Epoch: 035, Loss: 0.6704, Train Acc: 0.6552, Test Acc: 0.5000\n",
      "Epoch: 036, Loss: 0.6594, Train Acc: 0.6483, Test Acc: 0.4722\n",
      "Epoch: 037, Loss: 0.6630, Train Acc: 0.6069, Test Acc: 0.5278\n",
      "Epoch: 038, Loss: 0.6910, Train Acc: 0.6552, Test Acc: 0.4167\n",
      "Epoch: 039, Loss: 0.6435, Train Acc: 0.6828, Test Acc: 0.4167\n",
      "Epoch: 040, Loss: 0.6335, Train Acc: 0.6690, Test Acc: 0.5000\n",
      "Epoch: 041, Loss: 0.7248, Train Acc: 0.6690, Test Acc: 0.4444\n",
      "Epoch: 042, Loss: 0.7095, Train Acc: 0.7034, Test Acc: 0.4444\n",
      "Epoch: 043, Loss: 0.6772, Train Acc: 0.6828, Test Acc: 0.4167\n",
      "Epoch: 044, Loss: 0.6171, Train Acc: 0.6414, Test Acc: 0.5833\n",
      "Epoch: 045, Loss: 0.6760, Train Acc: 0.7103, Test Acc: 0.4167\n",
      "Epoch: 046, Loss: 0.7332, Train Acc: 0.6621, Test Acc: 0.4444\n",
      "Epoch: 047, Loss: 0.6826, Train Acc: 0.6621, Test Acc: 0.5278\n",
      "Epoch: 048, Loss: 0.6403, Train Acc: 0.7034, Test Acc: 0.3889\n",
      "Epoch: 049, Loss: 0.6654, Train Acc: 0.7103, Test Acc: 0.4444\n",
      "Epoch: 050, Loss: 0.6232, Train Acc: 0.6828, Test Acc: 0.4444\n",
      "Epoch: 051, Loss: 0.6702, Train Acc: 0.6966, Test Acc: 0.4167\n",
      "Epoch: 052, Loss: 0.6092, Train Acc: 0.7172, Test Acc: 0.4167\n",
      "Epoch: 053, Loss: 0.5722, Train Acc: 0.6966, Test Acc: 0.4167\n",
      "Epoch: 054, Loss: 0.6754, Train Acc: 0.6621, Test Acc: 0.4444\n",
      "Epoch: 055, Loss: 0.6223, Train Acc: 0.6966, Test Acc: 0.4722\n",
      "Epoch: 056, Loss: 0.6094, Train Acc: 0.7241, Test Acc: 0.3889\n",
      "Epoch: 057, Loss: 0.6035, Train Acc: 0.7241, Test Acc: 0.4444\n",
      "Epoch: 058, Loss: 0.6166, Train Acc: 0.6690, Test Acc: 0.5000\n",
      "Epoch: 059, Loss: 0.6118, Train Acc: 0.7103, Test Acc: 0.4167\n",
      "Epoch: 060, Loss: 0.6328, Train Acc: 0.7172, Test Acc: 0.4167\n",
      "Epoch: 061, Loss: 0.6317, Train Acc: 0.7034, Test Acc: 0.4167\n",
      "Epoch: 062, Loss: 0.6524, Train Acc: 0.7655, Test Acc: 0.4167\n",
      "Epoch: 063, Loss: 0.5768, Train Acc: 0.7724, Test Acc: 0.4444\n",
      "Epoch: 064, Loss: 0.5953, Train Acc: 0.7379, Test Acc: 0.4167\n",
      "Epoch: 065, Loss: 0.6366, Train Acc: 0.7862, Test Acc: 0.4167\n",
      "Epoch: 066, Loss: 0.5663, Train Acc: 0.7931, Test Acc: 0.3889\n",
      "Epoch: 067, Loss: 0.6059, Train Acc: 0.7517, Test Acc: 0.3889\n",
      "Epoch: 068, Loss: 0.5615, Train Acc: 0.7103, Test Acc: 0.4444\n",
      "Epoch: 069, Loss: 0.6193, Train Acc: 0.8138, Test Acc: 0.4167\n",
      "Epoch: 070, Loss: 0.5930, Train Acc: 0.8345, Test Acc: 0.4167\n",
      "Epoch: 071, Loss: 0.6057, Train Acc: 0.7931, Test Acc: 0.4444\n",
      "Epoch: 072, Loss: 0.5351, Train Acc: 0.8138, Test Acc: 0.4722\n",
      "Epoch: 073, Loss: 0.4566, Train Acc: 0.8069, Test Acc: 0.4167\n",
      "Epoch: 074, Loss: 0.5687, Train Acc: 0.7793, Test Acc: 0.4444\n",
      "Epoch: 075, Loss: 0.5476, Train Acc: 0.7931, Test Acc: 0.4167\n",
      "Epoch: 076, Loss: 0.5781, Train Acc: 0.8069, Test Acc: 0.4167\n",
      "Epoch: 077, Loss: 0.5444, Train Acc: 0.8207, Test Acc: 0.3889\n",
      "Epoch: 078, Loss: 0.5549, Train Acc: 0.8483, Test Acc: 0.3889\n",
      "Epoch: 079, Loss: 0.5483, Train Acc: 0.8345, Test Acc: 0.4167\n",
      "Epoch: 080, Loss: 0.5712, Train Acc: 0.8207, Test Acc: 0.3889\n",
      "Epoch: 081, Loss: 0.5343, Train Acc: 0.8345, Test Acc: 0.3889\n",
      "Epoch: 082, Loss: 0.5432, Train Acc: 0.8552, Test Acc: 0.4444\n",
      "Epoch: 083, Loss: 0.5500, Train Acc: 0.8000, Test Acc: 0.4444\n",
      "Epoch: 084, Loss: 0.5418, Train Acc: 0.8276, Test Acc: 0.4167\n",
      "Epoch: 085, Loss: 0.5104, Train Acc: 0.8276, Test Acc: 0.4444\n",
      "Epoch: 086, Loss: 0.4834, Train Acc: 0.8621, Test Acc: 0.4444\n",
      "Epoch: 087, Loss: 0.4702, Train Acc: 0.8690, Test Acc: 0.4167\n",
      "Epoch: 088, Loss: 0.5122, Train Acc: 0.8621, Test Acc: 0.3889\n",
      "Epoch: 089, Loss: 0.5026, Train Acc: 0.8621, Test Acc: 0.4167\n",
      "Epoch: 090, Loss: 0.4692, Train Acc: 0.8759, Test Acc: 0.3889\n",
      "Epoch: 091, Loss: 0.3921, Train Acc: 0.8759, Test Acc: 0.4444\n",
      "Epoch: 092, Loss: 0.4404, Train Acc: 0.8621, Test Acc: 0.4444\n",
      "Epoch: 093, Loss: 0.4232, Train Acc: 0.8414, Test Acc: 0.4444\n",
      "Epoch: 094, Loss: 0.5639, Train Acc: 0.8759, Test Acc: 0.3611\n",
      "Epoch: 095, Loss: 0.4885, Train Acc: 0.8690, Test Acc: 0.4167\n",
      "Epoch: 096, Loss: 0.4477, Train Acc: 0.8690, Test Acc: 0.3889\n",
      "Epoch: 097, Loss: 0.4606, Train Acc: 0.8828, Test Acc: 0.3889\n",
      "Epoch: 098, Loss: 0.3943, Train Acc: 0.8828, Test Acc: 0.3889\n",
      "Epoch: 099, Loss: 0.4112, Train Acc: 0.8483, Test Acc: 0.4444\n",
      "Epoch: 100, Loss: 0.4161, Train Acc: 0.8966, Test Acc: 0.3889\n",
      "Epoch: 101, Loss: 0.3668, Train Acc: 0.8966, Test Acc: 0.3611\n",
      "Epoch: 102, Loss: 0.3898, Train Acc: 0.8414, Test Acc: 0.4444\n",
      "Epoch: 103, Loss: 0.3783, Train Acc: 0.8552, Test Acc: 0.4444\n",
      "Epoch: 104, Loss: 0.3749, Train Acc: 0.9172, Test Acc: 0.3889\n",
      "Epoch: 105, Loss: 0.3156, Train Acc: 0.8897, Test Acc: 0.4167\n",
      "Epoch: 106, Loss: 0.3874, Train Acc: 0.9034, Test Acc: 0.3611\n",
      "Epoch: 107, Loss: 0.3110, Train Acc: 0.9103, Test Acc: 0.3889\n",
      "Epoch: 108, Loss: 0.3309, Train Acc: 0.8966, Test Acc: 0.3889\n",
      "Epoch: 109, Loss: 0.2727, Train Acc: 0.9241, Test Acc: 0.4167\n",
      "Epoch: 110, Loss: 0.3411, Train Acc: 0.9172, Test Acc: 0.4167\n",
      "Epoch: 111, Loss: 0.2658, Train Acc: 0.9103, Test Acc: 0.3889\n",
      "Epoch: 112, Loss: 0.3048, Train Acc: 0.9379, Test Acc: 0.4167\n",
      "Epoch: 113, Loss: 0.2864, Train Acc: 0.9379, Test Acc: 0.4167\n",
      "Epoch: 114, Loss: 0.2812, Train Acc: 0.9172, Test Acc: 0.4167\n",
      "Epoch: 115, Loss: 0.2750, Train Acc: 0.9655, Test Acc: 0.3889\n",
      "Epoch: 116, Loss: 0.2455, Train Acc: 0.9586, Test Acc: 0.3889\n",
      "Epoch: 117, Loss: 0.2737, Train Acc: 0.8690, Test Acc: 0.3889\n",
      "Epoch: 118, Loss: 0.2439, Train Acc: 0.9310, Test Acc: 0.4167\n",
      "Epoch: 119, Loss: 0.2311, Train Acc: 0.9379, Test Acc: 0.4167\n",
      "Epoch: 120, Loss: 0.2604, Train Acc: 0.9586, Test Acc: 0.3611\n",
      "Epoch: 121, Loss: 0.2650, Train Acc: 0.9586, Test Acc: 0.3611\n",
      "Epoch: 122, Loss: 0.2171, Train Acc: 0.9586, Test Acc: 0.3889\n",
      "Epoch: 123, Loss: 0.2326, Train Acc: 0.9655, Test Acc: 0.3889\n",
      "Epoch: 124, Loss: 0.2266, Train Acc: 0.9724, Test Acc: 0.3889\n",
      "Epoch: 125, Loss: 0.1758, Train Acc: 0.9586, Test Acc: 0.4167\n",
      "Epoch: 126, Loss: 0.1690, Train Acc: 0.9655, Test Acc: 0.3889\n",
      "Epoch: 127, Loss: 0.2000, Train Acc: 0.9862, Test Acc: 0.3611\n",
      "Epoch: 128, Loss: 0.1925, Train Acc: 0.9793, Test Acc: 0.3611\n",
      "Epoch: 129, Loss: 0.1891, Train Acc: 0.9931, Test Acc: 0.3611\n",
      "Epoch: 130, Loss: 0.1693, Train Acc: 0.9793, Test Acc: 0.3889\n",
      "Epoch: 131, Loss: 0.2423, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 132, Loss: 0.1749, Train Acc: 0.9655, Test Acc: 0.4167\n",
      "Epoch: 133, Loss: 0.0846, Train Acc: 0.9724, Test Acc: 0.3889\n",
      "Epoch: 134, Loss: 0.1586, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 135, Loss: 0.1094, Train Acc: 0.9862, Test Acc: 0.4167\n",
      "Epoch: 136, Loss: 0.1700, Train Acc: 0.9448, Test Acc: 0.3889\n",
      "Epoch: 137, Loss: 0.2055, Train Acc: 0.9931, Test Acc: 0.3889\n",
      "Epoch: 138, Loss: 0.1192, Train Acc: 0.9931, Test Acc: 0.3889\n",
      "Epoch: 139, Loss: 0.0610, Train Acc: 1.0000, Test Acc: 0.3611\n",
      "Epoch: 140, Loss: 0.0825, Train Acc: 1.0000, Test Acc: 0.3611\n",
      "Epoch: 141, Loss: 0.0590, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 142, Loss: 0.0695, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 143, Loss: 0.0706, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 144, Loss: 0.0708, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 145, Loss: 0.0596, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 146, Loss: 0.0522, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 147, Loss: 0.0411, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "Epoch: 148, Loss: 0.0528, Train Acc: 1.0000, Test Acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149, Loss: 0.0688, Train Acc: 1.0000, Test Acc: 0.3889\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 108\n",
      " 109 140 142 144 145 146 147 148 149 150 151 154 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180] TEST: [107 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 141 143 152 153 155]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(6, 600)\n",
      "  (pool1): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (conv2): GraphConv(600, 600)\n",
      "  (pool2): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 6)\n",
      "  (lin1): Linear(in_features=1200, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 11.9231, Train Acc: 0.4690, Test Acc: 0.4722\n",
      "Epoch: 002, Loss: 29.8165, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 003, Loss: 45.5407, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 004, Loss: 45.0478, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 005, Loss: 44.3107, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 006, Loss: 44.2986, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 007, Loss: 43.1032, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 008, Loss: 41.9508, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 009, Loss: 40.3158, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 010, Loss: 41.6958, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 011, Loss: 40.1050, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 012, Loss: 40.7134, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 013, Loss: 42.2645, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 014, Loss: 35.8096, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 015, Loss: 38.5923, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 016, Loss: 39.8114, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 017, Loss: 41.7044, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 018, Loss: 39.3212, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 019, Loss: 38.4366, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 020, Loss: 39.3304, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 021, Loss: 40.5354, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 022, Loss: 41.9959, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 023, Loss: 36.6188, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 024, Loss: 36.3834, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 025, Loss: 38.1779, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 026, Loss: 40.9206, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 027, Loss: 38.4186, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 028, Loss: 38.3719, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 029, Loss: 38.5726, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 030, Loss: 35.5477, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 031, Loss: 41.5005, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 032, Loss: 40.8245, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 033, Loss: 36.9290, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 034, Loss: 34.1809, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 035, Loss: 37.6203, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 036, Loss: 41.0115, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 037, Loss: 37.4511, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 038, Loss: 38.8999, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 039, Loss: 37.4691, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 040, Loss: 39.5955, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 041, Loss: 35.6343, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 042, Loss: 36.0899, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 043, Loss: 36.0782, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 044, Loss: 34.0519, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 045, Loss: 36.6932, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 046, Loss: 37.5160, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 047, Loss: 40.7600, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 048, Loss: 36.7754, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 049, Loss: 38.0273, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 050, Loss: 38.7973, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 051, Loss: 36.0253, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 052, Loss: 34.7790, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 053, Loss: 36.7833, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 054, Loss: 36.8118, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 055, Loss: 37.3988, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 056, Loss: 35.2914, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 057, Loss: 36.0408, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 058, Loss: 35.9920, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 059, Loss: 33.3039, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 060, Loss: 37.3765, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 061, Loss: 38.1571, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 062, Loss: 36.0084, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 063, Loss: 38.0990, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 064, Loss: 38.1087, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 065, Loss: 40.8473, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 066, Loss: 35.3879, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 067, Loss: 36.6937, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 068, Loss: 36.6999, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 069, Loss: 39.4410, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 070, Loss: 35.3188, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 071, Loss: 41.4778, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 072, Loss: 35.3449, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 073, Loss: 39.4357, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 074, Loss: 38.7292, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 075, Loss: 38.8090, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 076, Loss: 36.7248, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 077, Loss: 40.1499, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 078, Loss: 35.3757, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 079, Loss: 33.2713, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 080, Loss: 36.6733, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 081, Loss: 35.9770, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 082, Loss: 33.9631, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 083, Loss: 37.4184, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 084, Loss: 38.7608, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 085, Loss: 38.0298, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 086, Loss: 36.7418, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 087, Loss: 36.0232, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 088, Loss: 41.4866, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 089, Loss: 40.8454, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 090, Loss: 37.4078, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 091, Loss: 38.0300, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 092, Loss: 37.3945, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 093, Loss: 33.9575, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 094, Loss: 40.1369, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 095, Loss: 41.4584, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 096, Loss: 37.4365, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 097, Loss: 38.7543, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 098, Loss: 38.7982, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 099, Loss: 37.4148, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 100, Loss: 37.3771, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 101, Loss: 38.0784, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 102, Loss: 36.7120, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 103, Loss: 38.0404, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 104, Loss: 35.3579, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 105, Loss: 36.0334, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 106, Loss: 34.6586, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 107, Loss: 39.4486, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 108, Loss: 36.0064, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 109, Loss: 38.0749, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 110, Loss: 39.4794, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 111, Loss: 36.0029, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 112, Loss: 37.3292, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 113, Loss: 36.6676, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 114, Loss: 38.0237, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 115, Loss: 38.0313, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 116, Loss: 36.6764, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 117, Loss: 36.6820, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 118, Loss: 36.6627, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 119, Loss: 37.3628, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 120, Loss: 32.5512, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 121, Loss: 36.0124, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 122, Loss: 38.7168, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 123, Loss: 34.6115, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 124, Loss: 35.3365, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 125, Loss: 40.7739, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 126, Loss: 38.0908, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 127, Loss: 33.2889, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 128, Loss: 40.0922, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 129, Loss: 39.4452, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 130, Loss: 38.0671, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 131, Loss: 38.7666, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 132, Loss: 37.3782, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 133, Loss: 34.6196, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 134, Loss: 34.6190, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 135, Loss: 32.5608, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 136, Loss: 38.7555, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 137, Loss: 37.4227, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 138, Loss: 40.1107, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 139, Loss: 38.7216, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 140, Loss: 34.6065, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 141, Loss: 38.7353, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 142, Loss: 38.0744, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 143, Loss: 38.7197, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 144, Loss: 39.4330, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 145, Loss: 36.0452, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 146, Loss: 38.0583, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 147, Loss: 35.9780, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 148, Loss: 36.7039, Train Acc: 0.5310, Test Acc: 0.5278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149, Loss: 35.2807, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 141 143 152 153\n",
      " 155] TEST: [140 142 144 145 146 147 148 149 150 151 154 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180]\n",
      "145\n",
      "36\n",
      "Net(\n",
      "  (conv1): GraphConv(6, 600)\n",
      "  (pool1): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (conv2): GraphConv(600, 600)\n",
      "  (pool2): SAGPooling(GraphConv, 600, ratio=0.1, multiplier=1.0)\n",
      "  (item_embedding): Embedding(101, 6)\n",
      "  (lin1): Linear(in_features=1200, out_features=500, bias=True)\n",
      "  (lin2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (lin3): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (act1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
      ")\n",
      "Epoch: 001, Loss: 3.3469, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 002, Loss: 20.6352, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 003, Loss: 29.6764, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 004, Loss: 26.1879, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 005, Loss: 21.8266, Train Acc: 0.4966, Test Acc: 0.5556\n",
      "Epoch: 006, Loss: 13.9932, Train Acc: 0.4966, Test Acc: 0.5278\n",
      "Epoch: 007, Loss: 3.1269, Train Acc: 0.4966, Test Acc: 0.5000\n",
      "Epoch: 008, Loss: 1.8266, Train Acc: 0.5931, Test Acc: 0.4444\n",
      "Epoch: 009, Loss: 1.3367, Train Acc: 0.4759, Test Acc: 0.4722\n",
      "Epoch: 010, Loss: 0.9796, Train Acc: 0.4897, Test Acc: 0.4722\n",
      "Epoch: 011, Loss: 0.8805, Train Acc: 0.5310, Test Acc: 0.4722\n",
      "Epoch: 012, Loss: 0.8771, Train Acc: 0.5310, Test Acc: 0.5278\n",
      "Epoch: 013, Loss: 0.7656, Train Acc: 0.5586, Test Acc: 0.4722\n",
      "Epoch: 014, Loss: 0.7120, Train Acc: 0.6000, Test Acc: 0.4444\n",
      "Epoch: 015, Loss: 0.6980, Train Acc: 0.6207, Test Acc: 0.5278\n",
      "Epoch: 016, Loss: 0.7731, Train Acc: 0.6414, Test Acc: 0.5278\n",
      "Epoch: 017, Loss: 0.7557, Train Acc: 0.5793, Test Acc: 0.5556\n",
      "Epoch: 018, Loss: 0.8163, Train Acc: 0.6345, Test Acc: 0.4722\n",
      "Epoch: 019, Loss: 0.7320, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 020, Loss: 0.7009, Train Acc: 0.6552, Test Acc: 0.5000\n",
      "Epoch: 021, Loss: 0.7286, Train Acc: 0.6345, Test Acc: 0.5833\n",
      "Epoch: 022, Loss: 0.6776, Train Acc: 0.6414, Test Acc: 0.5556\n",
      "Epoch: 023, Loss: 0.6745, Train Acc: 0.6552, Test Acc: 0.5278\n",
      "Epoch: 024, Loss: 0.6924, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 025, Loss: 0.7020, Train Acc: 0.6690, Test Acc: 0.5278\n",
      "Epoch: 026, Loss: 0.6633, Train Acc: 0.7103, Test Acc: 0.5556\n",
      "Epoch: 027, Loss: 0.7241, Train Acc: 0.6828, Test Acc: 0.5556\n",
      "Epoch: 028, Loss: 0.6741, Train Acc: 0.6897, Test Acc: 0.5278\n",
      "Epoch: 029, Loss: 0.7763, Train Acc: 0.6828, Test Acc: 0.5278\n",
      "Epoch: 030, Loss: 0.6589, Train Acc: 0.7172, Test Acc: 0.5278\n",
      "Epoch: 031, Loss: 0.6909, Train Acc: 0.6345, Test Acc: 0.5556\n",
      "Epoch: 032, Loss: 0.7003, Train Acc: 0.6552, Test Acc: 0.5833\n",
      "Epoch: 033, Loss: 0.6417, Train Acc: 0.6828, Test Acc: 0.5833\n",
      "Epoch: 034, Loss: 0.6874, Train Acc: 0.7241, Test Acc: 0.6111\n",
      "Epoch: 035, Loss: 0.6308, Train Acc: 0.6966, Test Acc: 0.5833\n",
      "Epoch: 036, Loss: 0.6709, Train Acc: 0.6690, Test Acc: 0.5278\n",
      "Epoch: 037, Loss: 0.6229, Train Acc: 0.7034, Test Acc: 0.5556\n",
      "Epoch: 038, Loss: 0.6631, Train Acc: 0.7103, Test Acc: 0.5833\n",
      "Epoch: 039, Loss: 0.6047, Train Acc: 0.6828, Test Acc: 0.5556\n",
      "Epoch: 040, Loss: 0.6436, Train Acc: 0.7241, Test Acc: 0.5278\n",
      "Epoch: 041, Loss: 0.7125, Train Acc: 0.6897, Test Acc: 0.5556\n",
      "Epoch: 042, Loss: 0.6700, Train Acc: 0.7172, Test Acc: 0.5556\n",
      "Epoch: 043, Loss: 0.6582, Train Acc: 0.6345, Test Acc: 0.5833\n",
      "Epoch: 044, Loss: 0.6459, Train Acc: 0.7172, Test Acc: 0.5556\n",
      "Epoch: 045, Loss: 0.6554, Train Acc: 0.6690, Test Acc: 0.5833\n",
      "Epoch: 046, Loss: 0.6160, Train Acc: 0.7517, Test Acc: 0.4444\n",
      "Epoch: 047, Loss: 0.6711, Train Acc: 0.7172, Test Acc: 0.4722\n",
      "Epoch: 048, Loss: 0.6487, Train Acc: 0.7517, Test Acc: 0.5278\n",
      "Epoch: 049, Loss: 0.6698, Train Acc: 0.7517, Test Acc: 0.5000\n",
      "Epoch: 050, Loss: 0.5920, Train Acc: 0.7517, Test Acc: 0.5000\n",
      "Epoch: 051, Loss: 0.6364, Train Acc: 0.7655, Test Acc: 0.5000\n",
      "Epoch: 052, Loss: 0.5994, Train Acc: 0.7448, Test Acc: 0.5278\n",
      "Epoch: 053, Loss: 0.6095, Train Acc: 0.7310, Test Acc: 0.5000\n",
      "Epoch: 054, Loss: 0.6220, Train Acc: 0.7586, Test Acc: 0.5000\n",
      "Epoch: 055, Loss: 0.6358, Train Acc: 0.7103, Test Acc: 0.4722\n",
      "Epoch: 056, Loss: 0.6063, Train Acc: 0.7586, Test Acc: 0.5556\n",
      "Epoch: 057, Loss: 0.5978, Train Acc: 0.7793, Test Acc: 0.5556\n",
      "Epoch: 058, Loss: 0.5655, Train Acc: 0.7034, Test Acc: 0.5833\n",
      "Epoch: 059, Loss: 0.6051, Train Acc: 0.7517, Test Acc: 0.4722\n",
      "Epoch: 060, Loss: 0.5698, Train Acc: 0.7793, Test Acc: 0.5278\n",
      "Epoch: 061, Loss: 0.6139, Train Acc: 0.7724, Test Acc: 0.5278\n",
      "Epoch: 062, Loss: 0.5525, Train Acc: 0.8000, Test Acc: 0.5278\n",
      "Epoch: 063, Loss: 0.5866, Train Acc: 0.8000, Test Acc: 0.5278\n",
      "Epoch: 064, Loss: 0.5943, Train Acc: 0.8000, Test Acc: 0.5278\n",
      "Epoch: 065, Loss: 0.5235, Train Acc: 0.8069, Test Acc: 0.5278\n",
      "Epoch: 066, Loss: 0.5195, Train Acc: 0.7793, Test Acc: 0.5833\n",
      "Epoch: 067, Loss: 0.5503, Train Acc: 0.8207, Test Acc: 0.5556\n",
      "Epoch: 068, Loss: 0.5035, Train Acc: 0.8207, Test Acc: 0.5000\n",
      "Epoch: 069, Loss: 0.5821, Train Acc: 0.8069, Test Acc: 0.5556\n",
      "Epoch: 070, Loss: 0.5092, Train Acc: 0.8414, Test Acc: 0.5278\n",
      "Epoch: 071, Loss: 0.5601, Train Acc: 0.8138, Test Acc: 0.5000\n",
      "Epoch: 072, Loss: 0.6017, Train Acc: 0.8276, Test Acc: 0.5000\n",
      "Epoch: 073, Loss: 0.5231, Train Acc: 0.8483, Test Acc: 0.5556\n",
      "Epoch: 074, Loss: 0.5768, Train Acc: 0.8000, Test Acc: 0.5278\n",
      "Epoch: 075, Loss: 0.4790, Train Acc: 0.8552, Test Acc: 0.5000\n",
      "Epoch: 076, Loss: 0.5306, Train Acc: 0.7655, Test Acc: 0.5556\n",
      "Epoch: 077, Loss: 0.6143, Train Acc: 0.8207, Test Acc: 0.5278\n",
      "Epoch: 078, Loss: 0.5443, Train Acc: 0.7655, Test Acc: 0.5278\n",
      "Epoch: 079, Loss: 0.6116, Train Acc: 0.7448, Test Acc: 0.5278\n",
      "Epoch: 080, Loss: 0.5039, Train Acc: 0.7793, Test Acc: 0.5556\n",
      "Epoch: 081, Loss: 0.5202, Train Acc: 0.8000, Test Acc: 0.5000\n",
      "Epoch: 082, Loss: 0.5379, Train Acc: 0.7793, Test Acc: 0.5278\n",
      "Epoch: 083, Loss: 0.4939, Train Acc: 0.7793, Test Acc: 0.5556\n",
      "Epoch: 084, Loss: 0.5188, Train Acc: 0.7862, Test Acc: 0.5278\n",
      "Epoch: 085, Loss: 0.5196, Train Acc: 0.8138, Test Acc: 0.5000\n",
      "Epoch: 086, Loss: 0.4438, Train Acc: 0.8207, Test Acc: 0.5556\n",
      "Epoch: 087, Loss: 0.5005, Train Acc: 0.8069, Test Acc: 0.5000\n",
      "Epoch: 088, Loss: 0.5440, Train Acc: 0.8138, Test Acc: 0.5556\n",
      "Epoch: 089, Loss: 0.4170, Train Acc: 0.8069, Test Acc: 0.5556\n",
      "Epoch: 090, Loss: 0.5240, Train Acc: 0.8759, Test Acc: 0.5000\n",
      "Epoch: 091, Loss: 0.4354, Train Acc: 0.8552, Test Acc: 0.5278\n",
      "Epoch: 092, Loss: 0.4258, Train Acc: 0.8276, Test Acc: 0.5278\n",
      "Epoch: 093, Loss: 0.4548, Train Acc: 0.8483, Test Acc: 0.5278\n",
      "Epoch: 094, Loss: 0.4004, Train Acc: 0.8759, Test Acc: 0.5833\n",
      "Epoch: 095, Loss: 0.3930, Train Acc: 0.8828, Test Acc: 0.5278\n",
      "Epoch: 096, Loss: 0.3857, Train Acc: 0.8828, Test Acc: 0.5000\n",
      "Epoch: 097, Loss: 0.3798, Train Acc: 0.8897, Test Acc: 0.5556\n",
      "Epoch: 098, Loss: 0.4258, Train Acc: 0.8897, Test Acc: 0.5833\n",
      "Epoch: 099, Loss: 0.3654, Train Acc: 0.8207, Test Acc: 0.5556\n",
      "Epoch: 100, Loss: 0.3923, Train Acc: 0.8966, Test Acc: 0.5833\n",
      "Epoch: 101, Loss: 0.4033, Train Acc: 0.8690, Test Acc: 0.5000\n",
      "Epoch: 102, Loss: 0.4106, Train Acc: 0.8966, Test Acc: 0.5278\n",
      "Epoch: 103, Loss: 0.3335, Train Acc: 0.8828, Test Acc: 0.5833\n",
      "Epoch: 104, Loss: 0.4128, Train Acc: 0.8759, Test Acc: 0.5556\n",
      "Epoch: 105, Loss: 0.3313, Train Acc: 0.8897, Test Acc: 0.5556\n",
      "Epoch: 106, Loss: 0.3327, Train Acc: 0.8828, Test Acc: 0.5000\n",
      "Epoch: 107, Loss: 0.3949, Train Acc: 0.8621, Test Acc: 0.5278\n",
      "Epoch: 108, Loss: 0.3095, Train Acc: 0.9172, Test Acc: 0.5000\n",
      "Epoch: 109, Loss: 0.3488, Train Acc: 0.9517, Test Acc: 0.5278\n",
      "Epoch: 110, Loss: 0.2828, Train Acc: 0.9310, Test Acc: 0.5278\n",
      "Epoch: 111, Loss: 0.2662, Train Acc: 0.8828, Test Acc: 0.5833\n",
      "Epoch: 112, Loss: 0.3288, Train Acc: 0.8966, Test Acc: 0.5278\n",
      "Epoch: 113, Loss: 0.3210, Train Acc: 0.9379, Test Acc: 0.5833\n",
      "Epoch: 114, Loss: 0.3168, Train Acc: 0.9379, Test Acc: 0.5278\n",
      "Epoch: 115, Loss: 0.2874, Train Acc: 0.9517, Test Acc: 0.5000\n",
      "Epoch: 116, Loss: 0.2524, Train Acc: 0.9310, Test Acc: 0.5000\n",
      "Epoch: 117, Loss: 0.2393, Train Acc: 0.9655, Test Acc: 0.5556\n",
      "Epoch: 118, Loss: 0.1963, Train Acc: 0.9586, Test Acc: 0.5000\n",
      "Epoch: 119, Loss: 0.2000, Train Acc: 0.9724, Test Acc: 0.5278\n",
      "Epoch: 120, Loss: 0.2266, Train Acc: 0.9655, Test Acc: 0.5000\n",
      "Epoch: 121, Loss: 0.1896, Train Acc: 0.9862, Test Acc: 0.5000\n",
      "Epoch: 122, Loss: 0.1941, Train Acc: 0.9517, Test Acc: 0.5278\n",
      "Epoch: 123, Loss: 0.2043, Train Acc: 0.9793, Test Acc: 0.5556\n",
      "Epoch: 124, Loss: 0.2146, Train Acc: 0.9517, Test Acc: 0.4722\n",
      "Epoch: 125, Loss: 0.2251, Train Acc: 0.9724, Test Acc: 0.4722\n",
      "Epoch: 126, Loss: 0.1664, Train Acc: 0.9655, Test Acc: 0.5278\n",
      "Epoch: 127, Loss: 0.1868, Train Acc: 0.9931, Test Acc: 0.5000\n",
      "Epoch: 128, Loss: 0.1494, Train Acc: 0.9931, Test Acc: 0.5278\n",
      "Epoch: 129, Loss: 0.1478, Train Acc: 0.9931, Test Acc: 0.5000\n",
      "Epoch: 130, Loss: 0.1487, Train Acc: 0.9931, Test Acc: 0.5278\n",
      "Epoch: 131, Loss: 0.1414, Train Acc: 0.9931, Test Acc: 0.5278\n",
      "Epoch: 132, Loss: 0.1094, Train Acc: 1.0000, Test Acc: 0.5556\n",
      "Epoch: 133, Loss: 0.1280, Train Acc: 0.9517, Test Acc: 0.5278\n",
      "Epoch: 134, Loss: 0.2606, Train Acc: 0.9655, Test Acc: 0.5000\n",
      "Epoch: 135, Loss: 0.1505, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "Epoch: 136, Loss: 0.1267, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "Epoch: 137, Loss: 0.0920, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "Epoch: 138, Loss: 0.1261, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "Epoch: 139, Loss: 0.1029, Train Acc: 1.0000, Test Acc: 0.5556\n",
      "Epoch: 140, Loss: 0.0906, Train Acc: 1.0000, Test Acc: 0.5556\n",
      "Epoch: 141, Loss: 0.0962, Train Acc: 0.9862, Test Acc: 0.5278\n",
      "Epoch: 142, Loss: 0.1359, Train Acc: 0.9931, Test Acc: 0.5278\n",
      "Epoch: 143, Loss: 0.0964, Train Acc: 1.0000, Test Acc: 0.5278\n",
      "Epoch: 144, Loss: 0.0902, Train Acc: 1.0000, Test Acc: 0.5556\n",
      "Epoch: 145, Loss: 0.0728, Train Acc: 0.9931, Test Acc: 0.5556\n",
      "Epoch: 146, Loss: 0.1163, Train Acc: 0.9931, Test Acc: 0.5833\n",
      "Epoch: 147, Loss: 0.0833, Train Acc: 0.9931, Test Acc: 0.5278\n",
      "Epoch: 148, Loss: 0.0677, Train Acc: 1.0000, Test Acc: 0.5278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149, Loss: 0.0904, Train Acc: 0.9931, Test Acc: 0.5556\n",
      "Test accuracy: 0.5246246246246246\n",
      "Test stv: 0.0702590401950206\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "test_avg = []\n",
    "for train_index, test_index in kf.split(total_data, Y):\n",
    "    train_dataset=[]\n",
    "    test_dataset=[]\n",
    "    print(\"TRAIN: \", train_index, \"TEST:\", test_index)\n",
    "    for i in train_index:\n",
    "        train_dataset.append(total_data[i])\n",
    "    for i in test_index:\n",
    "        test_dataset.append(total_data[i])\n",
    "\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dataset))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    model = Net(dim=600)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
    "    # optimizer = torch.optim.Adadelta(model.parameters(), lr=0.7) # 35 epochs\n",
    "\n",
    "    train_epoch=[]\n",
    "    test_epoch=[]\n",
    "    epoch = 1\n",
    "    train_acc=0\n",
    "    while epoch < 150:\n",
    "        loss = train(epoch)\n",
    "        train_acc = test(train_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        train_epoch.append(train_acc)\n",
    "        test_epoch.append(test_acc)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "            f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        epoch +=1\n",
    "\n",
    "    plt.plot(train_epoch, color=\"red\")\n",
    "    plt.plot(test_epoch, color=\"blue\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    test_avg.append(test_acc)\n",
    "\n",
    "print('Test accuracy: '+ str(np.array(test_avg).mean()))\n",
    "print('Test stv: '+ str(np.array(test_avg).std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
