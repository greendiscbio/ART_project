{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gene matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARAP1</th>\n",
       "      <th>CUL3</th>\n",
       "      <th>DLGAP4</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>FPR2</th>\n",
       "      <th>GJA9</th>\n",
       "      <th>GPR155</th>\n",
       "      <th>GRB2</th>\n",
       "      <th>IL25</th>\n",
       "      <th>KLHL5</th>\n",
       "      <th>...</th>\n",
       "      <th>RNF123</th>\n",
       "      <th>RNPS1</th>\n",
       "      <th>SDR42E1</th>\n",
       "      <th>SRPK2</th>\n",
       "      <th>TARBP2</th>\n",
       "      <th>TRIM25</th>\n",
       "      <th>TRIM43B</th>\n",
       "      <th>UBC</th>\n",
       "      <th>USP31</th>\n",
       "      <th>XPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.778072</td>\n",
       "      <td>32.41114</td>\n",
       "      <td>34.54982</td>\n",
       "      <td>34.66442</td>\n",
       "      <td>23.31461</td>\n",
       "      <td>29.68286</td>\n",
       "      <td>31.81161</td>\n",
       "      <td>35.06760</td>\n",
       "      <td>21.08036</td>\n",
       "      <td>33.45578</td>\n",
       "      <td>...</td>\n",
       "      <td>33.24403</td>\n",
       "      <td>34.71048</td>\n",
       "      <td>30.26124</td>\n",
       "      <td>32.20619</td>\n",
       "      <td>29.60417</td>\n",
       "      <td>32.61049</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>39.76191</td>\n",
       "      <td>32.00348</td>\n",
       "      <td>32.24472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.137558</td>\n",
       "      <td>33.78153</td>\n",
       "      <td>34.06647</td>\n",
       "      <td>35.04555</td>\n",
       "      <td>26.77815</td>\n",
       "      <td>26.80539</td>\n",
       "      <td>31.42781</td>\n",
       "      <td>34.56841</td>\n",
       "      <td>21.08036</td>\n",
       "      <td>34.03090</td>\n",
       "      <td>...</td>\n",
       "      <td>32.93945</td>\n",
       "      <td>34.56276</td>\n",
       "      <td>29.12730</td>\n",
       "      <td>32.73181</td>\n",
       "      <td>29.61188</td>\n",
       "      <td>33.35035</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>40.32706</td>\n",
       "      <td>32.11090</td>\n",
       "      <td>32.15619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.240182</td>\n",
       "      <td>34.25556</td>\n",
       "      <td>34.42561</td>\n",
       "      <td>35.03537</td>\n",
       "      <td>31.33380</td>\n",
       "      <td>30.09292</td>\n",
       "      <td>30.47292</td>\n",
       "      <td>36.01318</td>\n",
       "      <td>21.08036</td>\n",
       "      <td>31.97097</td>\n",
       "      <td>...</td>\n",
       "      <td>33.15722</td>\n",
       "      <td>34.41174</td>\n",
       "      <td>27.22907</td>\n",
       "      <td>34.06143</td>\n",
       "      <td>31.90343</td>\n",
       "      <td>34.11570</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>40.85312</td>\n",
       "      <td>30.98575</td>\n",
       "      <td>31.86536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.077602</td>\n",
       "      <td>33.82623</td>\n",
       "      <td>34.41176</td>\n",
       "      <td>35.12911</td>\n",
       "      <td>29.45497</td>\n",
       "      <td>29.29223</td>\n",
       "      <td>30.72903</td>\n",
       "      <td>35.21336</td>\n",
       "      <td>21.08036</td>\n",
       "      <td>33.79569</td>\n",
       "      <td>...</td>\n",
       "      <td>32.99944</td>\n",
       "      <td>34.57809</td>\n",
       "      <td>22.83731</td>\n",
       "      <td>32.88583</td>\n",
       "      <td>30.35424</td>\n",
       "      <td>32.61024</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>40.33974</td>\n",
       "      <td>32.36353</td>\n",
       "      <td>31.63561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.663076</td>\n",
       "      <td>34.87586</td>\n",
       "      <td>34.29088</td>\n",
       "      <td>35.68321</td>\n",
       "      <td>23.31461</td>\n",
       "      <td>32.00382</td>\n",
       "      <td>31.16114</td>\n",
       "      <td>35.37475</td>\n",
       "      <td>21.08036</td>\n",
       "      <td>33.87798</td>\n",
       "      <td>...</td>\n",
       "      <td>34.04944</td>\n",
       "      <td>35.57754</td>\n",
       "      <td>22.83731</td>\n",
       "      <td>33.61440</td>\n",
       "      <td>31.60946</td>\n",
       "      <td>34.02714</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>40.28643</td>\n",
       "      <td>30.43196</td>\n",
       "      <td>33.12717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>33.121350</td>\n",
       "      <td>33.71060</td>\n",
       "      <td>34.55658</td>\n",
       "      <td>35.90468</td>\n",
       "      <td>27.77094</td>\n",
       "      <td>28.18967</td>\n",
       "      <td>29.90347</td>\n",
       "      <td>34.04756</td>\n",
       "      <td>21.43715</td>\n",
       "      <td>33.24384</td>\n",
       "      <td>...</td>\n",
       "      <td>34.15189</td>\n",
       "      <td>34.93992</td>\n",
       "      <td>31.49914</td>\n",
       "      <td>33.87853</td>\n",
       "      <td>31.57179</td>\n",
       "      <td>33.28910</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>39.58054</td>\n",
       "      <td>32.00141</td>\n",
       "      <td>32.70183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>35.264000</td>\n",
       "      <td>34.89118</td>\n",
       "      <td>33.15506</td>\n",
       "      <td>33.23884</td>\n",
       "      <td>29.99632</td>\n",
       "      <td>28.18967</td>\n",
       "      <td>31.66030</td>\n",
       "      <td>35.28814</td>\n",
       "      <td>21.43715</td>\n",
       "      <td>33.77807</td>\n",
       "      <td>...</td>\n",
       "      <td>31.75215</td>\n",
       "      <td>32.95477</td>\n",
       "      <td>28.17083</td>\n",
       "      <td>33.39445</td>\n",
       "      <td>34.36199</td>\n",
       "      <td>31.41810</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>38.08709</td>\n",
       "      <td>31.32892</td>\n",
       "      <td>30.79817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>33.777504</td>\n",
       "      <td>33.46728</td>\n",
       "      <td>34.68047</td>\n",
       "      <td>35.20723</td>\n",
       "      <td>29.69215</td>\n",
       "      <td>28.18967</td>\n",
       "      <td>31.92039</td>\n",
       "      <td>35.31580</td>\n",
       "      <td>21.43715</td>\n",
       "      <td>34.28987</td>\n",
       "      <td>...</td>\n",
       "      <td>34.11156</td>\n",
       "      <td>34.49169</td>\n",
       "      <td>24.22162</td>\n",
       "      <td>33.68642</td>\n",
       "      <td>29.30238</td>\n",
       "      <td>33.33372</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>40.76723</td>\n",
       "      <td>31.34410</td>\n",
       "      <td>32.60750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>33.922628</td>\n",
       "      <td>33.03798</td>\n",
       "      <td>35.60014</td>\n",
       "      <td>36.44440</td>\n",
       "      <td>21.88688</td>\n",
       "      <td>33.92530</td>\n",
       "      <td>32.78760</td>\n",
       "      <td>34.28260</td>\n",
       "      <td>21.43715</td>\n",
       "      <td>33.32866</td>\n",
       "      <td>...</td>\n",
       "      <td>33.48454</td>\n",
       "      <td>34.69895</td>\n",
       "      <td>27.21929</td>\n",
       "      <td>32.93499</td>\n",
       "      <td>30.72343</td>\n",
       "      <td>33.89416</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>40.23050</td>\n",
       "      <td>32.39718</td>\n",
       "      <td>33.35291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>34.476238</td>\n",
       "      <td>33.69790</td>\n",
       "      <td>35.23053</td>\n",
       "      <td>35.08417</td>\n",
       "      <td>30.58610</td>\n",
       "      <td>28.18967</td>\n",
       "      <td>30.59097</td>\n",
       "      <td>35.48037</td>\n",
       "      <td>21.43715</td>\n",
       "      <td>32.59490</td>\n",
       "      <td>...</td>\n",
       "      <td>33.91647</td>\n",
       "      <td>35.45342</td>\n",
       "      <td>32.08324</td>\n",
       "      <td>33.64248</td>\n",
       "      <td>31.34356</td>\n",
       "      <td>33.56210</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>41.07595</td>\n",
       "      <td>32.88592</td>\n",
       "      <td>32.50118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ARAP1      CUL3    DLGAP4      EGFR      FPR2      GJA9    GPR155  \\\n",
       "0    34.778072  32.41114  34.54982  34.66442  23.31461  29.68286  31.81161   \n",
       "1    34.137558  33.78153  34.06647  35.04555  26.77815  26.80539  31.42781   \n",
       "2    34.240182  34.25556  34.42561  35.03537  31.33380  30.09292  30.47292   \n",
       "3    34.077602  33.82623  34.41176  35.12911  29.45497  29.29223  30.72903   \n",
       "4    34.663076  34.87586  34.29088  35.68321  23.31461  32.00382  31.16114   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "176  33.121350  33.71060  34.55658  35.90468  27.77094  28.18967  29.90347   \n",
       "177  35.264000  34.89118  33.15506  33.23884  29.99632  28.18967  31.66030   \n",
       "178  33.777504  33.46728  34.68047  35.20723  29.69215  28.18967  31.92039   \n",
       "179  33.922628  33.03798  35.60014  36.44440  21.88688  33.92530  32.78760   \n",
       "180  34.476238  33.69790  35.23053  35.08417  30.58610  28.18967  30.59097   \n",
       "\n",
       "         GRB2      IL25     KLHL5  ...    RNF123     RNPS1   SDR42E1  \\\n",
       "0    35.06760  21.08036  33.45578  ...  33.24403  34.71048  30.26124   \n",
       "1    34.56841  21.08036  34.03090  ...  32.93945  34.56276  29.12730   \n",
       "2    36.01318  21.08036  31.97097  ...  33.15722  34.41174  27.22907   \n",
       "3    35.21336  21.08036  33.79569  ...  32.99944  34.57809  22.83731   \n",
       "4    35.37475  21.08036  33.87798  ...  34.04944  35.57754  22.83731   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  34.04756  21.43715  33.24384  ...  34.15189  34.93992  31.49914   \n",
       "177  35.28814  21.43715  33.77807  ...  31.75215  32.95477  28.17083   \n",
       "178  35.31580  21.43715  34.28987  ...  34.11156  34.49169  24.22162   \n",
       "179  34.28260  21.43715  33.32866  ...  33.48454  34.69895  27.21929   \n",
       "180  35.48037  21.43715  32.59490  ...  33.91647  35.45342  32.08324   \n",
       "\n",
       "        SRPK2    TARBP2    TRIM25  TRIM43B       UBC     USP31       XPC  \n",
       "0    32.20619  29.60417  32.61049  21.9744  39.76191  32.00348  32.24472  \n",
       "1    32.73181  29.61188  33.35035  21.9744  40.32706  32.11090  32.15619  \n",
       "2    34.06143  31.90343  34.11570  21.9744  40.85312  30.98575  31.86536  \n",
       "3    32.88583  30.35424  32.61024  21.9744  40.33974  32.36353  31.63561  \n",
       "4    33.61440  31.60946  34.02714  21.9744  40.28643  30.43196  33.12717  \n",
       "..        ...       ...       ...      ...       ...       ...       ...  \n",
       "176  33.87853  31.57179  33.28910  22.3863  39.58054  32.00141  32.70183  \n",
       "177  33.39445  34.36199  31.41810  22.3863  38.08709  31.32892  30.79817  \n",
       "178  33.68642  29.30238  33.33372  22.3863  40.76723  31.34410  32.60750  \n",
       "179  32.93499  30.72343  33.89416  22.3863  40.23050  32.39718  33.35291  \n",
       "180  33.64248  31.34356  33.56210  22.3863  41.07595  32.88592  32.50118  \n",
       "\n",
       "[181 rows x 25 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = pd.read_csv('../Biogrid/Data/mrcc_protein_matrix.csv')\n",
    "Y = genes.Y\n",
    "\n",
    "genes = genes.iloc[:,1:26] \n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARAP1</th>\n",
       "      <th>CUL3</th>\n",
       "      <th>DLGAP4</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>FPR2</th>\n",
       "      <th>GJA9</th>\n",
       "      <th>GPR155</th>\n",
       "      <th>GRB2</th>\n",
       "      <th>IL25</th>\n",
       "      <th>KLHL5</th>\n",
       "      <th>...</th>\n",
       "      <th>RNF123</th>\n",
       "      <th>RNPS1</th>\n",
       "      <th>SDR42E1</th>\n",
       "      <th>SRPK2</th>\n",
       "      <th>TARBP2</th>\n",
       "      <th>TRIM25</th>\n",
       "      <th>TRIM43B</th>\n",
       "      <th>UBC</th>\n",
       "      <th>USP31</th>\n",
       "      <th>XPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.664135</td>\n",
       "      <td>0.283275</td>\n",
       "      <td>0.460202</td>\n",
       "      <td>0.448186</td>\n",
       "      <td>0.388440</td>\n",
       "      <td>0.635056</td>\n",
       "      <td>0.633846</td>\n",
       "      <td>0.503390</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.545698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421257</td>\n",
       "      <td>0.637742</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.203042</td>\n",
       "      <td>0.593083</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.438217</td>\n",
       "      <td>0.704605</td>\n",
       "      <td>0.395122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512746</td>\n",
       "      <td>0.679314</td>\n",
       "      <td>0.314008</td>\n",
       "      <td>0.513990</td>\n",
       "      <td>0.620794</td>\n",
       "      <td>0.424069</td>\n",
       "      <td>0.551284</td>\n",
       "      <td>0.371816</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.714264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335253</td>\n",
       "      <td>0.594837</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.358760</td>\n",
       "      <td>0.593743</td>\n",
       "      <td>0.511822</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.560259</td>\n",
       "      <td>0.725331</td>\n",
       "      <td>0.370940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537002</td>\n",
       "      <td>0.816308</td>\n",
       "      <td>0.422634</td>\n",
       "      <td>0.512233</td>\n",
       "      <td>0.926412</td>\n",
       "      <td>0.665123</td>\n",
       "      <td>0.345871</td>\n",
       "      <td>0.752620</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.110506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396744</td>\n",
       "      <td>0.550974</td>\n",
       "      <td>0.549992</td>\n",
       "      <td>0.752668</td>\n",
       "      <td>0.789730</td>\n",
       "      <td>0.714551</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.673860</td>\n",
       "      <td>0.508236</td>\n",
       "      <td>0.291501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498575</td>\n",
       "      <td>0.692232</td>\n",
       "      <td>0.418445</td>\n",
       "      <td>0.528417</td>\n",
       "      <td>0.800370</td>\n",
       "      <td>0.606413</td>\n",
       "      <td>0.400965</td>\n",
       "      <td>0.541808</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.645324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352193</td>\n",
       "      <td>0.599290</td>\n",
       "      <td>0.201863</td>\n",
       "      <td>0.404389</td>\n",
       "      <td>0.657234</td>\n",
       "      <td>0.315779</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.562997</td>\n",
       "      <td>0.774076</td>\n",
       "      <td>0.228745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.636955</td>\n",
       "      <td>0.995573</td>\n",
       "      <td>0.381883</td>\n",
       "      <td>0.624086</td>\n",
       "      <td>0.388440</td>\n",
       "      <td>0.805237</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.584346</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.669443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648677</td>\n",
       "      <td>0.889578</td>\n",
       "      <td>0.201863</td>\n",
       "      <td>0.620233</td>\n",
       "      <td>0.764588</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.551485</td>\n",
       "      <td>0.401383</td>\n",
       "      <td>0.636162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.272560</td>\n",
       "      <td>0.658816</td>\n",
       "      <td>0.462247</td>\n",
       "      <td>0.662324</td>\n",
       "      <td>0.687396</td>\n",
       "      <td>0.525569</td>\n",
       "      <td>0.223373</td>\n",
       "      <td>0.234533</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.483579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677606</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>0.888474</td>\n",
       "      <td>0.698483</td>\n",
       "      <td>0.761366</td>\n",
       "      <td>0.495598</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.399050</td>\n",
       "      <td>0.704205</td>\n",
       "      <td>0.519981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.778986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>0.202051</td>\n",
       "      <td>0.836686</td>\n",
       "      <td>0.525569</td>\n",
       "      <td>0.601296</td>\n",
       "      <td>0.561518</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.640160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.624643</td>\n",
       "      <td>0.555071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.076545</td>\n",
       "      <td>0.574450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.427645</td>\n",
       "      <td>0.588497</td>\n",
       "      <td>0.499719</td>\n",
       "      <td>0.541905</td>\n",
       "      <td>0.816281</td>\n",
       "      <td>0.525569</td>\n",
       "      <td>0.657246</td>\n",
       "      <td>0.568809</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.790167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666218</td>\n",
       "      <td>0.574195</td>\n",
       "      <td>0.311595</td>\n",
       "      <td>0.641569</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>0.507417</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.655312</td>\n",
       "      <td>0.577379</td>\n",
       "      <td>0.494215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.461946</td>\n",
       "      <td>0.464430</td>\n",
       "      <td>0.777882</td>\n",
       "      <td>0.755510</td>\n",
       "      <td>0.292661</td>\n",
       "      <td>0.946128</td>\n",
       "      <td>0.843797</td>\n",
       "      <td>0.296484</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489168</td>\n",
       "      <td>0.634393</td>\n",
       "      <td>0.549216</td>\n",
       "      <td>0.418953</td>\n",
       "      <td>0.688809</td>\n",
       "      <td>0.655868</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.539407</td>\n",
       "      <td>0.780568</td>\n",
       "      <td>0.697822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.592795</td>\n",
       "      <td>0.655145</td>\n",
       "      <td>0.666090</td>\n",
       "      <td>0.520658</td>\n",
       "      <td>0.876252</td>\n",
       "      <td>0.525569</td>\n",
       "      <td>0.371266</td>\n",
       "      <td>0.612185</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.293377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611131</td>\n",
       "      <td>0.853527</td>\n",
       "      <td>0.934775</td>\n",
       "      <td>0.628551</td>\n",
       "      <td>0.741846</td>\n",
       "      <td>0.567911</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.721979</td>\n",
       "      <td>0.874870</td>\n",
       "      <td>0.465174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ARAP1      CUL3    DLGAP4      EGFR      FPR2      GJA9    GPR155  \\\n",
       "0    0.664135  0.283275  0.460202  0.448186  0.388440  0.635056  0.633846   \n",
       "1    0.512746  0.679314  0.314008  0.513990  0.620794  0.424069  0.551284   \n",
       "2    0.537002  0.816308  0.422634  0.512233  0.926412  0.665123  0.345871   \n",
       "3    0.498575  0.692232  0.418445  0.528417  0.800370  0.606413  0.400965   \n",
       "4    0.636955  0.995573  0.381883  0.624086  0.388440  0.805237  0.493919   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  0.272560  0.658816  0.462247  0.662324  0.687396  0.525569  0.223373   \n",
       "177  0.778986  1.000000  0.038343  0.202051  0.836686  0.525569  0.601296   \n",
       "178  0.427645  0.588497  0.499719  0.541905  0.816281  0.525569  0.657246   \n",
       "179  0.461946  0.464430  0.777882  0.755510  0.292661  0.946128  0.843797   \n",
       "180  0.592795  0.655145  0.666090  0.520658  0.876252  0.525569  0.371266   \n",
       "\n",
       "         GRB2      IL25     KLHL5  ...    RNF123     RNPS1   SDR42E1  \\\n",
       "0    0.503390  0.021832  0.545698  ...  0.421257  0.637742  0.790347   \n",
       "1    0.371816  0.021832  0.714264  ...  0.335253  0.594837  0.700462   \n",
       "2    0.752620  0.021832  0.110506  ...  0.396744  0.550974  0.549992   \n",
       "3    0.541808  0.021832  0.645324  ...  0.352193  0.599290  0.201863   \n",
       "4    0.584346  0.021832  0.669443  ...  0.648677  0.889578  0.201863   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "176  0.234533  0.059321  0.483579  ...  0.677606  0.704382  0.888474   \n",
       "177  0.561518  0.059321  0.640160  ...  0.000000  0.127800  0.624643   \n",
       "178  0.568809  0.059321  0.790167  ...  0.666218  0.574195  0.311595   \n",
       "179  0.296484  0.059321  0.508440  ...  0.489168  0.634393  0.549216   \n",
       "180  0.612185  0.059321  0.293377  ...  0.611131  0.853527  0.934775   \n",
       "\n",
       "        SRPK2    TARBP2    TRIM25   TRIM43B       UBC     USP31       XPC  \n",
       "0    0.203042  0.593083  0.315845  0.077107  0.438217  0.704605  0.395122  \n",
       "1    0.358760  0.593743  0.511822  0.077107  0.560259  0.725331  0.370940  \n",
       "2    0.752668  0.789730  0.714551  0.077107  0.673860  0.508236  0.291501  \n",
       "3    0.404389  0.657234  0.315779  0.077107  0.562997  0.774076  0.228745  \n",
       "4    0.620233  0.764588  0.691092  0.077107  0.551485  0.401383  0.636162  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "176  0.698483  0.761366  0.495598  0.101726  0.399050  0.704205  0.519981  \n",
       "177  0.555071  1.000000  0.000000  0.101726  0.076545  0.574450  0.000000  \n",
       "178  0.641569  0.567273  0.507417  0.101726  0.655312  0.577379  0.494215  \n",
       "179  0.418953  0.688809  0.655868  0.101726  0.539407  0.780568  0.697822  \n",
       "180  0.628551  0.741846  0.567911  0.101726  0.721979  0.874870  0.465174  \n",
       "\n",
       "[181 rows x 25 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = genes.columns\n",
    "d = scaler.fit_transform(genes)\n",
    "genes = pd.DataFrame(d, columns=names)\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_genes, test_genes, Y_train, Y_test = train_test_split(genes, Y, test_size=0.1, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../Biogrid/Data/network_edges.tsv'\n",
    "data = pd.read_csv(path, delimiter='\\t')\n",
    "edge_index1=data[data.columns[1]].to_numpy()\n",
    "edge_index2=data[data.columns[2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = np.concatenate((edge_index1, edge_index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EGFR', 'EGFR', 'GRB2', 'MAP1LC3B', 'DLGAP4', 'TRIM25', 'XPC',\n",
       "       'NPM1', 'UBC', 'EGFR', 'KLHL5', 'CUL3', 'PCMT1', 'RNF123',\n",
       "       'DLGAP4', 'UBC', 'GPR155', 'FPR2', 'ARAP1', 'XPC', 'RNPS1',\n",
       "       'SRPK2', 'GRB2', 'GRB2', 'GRB2', 'IL25', 'MAP1LC3B', 'KLHL5',\n",
       "       'TRIM25', 'LANCL1-AS1', 'NPM1', 'LEMD1', 'PCMT1', 'USP31', 'CUL3',\n",
       "       'TARBP2', 'RNF123', 'TRIM43B', 'UBC', 'XPC', 'FPR2', 'ARAP1',\n",
       "       'GRB2', 'RNPS1', 'SRPK2', 'SDR42E1', 'GJA9', 'UBC'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(edge_index)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = le.transform(edge_index1)\n",
    "edge_index2 = le.transform(edge_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [edge_index1]+[edge_index2]\n",
    "edge_index = np.array(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3,  7, 12,  2, 20, 24, 13, 22,  3,  9,  1, 14, 15,  2, 22,\n",
       "         6,  4,  0, 24, 16, 18,  7,  7],\n",
       "       [ 7,  8, 12,  9, 20, 10, 13, 11, 14, 23,  1, 19, 15, 21, 22, 24,\n",
       "         4,  0,  7, 16, 18, 17,  5, 22]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  3,  7, 12,  2, 20, 24, 13, 22,  3,  9,  1, 14, 15,  2, 22,  6,  4,\n",
       "          0, 24, 16, 18,  7,  7],\n",
       "        [ 7,  8, 12,  9, 20, 10, 13, 11, 14, 23,  1, 19, 15, 21, 22, 24,  4,  0,\n",
       "          7, 16, 18, 17,  5, 22]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "for g in range(len(train_genes)):\n",
    "  b=[]\n",
    "  for i in train_genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    # a.append(Y[g])\n",
    "    # a.append(i*100)\n",
    "    a.append(i)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.float).reshape([-1,1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y_train.iloc[g]], dtype=torch.long).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  train_data.append(data)\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "test_data=[]\n",
    "for g in range(len(test_genes)):\n",
    "  b=[]\n",
    "  for i in test_genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    # a.append(Y[g])\n",
    "    # a.append(i*100)\n",
    "    a.append(i)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.float).reshape([-1,1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y_test.iloc[g]], dtype=torch.long).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  test_data.append(data)\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graph(data,description=True):\n",
    "    edges_raw = data.edge_index.numpy()\n",
    "    edges = [(x, y) for x, y in zip(edges_raw[0, :], edges_raw[1, :])]\n",
    "    labels = data.x.numpy()\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list(range(np.max(edges_raw))))\n",
    "    G.add_edges_from(edges)\n",
    "    plt.subplot(111)\n",
    "    options = {\n",
    "       'node_size': 100,\n",
    "       'width': 1,\n",
    "    }\n",
    "    nx.draw(G, with_labels=description, node_color=labels.tolist(), cmap=plt.cm.tab10, font_weight='bold', **options)\n",
    "    plt.show()\n",
    "\n",
    "plot_graph(data,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Patient sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 25\n",
      "Number of charcateristics per node: 1\n",
      "Number of edges: 24\n",
      "Average node degree: 0.96\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Number of node features: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of charcateristics per node: {data.num_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Number of node features: {data.num_node_features}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "# from torch_geometric.nn import GCNConv, GINConv\n",
    "# from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "# embed_dim = 32\n",
    "\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, dim_h):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = GCNConv(1, dim_h)\n",
    "#         self.conv2 = GCNConv(dim_h, dim_h)\n",
    "#         self.conv3 = GCNConv(dim_h, dim_h)\n",
    "#         self.lin = Linear(dim_h, 1)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch):\n",
    "#         # Node embeddings \n",
    "#         h = self.conv1(x, edge_index)\n",
    "#         h = h.relu()\n",
    "#         h = self.conv2(h, edge_index)\n",
    "#         h = h.relu()\n",
    "#         h = self.conv3(h, edge_index)\n",
    "\n",
    "#         # Graph-level readout\n",
    "#         hG = global_mean_pool(h, batch)\n",
    "\n",
    "#         # Classifier\n",
    "#         h = F.dropout(hG, p=0.5, training=self.training)\n",
    "#         h = self.lin(h)\n",
    "        \n",
    "#         return F.sigmoid(h).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, dim_h):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(1, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    acc = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(output, data.y.squeeze(1))  \n",
    "        total_loss += loss / len(train_loader)\n",
    "        acc += accuracy(output.argmax(dim=1), data.y.squeeze(1)) / len(train_loader)\n",
    "        f1score = f1_score(data.y.squeeze(1), output.argmax(dim=1), average='weighted')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # loss_all += loss.item() * data.num_graphs\n",
    "    return total_loss, acc, f1score\n",
    "\n",
    "    \n",
    "@torch.no_grad()\n",
    "def validation(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    loss = 0\n",
    "    for data in val_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss += criterion(output, data.y.squeeze(1))/ len(val_loader)\n",
    "        acc += accuracy(output.argmax(dim=1), data.y.squeeze(1)) / len(val_loader)\n",
    "        f1score = f1_score(data.y.squeeze(1), output.argmax(dim=1), average='weighted')\n",
    "    return loss, acc, f1score\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def test(model, test_data):\n",
    "    acc = 0\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "    for data in test_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        acc += accuracy(output.argmax(dim=1), data.y.squeeze(1)) / len(test_loader)\n",
    "        f1score = f1_score(data.y.squeeze(1), output.argmax(dim=1), average='weighted')\n",
    "    return acc, f1score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "kf=StratifiedKFold(n_splits=10, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [ 16  17  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18]\n",
      "145\n",
      "17\n",
      "Epoch: 000, Train loss: 0.9968, Train Acc: 0.4934, Train f1-score: 0.3665, Val loss: 0.7184, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 001, Train loss: 0.7447, Train Acc: 0.5184, Train f1-score: 0.3665, Val loss: 0.7040, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 002, Train loss: 0.6961, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6990, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 003, Train loss: 0.6963, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6976, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 004, Train loss: 0.6966, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6974, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 005, Train loss: 0.6950, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6953, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 006, Train loss: 0.6947, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6951, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 007, Train loss: 0.6937, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6952, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 008, Train loss: 0.6931, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6953, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 009, Train loss: 0.6924, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6954, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 010, Train loss: 0.6919, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6950, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 011, Train loss: 0.6916, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6956, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 012, Train loss: 0.6907, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6940, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 013, Train loss: 0.6906, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6934, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 014, Train loss: 0.6911, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6925, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 015, Train loss: 0.6893, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6913, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 016, Train loss: 0.6887, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6905, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 017, Train loss: 0.6893, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6937, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 018, Train loss: 0.6875, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6893, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 019, Train loss: 0.6870, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6906, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 020, Train loss: 0.6855, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6892, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 021, Train loss: 0.6852, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6879, Val Acc: 0.5294, Val f1-score: 0.4196,\n",
      "Epoch: 022, Train loss: 0.6845, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6868, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 023, Train loss: 0.6841, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6855, Val Acc: 0.5294, Val f1-score: 0.4759,\n",
      "Epoch: 024, Train loss: 0.6834, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6845, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 025, Train loss: 0.6827, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6839, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 026, Train loss: 0.6823, Train Acc: 0.5746, Train f1-score: 0.3665, Val loss: 0.6832, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 027, Train loss: 0.6812, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6794, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 028, Train loss: 0.6821, Train Acc: 0.5746, Train f1-score: 0.3665, Val loss: 0.6790, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 029, Train loss: 0.6811, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6805, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 030, Train loss: 0.6796, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6813, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 031, Train loss: 0.6786, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6801, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 032, Train loss: 0.6775, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6788, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 033, Train loss: 0.6763, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6784, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 034, Train loss: 0.6746, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6697, Val Acc: 0.5882, Val f1-score: 0.5853,\n",
      "Epoch: 035, Train loss: 0.6829, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6827, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 036, Train loss: 0.6810, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.7031, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 037, Train loss: 0.6708, Train Acc: 0.5746, Train f1-score: 0.3665, Val loss: 0.6778, Val Acc: 0.5294, Val f1-score: 0.4759,\n",
      "Epoch: 038, Train loss: 0.6759, Train Acc: 0.5246, Train f1-score: 0.3665, Val loss: 0.6838, Val Acc: 0.5294, Val f1-score: 0.4196,\n",
      "Epoch: 039, Train loss: 0.6713, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6784, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 040, Train loss: 0.6727, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6762, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 041, Train loss: 0.6746, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.6827, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 042, Train loss: 0.6701, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6764, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 043, Train loss: 0.6716, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.6779, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 044, Train loss: 0.6713, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6812, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 045, Train loss: 0.6686, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6757, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 046, Train loss: 0.6720, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.6833, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 047, Train loss: 0.6666, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6736, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 048, Train loss: 0.6718, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6796, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 049, Train loss: 0.6675, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6717, Val Acc: 0.6471, Val f1-score: 0.6070,\n",
      "Epoch: 050, Train loss: 0.6712, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6780, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 051, Train loss: 0.6669, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6717, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 052, Train loss: 0.6697, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6738, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 053, Train loss: 0.6678, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6708, Val Acc: 0.6471, Val f1-score: 0.6070,\n",
      "Epoch: 054, Train loss: 0.6677, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6691, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 055, Train loss: 0.6688, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6703, Val Acc: 0.6471, Val f1-score: 0.6070,\n",
      "Epoch: 056, Train loss: 0.6676, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6669, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 057, Train loss: 0.6678, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6635, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 058, Train loss: 0.6733, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6742, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 059, Train loss: 0.6661, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6635, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 060, Train loss: 0.6702, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6696, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 061, Train loss: 0.6695, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6697, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 062, Train loss: 0.6704, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6770, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 063, Train loss: 0.6635, Train Acc: 0.5379, Train f1-score: 0.3388, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 064, Train loss: 0.6704, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6703, Val Acc: 0.5294, Val f1-score: 0.4759,\n",
      "Epoch: 065, Train loss: 0.6652, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6668, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 066, Train loss: 0.6724, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6799, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 067, Train loss: 0.6640, Train Acc: 0.5371, Train f1-score: 0.4471, Val loss: 0.6660, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 068, Train loss: 0.6687, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6712, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 069, Train loss: 0.6644, Train Acc: 0.5441, Train f1-score: 0.3388, Val loss: 0.6634, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 070, Train loss: 0.6680, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6677, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 071, Train loss: 0.6648, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 072, Train loss: 0.6652, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6622, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 073, Train loss: 0.6690, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 074, Train loss: 0.6649, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6607, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 075, Train loss: 0.6690, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6638, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 076, Train loss: 0.6657, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6605, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 077, Train loss: 0.6671, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6640, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 078, Train loss: 0.6642, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6638, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 079, Train loss: 0.6650, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6639, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 080, Train loss: 0.6635, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.6579, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 081, Train loss: 0.6685, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6648, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 082, Train loss: 0.6625, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6592, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 083, Train loss: 0.6655, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6611, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 084, Train loss: 0.6665, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 085, Train loss: 0.6641, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6631, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 086, Train loss: 0.6626, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6593, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 087, Train loss: 0.6632, Train Acc: 0.5129, Train f1-score: 0.3388, Val loss: 0.6548, Val Acc: 0.5882, Val f1-score: 0.5882,\n",
      "Epoch: 088, Train loss: 0.6682, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6622, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 089, Train loss: 0.6617, Train Acc: 0.5246, Train f1-score: 0.3665, Val loss: 0.6594, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 090, Train loss: 0.6664, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6654, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 091, Train loss: 0.6627, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6625, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 092, Train loss: 0.6651, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 093, Train loss: 0.6624, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.6640, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 094, Train loss: 0.6613, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6613, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 095, Train loss: 0.6608, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6551, Val Acc: 0.6471, Val f1-score: 0.6446,\n",
      "Epoch: 096, Train loss: 0.6654, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6629, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 097, Train loss: 0.6605, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6626, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 098, Train loss: 0.6600, Train Acc: 0.5191, Train f1-score: 0.3388, Val loss: 0.6516, Val Acc: 0.6471, Val f1-score: 0.6395,\n",
      "Epoch: 099, Train loss: 0.6661, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.6634, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 100, Train loss: 0.6583, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.6540, Val Acc: 0.5882, Val f1-score: 0.5882,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  18  33\n",
      "  34  35  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161] TEST: [16 17 19 20 21 22 23 24 25 26 27 28 29 30 31 32 36]\n",
      "145\n",
      "17\n",
      "Epoch: 000, Train loss: 1.3942, Train Acc: 0.5184, Train f1-score: 0.3665, Val loss: 0.7896, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 001, Train loss: 0.7488, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.6921, Val Acc: 0.5294, Val f1-score: 0.4759,\n",
      "Epoch: 002, Train loss: 0.6940, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7001, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 003, Train loss: 0.6889, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7008, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 004, Train loss: 0.6869, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7095, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 005, Train loss: 0.6834, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7057, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 006, Train loss: 0.6835, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7128, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 007, Train loss: 0.6802, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.7030, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 008, Train loss: 0.6848, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.7352, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 009, Train loss: 0.6903, Train Acc: 0.5496, Train f1-score: 0.4938, Val loss: 0.6820, Val Acc: 0.6471, Val f1-score: 0.6395,\n",
      "Epoch: 010, Train loss: 0.7206, Train Acc: 0.5246, Train f1-score: 0.3665, Val loss: 0.7237, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 011, Train loss: 0.6833, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6959, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 012, Train loss: 0.6841, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.7107, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 013, Train loss: 0.6793, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6999, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 014, Train loss: 0.6820, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7170, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 015, Train loss: 0.6828, Train Acc: 0.5629, Train f1-score: 0.4078, Val loss: 0.6815, Val Acc: 0.6471, Val f1-score: 0.6395,\n",
      "Epoch: 016, Train loss: 0.7069, Train Acc: 0.5184, Train f1-score: 0.3665, Val loss: 0.7094, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 017, Train loss: 0.6803, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6915, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 018, Train loss: 0.6826, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7012, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 019, Train loss: 0.6779, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6955, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 020, Train loss: 0.6797, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7077, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 021, Train loss: 0.6759, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6889, Val Acc: 0.5294, Val f1-score: 0.4759,\n",
      "Epoch: 022, Train loss: 0.6923, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7152, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 023, Train loss: 0.6772, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6912, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 024, Train loss: 0.6844, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.7067, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 025, Train loss: 0.6748, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6901, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 026, Train loss: 0.6828, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.7095, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 027, Train loss: 0.6741, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6906, Val Acc: 0.5882, Val f1-score: 0.5199,\n",
      "Epoch: 028, Train loss: 0.6821, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.7113, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 029, Train loss: 0.6753, Train Acc: 0.5684, Train f1-score: 0.4471, Val loss: 0.6845, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 030, Train loss: 0.6868, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7043, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 031, Train loss: 0.6730, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6932, Val Acc: 0.5294, Val f1-score: 0.4196,\n",
      "Epoch: 032, Train loss: 0.6774, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.7035, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 033, Train loss: 0.6706, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7024, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 034, Train loss: 0.6685, Train Acc: 0.5434, Train f1-score: 0.4471, Val loss: 0.6841, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 035, Train loss: 0.7049, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7037, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 036, Train loss: 0.6721, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.6900, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 037, Train loss: 0.6722, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.6954, Val Acc: 0.5294, Val f1-score: 0.4196,\n",
      "Epoch: 038, Train loss: 0.6696, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.6981, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 039, Train loss: 0.6682, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.7038, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 040, Train loss: 0.6664, Train Acc: 0.5621, Train f1-score: 0.4471, Val loss: 0.6847, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 041, Train loss: 0.6936, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7123, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 042, Train loss: 0.6684, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.6908, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 043, Train loss: 0.6710, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7021, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 044, Train loss: 0.6653, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6941, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 045, Train loss: 0.6740, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7195, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 046, Train loss: 0.6673, Train Acc: 0.5629, Train f1-score: 0.3388, Val loss: 0.6866, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 047, Train loss: 0.6802, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.7103, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 048, Train loss: 0.6650, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.6927, Val Acc: 0.5882, Val f1-score: 0.5581,\n",
      "Epoch: 049, Train loss: 0.6676, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7081, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 050, Train loss: 0.6624, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6903, Val Acc: 0.6471, Val f1-score: 0.6319,\n",
      "Epoch: 051, Train loss: 0.6823, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7156, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 052, Train loss: 0.6642, Train Acc: 0.5746, Train f1-score: 0.3665, Val loss: 0.6897, Val Acc: 0.6471, Val f1-score: 0.6319,\n",
      "Epoch: 053, Train loss: 0.6719, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7085, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 054, Train loss: 0.6612, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6924, Val Acc: 0.6471, Val f1-score: 0.6319,\n",
      "Epoch: 055, Train loss: 0.6683, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7141, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 056, Train loss: 0.6623, Train Acc: 0.5746, Train f1-score: 0.4471, Val loss: 0.6885, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 057, Train loss: 0.6756, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.7115, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 058, Train loss: 0.6605, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.6919, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 059, Train loss: 0.6680, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7105, Val Acc: 0.4118, Val f1-score: 0.2745,\n",
      "Epoch: 060, Train loss: 0.6595, Train Acc: 0.5676, Train f1-score: 0.4858, Val loss: 0.6941, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 061, Train loss: 0.6720, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7177, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 062, Train loss: 0.6596, Train Acc: 0.5864, Train f1-score: 0.4858, Val loss: 0.6920, Val Acc: 0.5882, Val f1-score: 0.5796,\n",
      "Epoch: 063, Train loss: 0.6698, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7143, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 064, Train loss: 0.6585, Train Acc: 0.5739, Train f1-score: 0.4858, Val loss: 0.6938, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 065, Train loss: 0.6701, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.7170, Val Acc: 0.5294, Val f1-score: 0.4196,\n",
      "Epoch: 066, Train loss: 0.6591, Train Acc: 0.5801, Train f1-score: 0.4858, Val loss: 0.6936, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 067, Train loss: 0.6676, Train Acc: 0.5309, Train f1-score: 0.3665, Val loss: 0.7149, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 068, Train loss: 0.6571, Train Acc: 0.5739, Train f1-score: 0.4858, Val loss: 0.6967, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 069, Train loss: 0.6692, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7166, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 070, Train loss: 0.6566, Train Acc: 0.5739, Train f1-score: 0.4858, Val loss: 0.6979, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 071, Train loss: 0.6651, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7203, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 072, Train loss: 0.6569, Train Acc: 0.5864, Train f1-score: 0.4858, Val loss: 0.6984, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 073, Train loss: 0.6646, Train Acc: 0.5434, Train f1-score: 0.3665, Val loss: 0.7118, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 074, Train loss: 0.6544, Train Acc: 0.5857, Train f1-score: 0.5853, Val loss: 0.6997, Val Acc: 0.5294, Val f1-score: 0.5261,\n",
      "Epoch: 075, Train loss: 0.6836, Train Acc: 0.5371, Train f1-score: 0.3665, Val loss: 0.7282, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 076, Train loss: 0.6616, Train Acc: 0.5801, Train f1-score: 0.4858, Val loss: 0.6999, Val Acc: 0.4706, Val f1-score: 0.4706,\n",
      "Epoch: 077, Train loss: 0.6606, Train Acc: 0.5496, Train f1-score: 0.3665, Val loss: 0.7100, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 078, Train loss: 0.6526, Train Acc: 0.5864, Train f1-score: 0.4858, Val loss: 0.7032, Val Acc: 0.5294, Val f1-score: 0.5092,\n",
      "Epoch: 079, Train loss: 0.6530, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7224, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 080, Train loss: 0.6547, Train Acc: 0.6217, Train f1-score: 0.7469, Val loss: 0.7049, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 081, Train loss: 0.6713, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.7146, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 082, Train loss: 0.6520, Train Acc: 0.5794, Train f1-score: 0.5853, Val loss: 0.7078, Val Acc: 0.4706, Val f1-score: 0.4594,\n",
      "Epoch: 083, Train loss: 0.6566, Train Acc: 0.5684, Train f1-score: 0.3665, Val loss: 0.7259, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 084, Train loss: 0.6548, Train Acc: 0.6107, Train f1-score: 0.6203, Val loss: 0.7056, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 085, Train loss: 0.6651, Train Acc: 0.5559, Train f1-score: 0.3665, Val loss: 0.7168, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 086, Train loss: 0.6504, Train Acc: 0.5794, Train f1-score: 0.5853, Val loss: 0.7113, Val Acc: 0.4118, Val f1-score: 0.4077,\n",
      "Epoch: 087, Train loss: 0.6631, Train Acc: 0.5621, Train f1-score: 0.3665, Val loss: 0.7225, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 088, Train loss: 0.6545, Train Acc: 0.6217, Train f1-score: 0.7597, Val loss: 0.7161, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 089, Train loss: 0.6676, Train Acc: 0.5739, Train f1-score: 0.4858, Val loss: 0.7103, Val Acc: 0.4706, Val f1-score: 0.4318,\n",
      "Epoch: 090, Train loss: 0.6483, Train Acc: 0.5857, Train f1-score: 0.5853, Val loss: 0.7126, Val Acc: 0.4118, Val f1-score: 0.4077,\n",
      "Epoch: 091, Train loss: 0.6526, Train Acc: 0.5614, Train f1-score: 0.4858, Val loss: 0.7226, Val Acc: 0.4706, Val f1-score: 0.3827,\n",
      "Epoch: 092, Train loss: 0.6530, Train Acc: 0.6452, Train f1-score: 0.8798, Val loss: 0.7194, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 093, Train loss: 0.6693, Train Acc: 0.5739, Train f1-score: 0.4858, Val loss: 0.7214, Val Acc: 0.4118, Val f1-score: 0.3449,\n",
      "Epoch: 094, Train loss: 0.6494, Train Acc: 0.5482, Train f1-score: 0.5853, Val loss: 0.7132, Val Acc: 0.4706, Val f1-score: 0.4706,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 095, Train loss: 0.6543, Train Acc: 0.5676, Train f1-score: 0.4858, Val loss: 0.7185, Val Acc: 0.4118, Val f1-score: 0.3449,\n",
      "Epoch: 096, Train loss: 0.6552, Train Acc: 0.6154, Train f1-score: 0.7647, Val loss: 0.7240, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 097, Train loss: 0.6713, Train Acc: 0.5614, Train f1-score: 0.4858, Val loss: 0.7205, Val Acc: 0.4706, Val f1-score: 0.4318,\n",
      "Epoch: 098, Train loss: 0.6479, Train Acc: 0.5482, Train f1-score: 0.5853, Val loss: 0.7158, Val Acc: 0.4118, Val f1-score: 0.4077,\n",
      "Epoch: 099, Train loss: 0.6493, Train Acc: 0.5801, Train f1-score: 0.4858, Val loss: 0.7266, Val Acc: 0.4118, Val f1-score: 0.3449,\n",
      "Epoch: 100, Train loss: 0.6573, Train Acc: 0.6265, Train f1-score: 0.8798, Val loss: 0.7272, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  36  45  47\n",
      "  48  50  51  52  53  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [33 34 35 37 38 39 40 41 42 43 44 46 49 54 55 56]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.0691, Train Acc: 0.5722, Train f1-score: 0.6075, Val loss: 0.6861, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 001, Train loss: 0.6961, Train Acc: 0.5264, Train f1-score: 0.2735, Val loss: 0.7535, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 002, Train loss: 0.7033, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6819, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 003, Train loss: 0.7339, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.6897, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 004, Train loss: 0.7070, Train Acc: 0.5424, Train f1-score: 0.5444, Val loss: 0.6839, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 005, Train loss: 0.7059, Train Acc: 0.5375, Train f1-score: 0.4364, Val loss: 0.6805, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 006, Train loss: 0.7060, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6805, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 007, Train loss: 0.7046, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.6809, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 008, Train loss: 0.7021, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6810, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 009, Train loss: 0.7006, Train Acc: 0.5361, Train f1-score: 0.4735, Val loss: 0.6806, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 010, Train loss: 0.7007, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6810, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 011, Train loss: 0.6997, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6818, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 012, Train loss: 0.6972, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6794, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 013, Train loss: 0.6983, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6816, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 014, Train loss: 0.6960, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6808, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 015, Train loss: 0.6966, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6806, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 016, Train loss: 0.6953, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6804, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 017, Train loss: 0.6958, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6798, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 018, Train loss: 0.6925, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6791, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 019, Train loss: 0.6929, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6800, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 020, Train loss: 0.6927, Train Acc: 0.5486, Train f1-score: 0.4735, Val loss: 0.6780, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 021, Train loss: 0.6913, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6822, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 022, Train loss: 0.6895, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6802, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 023, Train loss: 0.6890, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.6830, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 024, Train loss: 0.6875, Train Acc: 0.5410, Train f1-score: 0.5616, Val loss: 0.6801, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 025, Train loss: 0.6938, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6833, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 026, Train loss: 0.6865, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.6866, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 027, Train loss: 0.6818, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.6852, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 028, Train loss: 0.6819, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6852, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 029, Train loss: 0.6801, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6860, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 030, Train loss: 0.6881, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6875, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 031, Train loss: 0.6840, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6928, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 032, Train loss: 0.6772, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.6935, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 033, Train loss: 0.6743, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6914, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 034, Train loss: 0.6883, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6913, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 035, Train loss: 0.6739, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6966, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 036, Train loss: 0.6717, Train Acc: 0.5597, Train f1-score: 0.6074, Val loss: 0.6974, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 037, Train loss: 0.6703, Train Acc: 0.5771, Train f1-score: 0.6051, Val loss: 0.6954, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 038, Train loss: 0.6721, Train Acc: 0.5993, Train f1-score: 0.7593, Val loss: 0.6971, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 039, Train loss: 0.6695, Train Acc: 0.5722, Train f1-score: 0.6074, Val loss: 0.7005, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 040, Train loss: 0.6747, Train Acc: 0.5771, Train f1-score: 0.6580, Val loss: 0.7023, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 041, Train loss: 0.6708, Train Acc: 0.5882, Train f1-score: 0.7083, Val loss: 0.6979, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 042, Train loss: 0.6722, Train Acc: 0.5833, Train f1-score: 0.6580, Val loss: 0.7045, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 043, Train loss: 0.6709, Train Acc: 0.5896, Train f1-score: 0.6580, Val loss: 0.7014, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 044, Train loss: 0.6711, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7092, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 045, Train loss: 0.6730, Train Acc: 0.5597, Train f1-score: 0.5103, Val loss: 0.7089, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 046, Train loss: 0.6700, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.7083, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 047, Train loss: 0.6706, Train Acc: 0.5833, Train f1-score: 0.6580, Val loss: 0.7072, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 048, Train loss: 0.6691, Train Acc: 0.6083, Train f1-score: 0.6051, Val loss: 0.7089, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 049, Train loss: 0.6666, Train Acc: 0.5819, Train f1-score: 0.6869, Val loss: 0.7091, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 050, Train loss: 0.6682, Train Acc: 0.5646, Train f1-score: 0.6580, Val loss: 0.7099, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 051, Train loss: 0.6685, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.7108, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 052, Train loss: 0.6647, Train Acc: 0.5819, Train f1-score: 0.7083, Val loss: 0.7130, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 053, Train loss: 0.6664, Train Acc: 0.5757, Train f1-score: 0.7083, Val loss: 0.7085, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 054, Train loss: 0.6646, Train Acc: 0.5722, Train f1-score: 0.6074, Val loss: 0.7126, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 055, Train loss: 0.6657, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.7137, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 056, Train loss: 0.6646, Train Acc: 0.5646, Train f1-score: 0.6580, Val loss: 0.7132, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 057, Train loss: 0.6656, Train Acc: 0.5757, Train f1-score: 0.7083, Val loss: 0.7093, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 058, Train loss: 0.6676, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.7154, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 059, Train loss: 0.6630, Train Acc: 0.5771, Train f1-score: 0.6580, Val loss: 0.7182, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 060, Train loss: 0.6616, Train Acc: 0.5632, Train f1-score: 0.7083, Val loss: 0.7190, Val Acc: 0.4375, Val f1-score: 0.4397,\n",
      "Epoch: 061, Train loss: 0.6631, Train Acc: 0.5819, Train f1-score: 0.7083, Val loss: 0.7124, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 062, Train loss: 0.6638, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.7191, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 063, Train loss: 0.6616, Train Acc: 0.5681, Train f1-score: 0.7593, Val loss: 0.7177, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 064, Train loss: 0.6608, Train Acc: 0.5806, Train f1-score: 0.7593, Val loss: 0.7173, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 065, Train loss: 0.6620, Train Acc: 0.5757, Train f1-score: 0.7083, Val loss: 0.7175, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 066, Train loss: 0.6585, Train Acc: 0.5882, Train f1-score: 0.7083, Val loss: 0.7166, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 067, Train loss: 0.6638, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.7216, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 068, Train loss: 0.6651, Train Acc: 0.5993, Train f1-score: 0.7593, Val loss: 0.7189, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 069, Train loss: 0.6597, Train Acc: 0.5931, Train f1-score: 0.7593, Val loss: 0.7220, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 070, Train loss: 0.6586, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.7195, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 071, Train loss: 0.6570, Train Acc: 0.6056, Train f1-score: 0.7593, Val loss: 0.7175, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 072, Train loss: 0.6591, Train Acc: 0.5868, Train f1-score: 0.7593, Val loss: 0.7216, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 073, Train loss: 0.6579, Train Acc: 0.5931, Train f1-score: 0.7593, Val loss: 0.7213, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 074, Train loss: 0.6577, Train Acc: 0.5993, Train f1-score: 0.7593, Val loss: 0.7228, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 075, Train loss: 0.6573, Train Acc: 0.6118, Train f1-score: 0.7593, Val loss: 0.7198, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 076, Train loss: 0.6550, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.7222, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 077, Train loss: 0.6550, Train Acc: 0.5833, Train f1-score: 0.6580, Val loss: 0.7226, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 078, Train loss: 0.6582, Train Acc: 0.6090, Train f1-score: 0.8860, Val loss: 0.7369, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 079, Train loss: 0.6507, Train Acc: 0.6118, Train f1-score: 0.7593, Val loss: 0.7157, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 080, Train loss: 0.6525, Train Acc: 0.5965, Train f1-score: 0.8860, Val loss: 0.7210, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 081, Train loss: 0.6526, Train Acc: 0.5931, Train f1-score: 0.7593, Val loss: 0.7239, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 082, Train loss: 0.6562, Train Acc: 0.6340, Train f1-score: 0.8860, Val loss: 0.7310, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 083, Train loss: 0.6525, Train Acc: 0.5931, Train f1-score: 0.7593, Val loss: 0.7246, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 084, Train loss: 0.6525, Train Acc: 0.5715, Train f1-score: 0.8860, Val loss: 0.7275, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 085, Train loss: 0.6531, Train Acc: 0.5903, Train f1-score: 0.8860, Val loss: 0.7351, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 086, Train loss: 0.6587, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.7331, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 087, Train loss: 0.6502, Train Acc: 0.6278, Train f1-score: 0.8860, Val loss: 0.7223, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 088, Train loss: 0.6487, Train Acc: 0.6028, Train f1-score: 0.8860, Val loss: 0.7383, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 089, Train loss: 0.6492, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7216, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 090, Train loss: 0.6485, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7343, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 091, Train loss: 0.6493, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.7307, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 092, Train loss: 0.6501, Train Acc: 0.5931, Train f1-score: 0.7593, Val loss: 0.7250, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 093, Train loss: 0.6535, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.7367, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 094, Train loss: 0.6510, Train Acc: 0.6104, Train f1-score: 0.8317, Val loss: 0.7399, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 095, Train loss: 0.6472, Train Acc: 0.6042, Train f1-score: 0.8317, Val loss: 0.7347, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 096, Train loss: 0.6502, Train Acc: 0.6104, Train f1-score: 0.8317, Val loss: 0.7413, Val Acc: 0.5625, Val f1-score: 0.5572,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 097, Train loss: 0.6481, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7236, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 098, Train loss: 0.6425, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.7287, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 099, Train loss: 0.6547, Train Acc: 0.6090, Train f1-score: 0.8860, Val loss: 0.7500, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 100, Train loss: 0.6577, Train Acc: 0.6104, Train f1-score: 0.8317, Val loss: 0.7236, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "GIN accuracy: 0.4736842215061188\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  46  49  54  55  56  58  61  62  67\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [45 47 48 50 51 52 53 57 59 60 63 64 65 66 68 69]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.4113, Train Acc: 0.4604, Train f1-score: 0.3167, Val loss: 0.7341, Val Acc: 0.4375, Val f1-score: 0.2663,\n",
      "Epoch: 001, Train loss: 0.7614, Train Acc: 0.4924, Train f1-score: 0.3968, Val loss: 0.6986, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 002, Train loss: 0.7063, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6780, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 003, Train loss: 0.7022, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6759, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 004, Train loss: 0.7045, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.6719, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 005, Train loss: 0.7071, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.6812, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 006, Train loss: 0.6992, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.6719, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 007, Train loss: 0.7014, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6674, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 008, Train loss: 0.6986, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.6679, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 009, Train loss: 0.6978, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.6662, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 010, Train loss: 0.6976, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6677, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 011, Train loss: 0.6971, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6578, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 012, Train loss: 0.6994, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.6647, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 013, Train loss: 0.6961, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6601, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 014, Train loss: 0.6970, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6606, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 015, Train loss: 0.6927, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6521, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 016, Train loss: 0.6928, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6549, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 017, Train loss: 0.6915, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6389, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 018, Train loss: 0.6943, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6532, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 019, Train loss: 0.6909, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6522, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 020, Train loss: 0.6896, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6540, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 021, Train loss: 0.6870, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6474, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 022, Train loss: 0.6886, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6489, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 023, Train loss: 0.6883, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6593, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 024, Train loss: 0.6853, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6444, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 025, Train loss: 0.6938, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6344, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 026, Train loss: 0.6915, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6438, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 027, Train loss: 0.6864, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.6485, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 028, Train loss: 0.6859, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.6529, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 029, Train loss: 0.6797, Train Acc: 0.5799, Train f1-score: 0.3968, Val loss: 0.6598, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 030, Train loss: 0.6798, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.6464, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 031, Train loss: 0.6821, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.6446, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 032, Train loss: 0.6813, Train Acc: 0.5799, Train f1-score: 0.3968, Val loss: 0.6562, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 033, Train loss: 0.6807, Train Acc: 0.5861, Train f1-score: 0.3968, Val loss: 0.6564, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 034, Train loss: 0.6787, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.6463, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 035, Train loss: 0.6797, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.6461, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 036, Train loss: 0.6805, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.6397, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 037, Train loss: 0.6802, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.6492, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 038, Train loss: 0.6780, Train Acc: 0.5785, Train f1-score: 0.5103, Val loss: 0.6457, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 039, Train loss: 0.6769, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6447, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 040, Train loss: 0.6777, Train Acc: 0.5785, Train f1-score: 0.5103, Val loss: 0.6358, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 041, Train loss: 0.6794, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.6310, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 042, Train loss: 0.6798, Train Acc: 0.5924, Train f1-score: 0.3968, Val loss: 0.6128, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 043, Train loss: 0.6797, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.6192, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 044, Train loss: 0.6779, Train Acc: 0.5861, Train f1-score: 0.3968, Val loss: 0.6440, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 045, Train loss: 0.6775, Train Acc: 0.5597, Train f1-score: 0.5103, Val loss: 0.6493, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 046, Train loss: 0.6743, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6560, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 047, Train loss: 0.6734, Train Acc: 0.5882, Train f1-score: 0.6869, Val loss: 0.6432, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 048, Train loss: 0.6726, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6466, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 049, Train loss: 0.6719, Train Acc: 0.5882, Train f1-score: 0.6869, Val loss: 0.6366, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 050, Train loss: 0.6731, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6569, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 051, Train loss: 0.6727, Train Acc: 0.5819, Train f1-score: 0.6869, Val loss: 0.6395, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 052, Train loss: 0.6712, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6466, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 053, Train loss: 0.6715, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6427, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 054, Train loss: 0.6721, Train Acc: 0.5958, Train f1-score: 0.6051, Val loss: 0.6460, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 055, Train loss: 0.6716, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6449, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 056, Train loss: 0.6701, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6520, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 057, Train loss: 0.6734, Train Acc: 0.5771, Train f1-score: 0.6051, Val loss: 0.6542, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 058, Train loss: 0.6716, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6188, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 059, Train loss: 0.6741, Train Acc: 0.6146, Train f1-score: 0.6051, Val loss: 0.6416, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 060, Train loss: 0.6685, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6516, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 061, Train loss: 0.6704, Train Acc: 0.5771, Train f1-score: 0.6051, Val loss: 0.6281, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 062, Train loss: 0.6669, Train Acc: 0.6083, Train f1-score: 0.6051, Val loss: 0.6553, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 063, Train loss: 0.6683, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.6371, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 064, Train loss: 0.6693, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6442, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 065, Train loss: 0.6693, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6394, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 066, Train loss: 0.6687, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6408, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 067, Train loss: 0.6680, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6611, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 068, Train loss: 0.6674, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.6422, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 069, Train loss: 0.6660, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6400, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 070, Train loss: 0.6682, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.6599, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 071, Train loss: 0.6669, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6433, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 072, Train loss: 0.6652, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6368, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 073, Train loss: 0.6661, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.6585, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 074, Train loss: 0.6661, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6277, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 075, Train loss: 0.6637, Train Acc: 0.6132, Train f1-score: 0.6869, Val loss: 0.6668, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 076, Train loss: 0.6650, Train Acc: 0.5993, Train f1-score: 0.7593, Val loss: 0.6411, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 077, Train loss: 0.6633, Train Acc: 0.6167, Train f1-score: 0.8250, Val loss: 0.6200, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 078, Train loss: 0.6650, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6679, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 079, Train loss: 0.6618, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6607, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 080, Train loss: 0.6625, Train Acc: 0.6181, Train f1-score: 0.7593, Val loss: 0.6312, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 081, Train loss: 0.6644, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6666, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 082, Train loss: 0.6645, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.6529, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 083, Train loss: 0.6650, Train Acc: 0.6215, Train f1-score: 0.8860, Val loss: 0.6491, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 084, Train loss: 0.6601, Train Acc: 0.5993, Train f1-score: 0.7593, Val loss: 0.6528, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 085, Train loss: 0.6629, Train Acc: 0.6056, Train f1-score: 0.7593, Val loss: 0.6546, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 086, Train loss: 0.6626, Train Acc: 0.5868, Train f1-score: 0.7593, Val loss: 0.6317, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 087, Train loss: 0.6583, Train Acc: 0.6056, Train f1-score: 0.7593, Val loss: 0.6696, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 088, Train loss: 0.6654, Train Acc: 0.6104, Train f1-score: 0.8250, Val loss: 0.6326, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 089, Train loss: 0.6588, Train Acc: 0.5868, Train f1-score: 0.7593, Val loss: 0.6705, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 090, Train loss: 0.6657, Train Acc: 0.5792, Train f1-score: 0.8250, Val loss: 0.6268, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 091, Train loss: 0.6597, Train Acc: 0.6056, Train f1-score: 0.7593, Val loss: 0.6732, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 092, Train loss: 0.6595, Train Acc: 0.5743, Train f1-score: 0.7593, Val loss: 0.6732, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 093, Train loss: 0.6632, Train Acc: 0.6042, Train f1-score: 0.8250, Val loss: 0.6492, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 094, Train loss: 0.6597, Train Acc: 0.5757, Train f1-score: 0.7083, Val loss: 0.6636, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 095, Train loss: 0.6598, Train Acc: 0.5743, Train f1-score: 0.7593, Val loss: 0.6317, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 096, Train loss: 0.6616, Train Acc: 0.5708, Train f1-score: 0.6580, Val loss: 0.6673, Val Acc: 0.5625, Val f1-score: 0.4050,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 097, Train loss: 0.6587, Train Acc: 0.5792, Train f1-score: 0.8250, Val loss: 0.6373, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 098, Train loss: 0.6577, Train Acc: 0.5729, Train f1-score: 0.8250, Val loss: 0.6485, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 099, Train loss: 0.6573, Train Acc: 0.5917, Train f1-score: 0.8250, Val loss: 0.6610, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 100, Train loss: 0.6585, Train Acc: 0.5917, Train f1-score: 0.8250, Val loss: 0.6381, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "GIN accuracy: 0.4736842215061188\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  59  60  63  64  65  66  68  69  76  77  78  79  80  81\n",
      "  83  84  86  88  89  92  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [58 61 62 67 70 71 72 73 74 75 82 85 87 90 91 93]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.0873, Train Acc: 0.5236, Train f1-score: 0.4735, Val loss: 0.6827, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 001, Train loss: 0.7273, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6897, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 002, Train loss: 0.7002, Train Acc: 0.4986, Train f1-score: 0.3968, Val loss: 0.6882, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 003, Train loss: 0.6982, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6878, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 004, Train loss: 0.6996, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6873, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 005, Train loss: 0.6977, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.6865, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 006, Train loss: 0.6949, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.6847, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 007, Train loss: 0.6945, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.6847, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 008, Train loss: 0.6941, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6856, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 009, Train loss: 0.6937, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6867, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 010, Train loss: 0.6931, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6871, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 011, Train loss: 0.6930, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.7134, Val Acc: 0.4375, Val f1-score: 0.3523,\n",
      "Epoch: 012, Train loss: 0.6937, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6894, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 013, Train loss: 0.6918, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6842, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 014, Train loss: 0.6894, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6836, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 015, Train loss: 0.6847, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6897, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 016, Train loss: 0.6884, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6838, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 017, Train loss: 0.6876, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6849, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 018, Train loss: 0.6848, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6890, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 019, Train loss: 0.6863, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6885, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 020, Train loss: 0.6847, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6905, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 021, Train loss: 0.6845, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6868, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 022, Train loss: 0.6834, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6854, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 023, Train loss: 0.6808, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.6843, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 024, Train loss: 0.6764, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.6871, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 025, Train loss: 0.6800, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6895, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 026, Train loss: 0.6790, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6932, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 027, Train loss: 0.6792, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6922, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 028, Train loss: 0.6815, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6908, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 029, Train loss: 0.6778, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.6888, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 030, Train loss: 0.6744, Train Acc: 0.5312, Train f1-score: 0.3704, Val loss: 0.6886, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 031, Train loss: 0.6726, Train Acc: 0.5424, Train f1-score: 0.4735, Val loss: 0.6885, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 032, Train loss: 0.6758, Train Acc: 0.5674, Train f1-score: 0.4735, Val loss: 0.6877, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 033, Train loss: 0.6683, Train Acc: 0.6049, Train f1-score: 0.4735, Val loss: 0.7013, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 034, Train loss: 0.6748, Train Acc: 0.5437, Train f1-score: 0.3704, Val loss: 0.6864, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 035, Train loss: 0.6712, Train Acc: 0.5674, Train f1-score: 0.4735, Val loss: 0.6941, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 036, Train loss: 0.6736, Train Acc: 0.5611, Train f1-score: 0.4735, Val loss: 0.6899, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 037, Train loss: 0.6701, Train Acc: 0.5736, Train f1-score: 0.4735, Val loss: 0.6905, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 038, Train loss: 0.6654, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.6914, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 039, Train loss: 0.6661, Train Acc: 0.5924, Train f1-score: 0.4735, Val loss: 0.6884, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 040, Train loss: 0.6679, Train Acc: 0.5736, Train f1-score: 0.4735, Val loss: 0.6893, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 041, Train loss: 0.6688, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.6906, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 042, Train loss: 0.6677, Train Acc: 0.5660, Train f1-score: 0.5616, Val loss: 0.7089, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 043, Train loss: 0.6615, Train Acc: 0.6063, Train f1-score: 0.4749, Val loss: 0.6908, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 044, Train loss: 0.6643, Train Acc: 0.5785, Train f1-score: 0.5616, Val loss: 0.6977, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 045, Train loss: 0.6686, Train Acc: 0.5785, Train f1-score: 0.5616, Val loss: 0.6933, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 046, Train loss: 0.6614, Train Acc: 0.5563, Train f1-score: 0.4749, Val loss: 0.6910, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 047, Train loss: 0.6630, Train Acc: 0.5563, Train f1-score: 0.4749, Val loss: 0.6923, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 048, Train loss: 0.6611, Train Acc: 0.5625, Train f1-score: 0.4749, Val loss: 0.6924, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 049, Train loss: 0.6623, Train Acc: 0.5799, Train f1-score: 0.5440, Val loss: 0.6881, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 050, Train loss: 0.6653, Train Acc: 0.5611, Train f1-score: 0.5440, Val loss: 0.7014, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 051, Train loss: 0.6591, Train Acc: 0.5736, Train f1-score: 0.5556, Val loss: 0.6969, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 052, Train loss: 0.6596, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.6974, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 053, Train loss: 0.6603, Train Acc: 0.5924, Train f1-score: 0.5556, Val loss: 0.6913, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 054, Train loss: 0.6635, Train Acc: 0.5799, Train f1-score: 0.5556, Val loss: 0.6896, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 055, Train loss: 0.6681, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.7071, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 056, Train loss: 0.6581, Train Acc: 0.5674, Train f1-score: 0.5556, Val loss: 0.6917, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 057, Train loss: 0.6650, Train Acc: 0.5910, Train f1-score: 0.6074, Val loss: 0.7053, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 058, Train loss: 0.6584, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6893, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 059, Train loss: 0.6662, Train Acc: 0.5847, Train f1-score: 0.6074, Val loss: 0.6929, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 060, Train loss: 0.6597, Train Acc: 0.5910, Train f1-score: 0.6123, Val loss: 0.7057, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 061, Train loss: 0.6560, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.6944, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 062, Train loss: 0.6606, Train Acc: 0.5861, Train f1-score: 0.5556, Val loss: 0.6886, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 063, Train loss: 0.6687, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.7140, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 064, Train loss: 0.6551, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 065, Train loss: 0.6586, Train Acc: 0.5910, Train f1-score: 0.6123, Val loss: 0.6903, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 066, Train loss: 0.6649, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.7145, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 067, Train loss: 0.6558, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6927, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 068, Train loss: 0.6648, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.7053, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 069, Train loss: 0.6556, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.7250, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 070, Train loss: 0.6550, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.6945, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 071, Train loss: 0.6568, Train Acc: 0.5910, Train f1-score: 0.6123, Val loss: 0.7107, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 072, Train loss: 0.6534, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.6954, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 073, Train loss: 0.6646, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.6960, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 074, Train loss: 0.6607, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.7174, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 075, Train loss: 0.6534, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.7234, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 076, Train loss: 0.6538, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.7006, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 077, Train loss: 0.6559, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6968, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 078, Train loss: 0.6563, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.6977, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 079, Train loss: 0.6556, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.7042, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 080, Train loss: 0.6525, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.7367, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 081, Train loss: 0.6585, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.7028, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 082, Train loss: 0.6525, Train Acc: 0.6083, Train f1-score: 0.6667, Val loss: 0.7126, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 083, Train loss: 0.6497, Train Acc: 0.6146, Train f1-score: 0.6667, Val loss: 0.7211, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 084, Train loss: 0.6518, Train Acc: 0.6222, Train f1-score: 0.6123, Val loss: 0.6991, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 085, Train loss: 0.6513, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.7014, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 086, Train loss: 0.6531, Train Acc: 0.6035, Train f1-score: 0.6123, Val loss: 0.7206, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 087, Train loss: 0.6672, Train Acc: 0.5833, Train f1-score: 0.6667, Val loss: 0.6999, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 088, Train loss: 0.6507, Train Acc: 0.5896, Train f1-score: 0.6667, Val loss: 0.7193, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 089, Train loss: 0.6520, Train Acc: 0.6271, Train f1-score: 0.6667, Val loss: 0.7066, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 090, Train loss: 0.6487, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.6958, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 091, Train loss: 0.6535, Train Acc: 0.5910, Train f1-score: 0.6123, Val loss: 0.7256, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 092, Train loss: 0.6542, Train Acc: 0.5833, Train f1-score: 0.6667, Val loss: 0.7095, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 093, Train loss: 0.6484, Train Acc: 0.6146, Train f1-score: 0.6667, Val loss: 0.6999, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 094, Train loss: 0.6543, Train Acc: 0.6021, Train f1-score: 0.6667, Val loss: 0.7455, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 095, Train loss: 0.6520, Train Acc: 0.5972, Train f1-score: 0.6123, Val loss: 0.7042, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 096, Train loss: 0.6451, Train Acc: 0.5958, Train f1-score: 0.6667, Val loss: 0.7059, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 097, Train loss: 0.6488, Train Acc: 0.6160, Train f1-score: 0.6123, Val loss: 0.6973, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 098, Train loss: 0.6502, Train Acc: 0.5708, Train f1-score: 0.6667, Val loss: 0.7198, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 099, Train loss: 0.6441, Train Acc: 0.6083, Train f1-score: 0.6667, Val loss: 0.7099, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 100, Train loss: 0.6453, Train Acc: 0.6021, Train f1-score: 0.6667, Val loss: 0.7146, Val Acc: 0.5000, Val f1-score: 0.4833,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN accuracy: 0.6315789222717285\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  82  84  85  86  87  88  89  90  91  92  93  95  97  99\n",
      " 101 105 106 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [ 76  77  78  79  80  81  83  94  96  98 100 102 103 104 107 108]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.0767, Train Acc: 0.4424, Train f1-score: 0.5440, Val loss: 0.7496, Val Acc: 0.4375, Val f1-score: 0.2663,\n",
      "Epoch: 001, Train loss: 0.7584, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.6861, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 002, Train loss: 0.6935, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.6850, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 003, Train loss: 0.6938, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6835, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 004, Train loss: 0.6927, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6829, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 005, Train loss: 0.6924, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.6817, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 006, Train loss: 0.6910, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6810, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 007, Train loss: 0.6903, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6809, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 008, Train loss: 0.6894, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6804, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 009, Train loss: 0.6889, Train Acc: 0.5472, Train f1-score: 0.5616, Val loss: 0.6799, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 010, Train loss: 0.6862, Train Acc: 0.5535, Train f1-score: 0.5616, Val loss: 0.6796, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 011, Train loss: 0.6844, Train Acc: 0.5424, Train f1-score: 0.5185, Val loss: 0.6761, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 012, Train loss: 0.6992, Train Acc: 0.5597, Train f1-score: 0.5656, Val loss: 0.6879, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 013, Train loss: 0.6824, Train Acc: 0.5535, Train f1-score: 0.5616, Val loss: 0.6755, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 014, Train loss: 0.6868, Train Acc: 0.5597, Train f1-score: 0.6123, Val loss: 0.6760, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 015, Train loss: 0.6857, Train Acc: 0.5535, Train f1-score: 0.6123, Val loss: 0.6766, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 016, Train loss: 0.6806, Train Acc: 0.5535, Train f1-score: 0.5616, Val loss: 0.6732, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 017, Train loss: 0.6842, Train Acc: 0.5500, Train f1-score: 0.4749, Val loss: 0.6728, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 018, Train loss: 0.6830, Train Acc: 0.5549, Train f1-score: 0.5185, Val loss: 0.6726, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 019, Train loss: 0.6826, Train Acc: 0.5722, Train f1-score: 0.5616, Val loss: 0.6722, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 020, Train loss: 0.6822, Train Acc: 0.5597, Train f1-score: 0.5616, Val loss: 0.6722, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 021, Train loss: 0.6810, Train Acc: 0.5375, Train f1-score: 0.3704, Val loss: 0.6721, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 022, Train loss: 0.6855, Train Acc: 0.5563, Train f1-score: 0.3704, Val loss: 0.6720, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 023, Train loss: 0.6797, Train Acc: 0.5660, Train f1-score: 0.5616, Val loss: 0.6731, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 024, Train loss: 0.6807, Train Acc: 0.5611, Train f1-score: 0.4735, Val loss: 0.6716, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 025, Train loss: 0.6785, Train Acc: 0.5660, Train f1-score: 0.5616, Val loss: 0.6734, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 026, Train loss: 0.6890, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.6755, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 027, Train loss: 0.6791, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.6746, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 028, Train loss: 0.6760, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6773, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 029, Train loss: 0.6747, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6759, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 030, Train loss: 0.6765, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6798, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 031, Train loss: 0.6721, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6785, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 032, Train loss: 0.6733, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.6797, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 033, Train loss: 0.6722, Train Acc: 0.5910, Train f1-score: 0.6123, Val loss: 0.6814, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 034, Train loss: 0.6706, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6829, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 035, Train loss: 0.6700, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6835, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 036, Train loss: 0.6726, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6833, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 037, Train loss: 0.6699, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6774, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 038, Train loss: 0.6744, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.6799, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 039, Train loss: 0.6724, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6820, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 040, Train loss: 0.6720, Train Acc: 0.5847, Train f1-score: 0.6123, Val loss: 0.6801, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 041, Train loss: 0.6701, Train Acc: 0.5785, Train f1-score: 0.6123, Val loss: 0.6788, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 042, Train loss: 0.6717, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.6793, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 043, Train loss: 0.6700, Train Acc: 0.5896, Train f1-score: 0.6667, Val loss: 0.6804, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 044, Train loss: 0.6705, Train Acc: 0.5375, Train f1-score: 0.4749, Val loss: 0.6798, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 045, Train loss: 0.6692, Train Acc: 0.5722, Train f1-score: 0.6123, Val loss: 0.6799, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 046, Train loss: 0.6694, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.6881, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 047, Train loss: 0.6670, Train Acc: 0.5472, Train f1-score: 0.6123, Val loss: 0.6892, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 048, Train loss: 0.6682, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6868, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 049, Train loss: 0.6685, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 050, Train loss: 0.6701, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6786, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 051, Train loss: 0.6727, Train Acc: 0.5708, Train f1-score: 0.6667, Val loss: 0.6786, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 052, Train loss: 0.6715, Train Acc: 0.5597, Train f1-score: 0.5616, Val loss: 0.6788, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 053, Train loss: 0.6768, Train Acc: 0.5799, Train f1-score: 0.3968, Val loss: 0.6760, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 054, Train loss: 0.6720, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.6777, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 055, Train loss: 0.6701, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.6767, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 056, Train loss: 0.6720, Train Acc: 0.5736, Train f1-score: 0.4735, Val loss: 0.6779, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 057, Train loss: 0.6695, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.6794, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 058, Train loss: 0.6695, Train Acc: 0.5861, Train f1-score: 0.4735, Val loss: 0.6761, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 059, Train loss: 0.6759, Train Acc: 0.5799, Train f1-score: 0.3968, Val loss: 0.6756, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 060, Train loss: 0.6712, Train Acc: 0.6083, Train f1-score: 0.6389, Val loss: 0.6806, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 061, Train loss: 0.6677, Train Acc: 0.5847, Train f1-score: 0.5616, Val loss: 0.6809, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 062, Train loss: 0.6691, Train Acc: 0.6257, Train f1-score: 0.7083, Val loss: 0.6833, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 063, Train loss: 0.6675, Train Acc: 0.5958, Train f1-score: 0.6389, Val loss: 0.6792, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 064, Train loss: 0.6690, Train Acc: 0.6132, Train f1-score: 0.7083, Val loss: 0.6832, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 065, Train loss: 0.6672, Train Acc: 0.5847, Train f1-score: 0.5103, Val loss: 0.6781, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 066, Train loss: 0.6739, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.6815, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 067, Train loss: 0.6676, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6810, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 068, Train loss: 0.6656, Train Acc: 0.6194, Train f1-score: 0.7083, Val loss: 0.6827, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 069, Train loss: 0.6642, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.6853, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 070, Train loss: 0.6637, Train Acc: 0.6181, Train f1-score: 0.7593, Val loss: 0.6820, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 071, Train loss: 0.6678, Train Acc: 0.6306, Train f1-score: 0.7593, Val loss: 0.6833, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 072, Train loss: 0.6674, Train Acc: 0.6368, Train f1-score: 0.7593, Val loss: 0.6880, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 073, Train loss: 0.6610, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6816, Val Acc: 0.3750, Val f1-score: 0.3542,\n",
      "Epoch: 074, Train loss: 0.6691, Train Acc: 0.6021, Train f1-score: 0.6051, Val loss: 0.6836, Val Acc: 0.3750, Val f1-score: 0.3542,\n",
      "Epoch: 075, Train loss: 0.6698, Train Acc: 0.6021, Train f1-score: 0.6051, Val loss: 0.6807, Val Acc: 0.3750, Val f1-score: 0.3542,\n",
      "Epoch: 076, Train loss: 0.6652, Train Acc: 0.6035, Train f1-score: 0.5103, Val loss: 0.6833, Val Acc: 0.3750, Val f1-score: 0.3542,\n",
      "Epoch: 077, Train loss: 0.6663, Train Acc: 0.6319, Train f1-score: 0.6869, Val loss: 0.6912, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 078, Train loss: 0.6595, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6856, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 079, Train loss: 0.6689, Train Acc: 0.6368, Train f1-score: 0.7593, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 080, Train loss: 0.6586, Train Acc: 0.6319, Train f1-score: 0.6869, Val loss: 0.6905, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 081, Train loss: 0.6628, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6908, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 082, Train loss: 0.6587, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6935, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 083, Train loss: 0.6651, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6947, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 084, Train loss: 0.6608, Train Acc: 0.5882, Train f1-score: 0.7083, Val loss: 0.6851, Val Acc: 0.3750, Val f1-score: 0.3542,\n",
      "Epoch: 085, Train loss: 0.6635, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6978, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 086, Train loss: 0.6537, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6928, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 087, Train loss: 0.6686, Train Acc: 0.6306, Train f1-score: 0.7593, Val loss: 0.6973, Val Acc: 0.4375, Val f1-score: 0.4010,\n",
      "Epoch: 088, Train loss: 0.6573, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6967, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 089, Train loss: 0.6583, Train Acc: 0.5896, Train f1-score: 0.6051, Val loss: 0.6926, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 090, Train loss: 0.6613, Train Acc: 0.6319, Train f1-score: 0.6869, Val loss: 0.7059, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 091, Train loss: 0.6528, Train Acc: 0.6146, Train f1-score: 0.6051, Val loss: 0.6963, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 092, Train loss: 0.6705, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6989, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 093, Train loss: 0.6556, Train Acc: 0.6021, Train f1-score: 0.6051, Val loss: 0.6948, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 094, Train loss: 0.6581, Train Acc: 0.6319, Train f1-score: 0.6869, Val loss: 0.7183, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 095, Train loss: 0.6505, Train Acc: 0.6160, Train f1-score: 0.5103, Val loss: 0.6952, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 096, Train loss: 0.6648, Train Acc: 0.6257, Train f1-score: 0.6869, Val loss: 0.7125, Val Acc: 0.5625, Val f1-score: 0.4885,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 097, Train loss: 0.6493, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.6966, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 098, Train loss: 0.6598, Train Acc: 0.6118, Train f1-score: 0.7593, Val loss: 0.7036, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 099, Train loss: 0.6535, Train Acc: 0.6431, Train f1-score: 0.7593, Val loss: 0.7042, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 100, Train loss: 0.6511, Train Acc: 0.6493, Train f1-score: 0.7593, Val loss: 0.7167, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "GIN accuracy: 0.3684210479259491\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  85  87  90  91  93  94\n",
      "  96  98 100 101 102 103 104 105 106 107 108 112 115 118 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [ 84  86  88  89  92  95  97  99 109 110 111 113 114 116 117 119]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.1383, Train Acc: 0.4604, Train f1-score: 0.2222, Val loss: 0.7472, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 0.7181, Train Acc: 0.4889, Train f1-score: 0.2735, Val loss: 0.7081, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.7124, Train Acc: 0.5160, Train f1-score: 0.5656, Val loss: 0.7014, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.7075, Train Acc: 0.4750, Train f1-score: 0.4749, Val loss: 0.6999, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.7045, Train Acc: 0.5160, Train f1-score: 0.5616, Val loss: 0.6981, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.7045, Train Acc: 0.4924, Train f1-score: 0.4735, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.7024, Train Acc: 0.4639, Train f1-score: 0.4300, Val loss: 0.6989, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.7006, Train Acc: 0.5049, Train f1-score: 0.5185, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.7005, Train Acc: 0.4986, Train f1-score: 0.4735, Val loss: 0.6968, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6988, Train Acc: 0.5049, Train f1-score: 0.4735, Val loss: 0.6958, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6987, Train Acc: 0.4826, Train f1-score: 0.4300, Val loss: 0.6954, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6967, Train Acc: 0.5049, Train f1-score: 0.5185, Val loss: 0.6944, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6963, Train Acc: 0.4826, Train f1-score: 0.4300, Val loss: 0.6956, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6964, Train Acc: 0.5000, Train f1-score: 0.4749, Val loss: 0.6939, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6959, Train Acc: 0.4938, Train f1-score: 0.4749, Val loss: 0.6928, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6965, Train Acc: 0.5285, Train f1-score: 0.6123, Val loss: 0.6942, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6954, Train Acc: 0.4889, Train f1-score: 0.4300, Val loss: 0.6936, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6944, Train Acc: 0.4889, Train f1-score: 0.4300, Val loss: 0.6925, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6935, Train Acc: 0.4986, Train f1-score: 0.5185, Val loss: 0.6938, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6922, Train Acc: 0.5000, Train f1-score: 0.4749, Val loss: 0.6973, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6926, Train Acc: 0.5410, Train f1-score: 0.6075, Val loss: 0.6902, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6915, Train Acc: 0.5472, Train f1-score: 0.6123, Val loss: 0.6908, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6905, Train Acc: 0.5188, Train f1-score: 0.4952, Val loss: 0.6910, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6906, Train Acc: 0.5299, Train f1-score: 0.5556, Val loss: 0.6909, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6893, Train Acc: 0.5410, Train f1-score: 0.6123, Val loss: 0.6886, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6903, Train Acc: 0.5472, Train f1-score: 0.6123, Val loss: 0.6874, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6902, Train Acc: 0.5361, Train f1-score: 0.5556, Val loss: 0.6887, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 027, Train loss: 0.6886, Train Acc: 0.5410, Train f1-score: 0.6075, Val loss: 0.6872, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 028, Train loss: 0.6881, Train Acc: 0.5424, Train f1-score: 0.5556, Val loss: 0.6865, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 029, Train loss: 0.6892, Train Acc: 0.5410, Train f1-score: 0.6123, Val loss: 0.6842, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 030, Train loss: 0.6880, Train Acc: 0.5535, Train f1-score: 0.6075, Val loss: 0.6854, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 031, Train loss: 0.6867, Train Acc: 0.5361, Train f1-score: 0.5556, Val loss: 0.6824, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 032, Train loss: 0.6881, Train Acc: 0.5299, Train f1-score: 0.5556, Val loss: 0.6837, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 033, Train loss: 0.6867, Train Acc: 0.5549, Train f1-score: 0.5444, Val loss: 0.6826, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 034, Train loss: 0.6849, Train Acc: 0.5535, Train f1-score: 0.6075, Val loss: 0.6807, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 035, Train loss: 0.6853, Train Acc: 0.5299, Train f1-score: 0.5556, Val loss: 0.6815, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6843, Train Acc: 0.5535, Train f1-score: 0.6075, Val loss: 0.6835, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6848, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.6828, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 038, Train loss: 0.6836, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.6811, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 039, Train loss: 0.6828, Train Acc: 0.5597, Train f1-score: 0.6075, Val loss: 0.6779, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 040, Train loss: 0.6847, Train Acc: 0.5472, Train f1-score: 0.6075, Val loss: 0.6799, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 041, Train loss: 0.6833, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.6789, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 042, Train loss: 0.6827, Train Acc: 0.5549, Train f1-score: 0.5556, Val loss: 0.6784, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 043, Train loss: 0.6839, Train Acc: 0.5674, Train f1-score: 0.5444, Val loss: 0.6779, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 044, Train loss: 0.6827, Train Acc: 0.5472, Train f1-score: 0.6123, Val loss: 0.6765, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 045, Train loss: 0.6824, Train Acc: 0.5910, Train f1-score: 0.6075, Val loss: 0.6766, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 046, Train loss: 0.6841, Train Acc: 0.5785, Train f1-score: 0.5926, Val loss: 0.6776, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 047, Train loss: 0.6820, Train Acc: 0.5660, Train f1-score: 0.6075, Val loss: 0.6761, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 048, Train loss: 0.6840, Train Acc: 0.5549, Train f1-score: 0.5444, Val loss: 0.6762, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 049, Train loss: 0.6818, Train Acc: 0.5847, Train f1-score: 0.5926, Val loss: 0.6760, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 050, Train loss: 0.6812, Train Acc: 0.5611, Train f1-score: 0.5444, Val loss: 0.6762, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 051, Train loss: 0.6807, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6761, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 052, Train loss: 0.6813, Train Acc: 0.5736, Train f1-score: 0.5444, Val loss: 0.6754, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 053, Train loss: 0.6803, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.6757, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 054, Train loss: 0.6808, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6756, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 055, Train loss: 0.6815, Train Acc: 0.5611, Train f1-score: 0.5444, Val loss: 0.6744, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 056, Train loss: 0.6810, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.6747, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 057, Train loss: 0.6802, Train Acc: 0.5736, Train f1-score: 0.5444, Val loss: 0.6748, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 058, Train loss: 0.6808, Train Acc: 0.5611, Train f1-score: 0.5444, Val loss: 0.6753, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 059, Train loss: 0.6803, Train Acc: 0.5486, Train f1-score: 0.5444, Val loss: 0.6741, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 060, Train loss: 0.6792, Train Acc: 0.5424, Train f1-score: 0.5444, Val loss: 0.6743, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 061, Train loss: 0.6792, Train Acc: 0.5299, Train f1-score: 0.5444, Val loss: 0.6743, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 062, Train loss: 0.6797, Train Acc: 0.5611, Train f1-score: 0.5444, Val loss: 0.6746, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 063, Train loss: 0.6781, Train Acc: 0.5611, Train f1-score: 0.5444, Val loss: 0.6747, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 064, Train loss: 0.6787, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6743, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 065, Train loss: 0.6792, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6733, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 066, Train loss: 0.6793, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6737, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 067, Train loss: 0.6792, Train Acc: 0.5958, Train f1-score: 0.6407, Val loss: 0.6740, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 068, Train loss: 0.6778, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6743, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 069, Train loss: 0.6783, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.6729, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 070, Train loss: 0.6780, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.6730, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 071, Train loss: 0.6786, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6726, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 072, Train loss: 0.6773, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.6725, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 073, Train loss: 0.6786, Train Acc: 0.5958, Train f1-score: 0.6407, Val loss: 0.6723, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 074, Train loss: 0.6766, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6723, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 075, Train loss: 0.6774, Train Acc: 0.5847, Train f1-score: 0.5926, Val loss: 0.6737, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 076, Train loss: 0.6757, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.6703, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 077, Train loss: 0.6781, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.6713, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 078, Train loss: 0.6779, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6718, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 079, Train loss: 0.6772, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6721, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 080, Train loss: 0.6750, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6713, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 081, Train loss: 0.6745, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6713, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 082, Train loss: 0.6772, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 083, Train loss: 0.6764, Train Acc: 0.5486, Train f1-score: 0.5444, Val loss: 0.6740, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 084, Train loss: 0.6740, Train Acc: 0.5736, Train f1-score: 0.5444, Val loss: 0.6702, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 085, Train loss: 0.6749, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.6693, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 086, Train loss: 0.6753, Train Acc: 0.5771, Train f1-score: 0.6667, Val loss: 0.6680, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 087, Train loss: 0.6762, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.6670, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 088, Train loss: 0.6753, Train Acc: 0.5646, Train f1-score: 0.6667, Val loss: 0.6670, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 089, Train loss: 0.6749, Train Acc: 0.5708, Train f1-score: 0.6667, Val loss: 0.6665, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 090, Train loss: 0.6744, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6660, Val Acc: 0.7500, Val f1-score: 0.7460,\n",
      "Epoch: 091, Train loss: 0.6762, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.6668, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 092, Train loss: 0.6751, Train Acc: 0.5944, Train f1-score: 0.7090, Val loss: 0.6672, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 093, Train loss: 0.6741, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6693, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 094, Train loss: 0.6716, Train Acc: 0.5424, Train f1-score: 0.5444, Val loss: 0.6660, Val Acc: 0.7500, Val f1-score: 0.7460,\n",
      "Epoch: 095, Train loss: 0.6726, Train Acc: 0.5958, Train f1-score: 0.6407, Val loss: 0.6691, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 096, Train loss: 0.6710, Train Acc: 0.5944, Train f1-score: 0.7090, Val loss: 0.6649, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 097, Train loss: 0.6718, Train Acc: 0.5583, Train f1-score: 0.6667, Val loss: 0.6630, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 098, Train loss: 0.6724, Train Acc: 0.5646, Train f1-score: 0.6580, Val loss: 0.6627, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 099, Train loss: 0.6719, Train Acc: 0.5660, Train f1-score: 0.6123, Val loss: 0.6651, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 100, Train loss: 0.6716, Train Acc: 0.6292, Train f1-score: 0.8338, Val loss: 0.6608, Val Acc: 0.6875, Val f1-score: 0.6863,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 102 103 104 107 108 109 110\n",
      " 111 113 114 116 117 119 126 130 131 132 133 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [101 105 106 112 115 118 120 121 122 123 124 125 127 128 129 134]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.1555, Train Acc: 0.5396, Train f1-score: 0.6051, Val loss: 0.6996, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 0.7408, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7011, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.7200, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6965, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.7147, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6940, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 004, Train loss: 0.7111, Train Acc: 0.4861, Train f1-score: 0.3968, Val loss: 0.6944, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.7080, Train Acc: 0.4736, Train f1-score: 0.3968, Val loss: 0.6948, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.7056, Train Acc: 0.4736, Train f1-score: 0.3968, Val loss: 0.6963, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.7044, Train Acc: 0.4736, Train f1-score: 0.3968, Val loss: 0.6955, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.7022, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6981, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.7018, Train Acc: 0.4736, Train f1-score: 0.3968, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.7014, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.7001, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6983, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6993, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6984, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6982, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6995, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6974, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6997, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6965, Train Acc: 0.4924, Train f1-score: 0.3968, Val loss: 0.7008, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6967, Train Acc: 0.4924, Train f1-score: 0.3968, Val loss: 0.7001, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6950, Train Acc: 0.4924, Train f1-score: 0.3968, Val loss: 0.7011, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6942, Train Acc: 0.4986, Train f1-score: 0.3968, Val loss: 0.7020, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6938, Train Acc: 0.4986, Train f1-score: 0.3968, Val loss: 0.7008, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6929, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.7023, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6922, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.7018, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6913, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.7029, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6911, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.7022, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6903, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.7012, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6894, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7024, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6890, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7028, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 027, Train loss: 0.6884, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7004, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 028, Train loss: 0.6885, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7002, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 029, Train loss: 0.6865, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7036, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 030, Train loss: 0.6865, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.7042, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 031, Train loss: 0.6860, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.7034, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 032, Train loss: 0.6856, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.7017, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 033, Train loss: 0.6854, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.7022, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 034, Train loss: 0.6848, Train Acc: 0.5861, Train f1-score: 0.3968, Val loss: 0.7027, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 035, Train loss: 0.6842, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.7057, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 036, Train loss: 0.6835, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.7040, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 037, Train loss: 0.6822, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.7061, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 038, Train loss: 0.6825, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.7059, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 039, Train loss: 0.6837, Train Acc: 0.5799, Train f1-score: 0.3968, Val loss: 0.7072, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 040, Train loss: 0.6811, Train Acc: 0.5736, Train f1-score: 0.3968, Val loss: 0.7072, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 041, Train loss: 0.6806, Train Acc: 0.5861, Train f1-score: 0.3968, Val loss: 0.7094, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 042, Train loss: 0.6799, Train Acc: 0.5813, Train f1-score: 0.3704, Val loss: 0.7087, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 043, Train loss: 0.6784, Train Acc: 0.6049, Train f1-score: 0.3968, Val loss: 0.7078, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 044, Train loss: 0.6786, Train Acc: 0.6111, Train f1-score: 0.3968, Val loss: 0.7083, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 045, Train loss: 0.6782, Train Acc: 0.5986, Train f1-score: 0.3968, Val loss: 0.7099, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 046, Train loss: 0.6777, Train Acc: 0.6174, Train f1-score: 0.4735, Val loss: 0.7113, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 047, Train loss: 0.6801, Train Acc: 0.6111, Train f1-score: 0.3968, Val loss: 0.7097, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 048, Train loss: 0.6780, Train Acc: 0.6111, Train f1-score: 0.4735, Val loss: 0.7146, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 049, Train loss: 0.6770, Train Acc: 0.6111, Train f1-score: 0.4735, Val loss: 0.7129, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 050, Train loss: 0.6768, Train Acc: 0.6111, Train f1-score: 0.4735, Val loss: 0.7168, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 051, Train loss: 0.6767, Train Acc: 0.6174, Train f1-score: 0.4735, Val loss: 0.7104, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 052, Train loss: 0.6770, Train Acc: 0.6236, Train f1-score: 0.4735, Val loss: 0.7166, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 053, Train loss: 0.6768, Train Acc: 0.6174, Train f1-score: 0.4735, Val loss: 0.7149, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 054, Train loss: 0.6753, Train Acc: 0.6236, Train f1-score: 0.4735, Val loss: 0.7178, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 055, Train loss: 0.6746, Train Acc: 0.6299, Train f1-score: 0.4735, Val loss: 0.7162, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 056, Train loss: 0.6743, Train Acc: 0.6174, Train f1-score: 0.4735, Val loss: 0.7152, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 057, Train loss: 0.6749, Train Acc: 0.6236, Train f1-score: 0.4735, Val loss: 0.7187, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 058, Train loss: 0.6741, Train Acc: 0.6222, Train f1-score: 0.5616, Val loss: 0.7162, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 059, Train loss: 0.6736, Train Acc: 0.6347, Train f1-score: 0.5616, Val loss: 0.7177, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 060, Train loss: 0.6759, Train Acc: 0.6049, Train f1-score: 0.4735, Val loss: 0.7186, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 061, Train loss: 0.6731, Train Acc: 0.6160, Train f1-score: 0.5616, Val loss: 0.7201, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 062, Train loss: 0.6718, Train Acc: 0.6222, Train f1-score: 0.5616, Val loss: 0.7195, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 063, Train loss: 0.6733, Train Acc: 0.6347, Train f1-score: 0.5616, Val loss: 0.7260, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 064, Train loss: 0.6707, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7231, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 065, Train loss: 0.6717, Train Acc: 0.6222, Train f1-score: 0.5616, Val loss: 0.7174, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 066, Train loss: 0.6730, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7215, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 067, Train loss: 0.6727, Train Acc: 0.6285, Train f1-score: 0.5616, Val loss: 0.7269, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 068, Train loss: 0.6717, Train Acc: 0.6285, Train f1-score: 0.5616, Val loss: 0.7254, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 069, Train loss: 0.6725, Train Acc: 0.6347, Train f1-score: 0.5616, Val loss: 0.7236, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 070, Train loss: 0.6717, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7231, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 071, Train loss: 0.6732, Train Acc: 0.6347, Train f1-score: 0.5616, Val loss: 0.7292, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 072, Train loss: 0.6682, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.7247, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 073, Train loss: 0.6704, Train Acc: 0.6111, Train f1-score: 0.5185, Val loss: 0.7331, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 074, Train loss: 0.6701, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7266, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 075, Train loss: 0.6703, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.7245, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 076, Train loss: 0.6709, Train Acc: 0.6049, Train f1-score: 0.5185, Val loss: 0.7256, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 077, Train loss: 0.6714, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.7272, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 078, Train loss: 0.6697, Train Acc: 0.5799, Train f1-score: 0.5185, Val loss: 0.7294, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 079, Train loss: 0.6715, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.7258, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 080, Train loss: 0.6700, Train Acc: 0.5799, Train f1-score: 0.5185, Val loss: 0.7350, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 081, Train loss: 0.6678, Train Acc: 0.5986, Train f1-score: 0.5185, Val loss: 0.7222, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 082, Train loss: 0.6693, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7268, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 083, Train loss: 0.6699, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7255, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 084, Train loss: 0.6691, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.7287, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 085, Train loss: 0.6693, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.7319, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 086, Train loss: 0.6696, Train Acc: 0.6174, Train f1-score: 0.5185, Val loss: 0.7259, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 087, Train loss: 0.6663, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.7324, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 088, Train loss: 0.6671, Train Acc: 0.5972, Train f1-score: 0.5616, Val loss: 0.7357, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 089, Train loss: 0.6674, Train Acc: 0.5986, Train f1-score: 0.5185, Val loss: 0.7389, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 090, Train loss: 0.6666, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.7335, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 091, Train loss: 0.6661, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.7388, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 092, Train loss: 0.6671, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.7323, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 093, Train loss: 0.6659, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.7368, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 094, Train loss: 0.6671, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.7323, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 095, Train loss: 0.6656, Train Acc: 0.5861, Train f1-score: 0.5185, Val loss: 0.7324, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 096, Train loss: 0.6657, Train Acc: 0.5799, Train f1-score: 0.5185, Val loss: 0.7346, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 097, Train loss: 0.6663, Train Acc: 0.5861, Train f1-score: 0.5185, Val loss: 0.7415, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 098, Train loss: 0.6648, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.7324, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 099, Train loss: 0.6653, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.7341, Val Acc: 0.5000, Val f1-score: 0.4921,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train loss: 0.6643, Train Acc: 0.5799, Train f1-score: 0.5185, Val loss: 0.7381, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "GIN accuracy: 0.6315789222717285\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 127 128 129 134 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [126 130 131 132 133 135 136 137 138 139 140 141 142 143 144 145]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.3907, Train Acc: 0.5035, Train f1-score: 0.5103, Val loss: 0.6935, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 0.7116, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.6916, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.7077, Train Acc: 0.4736, Train f1-score: 0.3968, Val loss: 0.6951, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.7035, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6979, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.7025, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.6993, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.7019, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.7003, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.7008, Train Acc: 0.4799, Train f1-score: 0.3968, Val loss: 0.7015, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.6994, Train Acc: 0.4861, Train f1-score: 0.3968, Val loss: 0.7014, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.6988, Train Acc: 0.4924, Train f1-score: 0.3968, Val loss: 0.7015, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6979, Train Acc: 0.4986, Train f1-score: 0.3968, Val loss: 0.7019, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6971, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.7021, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6966, Train Acc: 0.4986, Train f1-score: 0.3968, Val loss: 0.7018, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6991, Train Acc: 0.5111, Train f1-score: 0.3968, Val loss: 0.6959, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 013, Train loss: 0.6975, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6987, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6965, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.7009, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6950, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.7023, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6944, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.7007, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6930, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7036, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6915, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.7057, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6925, Train Acc: 0.5236, Train f1-score: 0.3968, Val loss: 0.7054, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6905, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.7055, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6911, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.7032, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6889, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7060, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6888, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.7057, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 024, Train loss: 0.6890, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7054, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 025, Train loss: 0.6872, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.7083, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 026, Train loss: 0.6898, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7072, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 027, Train loss: 0.6866, Train Acc: 0.5674, Train f1-score: 0.3968, Val loss: 0.7062, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 028, Train loss: 0.6900, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7050, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 029, Train loss: 0.6854, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7049, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 030, Train loss: 0.6854, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7060, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 031, Train loss: 0.6836, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7041, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 032, Train loss: 0.6843, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7088, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 033, Train loss: 0.6829, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7016, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 034, Train loss: 0.6835, Train Acc: 0.5611, Train f1-score: 0.3968, Val loss: 0.7043, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 035, Train loss: 0.6824, Train Acc: 0.5549, Train f1-score: 0.4735, Val loss: 0.7047, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6826, Train Acc: 0.5549, Train f1-score: 0.4735, Val loss: 0.7030, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6817, Train Acc: 0.5611, Train f1-score: 0.4735, Val loss: 0.7035, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 038, Train loss: 0.6811, Train Acc: 0.5549, Train f1-score: 0.4735, Val loss: 0.7011, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 039, Train loss: 0.6817, Train Acc: 0.5736, Train f1-score: 0.4735, Val loss: 0.7021, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 040, Train loss: 0.6822, Train Acc: 0.5674, Train f1-score: 0.4735, Val loss: 0.7056, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 041, Train loss: 0.6779, Train Acc: 0.5861, Train f1-score: 0.4735, Val loss: 0.6999, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 042, Train loss: 0.6822, Train Acc: 0.5674, Train f1-score: 0.4735, Val loss: 0.7032, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 043, Train loss: 0.6797, Train Acc: 0.5736, Train f1-score: 0.4735, Val loss: 0.6987, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 044, Train loss: 0.6801, Train Acc: 0.5986, Train f1-score: 0.4735, Val loss: 0.7053, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 045, Train loss: 0.6781, Train Acc: 0.5924, Train f1-score: 0.4735, Val loss: 0.7030, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 046, Train loss: 0.6773, Train Acc: 0.6097, Train f1-score: 0.5616, Val loss: 0.7013, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 047, Train loss: 0.6795, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.7022, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 048, Train loss: 0.6775, Train Acc: 0.5986, Train f1-score: 0.5185, Val loss: 0.7033, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 049, Train loss: 0.6781, Train Acc: 0.6285, Train f1-score: 0.5616, Val loss: 0.6977, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 050, Train loss: 0.6805, Train Acc: 0.5451, Train f1-score: 0.4300, Val loss: 0.7011, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 051, Train loss: 0.6754, Train Acc: 0.5875, Train f1-score: 0.4749, Val loss: 0.6973, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 052, Train loss: 0.6776, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 053, Train loss: 0.6768, Train Acc: 0.6111, Train f1-score: 0.5185, Val loss: 0.6971, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 054, Train loss: 0.6765, Train Acc: 0.5764, Train f1-score: 0.4300, Val loss: 0.7038, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 055, Train loss: 0.6733, Train Acc: 0.5924, Train f1-score: 0.5185, Val loss: 0.6954, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 056, Train loss: 0.6757, Train Acc: 0.6000, Train f1-score: 0.4749, Val loss: 0.6947, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 057, Train loss: 0.6741, Train Acc: 0.5938, Train f1-score: 0.4749, Val loss: 0.6961, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 058, Train loss: 0.6733, Train Acc: 0.5938, Train f1-score: 0.4749, Val loss: 0.6984, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 059, Train loss: 0.6741, Train Acc: 0.6062, Train f1-score: 0.4749, Val loss: 0.6966, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 060, Train loss: 0.6736, Train Acc: 0.5938, Train f1-score: 0.4749, Val loss: 0.6966, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 061, Train loss: 0.6723, Train Acc: 0.5875, Train f1-score: 0.4749, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 062, Train loss: 0.6722, Train Acc: 0.5764, Train f1-score: 0.4300, Val loss: 0.7001, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 063, Train loss: 0.6723, Train Acc: 0.5826, Train f1-score: 0.4300, Val loss: 0.6928, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 064, Train loss: 0.6736, Train Acc: 0.5826, Train f1-score: 0.4300, Val loss: 0.6947, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 065, Train loss: 0.6703, Train Acc: 0.5701, Train f1-score: 0.4300, Val loss: 0.6992, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 066, Train loss: 0.6697, Train Acc: 0.5639, Train f1-score: 0.4300, Val loss: 0.6941, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 067, Train loss: 0.6706, Train Acc: 0.5639, Train f1-score: 0.4300, Val loss: 0.6929, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 068, Train loss: 0.6711, Train Acc: 0.5701, Train f1-score: 0.4300, Val loss: 0.6916, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 069, Train loss: 0.6686, Train Acc: 0.5576, Train f1-score: 0.4300, Val loss: 0.6923, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 070, Train loss: 0.6698, Train Acc: 0.5576, Train f1-score: 0.4300, Val loss: 0.6892, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 071, Train loss: 0.6707, Train Acc: 0.5764, Train f1-score: 0.4300, Val loss: 0.6938, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 072, Train loss: 0.6689, Train Acc: 0.5625, Train f1-score: 0.4749, Val loss: 0.6906, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 073, Train loss: 0.6709, Train Acc: 0.5875, Train f1-score: 0.4749, Val loss: 0.6901, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 074, Train loss: 0.6685, Train Acc: 0.5750, Train f1-score: 0.4749, Val loss: 0.6933, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 075, Train loss: 0.6678, Train Acc: 0.5639, Train f1-score: 0.4300, Val loss: 0.6933, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 076, Train loss: 0.6675, Train Acc: 0.5861, Train f1-score: 0.5185, Val loss: 0.6911, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 077, Train loss: 0.6671, Train Acc: 0.5687, Train f1-score: 0.4749, Val loss: 0.6908, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 078, Train loss: 0.6685, Train Acc: 0.5972, Train f1-score: 0.5616, Val loss: 0.6947, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 079, Train loss: 0.6679, Train Acc: 0.5812, Train f1-score: 0.4749, Val loss: 0.6928, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 080, Train loss: 0.6671, Train Acc: 0.5812, Train f1-score: 0.4749, Val loss: 0.6941, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 081, Train loss: 0.6688, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.6961, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 082, Train loss: 0.6642, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.6923, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 083, Train loss: 0.6663, Train Acc: 0.5812, Train f1-score: 0.4749, Val loss: 0.6920, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 084, Train loss: 0.6662, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.6926, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 085, Train loss: 0.6656, Train Acc: 0.5736, Train f1-score: 0.4735, Val loss: 0.6918, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 086, Train loss: 0.6647, Train Acc: 0.6160, Train f1-score: 0.5616, Val loss: 0.6932, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 087, Train loss: 0.6643, Train Acc: 0.5910, Train f1-score: 0.5616, Val loss: 0.6943, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 088, Train loss: 0.6649, Train Acc: 0.5924, Train f1-score: 0.4735, Val loss: 0.6933, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 089, Train loss: 0.6625, Train Acc: 0.6035, Train f1-score: 0.5616, Val loss: 0.6939, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 090, Train loss: 0.6619, Train Acc: 0.5924, Train f1-score: 0.4735, Val loss: 0.6934, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 091, Train loss: 0.6643, Train Acc: 0.6049, Train f1-score: 0.4735, Val loss: 0.6908, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 092, Train loss: 0.6638, Train Acc: 0.5986, Train f1-score: 0.4735, Val loss: 0.6987, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 093, Train loss: 0.6610, Train Acc: 0.5924, Train f1-score: 0.4735, Val loss: 0.6966, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 094, Train loss: 0.6611, Train Acc: 0.5986, Train f1-score: 0.4735, Val loss: 0.6915, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 095, Train loss: 0.6617, Train Acc: 0.5799, Train f1-score: 0.4735, Val loss: 0.6928, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 096, Train loss: 0.6606, Train Acc: 0.6035, Train f1-score: 0.5103, Val loss: 0.6973, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 097, Train loss: 0.6591, Train Acc: 0.6035, Train f1-score: 0.5103, Val loss: 0.6977, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 098, Train loss: 0.6585, Train Acc: 0.5875, Train f1-score: 0.4749, Val loss: 0.6991, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 099, Train loss: 0.6588, Train Acc: 0.6049, Train f1-score: 0.3968, Val loss: 0.6950, Val Acc: 0.5000, Val f1-score: 0.4921,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train loss: 0.6582, Train Acc: 0.5986, Train f1-score: 0.3968, Val loss: 0.6940, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "GIN accuracy: 0.42105263471603394\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145] TEST: [146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.1555, Train Acc: 0.4972, Train f1-score: 0.4636, Val loss: 0.7058, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 0.7113, Train Acc: 0.5410, Train f1-score: 0.4636, Val loss: 0.6992, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.6943, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6973, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.6920, Train Acc: 0.5472, Train f1-score: 0.4636, Val loss: 0.6978, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.6919, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6985, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.6917, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6988, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.6908, Train Acc: 0.5472, Train f1-score: 0.4636, Val loss: 0.6985, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.6906, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6961, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.6899, Train Acc: 0.5410, Train f1-score: 0.4636, Val loss: 0.6961, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6898, Train Acc: 0.5535, Train f1-score: 0.4636, Val loss: 0.6932, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6889, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6906, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6884, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6928, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6884, Train Acc: 0.5410, Train f1-score: 0.4636, Val loss: 0.6916, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6889, Train Acc: 0.5347, Train f1-score: 0.4636, Val loss: 0.6888, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6872, Train Acc: 0.5535, Train f1-score: 0.4636, Val loss: 0.6885, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6868, Train Acc: 0.5410, Train f1-score: 0.4636, Val loss: 0.6883, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6872, Train Acc: 0.5472, Train f1-score: 0.4636, Val loss: 0.6872, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6862, Train Acc: 0.5472, Train f1-score: 0.4636, Val loss: 0.6857, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6860, Train Acc: 0.5472, Train f1-score: 0.4636, Val loss: 0.6849, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6857, Train Acc: 0.5472, Train f1-score: 0.4636, Val loss: 0.6792, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6855, Train Acc: 0.5535, Train f1-score: 0.4636, Val loss: 0.6777, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6847, Train Acc: 0.5535, Train f1-score: 0.4636, Val loss: 0.6821, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6860, Train Acc: 0.5535, Train f1-score: 0.4636, Val loss: 0.6792, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6842, Train Acc: 0.5660, Train f1-score: 0.4636, Val loss: 0.6782, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6841, Train Acc: 0.5722, Train f1-score: 0.4636, Val loss: 0.6762, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6837, Train Acc: 0.5722, Train f1-score: 0.4636, Val loss: 0.6774, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6832, Train Acc: 0.5722, Train f1-score: 0.4636, Val loss: 0.6753, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 027, Train loss: 0.6843, Train Acc: 0.5660, Train f1-score: 0.4636, Val loss: 0.6719, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 028, Train loss: 0.6839, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6716, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 029, Train loss: 0.6855, Train Acc: 0.5660, Train f1-score: 0.4636, Val loss: 0.6704, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 030, Train loss: 0.6829, Train Acc: 0.5910, Train f1-score: 0.4636, Val loss: 0.6729, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 031, Train loss: 0.6823, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6678, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 032, Train loss: 0.6833, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6724, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 033, Train loss: 0.6832, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6736, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 034, Train loss: 0.6830, Train Acc: 0.5785, Train f1-score: 0.4636, Val loss: 0.6750, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 035, Train loss: 0.6835, Train Acc: 0.5785, Train f1-score: 0.4636, Val loss: 0.6711, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6817, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6696, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6826, Train Acc: 0.5910, Train f1-score: 0.4636, Val loss: 0.6687, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 038, Train loss: 0.6818, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6712, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 039, Train loss: 0.6802, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6618, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 040, Train loss: 0.6816, Train Acc: 0.5910, Train f1-score: 0.4636, Val loss: 0.6648, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 041, Train loss: 0.6800, Train Acc: 0.5910, Train f1-score: 0.4636, Val loss: 0.6601, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 042, Train loss: 0.6820, Train Acc: 0.5910, Train f1-score: 0.4636, Val loss: 0.6627, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 043, Train loss: 0.6804, Train Acc: 0.5847, Train f1-score: 0.4636, Val loss: 0.6566, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 044, Train loss: 0.6818, Train Acc: 0.5861, Train f1-score: 0.4365, Val loss: 0.6578, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 045, Train loss: 0.6820, Train Acc: 0.5972, Train f1-score: 0.4636, Val loss: 0.6620, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 046, Train loss: 0.6804, Train Acc: 0.5736, Train f1-score: 0.4365, Val loss: 0.6632, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 047, Train loss: 0.6818, Train Acc: 0.5674, Train f1-score: 0.4365, Val loss: 0.6507, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 048, Train loss: 0.6827, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6605, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 049, Train loss: 0.6806, Train Acc: 0.5687, Train f1-score: 0.4074, Val loss: 0.6576, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 050, Train loss: 0.6812, Train Acc: 0.5750, Train f1-score: 0.4074, Val loss: 0.6548, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 051, Train loss: 0.6794, Train Acc: 0.5563, Train f1-score: 0.4074, Val loss: 0.6553, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 052, Train loss: 0.6798, Train Acc: 0.5910, Train f1-score: 0.4636, Val loss: 0.6573, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 053, Train loss: 0.6786, Train Acc: 0.5563, Train f1-score: 0.4074, Val loss: 0.6457, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 054, Train loss: 0.6826, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6524, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 055, Train loss: 0.6787, Train Acc: 0.5812, Train f1-score: 0.4074, Val loss: 0.6429, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 056, Train loss: 0.6809, Train Acc: 0.5563, Train f1-score: 0.4074, Val loss: 0.6430, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 057, Train loss: 0.6814, Train Acc: 0.5750, Train f1-score: 0.4074, Val loss: 0.6459, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 058, Train loss: 0.6787, Train Acc: 0.5750, Train f1-score: 0.4074, Val loss: 0.6504, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 059, Train loss: 0.6779, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6399, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 060, Train loss: 0.6813, Train Acc: 0.5687, Train f1-score: 0.4074, Val loss: 0.6396, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 061, Train loss: 0.6802, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6483, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 062, Train loss: 0.6779, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6459, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 063, Train loss: 0.6788, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6464, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 064, Train loss: 0.6764, Train Acc: 0.5625, Train f1-score: 0.4074, Val loss: 0.6374, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 065, Train loss: 0.6812, Train Acc: 0.5674, Train f1-score: 0.5009, Val loss: 0.6404, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 066, Train loss: 0.6798, Train Acc: 0.5736, Train f1-score: 0.5009, Val loss: 0.6387, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 067, Train loss: 0.6784, Train Acc: 0.5736, Train f1-score: 0.5009, Val loss: 0.6370, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 068, Train loss: 0.6777, Train Acc: 0.5736, Train f1-score: 0.5009, Val loss: 0.6369, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 069, Train loss: 0.6780, Train Acc: 0.5736, Train f1-score: 0.5009, Val loss: 0.6368, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 070, Train loss: 0.6776, Train Acc: 0.5687, Train f1-score: 0.4618, Val loss: 0.6373, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 071, Train loss: 0.6797, Train Acc: 0.5563, Train f1-score: 0.4618, Val loss: 0.6392, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 072, Train loss: 0.6776, Train Acc: 0.5736, Train f1-score: 0.5009, Val loss: 0.6377, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 073, Train loss: 0.6786, Train Acc: 0.5750, Train f1-score: 0.4618, Val loss: 0.6379, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 074, Train loss: 0.6778, Train Acc: 0.5687, Train f1-score: 0.4618, Val loss: 0.6319, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 075, Train loss: 0.6769, Train Acc: 0.5812, Train f1-score: 0.4618, Val loss: 0.6364, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 076, Train loss: 0.6750, Train Acc: 0.5750, Train f1-score: 0.4618, Val loss: 0.6297, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 077, Train loss: 0.6755, Train Acc: 0.5875, Train f1-score: 0.4618, Val loss: 0.6345, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 078, Train loss: 0.6754, Train Acc: 0.5750, Train f1-score: 0.4618, Val loss: 0.6307, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 079, Train loss: 0.6760, Train Acc: 0.5924, Train f1-score: 0.5009, Val loss: 0.6293, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 080, Train loss: 0.6749, Train Acc: 0.5875, Train f1-score: 0.4618, Val loss: 0.6334, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 081, Train loss: 0.6745, Train Acc: 0.5875, Train f1-score: 0.4618, Val loss: 0.6266, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 082, Train loss: 0.6747, Train Acc: 0.5938, Train f1-score: 0.4618, Val loss: 0.6328, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 083, Train loss: 0.6748, Train Acc: 0.5875, Train f1-score: 0.4618, Val loss: 0.6362, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 084, Train loss: 0.6739, Train Acc: 0.5812, Train f1-score: 0.4618, Val loss: 0.6302, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 085, Train loss: 0.6746, Train Acc: 0.5875, Train f1-score: 0.4618, Val loss: 0.6303, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 086, Train loss: 0.6733, Train Acc: 0.5812, Train f1-score: 0.4618, Val loss: 0.6380, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 087, Train loss: 0.6719, Train Acc: 0.5875, Train f1-score: 0.4618, Val loss: 0.6297, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 088, Train loss: 0.6736, Train Acc: 0.5938, Train f1-score: 0.4618, Val loss: 0.6375, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 089, Train loss: 0.6714, Train Acc: 0.6160, Train f1-score: 0.6148, Val loss: 0.6354, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 090, Train loss: 0.6717, Train Acc: 0.6208, Train f1-score: 0.6667, Val loss: 0.6380, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 091, Train loss: 0.6707, Train Acc: 0.6035, Train f1-score: 0.6148, Val loss: 0.6356, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 092, Train loss: 0.6725, Train Acc: 0.6035, Train f1-score: 0.6046, Val loss: 0.6127, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 093, Train loss: 0.6689, Train Acc: 0.5687, Train f1-score: 0.4618, Val loss: 0.6316, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 094, Train loss: 0.6715, Train Acc: 0.5972, Train f1-score: 0.6148, Val loss: 0.6507, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 095, Train loss: 0.6681, Train Acc: 0.5910, Train f1-score: 0.6148, Val loss: 0.6432, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 096, Train loss: 0.6734, Train Acc: 0.6035, Train f1-score: 0.6046, Val loss: 0.6287, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 097, Train loss: 0.6693, Train Acc: 0.6208, Train f1-score: 0.6667, Val loss: 0.6346, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 098, Train loss: 0.6696, Train Acc: 0.6049, Train f1-score: 0.5370, Val loss: 0.6056, Val Acc: 0.6250, Val f1-score: 0.6190,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 099, Train loss: 0.6686, Train Acc: 0.6222, Train f1-score: 0.6148, Val loss: 0.6444, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 100, Train loss: 0.6774, Train Acc: 0.6083, Train f1-score: 0.6667, Val loss: 0.6470, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "GIN accuracy: 0.4736842215061188\n",
      "Val accuracy: 0.5676470637321472\n",
      "Test accuracy: 0.5210526287555695\n",
      "Test f1-score: 0.4918998907271218\n",
      "Val stv: 0.056841613807589425\n",
      "Test stv: 0.0863221993234783\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_avg = []\n",
    "test_avg = []\n",
    "test_f1_score = []\n",
    "for train_index, val_index in kf.split(train_data, Y_train):\n",
    "    train_dataset=[]\n",
    "    val_dataset=[]\n",
    "    print(\"TRAIN: \", train_index, \"TEST:\", val_index)\n",
    "    for i in train_index:\n",
    "        train_dataset.append(train_data[i])\n",
    "    for i in val_index:\n",
    "        val_dataset.append(train_data[i])\n",
    "\n",
    "    print(len(train_dataset))\n",
    "    print(len(val_dataset))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = GIN(dim_h=32)\n",
    "    model.train()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.6)\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=0.7)\n",
    "    train_epoch=[]\n",
    "    val_epoch=[]\n",
    "    train_loss_=[]\n",
    "    val_loss_=[]\n",
    "    epochs = 100\n",
    "    train_acc=0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        train_loss, train_acc, train_f1score = train(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc, val_f1score = validation(model, val_loader, criterion)\n",
    "\n",
    "        train_loss = train_loss.detach().numpy()\n",
    "        train_loss_.append(train_loss)\n",
    "        val_loss_.append(val_loss.detach().numpy())\n",
    "        train_epoch.append(train_acc)\n",
    "        val_epoch.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Train loss: {train_loss:.4f}, '\n",
    "            f'Train Acc: {train_acc:.4f}, Train f1-score: {train_f1score:.4f}, Val loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val f1-score: {val_f1score:.4f},')\n",
    "\n",
    "    test_acc, test_f1score = test(model, test_data)\n",
    "    print(\"GIN accuracy: \" + str(test_acc))\n",
    "\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # ax1.plot(train_epoch, color=\"red\", label=\"train acc\")\n",
    "    # ax1.plot(val_epoch, color=\"blue\", label=\"test acc\")\n",
    "    # ax2.plot(train_loss_, color=\"orange\", label=\"train loss\")\n",
    "    # ax2.plot(val_loss_, color=\"purple\", label=\"test acc\")\n",
    "    # ax1.set_xlabel(\"Epoch\")\n",
    "    # ax1.set_ylabel(\"Accuracy\")\n",
    "    # ax2.set_xlabel(\"Epoch\")\n",
    "    # ax2.set_ylabel(\"Loss\")\n",
    "    # ax1.legend()\n",
    "    # ax2.legend()\n",
    "\n",
    "    plt.plot(train_epoch, color=\"red\")\n",
    "    plt.plot(val_epoch, color=\"blue\")\n",
    "    plt.plot(train_loss_, color=\"orange\")\n",
    "    plt.plot(val_loss_, color=\"purple\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    val_avg.append(val_acc)\n",
    "    test_avg.append(test_acc)\n",
    "    test_f1_score.append(test_f1score)\n",
    "\n",
    "print('Val accuracy: '+ str(np.array(val_avg).mean()))\n",
    "print('Test accuracy: '+ str(np.array(test_avg).mean()))\n",
    "print('Test f1-score: '+ str(np.array(test_f1_score).mean()))\n",
    "\n",
    "print('Val stv: '+ str(np.array(val_avg).std()))\n",
    "print('Test stv: '+ str(np.array(test_avg).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22cc1b50640>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_epoch, color=\"red\", label=\"train accuracy\")\n",
    "plt.plot(val_epoch, color=\"blue\", label=\"val accuracy\")\n",
    "plt.plot(train_loss_, color=\"orange\", label=\"train loss\")\n",
    "plt.plot(val_loss_, color=\"purple\", label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy and loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
