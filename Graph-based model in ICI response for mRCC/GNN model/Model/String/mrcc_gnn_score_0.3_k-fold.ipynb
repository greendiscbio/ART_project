{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.12.1+cpu.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gene matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACAD10</th>\n",
       "      <th>ACTB</th>\n",
       "      <th>BANF1</th>\n",
       "      <th>CCDC22</th>\n",
       "      <th>COMMD3</th>\n",
       "      <th>COPS7A</th>\n",
       "      <th>DLGAP4</th>\n",
       "      <th>DRD2</th>\n",
       "      <th>EIF4E</th>\n",
       "      <th>GPR155</th>\n",
       "      <th>...</th>\n",
       "      <th>RP11-96O20.4</th>\n",
       "      <th>SDR42E1</th>\n",
       "      <th>SUMO1</th>\n",
       "      <th>SUPT16H</th>\n",
       "      <th>TARBP1</th>\n",
       "      <th>TARBP2</th>\n",
       "      <th>TRIM43B</th>\n",
       "      <th>TRMT6</th>\n",
       "      <th>XPC</th>\n",
       "      <th>ZSCAN4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.123092</td>\n",
       "      <td>40.642985</td>\n",
       "      <td>34.744930</td>\n",
       "      <td>30.508649</td>\n",
       "      <td>33.150706</td>\n",
       "      <td>34.588349</td>\n",
       "      <td>34.54982</td>\n",
       "      <td>28.99024</td>\n",
       "      <td>34.55490</td>\n",
       "      <td>31.81161</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18753</td>\n",
       "      <td>30.26124</td>\n",
       "      <td>34.14365</td>\n",
       "      <td>32.91782</td>\n",
       "      <td>32.66222</td>\n",
       "      <td>29.60417</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>31.68113</td>\n",
       "      <td>32.24472</td>\n",
       "      <td>22.02469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.506262</td>\n",
       "      <td>39.979711</td>\n",
       "      <td>34.525362</td>\n",
       "      <td>31.250473</td>\n",
       "      <td>33.518125</td>\n",
       "      <td>34.043199</td>\n",
       "      <td>34.06647</td>\n",
       "      <td>26.46192</td>\n",
       "      <td>33.93919</td>\n",
       "      <td>31.42781</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18753</td>\n",
       "      <td>29.12730</td>\n",
       "      <td>35.18991</td>\n",
       "      <td>32.71985</td>\n",
       "      <td>33.34884</td>\n",
       "      <td>29.61188</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>31.41186</td>\n",
       "      <td>32.15619</td>\n",
       "      <td>22.02469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.885519</td>\n",
       "      <td>41.258876</td>\n",
       "      <td>35.122685</td>\n",
       "      <td>32.116300</td>\n",
       "      <td>32.567692</td>\n",
       "      <td>33.998049</td>\n",
       "      <td>34.42561</td>\n",
       "      <td>30.34221</td>\n",
       "      <td>35.11731</td>\n",
       "      <td>30.47292</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18753</td>\n",
       "      <td>27.22907</td>\n",
       "      <td>35.36213</td>\n",
       "      <td>33.49322</td>\n",
       "      <td>33.52074</td>\n",
       "      <td>31.90343</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>32.42037</td>\n",
       "      <td>31.86536</td>\n",
       "      <td>31.70408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.598330</td>\n",
       "      <td>40.911224</td>\n",
       "      <td>34.401187</td>\n",
       "      <td>31.276213</td>\n",
       "      <td>32.982594</td>\n",
       "      <td>32.723376</td>\n",
       "      <td>34.41176</td>\n",
       "      <td>22.29581</td>\n",
       "      <td>35.16043</td>\n",
       "      <td>30.72903</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18753</td>\n",
       "      <td>22.83731</td>\n",
       "      <td>35.67769</td>\n",
       "      <td>33.20078</td>\n",
       "      <td>32.98681</td>\n",
       "      <td>30.35424</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>31.30946</td>\n",
       "      <td>31.63561</td>\n",
       "      <td>22.02469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.022801</td>\n",
       "      <td>40.987280</td>\n",
       "      <td>33.325735</td>\n",
       "      <td>31.979366</td>\n",
       "      <td>34.894405</td>\n",
       "      <td>34.010091</td>\n",
       "      <td>34.29088</td>\n",
       "      <td>22.29581</td>\n",
       "      <td>34.90904</td>\n",
       "      <td>31.16114</td>\n",
       "      <td>...</td>\n",
       "      <td>21.18753</td>\n",
       "      <td>22.83731</td>\n",
       "      <td>33.54845</td>\n",
       "      <td>33.81102</td>\n",
       "      <td>33.86418</td>\n",
       "      <td>31.60946</td>\n",
       "      <td>21.9744</td>\n",
       "      <td>31.64113</td>\n",
       "      <td>33.12717</td>\n",
       "      <td>22.02469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>33.222605</td>\n",
       "      <td>40.848023</td>\n",
       "      <td>35.094895</td>\n",
       "      <td>31.644943</td>\n",
       "      <td>33.385944</td>\n",
       "      <td>33.553284</td>\n",
       "      <td>34.55658</td>\n",
       "      <td>32.80491</td>\n",
       "      <td>34.42998</td>\n",
       "      <td>29.90347</td>\n",
       "      <td>...</td>\n",
       "      <td>21.02478</td>\n",
       "      <td>31.49914</td>\n",
       "      <td>34.48418</td>\n",
       "      <td>33.70340</td>\n",
       "      <td>33.26085</td>\n",
       "      <td>31.57179</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>31.92132</td>\n",
       "      <td>32.70183</td>\n",
       "      <td>21.82186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>31.275450</td>\n",
       "      <td>40.552353</td>\n",
       "      <td>36.962227</td>\n",
       "      <td>30.232342</td>\n",
       "      <td>36.069228</td>\n",
       "      <td>35.115813</td>\n",
       "      <td>33.15506</td>\n",
       "      <td>24.15806</td>\n",
       "      <td>35.56667</td>\n",
       "      <td>31.66030</td>\n",
       "      <td>...</td>\n",
       "      <td>21.02478</td>\n",
       "      <td>28.17083</td>\n",
       "      <td>37.23507</td>\n",
       "      <td>31.72155</td>\n",
       "      <td>35.38923</td>\n",
       "      <td>34.36199</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>33.29491</td>\n",
       "      <td>30.79817</td>\n",
       "      <td>21.82186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>32.924285</td>\n",
       "      <td>41.287050</td>\n",
       "      <td>34.120100</td>\n",
       "      <td>31.683137</td>\n",
       "      <td>32.922726</td>\n",
       "      <td>33.356738</td>\n",
       "      <td>34.68047</td>\n",
       "      <td>24.15806</td>\n",
       "      <td>34.62822</td>\n",
       "      <td>31.92039</td>\n",
       "      <td>...</td>\n",
       "      <td>21.02478</td>\n",
       "      <td>24.22162</td>\n",
       "      <td>34.59033</td>\n",
       "      <td>32.87358</td>\n",
       "      <td>32.69340</td>\n",
       "      <td>29.30238</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>31.39512</td>\n",
       "      <td>32.60750</td>\n",
       "      <td>21.82186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>33.762107</td>\n",
       "      <td>39.676649</td>\n",
       "      <td>33.799451</td>\n",
       "      <td>31.081990</td>\n",
       "      <td>33.207047</td>\n",
       "      <td>32.864540</td>\n",
       "      <td>35.60014</td>\n",
       "      <td>24.15806</td>\n",
       "      <td>33.80982</td>\n",
       "      <td>32.78760</td>\n",
       "      <td>...</td>\n",
       "      <td>21.02478</td>\n",
       "      <td>27.21929</td>\n",
       "      <td>34.01564</td>\n",
       "      <td>33.29760</td>\n",
       "      <td>33.70786</td>\n",
       "      <td>30.72343</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>31.78725</td>\n",
       "      <td>33.35291</td>\n",
       "      <td>27.44984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>32.467870</td>\n",
       "      <td>40.868064</td>\n",
       "      <td>35.273889</td>\n",
       "      <td>31.497196</td>\n",
       "      <td>32.500998</td>\n",
       "      <td>34.205144</td>\n",
       "      <td>35.23053</td>\n",
       "      <td>24.15806</td>\n",
       "      <td>35.16140</td>\n",
       "      <td>30.59097</td>\n",
       "      <td>...</td>\n",
       "      <td>21.02478</td>\n",
       "      <td>32.08324</td>\n",
       "      <td>35.01634</td>\n",
       "      <td>32.46227</td>\n",
       "      <td>33.75390</td>\n",
       "      <td>31.34356</td>\n",
       "      <td>22.3863</td>\n",
       "      <td>31.77447</td>\n",
       "      <td>32.50118</td>\n",
       "      <td>21.82186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACAD10       ACTB      BANF1     CCDC22     COMMD3     COPS7A  \\\n",
       "0    33.123092  40.642985  34.744930  30.508649  33.150706  34.588349   \n",
       "1    32.506262  39.979711  34.525362  31.250473  33.518125  34.043199   \n",
       "2    33.885519  41.258876  35.122685  32.116300  32.567692  33.998049   \n",
       "3    32.598330  40.911224  34.401187  31.276213  32.982594  32.723376   \n",
       "4    34.022801  40.987280  33.325735  31.979366  34.894405  34.010091   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "176  33.222605  40.848023  35.094895  31.644943  33.385944  33.553284   \n",
       "177  31.275450  40.552353  36.962227  30.232342  36.069228  35.115813   \n",
       "178  32.924285  41.287050  34.120100  31.683137  32.922726  33.356738   \n",
       "179  33.762107  39.676649  33.799451  31.081990  33.207047  32.864540   \n",
       "180  32.467870  40.868064  35.273889  31.497196  32.500998  34.205144   \n",
       "\n",
       "       DLGAP4      DRD2     EIF4E    GPR155  ...  RP11-96O20.4   SDR42E1  \\\n",
       "0    34.54982  28.99024  34.55490  31.81161  ...      21.18753  30.26124   \n",
       "1    34.06647  26.46192  33.93919  31.42781  ...      21.18753  29.12730   \n",
       "2    34.42561  30.34221  35.11731  30.47292  ...      21.18753  27.22907   \n",
       "3    34.41176  22.29581  35.16043  30.72903  ...      21.18753  22.83731   \n",
       "4    34.29088  22.29581  34.90904  31.16114  ...      21.18753  22.83731   \n",
       "..        ...       ...       ...       ...  ...           ...       ...   \n",
       "176  34.55658  32.80491  34.42998  29.90347  ...      21.02478  31.49914   \n",
       "177  33.15506  24.15806  35.56667  31.66030  ...      21.02478  28.17083   \n",
       "178  34.68047  24.15806  34.62822  31.92039  ...      21.02478  24.22162   \n",
       "179  35.60014  24.15806  33.80982  32.78760  ...      21.02478  27.21929   \n",
       "180  35.23053  24.15806  35.16140  30.59097  ...      21.02478  32.08324   \n",
       "\n",
       "        SUMO1   SUPT16H    TARBP1    TARBP2  TRIM43B     TRMT6       XPC  \\\n",
       "0    34.14365  32.91782  32.66222  29.60417  21.9744  31.68113  32.24472   \n",
       "1    35.18991  32.71985  33.34884  29.61188  21.9744  31.41186  32.15619   \n",
       "2    35.36213  33.49322  33.52074  31.90343  21.9744  32.42037  31.86536   \n",
       "3    35.67769  33.20078  32.98681  30.35424  21.9744  31.30946  31.63561   \n",
       "4    33.54845  33.81102  33.86418  31.60946  21.9744  31.64113  33.12717   \n",
       "..        ...       ...       ...       ...      ...       ...       ...   \n",
       "176  34.48418  33.70340  33.26085  31.57179  22.3863  31.92132  32.70183   \n",
       "177  37.23507  31.72155  35.38923  34.36199  22.3863  33.29491  30.79817   \n",
       "178  34.59033  32.87358  32.69340  29.30238  22.3863  31.39512  32.60750   \n",
       "179  34.01564  33.29760  33.70786  30.72343  22.3863  31.78725  33.35291   \n",
       "180  35.01634  32.46227  33.75390  31.34356  22.3863  31.77447  32.50118   \n",
       "\n",
       "       ZSCAN4  \n",
       "0    22.02469  \n",
       "1    22.02469  \n",
       "2    31.70408  \n",
       "3    22.02469  \n",
       "4    22.02469  \n",
       "..        ...  \n",
       "176  21.82186  \n",
       "177  21.82186  \n",
       "178  21.82186  \n",
       "179  27.44984  \n",
       "180  21.82186  \n",
       "\n",
       "[181 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = pd.read_csv('../String/Data/mrcc_protein_matrix.csv')\n",
    "Y = genes.Y\n",
    "\n",
    "genes = genes.iloc[:,1:33] \n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACAD10</th>\n",
       "      <th>ACTB</th>\n",
       "      <th>BANF1</th>\n",
       "      <th>CCDC22</th>\n",
       "      <th>COMMD3</th>\n",
       "      <th>COPS7A</th>\n",
       "      <th>DLGAP4</th>\n",
       "      <th>DRD2</th>\n",
       "      <th>EIF4E</th>\n",
       "      <th>GPR155</th>\n",
       "      <th>...</th>\n",
       "      <th>RP11-96O20.4</th>\n",
       "      <th>SDR42E1</th>\n",
       "      <th>SUMO1</th>\n",
       "      <th>SUPT16H</th>\n",
       "      <th>TARBP1</th>\n",
       "      <th>TARBP2</th>\n",
       "      <th>TRIM43B</th>\n",
       "      <th>TRMT6</th>\n",
       "      <th>XPC</th>\n",
       "      <th>ZSCAN4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.434019</td>\n",
       "      <td>0.462781</td>\n",
       "      <td>0.560845</td>\n",
       "      <td>0.442340</td>\n",
       "      <td>0.572759</td>\n",
       "      <td>0.773473</td>\n",
       "      <td>0.460202</td>\n",
       "      <td>0.712065</td>\n",
       "      <td>0.727420</td>\n",
       "      <td>0.633846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.464347</td>\n",
       "      <td>0.461978</td>\n",
       "      <td>0.331945</td>\n",
       "      <td>0.593083</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.503429</td>\n",
       "      <td>0.395122</td>\n",
       "      <td>0.197606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289123</td>\n",
       "      <td>0.287340</td>\n",
       "      <td>0.517358</td>\n",
       "      <td>0.584385</td>\n",
       "      <td>0.626545</td>\n",
       "      <td>0.606744</td>\n",
       "      <td>0.314008</td>\n",
       "      <td>0.528699</td>\n",
       "      <td>0.619963</td>\n",
       "      <td>0.551284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.645633</td>\n",
       "      <td>0.401344</td>\n",
       "      <td>0.485835</td>\n",
       "      <td>0.593743</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.431572</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>0.197606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613116</td>\n",
       "      <td>0.625688</td>\n",
       "      <td>0.635663</td>\n",
       "      <td>0.750175</td>\n",
       "      <td>0.487412</td>\n",
       "      <td>0.592936</td>\n",
       "      <td>0.422634</td>\n",
       "      <td>0.810116</td>\n",
       "      <td>0.825575</td>\n",
       "      <td>0.345871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.549992</td>\n",
       "      <td>0.675474</td>\n",
       "      <td>0.638212</td>\n",
       "      <td>0.524363</td>\n",
       "      <td>0.789730</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.700702</td>\n",
       "      <td>0.291501</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310750</td>\n",
       "      <td>0.533732</td>\n",
       "      <td>0.492764</td>\n",
       "      <td>0.589314</td>\n",
       "      <td>0.548149</td>\n",
       "      <td>0.203089</td>\n",
       "      <td>0.418445</td>\n",
       "      <td>0.226552</td>\n",
       "      <td>0.833101</td>\n",
       "      <td>0.400965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.201863</td>\n",
       "      <td>0.730151</td>\n",
       "      <td>0.548643</td>\n",
       "      <td>0.404695</td>\n",
       "      <td>0.657234</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.404246</td>\n",
       "      <td>0.228745</td>\n",
       "      <td>0.197606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645364</td>\n",
       "      <td>0.553849</td>\n",
       "      <td>0.279762</td>\n",
       "      <td>0.723955</td>\n",
       "      <td>0.828018</td>\n",
       "      <td>0.596618</td>\n",
       "      <td>0.381883</td>\n",
       "      <td>0.226552</td>\n",
       "      <td>0.789227</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.201863</td>\n",
       "      <td>0.361216</td>\n",
       "      <td>0.735548</td>\n",
       "      <td>0.601337</td>\n",
       "      <td>0.764588</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>0.492755</td>\n",
       "      <td>0.636162</td>\n",
       "      <td>0.197606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.457395</td>\n",
       "      <td>0.517015</td>\n",
       "      <td>0.630159</td>\n",
       "      <td>0.659919</td>\n",
       "      <td>0.607195</td>\n",
       "      <td>0.456909</td>\n",
       "      <td>0.462247</td>\n",
       "      <td>0.988723</td>\n",
       "      <td>0.705619</td>\n",
       "      <td>0.223373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.888474</td>\n",
       "      <td>0.523351</td>\n",
       "      <td>0.702586</td>\n",
       "      <td>0.466114</td>\n",
       "      <td>0.761366</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.567526</td>\n",
       "      <td>0.519981</td>\n",
       "      <td>0.180792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.389432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934793</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>0.361612</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.601296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.624643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095584</td>\n",
       "      <td>0.943141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.934081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.387318</td>\n",
       "      <td>0.633140</td>\n",
       "      <td>0.437092</td>\n",
       "      <td>0.667232</td>\n",
       "      <td>0.539385</td>\n",
       "      <td>0.396797</td>\n",
       "      <td>0.499719</td>\n",
       "      <td>0.361612</td>\n",
       "      <td>0.740217</td>\n",
       "      <td>0.657246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.311595</td>\n",
       "      <td>0.541744</td>\n",
       "      <td>0.448428</td>\n",
       "      <td>0.338934</td>\n",
       "      <td>0.567273</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.427105</td>\n",
       "      <td>0.494215</td>\n",
       "      <td>0.180792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.584126</td>\n",
       "      <td>0.207178</td>\n",
       "      <td>0.373585</td>\n",
       "      <td>0.552124</td>\n",
       "      <td>0.581007</td>\n",
       "      <td>0.246263</td>\n",
       "      <td>0.777882</td>\n",
       "      <td>0.361612</td>\n",
       "      <td>0.597385</td>\n",
       "      <td>0.843797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.549216</td>\n",
       "      <td>0.442167</td>\n",
       "      <td>0.578298</td>\n",
       "      <td>0.566301</td>\n",
       "      <td>0.688809</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.531748</td>\n",
       "      <td>0.697822</td>\n",
       "      <td>0.647336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.280105</td>\n",
       "      <td>0.522315</td>\n",
       "      <td>0.665610</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>0.477648</td>\n",
       "      <td>0.656274</td>\n",
       "      <td>0.666090</td>\n",
       "      <td>0.361612</td>\n",
       "      <td>0.833270</td>\n",
       "      <td>0.371266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.934775</td>\n",
       "      <td>0.615559</td>\n",
       "      <td>0.322452</td>\n",
       "      <td>0.576620</td>\n",
       "      <td>0.741846</td>\n",
       "      <td>0.101726</td>\n",
       "      <td>0.528338</td>\n",
       "      <td>0.465174</td>\n",
       "      <td>0.180792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ACAD10      ACTB     BANF1    CCDC22    COMMD3    COPS7A    DLGAP4  \\\n",
       "0    0.434019  0.462781  0.560845  0.442340  0.572759  0.773473  0.460202   \n",
       "1    0.289123  0.287340  0.517358  0.584385  0.626545  0.606744  0.314008   \n",
       "2    0.613116  0.625688  0.635663  0.750175  0.487412  0.592936  0.422634   \n",
       "3    0.310750  0.533732  0.492764  0.589314  0.548149  0.203089  0.418445   \n",
       "4    0.645364  0.553849  0.279762  0.723955  0.828018  0.596618  0.381883   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "176  0.457395  0.517015  0.630159  0.659919  0.607195  0.456909  0.462247   \n",
       "177  0.000000  0.438808  1.000000  0.389432  1.000000  0.934793  0.038343   \n",
       "178  0.387318  0.633140  0.437092  0.667232  0.539385  0.396797  0.499719   \n",
       "179  0.584126  0.207178  0.373585  0.552124  0.581007  0.246263  0.777882   \n",
       "180  0.280105  0.522315  0.665610  0.631628  0.477648  0.656274  0.666090   \n",
       "\n",
       "         DRD2     EIF4E    GPR155  ...  RP11-96O20.4   SDR42E1     SUMO1  \\\n",
       "0    0.712065  0.727420  0.633846  ...      0.040424  0.790347  0.464347   \n",
       "1    0.528699  0.619963  0.551284  ...      0.040424  0.700462  0.645633   \n",
       "2    0.810116  0.825575  0.345871  ...      0.040424  0.549992  0.675474   \n",
       "3    0.226552  0.833101  0.400965  ...      0.040424  0.201863  0.730151   \n",
       "4    0.226552  0.789227  0.493919  ...      0.040424  0.201863  0.361216   \n",
       "..        ...       ...       ...  ...           ...       ...       ...   \n",
       "176  0.988723  0.705619  0.223373  ...      0.024573  0.888474  0.523351   \n",
       "177  0.361612  0.904000  0.601296  ...      0.024573  0.624643  1.000000   \n",
       "178  0.361612  0.740217  0.657246  ...      0.024573  0.311595  0.541744   \n",
       "179  0.361612  0.597385  0.843797  ...      0.024573  0.549216  0.442167   \n",
       "180  0.361612  0.833270  0.371266  ...      0.024573  0.934775  0.615559   \n",
       "\n",
       "      SUPT16H    TARBP1    TARBP2   TRIM43B     TRMT6       XPC    ZSCAN4  \n",
       "0    0.461978  0.331945  0.593083  0.077107  0.503429  0.395122  0.197606  \n",
       "1    0.401344  0.485835  0.593743  0.077107  0.431572  0.370940  0.197606  \n",
       "2    0.638212  0.524363  0.789730  0.077107  0.700702  0.291501  1.000000  \n",
       "3    0.548643  0.404695  0.657234  0.077107  0.404246  0.228745  0.197606  \n",
       "4    0.735548  0.601337  0.764588  0.077107  0.492755  0.636162  0.197606  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "176  0.702586  0.466114  0.761366  0.101726  0.567526  0.519981  0.180792  \n",
       "177  0.095584  0.943141  1.000000  0.101726  0.934081  0.000000  0.180792  \n",
       "178  0.448428  0.338934  0.567273  0.101726  0.427105  0.494215  0.180792  \n",
       "179  0.578298  0.566301  0.688809  0.101726  0.531748  0.697822  0.647336  \n",
       "180  0.322452  0.576620  0.741846  0.101726  0.528338  0.465174  0.180792  \n",
       "\n",
       "[181 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "names = genes.columns\n",
    "d = scaler.fit_transform(genes)\n",
    "genes = pd.DataFrame(d, columns=names)\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_genes, test_genes, Y_train, Y_test = train_test_split(genes, Y, test_size=0.1, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../String/Data/network_edges.tsv'\n",
    "data = pd.read_csv(path, delimiter='\\t')\n",
    "edge_index1=data[data.columns[1]].to_numpy()\n",
    "edge_index2=data[data.columns[2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = np.concatenate((edge_index1, edge_index2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DLGAP4', 'HOMER1', 'ACTB', 'ACTB', 'ACTB', 'ACTB', 'ACTB', 'XPC',\n",
       "       'XPC', 'XPC', 'XPC', 'GPR155', 'NASP', 'GYPE', 'DRD2', 'IL25',\n",
       "       'KLHL5', 'KLHL5', 'COMMD3', 'COPS7A', 'LEMD1', 'PCMT1',\n",
       "       'RP11-96O20.4', 'ACAD10', 'RANBP2', 'SDR42E1', 'TRMT6', 'TARBP1',\n",
       "       'TARBP2', 'TRIM43B', 'ZSCAN4', 'DLGAP4', 'GRIN1', 'ACTB', 'XPC',\n",
       "       'IL6', 'BANF1', 'MORF4L2', 'EIF4E', 'SUPT16H', 'COPS7A', 'SUMO1',\n",
       "       'KDM1A', 'NASP', 'SUPT16H', 'DRD2', 'GRIN1', 'IL6', 'COMMD3',\n",
       "       'CCDC22', 'COPS7A', 'CCDC22', 'BANF1', 'MORF4L2', 'ACAD10',\n",
       "       'RANBP2', 'SUMO1', 'TRMT6', 'TARBP1', 'TARBP2', 'EIF4E', 'ZSCAN4',\n",
       "       'KDM1A', 'HOMER1'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(edge_index)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1 = le.transform(edge_index1)\n",
    "edge_index2 = le.transform(edge_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = [edge_index1]+[edge_index2]\n",
    "edge_index = np.array(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 12,  1,  1,  1,  1,  1, 30, 30, 30, 30,  9, 19, 11,  7, 13,\n",
       "        16, 16,  4,  5, 17, 20, 22,  0, 21, 23, 29, 26, 27, 28, 31,  6],\n",
       "       [10,  1, 30, 14,  2, 18,  8, 25,  5, 24, 15, 19, 25,  7, 10, 14,\n",
       "         4,  3,  5,  3,  2, 18,  0, 21, 24, 29, 26, 27,  8, 31, 15, 12]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 12,  1,  1,  1,  1,  1, 30, 30, 30, 30,  9, 19, 11,  7, 13, 16, 16,\n",
       "          4,  5, 17, 20, 22,  0, 21, 23, 29, 26, 27, 28, 31,  6],\n",
       "        [10,  1, 30, 14,  2, 18,  8, 25,  5, 24, 15, 19, 25,  7, 10, 14,  4,  3,\n",
       "          5,  3,  2, 18,  0, 21, 24, 29, 26, 27,  8, 31, 15, 12]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "for g in range(len(train_genes)):\n",
    "  b=[]\n",
    "  for i in train_genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    # a.append(Y[g])\n",
    "    # a.append(i*100)\n",
    "    a.append(i)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.float).reshape([-1,1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y_train.iloc[g]], dtype=torch.long).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  train_data.append(data)\n",
    "\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "test_data=[]\n",
    "for g in range(len(test_genes)):\n",
    "  b=[]\n",
    "  for i in test_genes.iloc[g].to_numpy():\n",
    "    a=[]\n",
    "    # a.append(Y[g])\n",
    "    # a.append(i*100)\n",
    "    a.append(i)\n",
    "    b.append(a)\n",
    "  x = torch.tensor([b], dtype=torch.float).reshape([-1,1])\n",
    "  edge_index = edge_index\n",
    "  y = torch.tensor([Y_test.iloc[g]], dtype=torch.long).reshape([-1, 1])\n",
    "  data = Data(x=x, edge_index=edge_index, y=y)\n",
    "  test_data.append(data)\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graph(data,description=True):\n",
    "    edges_raw = data.edge_index.numpy()\n",
    "    edges = [(x, y) for x, y in zip(edges_raw[0, :], edges_raw[1, :])]\n",
    "    labels = data.x.numpy()\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list(range(np.max(edges_raw))))\n",
    "    G.add_edges_from(edges)\n",
    "    plt.subplot(111)\n",
    "    options = {\n",
    "       'node_size': 100,\n",
    "       'width': 1,\n",
    "    }\n",
    "    nx.draw(G, with_labels=description, node_color=labels.tolist(), cmap=plt.cm.tab10, font_weight='bold', **options)\n",
    "    plt.show()\n",
    "\n",
    "plot_graph(data,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Patient sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 32\n",
      "Number of charcateristics per node: 1\n",
      "Number of edges: 32\n",
      "Average node degree: 1.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Number of node features: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of charcateristics per node: {data.num_features}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Number of node features: {data.num_node_features}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.nn import SAGPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "# from torch_geometric.nn import GCNConv, GINConv\n",
    "# from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "# embed_dim = 32\n",
    "\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self, dim_h):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = GCNConv(1, dim_h)\n",
    "#         self.conv2 = GCNConv(dim_h, dim_h)\n",
    "#         self.conv3 = GCNConv(dim_h, dim_h)\n",
    "#         self.lin = Linear(dim_h, 1)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch):\n",
    "#         # Node embeddings \n",
    "#         h = self.conv1(x, edge_index)\n",
    "#         h = h.relu()\n",
    "#         h = self.conv2(h, edge_index)\n",
    "#         h = h.relu()\n",
    "#         h = self.conv3(h, edge_index)\n",
    "\n",
    "#         # Graph-level readout\n",
    "#         hG = global_mean_pool(h, batch)\n",
    "\n",
    "#         # Classifier\n",
    "#         h = F.dropout(hG, p=0.5, training=self.training)\n",
    "#         h = self.lin(h)\n",
    "        \n",
    "#         return F.sigmoid(h).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, dim_h):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(1, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    acc = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(output, data.y.squeeze(1))  \n",
    "        total_loss += loss / len(train_loader)\n",
    "        acc += accuracy(output.argmax(dim=1), data.y.squeeze(1)) / len(train_loader)\n",
    "        f1score = f1_score(data.y.squeeze(1), output.argmax(dim=1), average='weighted')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # loss_all += loss.item() * data.num_graphs\n",
    "    return total_loss, acc, f1score\n",
    "\n",
    "    \n",
    "@torch.no_grad()\n",
    "def validation(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    loss = 0\n",
    "    for data in val_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss += criterion(output, data.y.squeeze(1))/ len(val_loader)\n",
    "        acc += accuracy(output.argmax(dim=1), data.y.squeeze(1)) / len(val_loader)\n",
    "        f1score = f1_score(data.y.squeeze(1), output.argmax(dim=1), average='weighted')\n",
    "    return loss, acc, f1score\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def test(model, test_data):\n",
    "    acc = 0\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "    for data in test_loader:\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        acc += accuracy(output.argmax(dim=1), data.y.squeeze(1)) / len(test_loader)\n",
    "        f1score = f1_score(data.y.squeeze(1), output.argmax(dim=1), average='weighted')\n",
    "    return acc, f1score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold # import KFold\n",
    "kf=StratifiedKFold(n_splits=10, random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  [ 12  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17]\n",
      "145\n",
      "17\n",
      "Epoch: 000, Train loss: 1.4425, Train Acc: 0.3776, Train f1-score: 0.2990, Val loss: 0.7618, Val Acc: 0.4706, Val f1-score: 0.3012,\n",
      "Epoch: 001, Train loss: 0.6987, Train Acc: 0.4941, Train f1-score: 0.4628, Val loss: 0.6954, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 002, Train loss: 0.6913, Train Acc: 0.5309, Train f1-score: 0.5294, Val loss: 0.6961, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 003, Train loss: 0.6935, Train Acc: 0.4996, Train f1-score: 0.5294, Val loss: 0.6964, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 004, Train loss: 0.6929, Train Acc: 0.4879, Train f1-score: 0.4628, Val loss: 0.6969, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 005, Train loss: 0.6939, Train Acc: 0.5059, Train f1-score: 0.5294, Val loss: 0.6969, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 006, Train loss: 0.6934, Train Acc: 0.5059, Train f1-score: 0.5294, Val loss: 0.6983, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 007, Train loss: 0.6931, Train Acc: 0.4816, Train f1-score: 0.4706, Val loss: 0.6992, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 008, Train loss: 0.6915, Train Acc: 0.5129, Train f1-score: 0.4706, Val loss: 0.7038, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 009, Train loss: 0.6985, Train Acc: 0.5059, Train f1-score: 0.5327, Val loss: 0.7027, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 010, Train loss: 0.6940, Train Acc: 0.5176, Train f1-score: 0.5911, Val loss: 0.7003, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 011, Train loss: 0.6925, Train Acc: 0.5176, Train f1-score: 0.5911, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 012, Train loss: 0.6921, Train Acc: 0.5066, Train f1-score: 0.4706, Val loss: 0.7041, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 013, Train loss: 0.6983, Train Acc: 0.4996, Train f1-score: 0.5327, Val loss: 0.7033, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 014, Train loss: 0.6968, Train Acc: 0.5114, Train f1-score: 0.5911, Val loss: 0.7024, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 015, Train loss: 0.6958, Train Acc: 0.5176, Train f1-score: 0.5911, Val loss: 0.7017, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 016, Train loss: 0.6949, Train Acc: 0.5176, Train f1-score: 0.5911, Val loss: 0.7017, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 017, Train loss: 0.6944, Train Acc: 0.5114, Train f1-score: 0.5911, Val loss: 0.7014, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 018, Train loss: 0.6941, Train Acc: 0.5059, Train f1-score: 0.5229, Val loss: 0.7022, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 019, Train loss: 0.6926, Train Acc: 0.5239, Train f1-score: 0.5911, Val loss: 0.7008, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 020, Train loss: 0.6898, Train Acc: 0.5301, Train f1-score: 0.5911, Val loss: 0.7010, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 021, Train loss: 0.6896, Train Acc: 0.5301, Train f1-score: 0.5911, Val loss: 0.7015, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 022, Train loss: 0.6892, Train Acc: 0.5426, Train f1-score: 0.5911, Val loss: 0.7009, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 023, Train loss: 0.6893, Train Acc: 0.5426, Train f1-score: 0.5911, Val loss: 0.7008, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 024, Train loss: 0.6886, Train Acc: 0.5544, Train f1-score: 0.6471, Val loss: 0.7002, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 025, Train loss: 0.6887, Train Acc: 0.5544, Train f1-score: 0.6471, Val loss: 0.7001, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 026, Train loss: 0.6880, Train Acc: 0.5544, Train f1-score: 0.6471, Val loss: 0.7002, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 027, Train loss: 0.6877, Train Acc: 0.5482, Train f1-score: 0.6471, Val loss: 0.7004, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 028, Train loss: 0.6872, Train Acc: 0.5176, Train f1-score: 0.5911, Val loss: 0.7018, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 029, Train loss: 0.6876, Train Acc: 0.5419, Train f1-score: 0.6495, Val loss: 0.7014, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 030, Train loss: 0.6897, Train Acc: 0.5482, Train f1-score: 0.6471, Val loss: 0.7001, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 031, Train loss: 0.6871, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 032, Train loss: 0.6862, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.7022, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 033, Train loss: 0.6874, Train Acc: 0.5121, Train f1-score: 0.5229, Val loss: 0.7037, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 034, Train loss: 0.6884, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.7005, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 035, Train loss: 0.6854, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7022, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 036, Train loss: 0.6859, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7009, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 037, Train loss: 0.6850, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7022, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 038, Train loss: 0.6884, Train Acc: 0.5419, Train f1-score: 0.6471, Val loss: 0.6993, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 039, Train loss: 0.6857, Train Acc: 0.5419, Train f1-score: 0.6471, Val loss: 0.7002, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 040, Train loss: 0.6847, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 041, Train loss: 0.6846, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 042, Train loss: 0.6844, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7009, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 043, Train loss: 0.6849, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7017, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 044, Train loss: 0.6833, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7042, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 045, Train loss: 0.6836, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7041, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 046, Train loss: 0.6842, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7030, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 047, Train loss: 0.6850, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 048, Train loss: 0.6833, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7022, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 049, Train loss: 0.6835, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7016, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 050, Train loss: 0.6820, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7016, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 051, Train loss: 0.6831, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7014, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 052, Train loss: 0.6823, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7027, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 053, Train loss: 0.6823, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7015, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 054, Train loss: 0.6819, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7020, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 055, Train loss: 0.6813, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7035, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 056, Train loss: 0.6818, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7018, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 057, Train loss: 0.6803, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.7038, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 058, Train loss: 0.6814, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7022, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 059, Train loss: 0.6825, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7004, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 060, Train loss: 0.6875, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7024, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 061, Train loss: 0.6803, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7012, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 062, Train loss: 0.6783, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7008, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 063, Train loss: 0.6817, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7016, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 064, Train loss: 0.6781, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7053, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 065, Train loss: 0.6798, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7022, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 066, Train loss: 0.6781, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7053, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 067, Train loss: 0.6800, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7017, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 068, Train loss: 0.6779, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7050, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 069, Train loss: 0.6785, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7047, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 070, Train loss: 0.6785, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7058, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 071, Train loss: 0.6780, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7100, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 072, Train loss: 0.6832, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.7021, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 073, Train loss: 0.6769, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7036, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 074, Train loss: 0.6776, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7036, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 075, Train loss: 0.6761, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7106, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 076, Train loss: 0.6803, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7047, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 077, Train loss: 0.6769, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7020, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 078, Train loss: 0.6754, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7067, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 079, Train loss: 0.6789, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7019, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 080, Train loss: 0.6758, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7014, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 081, Train loss: 0.6752, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7056, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 082, Train loss: 0.6752, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7064, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 083, Train loss: 0.6794, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7052, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 084, Train loss: 0.6756, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7050, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 085, Train loss: 0.6752, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7059, Val Acc: 0.5882, Val f1-score: 0.4858,\n",
      "Epoch: 086, Train loss: 0.6749, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7070, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 087, Train loss: 0.6757, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7070, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 088, Train loss: 0.6781, Train Acc: 0.5287, Train f1-score: 0.7079, Val loss: 0.7047, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 089, Train loss: 0.6734, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.7054, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 090, Train loss: 0.6737, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.7099, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 091, Train loss: 0.6784, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.7048, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 092, Train loss: 0.6736, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7053, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 093, Train loss: 0.6767, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7023, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 094, Train loss: 0.6725, Train Acc: 0.5662, Train f1-score: 0.7079, Val loss: 0.7028, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 095, Train loss: 0.6722, Train Acc: 0.5662, Train f1-score: 0.7079, Val loss: 0.7108, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 096, Train loss: 0.6770, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7058, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 097, Train loss: 0.6733, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.7049, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 098, Train loss: 0.6727, Train Acc: 0.5662, Train f1-score: 0.7079, Val loss: 0.7048, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 099, Train loss: 0.6794, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7063, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 100, Train loss: 0.6746, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7033, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 101, Train loss: 0.6701, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7046, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 102, Train loss: 0.6716, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7080, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 103, Train loss: 0.6725, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7046, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 104, Train loss: 0.6705, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.7043, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 105, Train loss: 0.6713, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.7045, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 106, Train loss: 0.6704, Train Acc: 0.5662, Train f1-score: 0.7079, Val loss: 0.7049, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 107, Train loss: 0.6736, Train Acc: 0.5662, Train f1-score: 0.7079, Val loss: 0.7012, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 108, Train loss: 0.6690, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7144, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 109, Train loss: 0.6787, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7031, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 110, Train loss: 0.6676, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.7064, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 111, Train loss: 0.6749, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.7019, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 112, Train loss: 0.6675, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.7095, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 113, Train loss: 0.6719, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.7027, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 114, Train loss: 0.6675, Train Acc: 0.5779, Train f1-score: 0.7647, Val loss: 0.7177, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 115, Train loss: 0.6802, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.7049, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 116, Train loss: 0.6680, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.7042, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 117, Train loss: 0.6699, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.7062, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 118, Train loss: 0.6695, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.7024, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 119, Train loss: 0.6688, Train Acc: 0.5779, Train f1-score: 0.7647, Val loss: 0.7063, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 120, Train loss: 0.6701, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6989, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 121, Train loss: 0.6659, Train Acc: 0.5779, Train f1-score: 0.7647, Val loss: 0.7091, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 122, Train loss: 0.6732, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.7017, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 123, Train loss: 0.6673, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.7045, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 124, Train loss: 0.6731, Train Acc: 0.5599, Train f1-score: 0.7079, Val loss: 0.6991, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 125, Train loss: 0.6672, Train Acc: 0.5897, Train f1-score: 0.8248, Val loss: 0.6991, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 126, Train loss: 0.6691, Train Acc: 0.5654, Train f1-score: 0.7663, Val loss: 0.7008, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 127, Train loss: 0.6693, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.7002, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 128, Train loss: 0.6677, Train Acc: 0.5662, Train f1-score: 0.7059, Val loss: 0.7046, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 129, Train loss: 0.6713, Train Acc: 0.5592, Train f1-score: 0.7663, Val loss: 0.6947, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 130, Train loss: 0.6648, Train Acc: 0.5779, Train f1-score: 0.7647, Val loss: 0.6953, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 131, Train loss: 0.6695, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.7026, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 132, Train loss: 0.6701, Train Acc: 0.5474, Train f1-score: 0.7059, Val loss: 0.6984, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 133, Train loss: 0.6656, Train Acc: 0.5537, Train f1-score: 0.7059, Val loss: 0.7098, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 134, Train loss: 0.6732, Train Acc: 0.5529, Train f1-score: 0.7663, Val loss: 0.7017, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 135, Train loss: 0.6665, Train Acc: 0.5710, Train f1-score: 0.8248, Val loss: 0.7116, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 136, Train loss: 0.6743, Train Acc: 0.5474, Train f1-score: 0.7059, Val loss: 0.6976, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 137, Train loss: 0.6641, Train Acc: 0.5592, Train f1-score: 0.7663, Val loss: 0.7011, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 138, Train loss: 0.6716, Train Acc: 0.5529, Train f1-score: 0.7663, Val loss: 0.6953, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 139, Train loss: 0.6640, Train Acc: 0.5599, Train f1-score: 0.7059, Val loss: 0.7007, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 140, Train loss: 0.6663, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6973, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 141, Train loss: 0.6643, Train Acc: 0.5662, Train f1-score: 0.7059, Val loss: 0.7063, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 142, Train loss: 0.6704, Train Acc: 0.5654, Train f1-score: 0.7663, Val loss: 0.6946, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 143, Train loss: 0.6639, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.6979, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 144, Train loss: 0.6656, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.6958, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 145, Train loss: 0.6630, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.7077, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 146, Train loss: 0.6714, Train Acc: 0.5592, Train f1-score: 0.7663, Val loss: 0.6944, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 147, Train loss: 0.6614, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.7027, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 148, Train loss: 0.6682, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6949, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 149, Train loss: 0.6621, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6979, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 150, Train loss: 0.6678, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.6942, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 151, Train loss: 0.6616, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.6954, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 152, Train loss: 0.6625, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6976, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 153, Train loss: 0.6633, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.7061, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 154, Train loss: 0.6691, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6948, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 155, Train loss: 0.6600, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.7054, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 156, Train loss: 0.6684, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.6908, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 157, Train loss: 0.6594, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6960, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 158, Train loss: 0.6643, Train Acc: 0.5960, Train f1-score: 0.8248, Val loss: 0.6945, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 159, Train loss: 0.6595, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.7050, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 160, Train loss: 0.6668, Train Acc: 0.5717, Train f1-score: 0.7663, Val loss: 0.6923, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 161, Train loss: 0.6590, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6997, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 162, Train loss: 0.6688, Train Acc: 0.5654, Train f1-score: 0.7663, Val loss: 0.6919, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 163, Train loss: 0.6578, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6990, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 164, Train loss: 0.6634, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6999, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 165, Train loss: 0.6615, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6938, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 166, Train loss: 0.6639, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6910, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 167, Train loss: 0.6574, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 168, Train loss: 0.6650, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6937, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 169, Train loss: 0.6584, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6900, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 170, Train loss: 0.6600, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6970, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 171, Train loss: 0.6594, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6950, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 172, Train loss: 0.6595, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.7006, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 173, Train loss: 0.6653, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6903, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 174, Train loss: 0.6568, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.7009, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 175, Train loss: 0.6676, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6896, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 176, Train loss: 0.6564, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6951, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 177, Train loss: 0.6606, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6883, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 178, Train loss: 0.6553, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6975, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 179, Train loss: 0.6649, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6906, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 180, Train loss: 0.6565, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6962, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 181, Train loss: 0.6626, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6890, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 182, Train loss: 0.6549, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6951, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 183, Train loss: 0.6602, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6864, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 184, Train loss: 0.6548, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6987, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 185, Train loss: 0.6587, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6919, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 186, Train loss: 0.6583, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6937, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 187, Train loss: 0.6569, Train Acc: 0.5779, Train f1-score: 0.7663, Val loss: 0.6905, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 188, Train loss: 0.6582, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6920, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 189, Train loss: 0.6559, Train Acc: 0.5960, Train f1-score: 0.8248, Val loss: 0.6904, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 190, Train loss: 0.6555, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6920, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 191, Train loss: 0.6574, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6895, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 192, Train loss: 0.6573, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6889, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 193, Train loss: 0.6556, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6925, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 194, Train loss: 0.6556, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6884, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 195, Train loss: 0.6553, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6924, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 196, Train loss: 0.6561, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6907, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 197, Train loss: 0.6534, Train Acc: 0.5967, Train f1-score: 0.7663, Val loss: 0.6969, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 198, Train loss: 0.6619, Train Acc: 0.5967, Train f1-score: 0.7663, Val loss: 0.6857, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 199, Train loss: 0.6500, Train Acc: 0.6085, Train f1-score: 0.8248, Val loss: 0.6968, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 200, Train loss: 0.6596, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6840, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 201, Train loss: 0.6527, Train Acc: 0.5967, Train f1-score: 0.7663, Val loss: 0.6837, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 202, Train loss: 0.6552, Train Acc: 0.6092, Train f1-score: 0.7663, Val loss: 0.6871, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 203, Train loss: 0.6563, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6866, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 204, Train loss: 0.6525, Train Acc: 0.5967, Train f1-score: 0.7663, Val loss: 0.6883, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 205, Train loss: 0.6564, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6854, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 206, Train loss: 0.6495, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6967, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 207, Train loss: 0.6634, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6815, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 208, Train loss: 0.6489, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6945, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 209, Train loss: 0.6560, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6831, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 210, Train loss: 0.6519, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6949, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 211, Train loss: 0.6550, Train Acc: 0.6085, Train f1-score: 0.8248, Val loss: 0.6897, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 212, Train loss: 0.6497, Train Acc: 0.6085, Train f1-score: 0.8248, Val loss: 0.6942, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 213, Train loss: 0.6572, Train Acc: 0.5842, Train f1-score: 0.7663, Val loss: 0.6783, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 214, Train loss: 0.6483, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6910, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 215, Train loss: 0.6567, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6836, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 216, Train loss: 0.6475, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6897, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 217, Train loss: 0.6545, Train Acc: 0.6022, Train f1-score: 0.8248, Val loss: 0.6888, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 218, Train loss: 0.6507, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6809, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 219, Train loss: 0.6472, Train Acc: 0.6154, Train f1-score: 0.7663, Val loss: 0.6891, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 220, Train loss: 0.6546, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6883, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 221, Train loss: 0.6491, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6823, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 222, Train loss: 0.6466, Train Acc: 0.6272, Train f1-score: 0.8248, Val loss: 0.6847, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 223, Train loss: 0.6497, Train Acc: 0.6210, Train f1-score: 0.8248, Val loss: 0.6881, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 224, Train loss: 0.6524, Train Acc: 0.5967, Train f1-score: 0.7663, Val loss: 0.6735, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 225, Train loss: 0.6427, Train Acc: 0.6272, Train f1-score: 0.8248, Val loss: 0.6782, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 226, Train loss: 0.6575, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6720, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 227, Train loss: 0.6479, Train Acc: 0.6154, Train f1-score: 0.7663, Val loss: 0.6742, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 228, Train loss: 0.6439, Train Acc: 0.6154, Train f1-score: 0.7663, Val loss: 0.6852, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 229, Train loss: 0.6505, Train Acc: 0.6029, Train f1-score: 0.7663, Val loss: 0.6847, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 230, Train loss: 0.6477, Train Acc: 0.6327, Train f1-score: 0.8824, Val loss: 0.6829, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 231, Train loss: 0.6472, Train Acc: 0.6390, Train f1-score: 0.8824, Val loss: 0.6755, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 232, Train loss: 0.6420, Train Acc: 0.6452, Train f1-score: 0.8824, Val loss: 0.6847, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 233, Train loss: 0.6470, Train Acc: 0.6147, Train f1-score: 0.8248, Val loss: 0.6818, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 234, Train loss: 0.6483, Train Acc: 0.6390, Train f1-score: 0.8824, Val loss: 0.6733, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 235, Train loss: 0.6413, Train Acc: 0.6452, Train f1-score: 0.8824, Val loss: 0.6846, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 236, Train loss: 0.6472, Train Acc: 0.6265, Train f1-score: 0.8824, Val loss: 0.6744, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 237, Train loss: 0.6447, Train Acc: 0.6390, Train f1-score: 0.8824, Val loss: 0.6953, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 238, Train loss: 0.6505, Train Acc: 0.6085, Train f1-score: 0.8248, Val loss: 0.6808, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 239, Train loss: 0.6465, Train Acc: 0.6092, Train f1-score: 0.7663, Val loss: 0.6724, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 240, Train loss: 0.6400, Train Acc: 0.6272, Train f1-score: 0.8248, Val loss: 0.6783, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 241, Train loss: 0.6574, Train Acc: 0.5904, Train f1-score: 0.7663, Val loss: 0.6673, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 242, Train loss: 0.6423, Train Acc: 0.6279, Train f1-score: 0.7663, Val loss: 0.6639, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 243, Train loss: 0.6355, Train Acc: 0.6522, Train f1-score: 0.8248, Val loss: 0.6793, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 244, Train loss: 0.6484, Train Acc: 0.6335, Train f1-score: 0.8248, Val loss: 0.6716, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 245, Train loss: 0.6358, Train Acc: 0.6515, Train f1-score: 0.8824, Val loss: 0.6728, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 246, Train loss: 0.6459, Train Acc: 0.6397, Train f1-score: 0.8248, Val loss: 0.6616, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 247, Train loss: 0.6412, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 248, Train loss: 0.6450, Train Acc: 0.6522, Train f1-score: 0.8248, Val loss: 0.6637, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 249, Train loss: 0.6373, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6799, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 250, Train loss: 0.6421, Train Acc: 0.6397, Train f1-score: 0.8248, Val loss: 0.6780, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 251, Train loss: 0.6439, Train Acc: 0.6397, Train f1-score: 0.8248, Val loss: 0.6890, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 252, Train loss: 0.6430, Train Acc: 0.6390, Train f1-score: 0.8832, Val loss: 0.6719, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 253, Train loss: 0.6350, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6832, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 254, Train loss: 0.6417, Train Acc: 0.6515, Train f1-score: 0.8832, Val loss: 0.6741, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 255, Train loss: 0.6376, Train Acc: 0.6577, Train f1-score: 0.8824, Val loss: 0.6824, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 256, Train loss: 0.6404, Train Acc: 0.6577, Train f1-score: 0.8832, Val loss: 0.6751, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 257, Train loss: 0.6378, Train Acc: 0.6577, Train f1-score: 0.8824, Val loss: 0.6795, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 258, Train loss: 0.6407, Train Acc: 0.6515, Train f1-score: 0.8832, Val loss: 0.6693, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 259, Train loss: 0.6376, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6796, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 260, Train loss: 0.6401, Train Acc: 0.6577, Train f1-score: 0.8832, Val loss: 0.6733, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 261, Train loss: 0.6399, Train Acc: 0.6522, Train f1-score: 0.8209, Val loss: 0.6754, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 262, Train loss: 0.6380, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6688, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 263, Train loss: 0.6387, Train Acc: 0.6585, Train f1-score: 0.8209, Val loss: 0.6766, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 264, Train loss: 0.6384, Train Acc: 0.6640, Train f1-score: 0.8832, Val loss: 0.6681, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 265, Train loss: 0.6354, Train Acc: 0.6702, Train f1-score: 0.8832, Val loss: 0.6857, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 266, Train loss: 0.6424, Train Acc: 0.6522, Train f1-score: 0.8209, Val loss: 0.6749, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 267, Train loss: 0.6355, Train Acc: 0.6460, Train f1-score: 0.8209, Val loss: 0.6661, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 268, Train loss: 0.6319, Train Acc: 0.6647, Train f1-score: 0.8248, Val loss: 0.6864, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 269, Train loss: 0.6395, Train Acc: 0.6570, Train f1-score: 0.9416, Val loss: 0.6655, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 270, Train loss: 0.6304, Train Acc: 0.6945, Train f1-score: 0.9416, Val loss: 0.6729, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 271, Train loss: 0.6402, Train Acc: 0.6585, Train f1-score: 0.8248, Val loss: 0.6594, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 272, Train loss: 0.6294, Train Acc: 0.6772, Train f1-score: 0.8209, Val loss: 0.6806, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 273, Train loss: 0.6367, Train Acc: 0.6757, Train f1-score: 0.9416, Val loss: 0.6693, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 274, Train loss: 0.6311, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6722, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 275, Train loss: 0.6348, Train Acc: 0.6585, Train f1-score: 0.8248, Val loss: 0.6768, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 276, Train loss: 0.6343, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6668, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 277, Train loss: 0.6320, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6635, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 278, Train loss: 0.6325, Train Acc: 0.6772, Train f1-score: 0.8248, Val loss: 0.6818, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 279, Train loss: 0.6345, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6598, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 280, Train loss: 0.6267, Train Acc: 0.6882, Train f1-score: 0.9416, Val loss: 0.6697, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 281, Train loss: 0.6393, Train Acc: 0.6585, Train f1-score: 0.8248, Val loss: 0.6605, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 282, Train loss: 0.6279, Train Acc: 0.6710, Train f1-score: 0.8248, Val loss: 0.6739, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 283, Train loss: 0.6372, Train Acc: 0.6772, Train f1-score: 0.8248, Val loss: 0.6741, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 284, Train loss: 0.6317, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6664, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 285, Train loss: 0.6292, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6677, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 286, Train loss: 0.6321, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6826, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 287, Train loss: 0.6391, Train Acc: 0.6647, Train f1-score: 0.8248, Val loss: 0.6886, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 288, Train loss: 0.6346, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6636, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 289, Train loss: 0.6250, Train Acc: 0.7015, Train f1-score: 0.8824, Val loss: 0.6659, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 290, Train loss: 0.6321, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6716, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 291, Train loss: 0.6326, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6642, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 292, Train loss: 0.6264, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6617, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 293, Train loss: 0.6290, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6680, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 294, Train loss: 0.6321, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6742, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 295, Train loss: 0.6308, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 296, Train loss: 0.6273, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6730, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 297, Train loss: 0.6371, Train Acc: 0.6702, Train f1-score: 0.8832, Val loss: 0.6736, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 298, Train loss: 0.6309, Train Acc: 0.6882, Train f1-score: 0.9416, Val loss: 0.6749, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 299, Train loss: 0.6302, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6773, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 300, Train loss: 0.6301, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6656, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 301, Train loss: 0.6272, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6657, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 302, Train loss: 0.6258, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6718, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 303, Train loss: 0.6286, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6461, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 304, Train loss: 0.6210, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6783, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 305, Train loss: 0.6319, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6799, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 306, Train loss: 0.6289, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6754, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 307, Train loss: 0.6313, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 308, Train loss: 0.6260, Train Acc: 0.6835, Train f1-score: 0.8248, Val loss: 0.6656, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 309, Train loss: 0.6312, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6585, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 310, Train loss: 0.6244, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6840, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 311, Train loss: 0.6315, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6628, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 312, Train loss: 0.6217, Train Acc: 0.7077, Train f1-score: 0.8824, Val loss: 0.6757, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 313, Train loss: 0.6285, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6759, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 314, Train loss: 0.6250, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6773, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 315, Train loss: 0.6296, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6633, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 316, Train loss: 0.6219, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6784, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 317, Train loss: 0.6290, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6546, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 318, Train loss: 0.6193, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6611, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 319, Train loss: 0.6231, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6719, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 320, Train loss: 0.6258, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6512, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 321, Train loss: 0.6192, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6805, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 322, Train loss: 0.6293, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6576, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 323, Train loss: 0.6199, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6668, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 324, Train loss: 0.6216, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6679, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 325, Train loss: 0.6250, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6696, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 326, Train loss: 0.6258, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6619, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 327, Train loss: 0.6235, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6696, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 328, Train loss: 0.6202, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6421, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 329, Train loss: 0.6118, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6543, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 330, Train loss: 0.6211, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6756, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 331, Train loss: 0.6242, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6443, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 332, Train loss: 0.6138, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6459, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 333, Train loss: 0.6134, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6604, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 334, Train loss: 0.6229, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6681, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 335, Train loss: 0.6235, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6359, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 336, Train loss: 0.6198, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6642, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 337, Train loss: 0.6222, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6438, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 338, Train loss: 0.6120, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 339, Train loss: 0.6205, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6363, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 340, Train loss: 0.6142, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6784, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 341, Train loss: 0.6234, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6506, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 342, Train loss: 0.6152, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6669, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 343, Train loss: 0.6226, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6427, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 344, Train loss: 0.6108, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6651, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 345, Train loss: 0.6186, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6600, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 346, Train loss: 0.6142, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6840, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 347, Train loss: 0.6211, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6400, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 348, Train loss: 0.6131, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6747, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 349, Train loss: 0.6215, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6408, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 350, Train loss: 0.6116, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6681, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 351, Train loss: 0.6179, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6394, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 352, Train loss: 0.6125, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6684, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 353, Train loss: 0.6171, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6676, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 354, Train loss: 0.6168, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6342, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 355, Train loss: 0.6138, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6228, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 356, Train loss: 0.6050, Train Acc: 0.6772, Train f1-score: 0.8209, Val loss: 0.6547, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 357, Train loss: 0.6113, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6762, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 358, Train loss: 0.6171, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6317, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 359, Train loss: 0.6134, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6709, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 360, Train loss: 0.6184, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6311, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 361, Train loss: 0.6040, Train Acc: 0.6772, Train f1-score: 0.8209, Val loss: 0.6529, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 362, Train loss: 0.6067, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6644, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 363, Train loss: 0.6102, Train Acc: 0.6710, Train f1-score: 0.8209, Val loss: 0.6783, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 364, Train loss: 0.6126, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6676, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 365, Train loss: 0.6092, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6734, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 366, Train loss: 0.6111, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6726, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 367, Train loss: 0.6084, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6697, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 368, Train loss: 0.6087, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6718, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 369, Train loss: 0.6067, Train Acc: 0.6772, Train f1-score: 0.8209, Val loss: 0.6634, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 370, Train loss: 0.6046, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 371, Train loss: 0.6071, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6599, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 372, Train loss: 0.6049, Train Acc: 0.6772, Train f1-score: 0.8209, Val loss: 0.6611, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 373, Train loss: 0.6045, Train Acc: 0.7015, Train f1-score: 0.8824, Val loss: 0.6616, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 374, Train loss: 0.6072, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6465, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 375, Train loss: 0.6013, Train Acc: 0.6772, Train f1-score: 0.8209, Val loss: 0.6015, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 376, Train loss: 0.6023, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6403, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 377, Train loss: 0.6025, Train Acc: 0.6647, Train f1-score: 0.8209, Val loss: 0.6588, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 378, Train loss: 0.6066, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6138, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 379, Train loss: 0.6073, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.6482, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 380, Train loss: 0.6012, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6467, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 381, Train loss: 0.6002, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6579, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 382, Train loss: 0.6027, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6268, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 383, Train loss: 0.5970, Train Acc: 0.6952, Train f1-score: 0.8824, Val loss: 0.6520, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 384, Train loss: 0.6030, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.6054, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 385, Train loss: 0.6084, Train Acc: 0.6452, Train f1-score: 0.8824, Val loss: 0.6187, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 386, Train loss: 0.6080, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6018, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 387, Train loss: 0.5971, Train Acc: 0.6702, Train f1-score: 0.8824, Val loss: 0.6423, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 388, Train loss: 0.5961, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6326, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 389, Train loss: 0.5936, Train Acc: 0.7015, Train f1-score: 0.8824, Val loss: 0.6697, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 390, Train loss: 0.6013, Train Acc: 0.7015, Train f1-score: 0.8824, Val loss: 0.6425, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 391, Train loss: 0.5997, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6009, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 392, Train loss: 0.5989, Train Acc: 0.6640, Train f1-score: 0.8824, Val loss: 0.6350, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 393, Train loss: 0.5966, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6325, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 394, Train loss: 0.5987, Train Acc: 0.6765, Train f1-score: 0.8824, Val loss: 0.5960, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 395, Train loss: 0.6016, Train Acc: 0.6515, Train f1-score: 0.8824, Val loss: 0.5939, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 396, Train loss: 0.5936, Train Acc: 0.6515, Train f1-score: 0.8824, Val loss: 0.6606, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 397, Train loss: 0.6009, Train Acc: 0.6827, Train f1-score: 0.8824, Val loss: 0.5938, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 398, Train loss: 0.5941, Train Acc: 0.6577, Train f1-score: 0.8824, Val loss: 0.6343, Val Acc: 0.5882, Val f1-score: 0.5394,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 399, Train loss: 0.5950, Train Acc: 0.6890, Train f1-score: 0.8824, Val loss: 0.6002, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 400, Train loss: 0.5999, Train Acc: 0.6577, Train f1-score: 0.8824, Val loss: 0.6282, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "GIN accuracy: 0.4736842215061188\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  33\n",
      "  34  35  36  37  38  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124\n",
      " 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161] TEST: [12 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 39]\n",
      "145\n",
      "17\n",
      "Epoch: 000, Train loss: 1.1993, Train Acc: 0.5371, Train f1-score: 0.5116, Val loss: 0.7061, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 001, Train loss: 0.7031, Train Acc: 0.5246, Train f1-score: 0.4581, Val loss: 0.6938, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 002, Train loss: 0.7007, Train Acc: 0.4746, Train f1-score: 0.4581, Val loss: 0.6934, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 003, Train loss: 0.7008, Train Acc: 0.4809, Train f1-score: 0.4581, Val loss: 0.6932, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 004, Train loss: 0.7007, Train Acc: 0.4809, Train f1-score: 0.4581, Val loss: 0.6929, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 005, Train loss: 0.7007, Train Acc: 0.4809, Train f1-score: 0.4581, Val loss: 0.6928, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 006, Train loss: 0.7006, Train Acc: 0.4809, Train f1-score: 0.4581, Val loss: 0.6925, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 007, Train loss: 0.7005, Train Acc: 0.4871, Train f1-score: 0.4581, Val loss: 0.6923, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 008, Train loss: 0.7007, Train Acc: 0.4809, Train f1-score: 0.4581, Val loss: 0.6921, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 009, Train loss: 0.7004, Train Acc: 0.4989, Train f1-score: 0.5460, Val loss: 0.6918, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 010, Train loss: 0.7002, Train Acc: 0.5107, Train f1-score: 0.6244, Val loss: 0.6916, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 011, Train loss: 0.7003, Train Acc: 0.4989, Train f1-score: 0.5738, Val loss: 0.6912, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 012, Train loss: 0.6999, Train Acc: 0.4926, Train f1-score: 0.5738, Val loss: 0.6906, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 013, Train loss: 0.7002, Train Acc: 0.4926, Train f1-score: 0.5738, Val loss: 0.6906, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 014, Train loss: 0.6996, Train Acc: 0.4864, Train f1-score: 0.5738, Val loss: 0.6905, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 015, Train loss: 0.6993, Train Acc: 0.4926, Train f1-score: 0.5738, Val loss: 0.6903, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 016, Train loss: 0.6996, Train Acc: 0.4934, Train f1-score: 0.5229, Val loss: 0.6896, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 017, Train loss: 0.6992, Train Acc: 0.4809, Train f1-score: 0.5229, Val loss: 0.6898, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 018, Train loss: 0.6986, Train Acc: 0.4989, Train f1-score: 0.5738, Val loss: 0.6896, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 019, Train loss: 0.6987, Train Acc: 0.4871, Train f1-score: 0.5229, Val loss: 0.6891, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 020, Train loss: 0.6986, Train Acc: 0.4809, Train f1-score: 0.5229, Val loss: 0.6888, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 021, Train loss: 0.6981, Train Acc: 0.4871, Train f1-score: 0.5229, Val loss: 0.6891, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 022, Train loss: 0.7015, Train Acc: 0.4746, Train f1-score: 0.5229, Val loss: 0.6885, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 023, Train loss: 0.6971, Train Acc: 0.5114, Train f1-score: 0.5882, Val loss: 0.6842, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 024, Train loss: 0.6985, Train Acc: 0.5051, Train f1-score: 0.5882, Val loss: 0.6880, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 025, Train loss: 0.6968, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.6873, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 026, Train loss: 0.6972, Train Acc: 0.4871, Train f1-score: 0.5229, Val loss: 0.6876, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 027, Train loss: 0.6968, Train Acc: 0.4934, Train f1-score: 0.5229, Val loss: 0.6873, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 028, Train loss: 0.6967, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6873, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 029, Train loss: 0.6931, Train Acc: 0.5404, Train f1-score: 0.7373, Val loss: 0.6913, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 030, Train loss: 0.7005, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6883, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 031, Train loss: 0.6999, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6856, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 032, Train loss: 0.6998, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6846, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 033, Train loss: 0.6978, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.6845, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 034, Train loss: 0.6971, Train Acc: 0.5294, Train f1-score: 0.6337, Val loss: 0.6838, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 035, Train loss: 0.6971, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6834, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 036, Train loss: 0.6961, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6833, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 037, Train loss: 0.6955, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6831, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 038, Train loss: 0.6959, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6827, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 039, Train loss: 0.6950, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6823, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 040, Train loss: 0.6951, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6819, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 041, Train loss: 0.6953, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6817, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 042, Train loss: 0.6941, Train Acc: 0.5482, Train f1-score: 0.6471, Val loss: 0.6818, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 043, Train loss: 0.6942, Train Acc: 0.5482, Train f1-score: 0.6471, Val loss: 0.6814, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 044, Train loss: 0.6942, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6811, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 045, Train loss: 0.6939, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6814, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 046, Train loss: 0.6933, Train Acc: 0.5482, Train f1-score: 0.6471, Val loss: 0.6805, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 047, Train loss: 0.6952, Train Acc: 0.5419, Train f1-score: 0.6471, Val loss: 0.6807, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 048, Train loss: 0.6938, Train Acc: 0.5482, Train f1-score: 0.6471, Val loss: 0.6809, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 049, Train loss: 0.6935, Train Acc: 0.5419, Train f1-score: 0.6471, Val loss: 0.6803, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 050, Train loss: 0.6948, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6800, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 051, Train loss: 0.6929, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6800, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 052, Train loss: 0.6926, Train Acc: 0.5419, Train f1-score: 0.6471, Val loss: 0.6797, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 053, Train loss: 0.6931, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6797, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 054, Train loss: 0.6917, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.6802, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 055, Train loss: 0.6937, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6799, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 056, Train loss: 0.6918, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6792, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 057, Train loss: 0.6929, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6791, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 058, Train loss: 0.6920, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6787, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 059, Train loss: 0.6921, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6777, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 060, Train loss: 0.6916, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6785, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 061, Train loss: 0.6912, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6784, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 062, Train loss: 0.6911, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6781, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 063, Train loss: 0.6911, Train Acc: 0.5169, Train f1-score: 0.6471, Val loss: 0.6780, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 064, Train loss: 0.6909, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6779, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 065, Train loss: 0.6908, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6778, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 066, Train loss: 0.6919, Train Acc: 0.5357, Train f1-score: 0.6471, Val loss: 0.6775, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 067, Train loss: 0.6899, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6777, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 068, Train loss: 0.6905, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6772, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 069, Train loss: 0.6902, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6772, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 070, Train loss: 0.6899, Train Acc: 0.5349, Train f1-score: 0.7079, Val loss: 0.6773, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 071, Train loss: 0.6902, Train Acc: 0.5232, Train f1-score: 0.6471, Val loss: 0.6773, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 072, Train loss: 0.6901, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.6770, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 073, Train loss: 0.6898, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.6768, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 074, Train loss: 0.6896, Train Acc: 0.5294, Train f1-score: 0.6471, Val loss: 0.6764, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 075, Train loss: 0.6922, Train Acc: 0.5349, Train f1-score: 0.7016, Val loss: 0.6763, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 076, Train loss: 0.6887, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.6734, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 077, Train loss: 0.6922, Train Acc: 0.5412, Train f1-score: 0.7016, Val loss: 0.6761, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 078, Train loss: 0.6885, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.6770, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 079, Train loss: 0.6906, Train Acc: 0.5349, Train f1-score: 0.7016, Val loss: 0.6750, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 080, Train loss: 0.6875, Train Acc: 0.5412, Train f1-score: 0.7079, Val loss: 0.6763, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 081, Train loss: 0.6882, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6753, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 082, Train loss: 0.6874, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6774, Val Acc: 0.5294, Val f1-score: 0.3665,\n",
      "Epoch: 083, Train loss: 0.6877, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6765, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 084, Train loss: 0.6905, Train Acc: 0.5412, Train f1-score: 0.7016, Val loss: 0.6730, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 085, Train loss: 0.6887, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6724, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 086, Train loss: 0.6885, Train Acc: 0.5349, Train f1-score: 0.7016, Val loss: 0.6737, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 087, Train loss: 0.6872, Train Acc: 0.5412, Train f1-score: 0.7016, Val loss: 0.6725, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 088, Train loss: 0.6887, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6742, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 089, Train loss: 0.6861, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.6743, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 090, Train loss: 0.6877, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6733, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 091, Train loss: 0.6874, Train Acc: 0.5412, Train f1-score: 0.7016, Val loss: 0.6721, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 092, Train loss: 0.6882, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6719, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 093, Train loss: 0.6876, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6717, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 094, Train loss: 0.6887, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6716, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 095, Train loss: 0.6878, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6710, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 096, Train loss: 0.6880, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6714, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 097, Train loss: 0.6873, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6716, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 098, Train loss: 0.6867, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.6743, Val Acc: 0.4706, Val f1-score: 0.3388,\n",
      "Epoch: 099, Train loss: 0.6863, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6716, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 100, Train loss: 0.6863, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6716, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 101, Train loss: 0.6866, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6713, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 102, Train loss: 0.6862, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.6713, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 103, Train loss: 0.6864, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6712, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 104, Train loss: 0.6864, Train Acc: 0.5537, Train f1-score: 0.7079, Val loss: 0.6711, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 105, Train loss: 0.6857, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6710, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 106, Train loss: 0.6863, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6709, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 107, Train loss: 0.6856, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6707, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 108, Train loss: 0.6857, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6707, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 109, Train loss: 0.6860, Train Acc: 0.5474, Train f1-score: 0.7079, Val loss: 0.6706, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 110, Train loss: 0.6853, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6706, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 111, Train loss: 0.6851, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6704, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 112, Train loss: 0.6855, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6704, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 113, Train loss: 0.6852, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6702, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 114, Train loss: 0.6854, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6702, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 115, Train loss: 0.6845, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6703, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 116, Train loss: 0.6854, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 117, Train loss: 0.6843, Train Acc: 0.5474, Train f1-score: 0.7016, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 118, Train loss: 0.6842, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6703, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 119, Train loss: 0.6837, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6701, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 120, Train loss: 0.6845, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6702, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 121, Train loss: 0.6838, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 122, Train loss: 0.6835, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 123, Train loss: 0.6837, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6698, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 124, Train loss: 0.6834, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6698, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 125, Train loss: 0.6835, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6697, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 126, Train loss: 0.6829, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6697, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 127, Train loss: 0.6833, Train Acc: 0.5404, Train f1-score: 0.7647, Val loss: 0.6694, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 128, Train loss: 0.6831, Train Acc: 0.5404, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 129, Train loss: 0.6813, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 130, Train loss: 0.6815, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 131, Train loss: 0.6811, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6683, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 132, Train loss: 0.6816, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6700, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 133, Train loss: 0.6816, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6682, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 134, Train loss: 0.6817, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6697, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 135, Train loss: 0.6815, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6679, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 136, Train loss: 0.6811, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6697, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 137, Train loss: 0.6806, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6695, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 138, Train loss: 0.6814, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6676, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 139, Train loss: 0.6814, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6681, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 140, Train loss: 0.6793, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6692, Val Acc: 0.5294, Val f1-score: 0.4471,\n",
      "Epoch: 141, Train loss: 0.6809, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6674, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 142, Train loss: 0.6816, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6672, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 143, Train loss: 0.6806, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6672, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 144, Train loss: 0.6803, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6670, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 145, Train loss: 0.6802, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6670, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 146, Train loss: 0.6801, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6669, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 147, Train loss: 0.6799, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6667, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 148, Train loss: 0.6802, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6666, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 149, Train loss: 0.6796, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6666, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 150, Train loss: 0.6799, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 151, Train loss: 0.6791, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 152, Train loss: 0.6790, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6662, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 153, Train loss: 0.6797, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6662, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 154, Train loss: 0.6786, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6660, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 155, Train loss: 0.6791, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6660, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 156, Train loss: 0.6786, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6659, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 157, Train loss: 0.6792, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 158, Train loss: 0.6777, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6660, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 159, Train loss: 0.6786, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 160, Train loss: 0.6791, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 161, Train loss: 0.6773, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6659, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 162, Train loss: 0.6778, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 163, Train loss: 0.6771, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 164, Train loss: 0.6782, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 165, Train loss: 0.6770, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 166, Train loss: 0.6781, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 167, Train loss: 0.6773, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 168, Train loss: 0.6769, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 169, Train loss: 0.6768, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6661, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 170, Train loss: 0.6761, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 171, Train loss: 0.6775, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 172, Train loss: 0.6767, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 173, Train loss: 0.6759, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 174, Train loss: 0.6776, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 175, Train loss: 0.6765, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 176, Train loss: 0.6753, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 177, Train loss: 0.6778, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 178, Train loss: 0.6751, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 179, Train loss: 0.6765, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 180, Train loss: 0.6753, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 181, Train loss: 0.6754, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 182, Train loss: 0.6756, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 183, Train loss: 0.6764, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 184, Train loss: 0.6741, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 185, Train loss: 0.6761, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 186, Train loss: 0.6743, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 187, Train loss: 0.6750, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 188, Train loss: 0.6762, Train Acc: 0.5467, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 189, Train loss: 0.6738, Train Acc: 0.5529, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 190, Train loss: 0.6745, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 191, Train loss: 0.6751, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6644, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 192, Train loss: 0.6737, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 193, Train loss: 0.6741, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 194, Train loss: 0.6737, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 195, Train loss: 0.6739, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 196, Train loss: 0.6740, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6645, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 197, Train loss: 0.6740, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 198, Train loss: 0.6738, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6645, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 199, Train loss: 0.6736, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 200, Train loss: 0.6736, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 201, Train loss: 0.6736, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6644, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 202, Train loss: 0.6733, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 203, Train loss: 0.6729, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 204, Train loss: 0.6733, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6644, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 205, Train loss: 0.6732, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 206, Train loss: 0.6731, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 207, Train loss: 0.6725, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6645, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 208, Train loss: 0.6729, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6643, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 209, Train loss: 0.6726, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 210, Train loss: 0.6722, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 211, Train loss: 0.6731, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 212, Train loss: 0.6726, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 213, Train loss: 0.6717, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6644, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 214, Train loss: 0.6723, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 215, Train loss: 0.6720, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 216, Train loss: 0.6724, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 217, Train loss: 0.6716, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 218, Train loss: 0.6727, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 219, Train loss: 0.6707, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 220, Train loss: 0.6726, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 221, Train loss: 0.6705, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6644, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 222, Train loss: 0.6715, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 223, Train loss: 0.6707, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 224, Train loss: 0.6707, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 225, Train loss: 0.6707, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6659, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 226, Train loss: 0.6726, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 227, Train loss: 0.6705, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 228, Train loss: 0.6719, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 229, Train loss: 0.6695, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6645, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 230, Train loss: 0.6715, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6668, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 231, Train loss: 0.6710, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 232, Train loss: 0.6703, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 233, Train loss: 0.6697, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 234, Train loss: 0.6700, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 235, Train loss: 0.6700, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6667, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 236, Train loss: 0.6714, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 237, Train loss: 0.6709, Train Acc: 0.5592, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 238, Train loss: 0.6701, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 239, Train loss: 0.6695, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 240, Train loss: 0.6711, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 241, Train loss: 0.6690, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6670, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 242, Train loss: 0.6712, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 243, Train loss: 0.6689, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6670, Val Acc: 0.5882, Val f1-score: 0.5394,\n",
      "Epoch: 244, Train loss: 0.6707, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 245, Train loss: 0.6695, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 246, Train loss: 0.6695, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6672, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 247, Train loss: 0.6703, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 248, Train loss: 0.6699, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 249, Train loss: 0.6697, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6668, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 250, Train loss: 0.6702, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 251, Train loss: 0.6695, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 252, Train loss: 0.6692, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 253, Train loss: 0.6695, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 254, Train loss: 0.6692, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 255, Train loss: 0.6692, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 256, Train loss: 0.6697, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 257, Train loss: 0.6689, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 258, Train loss: 0.6689, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 259, Train loss: 0.6688, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 260, Train loss: 0.6689, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 261, Train loss: 0.6691, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 262, Train loss: 0.6681, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 263, Train loss: 0.6690, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 264, Train loss: 0.6680, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 265, Train loss: 0.6690, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 266, Train loss: 0.6677, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6668, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 267, Train loss: 0.6683, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 268, Train loss: 0.6675, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6667, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 269, Train loss: 0.6682, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 270, Train loss: 0.6673, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6668, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 271, Train loss: 0.6684, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 272, Train loss: 0.6682, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 273, Train loss: 0.6667, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 274, Train loss: 0.6680, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 275, Train loss: 0.6676, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 276, Train loss: 0.6677, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 277, Train loss: 0.6668, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 278, Train loss: 0.6683, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 279, Train loss: 0.6676, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 280, Train loss: 0.6668, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 281, Train loss: 0.6675, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6666, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 282, Train loss: 0.6680, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 283, Train loss: 0.6670, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 284, Train loss: 0.6681, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6661, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 285, Train loss: 0.6675, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 286, Train loss: 0.6663, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6662, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 287, Train loss: 0.6680, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 288, Train loss: 0.6668, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 289, Train loss: 0.6677, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 290, Train loss: 0.6665, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 291, Train loss: 0.6675, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 292, Train loss: 0.6670, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 293, Train loss: 0.6661, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6664, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 294, Train loss: 0.6674, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 295, Train loss: 0.6660, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 296, Train loss: 0.6673, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 297, Train loss: 0.6661, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 298, Train loss: 0.6672, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 299, Train loss: 0.6670, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 300, Train loss: 0.6659, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6662, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 301, Train loss: 0.6672, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 302, Train loss: 0.6657, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 303, Train loss: 0.6669, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 304, Train loss: 0.6660, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6661, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 305, Train loss: 0.6669, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 306, Train loss: 0.6664, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 307, Train loss: 0.6656, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6659, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 308, Train loss: 0.6660, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6680, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 309, Train loss: 0.6693, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6687, Val Acc: 0.5294, Val f1-score: 0.4938,\n",
      "Epoch: 310, Train loss: 0.6696, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6679, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 311, Train loss: 0.6684, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6680, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 312, Train loss: 0.6681, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6666, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 313, Train loss: 0.6667, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6676, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 314, Train loss: 0.6672, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6672, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 315, Train loss: 0.6668, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6660, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 316, Train loss: 0.6662, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6668, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 317, Train loss: 0.6669, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 318, Train loss: 0.6658, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 319, Train loss: 0.6663, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 320, Train loss: 0.6653, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6666, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 321, Train loss: 0.6665, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 322, Train loss: 0.6654, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6662, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 323, Train loss: 0.6660, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 324, Train loss: 0.6651, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6662, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 325, Train loss: 0.6660, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 326, Train loss: 0.6650, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 327, Train loss: 0.6658, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 328, Train loss: 0.6647, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 329, Train loss: 0.6655, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 330, Train loss: 0.6645, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6663, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 331, Train loss: 0.6657, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 332, Train loss: 0.6644, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 333, Train loss: 0.6646, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 334, Train loss: 0.6653, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 335, Train loss: 0.6644, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 336, Train loss: 0.6653, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 337, Train loss: 0.6644, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 338, Train loss: 0.6651, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6646, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 339, Train loss: 0.6644, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 340, Train loss: 0.6650, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6645, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 341, Train loss: 0.6639, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 342, Train loss: 0.6651, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 343, Train loss: 0.6641, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 344, Train loss: 0.6650, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 345, Train loss: 0.6640, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6659, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 346, Train loss: 0.6649, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 347, Train loss: 0.6639, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6659, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 348, Train loss: 0.6648, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 349, Train loss: 0.6637, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 350, Train loss: 0.6649, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 351, Train loss: 0.6638, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 352, Train loss: 0.6647, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 353, Train loss: 0.6636, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 354, Train loss: 0.6645, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 355, Train loss: 0.6641, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6665, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 356, Train loss: 0.6651, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 357, Train loss: 0.6641, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 358, Train loss: 0.6637, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 359, Train loss: 0.6635, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 360, Train loss: 0.6643, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 361, Train loss: 0.6633, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 362, Train loss: 0.6635, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 363, Train loss: 0.6641, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 364, Train loss: 0.6632, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 365, Train loss: 0.6640, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 366, Train loss: 0.6631, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 367, Train loss: 0.6642, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6647, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 368, Train loss: 0.6633, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 369, Train loss: 0.6635, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 370, Train loss: 0.6633, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6656, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 371, Train loss: 0.6638, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 372, Train loss: 0.6629, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6648, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 373, Train loss: 0.6631, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 374, Train loss: 0.6637, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 375, Train loss: 0.6628, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 376, Train loss: 0.6639, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 377, Train loss: 0.6629, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 378, Train loss: 0.6636, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 379, Train loss: 0.6628, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 380, Train loss: 0.6636, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 381, Train loss: 0.6625, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 382, Train loss: 0.6624, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6649, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 383, Train loss: 0.6626, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 384, Train loss: 0.6633, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 385, Train loss: 0.6625, Train Acc: 0.5654, Train f1-score: 0.7647, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 386, Train loss: 0.6634, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6655, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 387, Train loss: 0.6633, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6652, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 388, Train loss: 0.6622, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 389, Train loss: 0.6625, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6657, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 390, Train loss: 0.6630, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6654, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 391, Train loss: 0.6623, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 392, Train loss: 0.6629, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6650, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 393, Train loss: 0.6621, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 394, Train loss: 0.6623, Train Acc: 0.5772, Train f1-score: 0.8248, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 395, Train loss: 0.6630, Train Acc: 0.5717, Train f1-score: 0.7647, Val loss: 0.6651, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 396, Train loss: 0.6620, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6653, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 397, Train loss: 0.6626, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6649, Val Acc: 0.5294, Val f1-score: 0.5193,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 398, Train loss: 0.6621, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6654, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "Epoch: 399, Train loss: 0.6627, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6653, Val Acc: 0.5294, Val f1-score: 0.5193,\n",
      "Epoch: 400, Train loss: 0.6618, Train Acc: 0.5835, Train f1-score: 0.8248, Val loss: 0.6658, Val Acc: 0.5882, Val f1-score: 0.5701,\n",
      "GIN accuracy: 0.5263158082962036\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  39  44  49\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [33 34 35 36 37 38 40 41 42 43 45 46 47 48 50 51]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 2.6114, Train Acc: 0.5361, Train f1-score: 0.4735, Val loss: 2.2302, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 1.4630, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.8287, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.7231, Train Acc: 0.5250, Train f1-score: 0.3704, Val loss: 0.6932, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.6980, Train Acc: 0.5028, Train f1-score: 0.3582, Val loss: 0.6929, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.6976, Train Acc: 0.4917, Train f1-score: 0.2778, Val loss: 0.6937, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.6971, Train Acc: 0.5028, Train f1-score: 0.3582, Val loss: 0.6949, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.6969, Train Acc: 0.4917, Train f1-score: 0.3160, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.6971, Train Acc: 0.4965, Train f1-score: 0.3831, Val loss: 0.6976, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.6973, Train Acc: 0.4903, Train f1-score: 0.3831, Val loss: 0.6992, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6977, Train Acc: 0.4792, Train f1-score: 0.3160, Val loss: 0.7010, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6980, Train Acc: 0.5028, Train f1-score: 0.3111, Val loss: 0.7025, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6985, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7037, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6989, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7044, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6992, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7047, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6993, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7048, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6993, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7052, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6992, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7054, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6993, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7045, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6982, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7049, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6978, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7050, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6972, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7054, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6965, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7059, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6961, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7063, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6955, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7066, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6949, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7069, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6947, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7080, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6944, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7085, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 027, Train loss: 0.6939, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7104, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 028, Train loss: 0.6942, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7089, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 029, Train loss: 0.6925, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7100, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 030, Train loss: 0.6925, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.7098, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 031, Train loss: 0.6918, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7113, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 032, Train loss: 0.6913, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7119, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 033, Train loss: 0.6908, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7120, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 034, Train loss: 0.6900, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.7136, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 035, Train loss: 0.6902, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7145, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6895, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7150, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6883, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7157, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 038, Train loss: 0.6886, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7149, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 039, Train loss: 0.6868, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.7169, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 040, Train loss: 0.6872, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.7170, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 041, Train loss: 0.6858, Train Acc: 0.5486, Train f1-score: 0.3968, Val loss: 0.7185, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 042, Train loss: 0.6859, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.7191, Val Acc: 0.3750, Val f1-score: 0.2727,\n",
      "Epoch: 043, Train loss: 0.6853, Train Acc: 0.5549, Train f1-score: 0.3968, Val loss: 0.7195, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 044, Train loss: 0.6844, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7206, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 045, Train loss: 0.6845, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7214, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 046, Train loss: 0.6839, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7223, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 047, Train loss: 0.6834, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7225, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 048, Train loss: 0.6823, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7253, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 049, Train loss: 0.6835, Train Acc: 0.5722, Train f1-score: 0.5103, Val loss: 0.7246, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 050, Train loss: 0.6822, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7256, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 051, Train loss: 0.6814, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7262, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 052, Train loss: 0.6814, Train Acc: 0.5660, Train f1-score: 0.5103, Val loss: 0.7273, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 053, Train loss: 0.6812, Train Acc: 0.5722, Train f1-score: 0.5103, Val loss: 0.7275, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 054, Train loss: 0.6803, Train Acc: 0.5785, Train f1-score: 0.5103, Val loss: 0.7277, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 055, Train loss: 0.6804, Train Acc: 0.5785, Train f1-score: 0.5103, Val loss: 0.7284, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 056, Train loss: 0.6798, Train Acc: 0.5785, Train f1-score: 0.5103, Val loss: 0.7305, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 057, Train loss: 0.6802, Train Acc: 0.5722, Train f1-score: 0.5103, Val loss: 0.7297, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 058, Train loss: 0.6788, Train Acc: 0.5785, Train f1-score: 0.5103, Val loss: 0.7313, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 059, Train loss: 0.6789, Train Acc: 0.5722, Train f1-score: 0.5103, Val loss: 0.7319, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 060, Train loss: 0.6785, Train Acc: 0.5771, Train f1-score: 0.6051, Val loss: 0.7329, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 061, Train loss: 0.6783, Train Acc: 0.5771, Train f1-score: 0.6051, Val loss: 0.7336, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 062, Train loss: 0.6779, Train Acc: 0.5771, Train f1-score: 0.6051, Val loss: 0.7340, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 063, Train loss: 0.6772, Train Acc: 0.5660, Train f1-score: 0.5616, Val loss: 0.7358, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 064, Train loss: 0.6774, Train Acc: 0.5660, Train f1-score: 0.5616, Val loss: 0.7359, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 065, Train loss: 0.6766, Train Acc: 0.5660, Train f1-score: 0.5616, Val loss: 0.7376, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 066, Train loss: 0.6769, Train Acc: 0.5785, Train f1-score: 0.5616, Val loss: 0.7377, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 067, Train loss: 0.6762, Train Acc: 0.5722, Train f1-score: 0.5616, Val loss: 0.7393, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 068, Train loss: 0.6765, Train Acc: 0.5785, Train f1-score: 0.5616, Val loss: 0.7386, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 069, Train loss: 0.6750, Train Acc: 0.5785, Train f1-score: 0.5616, Val loss: 0.7410, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 070, Train loss: 0.6758, Train Acc: 0.5847, Train f1-score: 0.5616, Val loss: 0.7390, Val Acc: 0.3750, Val f1-score: 0.3651,\n",
      "Epoch: 071, Train loss: 0.6733, Train Acc: 0.5847, Train f1-score: 0.5616, Val loss: 0.7411, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 072, Train loss: 0.6741, Train Acc: 0.5785, Train f1-score: 0.5616, Val loss: 0.7402, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 073, Train loss: 0.6729, Train Acc: 0.5958, Train f1-score: 0.6389, Val loss: 0.7425, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 074, Train loss: 0.6734, Train Acc: 0.5896, Train f1-score: 0.6389, Val loss: 0.7419, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 075, Train loss: 0.6723, Train Acc: 0.5958, Train f1-score: 0.6389, Val loss: 0.7441, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 076, Train loss: 0.6731, Train Acc: 0.5833, Train f1-score: 0.6389, Val loss: 0.7440, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 077, Train loss: 0.6721, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7445, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 078, Train loss: 0.6713, Train Acc: 0.5896, Train f1-score: 0.6389, Val loss: 0.7460, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 079, Train loss: 0.6719, Train Acc: 0.5833, Train f1-score: 0.6389, Val loss: 0.7465, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 080, Train loss: 0.6716, Train Acc: 0.5785, Train f1-score: 0.5916, Val loss: 0.7472, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 081, Train loss: 0.6712, Train Acc: 0.5660, Train f1-score: 0.5916, Val loss: 0.7481, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 082, Train loss: 0.6711, Train Acc: 0.5660, Train f1-score: 0.5916, Val loss: 0.7487, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 083, Train loss: 0.6705, Train Acc: 0.5722, Train f1-score: 0.5916, Val loss: 0.7490, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 084, Train loss: 0.6701, Train Acc: 0.5785, Train f1-score: 0.5916, Val loss: 0.7504, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 085, Train loss: 0.6702, Train Acc: 0.5785, Train f1-score: 0.5916, Val loss: 0.7502, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 086, Train loss: 0.6693, Train Acc: 0.5785, Train f1-score: 0.5916, Val loss: 0.7514, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 087, Train loss: 0.6693, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7514, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 088, Train loss: 0.6687, Train Acc: 0.5785, Train f1-score: 0.5916, Val loss: 0.7524, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 089, Train loss: 0.6686, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7522, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 090, Train loss: 0.6682, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7530, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 091, Train loss: 0.6677, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7545, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 092, Train loss: 0.6679, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7545, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 093, Train loss: 0.6673, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7546, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 094, Train loss: 0.6665, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7560, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 095, Train loss: 0.6667, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7559, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 096, Train loss: 0.6662, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7562, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 097, Train loss: 0.6656, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7568, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 098, Train loss: 0.6653, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7577, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 099, Train loss: 0.6654, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7584, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 100, Train loss: 0.6651, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7592, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 101, Train loss: 0.6650, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7587, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 102, Train loss: 0.6643, Train Acc: 0.5847, Train f1-score: 0.5916, Val loss: 0.7600, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 103, Train loss: 0.6644, Train Acc: 0.5958, Train f1-score: 0.6580, Val loss: 0.7609, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 104, Train loss: 0.6641, Train Acc: 0.5958, Train f1-score: 0.6580, Val loss: 0.7613, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 105, Train loss: 0.6639, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7612, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 106, Train loss: 0.6637, Train Acc: 0.5958, Train f1-score: 0.6580, Val loss: 0.7620, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 107, Train loss: 0.6632, Train Acc: 0.5958, Train f1-score: 0.6580, Val loss: 0.7624, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 108, Train loss: 0.6630, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7638, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 109, Train loss: 0.6635, Train Acc: 0.5896, Train f1-score: 0.6580, Val loss: 0.7635, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 110, Train loss: 0.6626, Train Acc: 0.5896, Train f1-score: 0.6580, Val loss: 0.7634, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 111, Train loss: 0.6623, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7646, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 112, Train loss: 0.6624, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7651, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 113, Train loss: 0.6625, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7655, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 114, Train loss: 0.6619, Train Acc: 0.5896, Train f1-score: 0.6580, Val loss: 0.7654, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 115, Train loss: 0.6616, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7658, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 116, Train loss: 0.6613, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7663, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 117, Train loss: 0.6612, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7665, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 118, Train loss: 0.6608, Train Acc: 0.5958, Train f1-score: 0.6580, Val loss: 0.7665, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 119, Train loss: 0.6605, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7673, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 120, Train loss: 0.6605, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7676, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 121, Train loss: 0.6602, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7677, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 122, Train loss: 0.6599, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7686, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 123, Train loss: 0.6599, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7684, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 124, Train loss: 0.6595, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7693, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 125, Train loss: 0.6600, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7705, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 126, Train loss: 0.6602, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7700, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 127, Train loss: 0.6596, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7713, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 128, Train loss: 0.6598, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7707, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 129, Train loss: 0.6586, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7707, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 130, Train loss: 0.6584, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7714, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 131, Train loss: 0.6583, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7715, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 132, Train loss: 0.6581, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7718, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 133, Train loss: 0.6580, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7721, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 134, Train loss: 0.6577, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7721, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 135, Train loss: 0.6576, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7731, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 136, Train loss: 0.6576, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7725, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 137, Train loss: 0.6574, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7734, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 138, Train loss: 0.6573, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7737, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 139, Train loss: 0.6577, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7744, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 140, Train loss: 0.6576, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7750, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 141, Train loss: 0.6576, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7746, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 142, Train loss: 0.6572, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7759, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 143, Train loss: 0.6575, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7751, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 144, Train loss: 0.6570, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7761, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 145, Train loss: 0.6569, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7755, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 146, Train loss: 0.6568, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7767, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 147, Train loss: 0.6566, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7754, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 148, Train loss: 0.6558, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7759, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 149, Train loss: 0.6556, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7763, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 150, Train loss: 0.6564, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7775, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 151, Train loss: 0.6562, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7770, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 152, Train loss: 0.6557, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7782, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 153, Train loss: 0.6561, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7799, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 154, Train loss: 0.6558, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7823, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 155, Train loss: 0.6564, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7787, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 156, Train loss: 0.6554, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7835, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 157, Train loss: 0.6562, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7799, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 158, Train loss: 0.6552, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7843, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 159, Train loss: 0.6561, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7844, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 160, Train loss: 0.6558, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7804, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 161, Train loss: 0.6550, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7836, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 162, Train loss: 0.6551, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7805, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 163, Train loss: 0.6544, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7802, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 164, Train loss: 0.6539, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7802, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 165, Train loss: 0.6540, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7845, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 166, Train loss: 0.6549, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7852, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 167, Train loss: 0.6548, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7813, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 168, Train loss: 0.6538, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7854, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 169, Train loss: 0.6550, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7838, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 170, Train loss: 0.6538, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7816, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 171, Train loss: 0.6536, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7858, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 172, Train loss: 0.6545, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7861, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 173, Train loss: 0.6543, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7817, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 174, Train loss: 0.6533, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7840, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 175, Train loss: 0.6535, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7863, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 176, Train loss: 0.6538, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7822, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 177, Train loss: 0.6529, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7861, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 178, Train loss: 0.6538, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7858, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 179, Train loss: 0.6532, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7811, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 180, Train loss: 0.6521, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7858, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 181, Train loss: 0.6535, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7854, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 182, Train loss: 0.6530, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7808, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 183, Train loss: 0.6515, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7850, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 184, Train loss: 0.6525, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7822, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 185, Train loss: 0.6510, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7808, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 186, Train loss: 0.6506, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7848, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 187, Train loss: 0.6518, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7849, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 188, Train loss: 0.6514, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7810, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 189, Train loss: 0.6502, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7845, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 190, Train loss: 0.6509, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7856, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 191, Train loss: 0.6512, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7816, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 192, Train loss: 0.6500, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7859, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 193, Train loss: 0.6510, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7817, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 194, Train loss: 0.6489, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7852, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 195, Train loss: 0.6499, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7868, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 196, Train loss: 0.6491, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7872, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 197, Train loss: 0.6488, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7847, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 198, Train loss: 0.6482, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7879, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 199, Train loss: 0.6483, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7871, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 200, Train loss: 0.6484, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7844, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 201, Train loss: 0.6476, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7849, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 202, Train loss: 0.6474, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7886, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 203, Train loss: 0.6477, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7865, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 204, Train loss: 0.6464, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7892, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 205, Train loss: 0.6475, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7906, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 206, Train loss: 0.6475, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7909, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 207, Train loss: 0.6474, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7916, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 208, Train loss: 0.6472, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7881, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 209, Train loss: 0.6457, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.8159, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 210, Train loss: 0.6549, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.7890, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 211, Train loss: 0.6446, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.8099, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 212, Train loss: 0.6541, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.7843, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 213, Train loss: 0.6447, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7890, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 214, Train loss: 0.6450, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7908, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 215, Train loss: 0.6437, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.7893, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 216, Train loss: 0.6439, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7949, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 217, Train loss: 0.6450, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.7951, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 218, Train loss: 0.6483, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7868, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 219, Train loss: 0.6407, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7926, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 220, Train loss: 0.6428, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7956, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 221, Train loss: 0.6435, Train Acc: 0.6132, Train f1-score: 0.7196, Val loss: 0.7909, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 222, Train loss: 0.6426, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.8038, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 223, Train loss: 0.6509, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.7872, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 224, Train loss: 0.6385, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.8121, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 225, Train loss: 0.6538, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.8007, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 226, Train loss: 0.6451, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.8007, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 227, Train loss: 0.6435, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.8003, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 228, Train loss: 0.6436, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7938, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 229, Train loss: 0.6406, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.8068, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 230, Train loss: 0.6434, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.8050, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 231, Train loss: 0.6465, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.8066, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 232, Train loss: 0.6463, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7918, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 233, Train loss: 0.6387, Train Acc: 0.6132, Train f1-score: 0.7196, Val loss: 0.8002, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 234, Train loss: 0.6482, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.7905, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 235, Train loss: 0.6400, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.8069, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 236, Train loss: 0.6446, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7934, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 237, Train loss: 0.6387, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.8034, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 238, Train loss: 0.6404, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.8098, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 239, Train loss: 0.6470, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7966, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 240, Train loss: 0.6376, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.8157, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 241, Train loss: 0.6490, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7976, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 242, Train loss: 0.6377, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.8114, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 243, Train loss: 0.6426, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.7965, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 244, Train loss: 0.6385, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7927, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 245, Train loss: 0.6392, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7979, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 246, Train loss: 0.6390, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7947, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 247, Train loss: 0.6365, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7953, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 248, Train loss: 0.6378, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7967, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 249, Train loss: 0.6382, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7997, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 250, Train loss: 0.6397, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7927, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 251, Train loss: 0.6371, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7932, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 252, Train loss: 0.6391, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7955, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 253, Train loss: 0.6342, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7897, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 254, Train loss: 0.6344, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.8091, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 255, Train loss: 0.6482, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.7952, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 256, Train loss: 0.6376, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.8026, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 257, Train loss: 0.6408, Train Acc: 0.6292, Train f1-score: 0.8317, Val loss: 0.8069, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 258, Train loss: 0.6405, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7983, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 259, Train loss: 0.6374, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.7995, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 260, Train loss: 0.6404, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.7908, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 261, Train loss: 0.6333, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.7974, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 262, Train loss: 0.6375, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7935, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 263, Train loss: 0.6323, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.7884, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 264, Train loss: 0.6331, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.7914, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 265, Train loss: 0.6342, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7950, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 266, Train loss: 0.6381, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.7901, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 267, Train loss: 0.6292, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7998, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 268, Train loss: 0.6343, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7991, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 269, Train loss: 0.6357, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.7941, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 270, Train loss: 0.6320, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7953, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 271, Train loss: 0.6336, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7943, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 272, Train loss: 0.6332, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7920, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 273, Train loss: 0.6328, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.7950, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 274, Train loss: 0.6347, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7874, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 275, Train loss: 0.6292, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7933, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 276, Train loss: 0.6315, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7971, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 277, Train loss: 0.6379, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7982, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 278, Train loss: 0.6338, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7876, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 279, Train loss: 0.6311, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.7873, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 280, Train loss: 0.6319, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7890, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 281, Train loss: 0.6303, Train Acc: 0.6306, Train f1-score: 0.7720, Val loss: 0.7969, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 282, Train loss: 0.6359, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.8014, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 283, Train loss: 0.6355, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.7920, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 284, Train loss: 0.6315, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.7930, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 285, Train loss: 0.6308, Train Acc: 0.6306, Train f1-score: 0.7720, Val loss: 0.7840, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 286, Train loss: 0.6283, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7920, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 287, Train loss: 0.6340, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.7961, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 288, Train loss: 0.6283, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7944, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 289, Train loss: 0.6299, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7951, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 290, Train loss: 0.6282, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7968, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 291, Train loss: 0.6302, Train Acc: 0.6306, Train f1-score: 0.7720, Val loss: 0.7920, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 292, Train loss: 0.6303, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7968, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 293, Train loss: 0.6309, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7916, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 294, Train loss: 0.6274, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7944, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 295, Train loss: 0.6304, Train Acc: 0.6306, Train f1-score: 0.7720, Val loss: 0.7864, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 296, Train loss: 0.6267, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.7844, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 297, Train loss: 0.6285, Train Acc: 0.6542, Train f1-score: 0.8317, Val loss: 0.7986, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 298, Train loss: 0.6316, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7805, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 299, Train loss: 0.6239, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.7876, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 300, Train loss: 0.6290, Train Acc: 0.6542, Train f1-score: 0.8317, Val loss: 0.7978, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 301, Train loss: 0.6322, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.7806, Val Acc: 0.3750, Val f1-score: 0.3333,\n",
      "Epoch: 302, Train loss: 0.6236, Train Acc: 0.6542, Train f1-score: 0.8317, Val loss: 0.7873, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 303, Train loss: 0.6311, Train Acc: 0.6542, Train f1-score: 0.8317, Val loss: 0.7914, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 304, Train loss: 0.6267, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.7850, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 305, Train loss: 0.6267, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.7789, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 306, Train loss: 0.6227, Train Acc: 0.6542, Train f1-score: 0.8317, Val loss: 0.7899, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 307, Train loss: 0.6313, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.7949, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 308, Train loss: 0.6264, Train Acc: 0.6431, Train f1-score: 0.7720, Val loss: 0.7819, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 309, Train loss: 0.6219, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.7904, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 310, Train loss: 0.6307, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.8030, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 311, Train loss: 0.6284, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7913, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 312, Train loss: 0.6254, Train Acc: 0.6417, Train f1-score: 0.8317, Val loss: 0.7917, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 313, Train loss: 0.6272, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.8011, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 314, Train loss: 0.6286, Train Acc: 0.6479, Train f1-score: 0.8317, Val loss: 0.7903, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 315, Train loss: 0.6234, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.7909, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 316, Train loss: 0.6271, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7993, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 317, Train loss: 0.6258, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7883, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 318, Train loss: 0.6264, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7952, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 319, Train loss: 0.6235, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7929, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 320, Train loss: 0.6251, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7922, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 321, Train loss: 0.6241, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.8062, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 322, Train loss: 0.6239, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.8046, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 323, Train loss: 0.6345, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7986, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 324, Train loss: 0.6245, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7931, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 325, Train loss: 0.6250, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7856, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 326, Train loss: 0.6230, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7899, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 327, Train loss: 0.6251, Train Acc: 0.6479, Train f1-score: 0.8338, Val loss: 0.8065, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 328, Train loss: 0.6289, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7940, Val Acc: 0.4375, Val f1-score: 0.3766,\n",
      "Epoch: 329, Train loss: 0.6236, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7900, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 330, Train loss: 0.6221, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7905, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 331, Train loss: 0.6252, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.8027, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 332, Train loss: 0.6270, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7922, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 333, Train loss: 0.6219, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7913, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 334, Train loss: 0.6278, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.8051, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 335, Train loss: 0.6207, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.7941, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 336, Train loss: 0.6238, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7850, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 337, Train loss: 0.6188, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.7771, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 338, Train loss: 0.6123, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.7712, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 339, Train loss: 0.6201, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7971, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 340, Train loss: 0.6225, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7898, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 341, Train loss: 0.6251, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7941, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 342, Train loss: 0.6251, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.7898, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 343, Train loss: 0.6159, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7759, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 344, Train loss: 0.6182, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.7997, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 345, Train loss: 0.6212, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.7699, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 346, Train loss: 0.6067, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.7775, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 347, Train loss: 0.6210, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.8069, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 348, Train loss: 0.6253, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8012, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 349, Train loss: 0.6181, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7743, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 350, Train loss: 0.6163, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 0.7736, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 351, Train loss: 0.6181, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.8141, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 352, Train loss: 0.6260, Train Acc: 0.6479, Train f1-score: 0.8338, Val loss: 0.8137, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 353, Train loss: 0.6212, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7842, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 354, Train loss: 0.6160, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.7812, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 355, Train loss: 0.6185, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7943, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 356, Train loss: 0.6149, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.7853, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 357, Train loss: 0.6173, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8002, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 358, Train loss: 0.6186, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7831, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 359, Train loss: 0.6158, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8008, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 360, Train loss: 0.6204, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.7834, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 361, Train loss: 0.6058, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7884, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 362, Train loss: 0.6276, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.7784, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 363, Train loss: 0.6060, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.8117, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 364, Train loss: 0.6261, Train Acc: 0.6354, Train f1-score: 0.8338, Val loss: 0.7923, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 365, Train loss: 0.6081, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7798, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 366, Train loss: 0.6141, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7943, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 367, Train loss: 0.6111, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.7887, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 368, Train loss: 0.6214, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8048, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 369, Train loss: 0.6109, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.7896, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 370, Train loss: 0.6190, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7943, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 371, Train loss: 0.6057, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7846, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 372, Train loss: 0.6180, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8147, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 373, Train loss: 0.6218, Train Acc: 0.6354, Train f1-score: 0.8338, Val loss: 0.8099, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 374, Train loss: 0.6118, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.8132, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 375, Train loss: 0.6260, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.7944, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 376, Train loss: 0.6086, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.8253, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 377, Train loss: 0.6148, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.8004, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 378, Train loss: 0.6056, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7825, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 379, Train loss: 0.6145, Train Acc: 0.6354, Train f1-score: 0.8338, Val loss: 0.8155, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 380, Train loss: 0.6253, Train Acc: 0.6354, Train f1-score: 0.8338, Val loss: 0.8110, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 381, Train loss: 0.6061, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.8097, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 382, Train loss: 0.6139, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.8077, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 383, Train loss: 0.6041, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.7878, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 384, Train loss: 0.6138, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8134, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 385, Train loss: 0.6054, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.8281, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 386, Train loss: 0.6243, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.8256, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 387, Train loss: 0.6210, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.8145, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 388, Train loss: 0.6027, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.8245, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 389, Train loss: 0.6183, Train Acc: 0.6479, Train f1-score: 0.8338, Val loss: 0.8162, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 390, Train loss: 0.6026, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.8294, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 391, Train loss: 0.6313, Train Acc: 0.6354, Train f1-score: 0.8338, Val loss: 0.7932, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 392, Train loss: 0.6026, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.7860, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 393, Train loss: 0.6045, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.8018, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 394, Train loss: 0.6079, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.8116, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 395, Train loss: 0.6035, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.8037, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 396, Train loss: 0.6072, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8239, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 397, Train loss: 0.6193, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.8127, Val Acc: 0.5000, Val f1-score: 0.4667,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 398, Train loss: 0.5982, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.8197, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 399, Train loss: 0.6100, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.8157, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 400, Train loss: 0.6150, Train Acc: 0.6479, Train f1-score: 0.8338, Val loss: 0.8216, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  45  46  47  48  50  51  65  66  67  68\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [44 49 52 53 54 55 56 57 58 59 60 61 62 63 64 69]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.0764, Train Acc: 0.4750, Train f1-score: 0.4762, Val loss: 0.7048, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 0.6907, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6956, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.6897, Train Acc: 0.5361, Train f1-score: 0.4735, Val loss: 0.6946, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.6884, Train Acc: 0.5486, Train f1-score: 0.4735, Val loss: 0.6945, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.6887, Train Acc: 0.5771, Train f1-score: 0.6667, Val loss: 0.6971, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.6887, Train Acc: 0.5771, Train f1-score: 0.6667, Val loss: 0.6944, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.6884, Train Acc: 0.5708, Train f1-score: 0.6667, Val loss: 0.6946, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.6884, Train Acc: 0.5771, Train f1-score: 0.6667, Val loss: 0.6949, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.6882, Train Acc: 0.5597, Train f1-score: 0.5916, Val loss: 0.6946, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6885, Train Acc: 0.5646, Train f1-score: 0.6667, Val loss: 0.6946, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6884, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6942, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6881, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6938, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6879, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6934, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6876, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6927, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6873, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6923, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6870, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.6919, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6868, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.6916, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6866, Train Acc: 0.5833, Train f1-score: 0.6580, Val loss: 0.6912, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6863, Train Acc: 0.5708, Train f1-score: 0.6580, Val loss: 0.6908, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6860, Train Acc: 0.5708, Train f1-score: 0.6580, Val loss: 0.6899, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6855, Train Acc: 0.5708, Train f1-score: 0.6580, Val loss: 0.6894, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6850, Train Acc: 0.5708, Train f1-score: 0.6580, Val loss: 0.6885, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6845, Train Acc: 0.5708, Train f1-score: 0.6580, Val loss: 0.6877, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6837, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6865, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6832, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6864, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6828, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6862, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6822, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6860, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 027, Train loss: 0.6817, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6858, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 028, Train loss: 0.6813, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6857, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 029, Train loss: 0.6811, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6852, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 030, Train loss: 0.6808, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6850, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 031, Train loss: 0.6804, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6847, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 032, Train loss: 0.6802, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6841, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 033, Train loss: 0.6798, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6836, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 034, Train loss: 0.6795, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6836, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 035, Train loss: 0.6792, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6834, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6789, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6832, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6785, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6829, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 038, Train loss: 0.6781, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6825, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 039, Train loss: 0.6777, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6821, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 040, Train loss: 0.6774, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6815, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 041, Train loss: 0.6770, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6810, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 042, Train loss: 0.6766, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6806, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 043, Train loss: 0.6763, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6801, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 044, Train loss: 0.6758, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6797, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 045, Train loss: 0.6754, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6791, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 046, Train loss: 0.6749, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6787, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 047, Train loss: 0.6746, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6785, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 048, Train loss: 0.6741, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6782, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 049, Train loss: 0.6739, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6777, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 050, Train loss: 0.6735, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6775, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 051, Train loss: 0.6732, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6771, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 052, Train loss: 0.6728, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6769, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 053, Train loss: 0.6726, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6766, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 054, Train loss: 0.6721, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6763, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 055, Train loss: 0.6718, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6760, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 056, Train loss: 0.6714, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6757, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 057, Train loss: 0.6710, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6756, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 058, Train loss: 0.6708, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 059, Train loss: 0.6706, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6752, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 060, Train loss: 0.6702, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6748, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 061, Train loss: 0.6702, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6747, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 062, Train loss: 0.6696, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6745, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 063, Train loss: 0.6694, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6744, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 064, Train loss: 0.6692, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6742, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 065, Train loss: 0.6689, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6740, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 066, Train loss: 0.6686, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6737, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 067, Train loss: 0.6684, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6734, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 068, Train loss: 0.6681, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6732, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 069, Train loss: 0.6679, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6730, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 070, Train loss: 0.6677, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6733, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 071, Train loss: 0.6675, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6728, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 072, Train loss: 0.6672, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6726, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 073, Train loss: 0.6669, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6722, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 074, Train loss: 0.6667, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6716, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 075, Train loss: 0.6666, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6720, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 076, Train loss: 0.6665, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6720, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 077, Train loss: 0.6663, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6717, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 078, Train loss: 0.6659, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6710, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 079, Train loss: 0.6656, Train Acc: 0.5569, Train f1-score: 0.7231, Val loss: 0.6714, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 080, Train loss: 0.6655, Train Acc: 0.5569, Train f1-score: 0.7231, Val loss: 0.6711, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 081, Train loss: 0.6653, Train Acc: 0.5569, Train f1-score: 0.7231, Val loss: 0.6708, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 082, Train loss: 0.6650, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6702, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 083, Train loss: 0.6647, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6702, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 084, Train loss: 0.6646, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6705, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 085, Train loss: 0.6645, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6702, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 086, Train loss: 0.6643, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6699, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 087, Train loss: 0.6639, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6700, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 088, Train loss: 0.6638, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6700, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 089, Train loss: 0.6637, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6699, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 090, Train loss: 0.6634, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6695, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 091, Train loss: 0.6634, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6692, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 092, Train loss: 0.6631, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6695, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 093, Train loss: 0.6628, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6693, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 094, Train loss: 0.6625, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6691, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 095, Train loss: 0.6625, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6692, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 096, Train loss: 0.6622, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6697, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 097, Train loss: 0.6623, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6695, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 098, Train loss: 0.6620, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6695, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 099, Train loss: 0.6619, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6694, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 100, Train loss: 0.6618, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6691, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 101, Train loss: 0.6617, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6695, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 102, Train loss: 0.6615, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6690, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 103, Train loss: 0.6614, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 104, Train loss: 0.6617, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 105, Train loss: 0.6612, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 106, Train loss: 0.6609, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 107, Train loss: 0.6609, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6690, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 108, Train loss: 0.6608, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6686, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 109, Train loss: 0.6605, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 110, Train loss: 0.6605, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6686, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 111, Train loss: 0.6603, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6693, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 112, Train loss: 0.6603, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6686, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 113, Train loss: 0.6599, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6686, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 114, Train loss: 0.6600, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6692, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 115, Train loss: 0.6599, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6684, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 116, Train loss: 0.6597, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6687, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 117, Train loss: 0.6597, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6692, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 118, Train loss: 0.6597, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6684, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 119, Train loss: 0.6594, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6689, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 120, Train loss: 0.6596, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6685, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 121, Train loss: 0.6592, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6688, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 122, Train loss: 0.6591, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6682, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 123, Train loss: 0.6590, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 124, Train loss: 0.6591, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 125, Train loss: 0.6590, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6682, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 126, Train loss: 0.6589, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6685, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 127, Train loss: 0.6586, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6681, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 128, Train loss: 0.6585, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 129, Train loss: 0.6584, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 130, Train loss: 0.6583, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6683, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 131, Train loss: 0.6582, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6682, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 132, Train loss: 0.6581, Train Acc: 0.5632, Train f1-score: 0.7231, Val loss: 0.6681, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 133, Train loss: 0.6582, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6686, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 134, Train loss: 0.6579, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6684, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 135, Train loss: 0.6579, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 136, Train loss: 0.6577, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6684, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 137, Train loss: 0.6577, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 138, Train loss: 0.6576, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6690, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 139, Train loss: 0.6575, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 140, Train loss: 0.6572, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6690, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 141, Train loss: 0.6572, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 142, Train loss: 0.6569, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 143, Train loss: 0.6569, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 144, Train loss: 0.6567, Train Acc: 0.5694, Train f1-score: 0.7231, Val loss: 0.6684, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 145, Train loss: 0.6565, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6688, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 146, Train loss: 0.6564, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6687, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 147, Train loss: 0.6564, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6691, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 148, Train loss: 0.6561, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6695, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 149, Train loss: 0.6563, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 150, Train loss: 0.6557, Train Acc: 0.5917, Train f1-score: 0.8338, Val loss: 0.6696, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 151, Train loss: 0.6562, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6691, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 152, Train loss: 0.6557, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6693, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 153, Train loss: 0.6556, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6691, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 154, Train loss: 0.6553, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6696, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 155, Train loss: 0.6552, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6697, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 156, Train loss: 0.6552, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6701, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 157, Train loss: 0.6552, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6697, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 158, Train loss: 0.6547, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6702, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 159, Train loss: 0.6547, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6699, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 160, Train loss: 0.6543, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6698, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 161, Train loss: 0.6542, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6699, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 162, Train loss: 0.6542, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6704, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 163, Train loss: 0.6540, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6706, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 164, Train loss: 0.6539, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6709, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 165, Train loss: 0.6538, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6706, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 166, Train loss: 0.6535, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6709, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 167, Train loss: 0.6532, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6711, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 168, Train loss: 0.6533, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6716, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 169, Train loss: 0.6532, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6717, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 170, Train loss: 0.6529, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6716, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 171, Train loss: 0.6527, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6713, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 172, Train loss: 0.6525, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6721, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 173, Train loss: 0.6526, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6719, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 174, Train loss: 0.6524, Train Acc: 0.5979, Train f1-score: 0.8338, Val loss: 0.6718, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 175, Train loss: 0.6523, Train Acc: 0.6042, Train f1-score: 0.8338, Val loss: 0.6725, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 176, Train loss: 0.6523, Train Acc: 0.6042, Train f1-score: 0.8338, Val loss: 0.6721, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 177, Train loss: 0.6520, Train Acc: 0.6042, Train f1-score: 0.8338, Val loss: 0.6723, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 178, Train loss: 0.6519, Train Acc: 0.6042, Train f1-score: 0.8338, Val loss: 0.6724, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 179, Train loss: 0.6520, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6732, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 180, Train loss: 0.6519, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6725, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 181, Train loss: 0.6514, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6730, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 182, Train loss: 0.6509, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6732, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 183, Train loss: 0.6512, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6731, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 184, Train loss: 0.6508, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6738, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 185, Train loss: 0.6506, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6728, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 186, Train loss: 0.6505, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6734, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 187, Train loss: 0.6501, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6736, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 188, Train loss: 0.6499, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6735, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 189, Train loss: 0.6501, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6742, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 190, Train loss: 0.6497, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6738, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 191, Train loss: 0.6494, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6743, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 192, Train loss: 0.6495, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6752, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 193, Train loss: 0.6491, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6736, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 194, Train loss: 0.6495, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6748, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 195, Train loss: 0.6497, Train Acc: 0.6104, Train f1-score: 0.8338, Val loss: 0.6744, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 196, Train loss: 0.6490, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6736, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 197, Train loss: 0.6486, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6732, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 198, Train loss: 0.6483, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6732, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 199, Train loss: 0.6480, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6740, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 200, Train loss: 0.6481, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6744, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 201, Train loss: 0.6474, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6737, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 202, Train loss: 0.6474, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6749, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 203, Train loss: 0.6471, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6729, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 204, Train loss: 0.6471, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6743, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 205, Train loss: 0.6466, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6745, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 206, Train loss: 0.6463, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6723, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 207, Train loss: 0.6463, Train Acc: 0.6229, Train f1-score: 0.8338, Val loss: 0.6744, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 208, Train loss: 0.6457, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6733, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 209, Train loss: 0.6455, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6740, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 210, Train loss: 0.6455, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6735, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 211, Train loss: 0.6454, Train Acc: 0.6229, Train f1-score: 0.8338, Val loss: 0.6745, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 212, Train loss: 0.6451, Train Acc: 0.6229, Train f1-score: 0.8338, Val loss: 0.6747, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 213, Train loss: 0.6448, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 214, Train loss: 0.6444, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6749, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 215, Train loss: 0.6442, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6753, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 216, Train loss: 0.6441, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6765, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 217, Train loss: 0.6441, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6767, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 218, Train loss: 0.6435, Train Acc: 0.6229, Train f1-score: 0.8338, Val loss: 0.6769, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 219, Train loss: 0.6436, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6775, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 220, Train loss: 0.6432, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 221, Train loss: 0.6433, Train Acc: 0.6278, Train f1-score: 0.8889, Val loss: 0.6773, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 222, Train loss: 0.6425, Train Acc: 0.6340, Train f1-score: 0.8889, Val loss: 0.6777, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 223, Train loss: 0.6426, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6770, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 224, Train loss: 0.6420, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6780, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 225, Train loss: 0.6419, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6780, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 226, Train loss: 0.6420, Train Acc: 0.6278, Train f1-score: 0.8889, Val loss: 0.6800, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 227, Train loss: 0.6416, Train Acc: 0.6278, Train f1-score: 0.8889, Val loss: 0.6776, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 228, Train loss: 0.6412, Train Acc: 0.6340, Train f1-score: 0.8889, Val loss: 0.6767, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 229, Train loss: 0.6407, Train Acc: 0.6278, Train f1-score: 0.8889, Val loss: 0.6806, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 230, Train loss: 0.6409, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6773, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 231, Train loss: 0.6407, Train Acc: 0.6215, Train f1-score: 0.8889, Val loss: 0.6799, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 232, Train loss: 0.6403, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6796, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 233, Train loss: 0.6404, Train Acc: 0.6104, Train f1-score: 0.8317, Val loss: 0.6777, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 234, Train loss: 0.6403, Train Acc: 0.6215, Train f1-score: 0.8889, Val loss: 0.6815, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 235, Train loss: 0.6395, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6806, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 236, Train loss: 0.6395, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6791, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 237, Train loss: 0.6390, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6808, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 238, Train loss: 0.6394, Train Acc: 0.6104, Train f1-score: 0.8317, Val loss: 0.6797, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 239, Train loss: 0.6384, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6783, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 240, Train loss: 0.6384, Train Acc: 0.6292, Train f1-score: 0.8317, Val loss: 0.6831, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 241, Train loss: 0.6388, Train Acc: 0.6104, Train f1-score: 0.8317, Val loss: 0.6802, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 242, Train loss: 0.6379, Train Acc: 0.6292, Train f1-score: 0.8317, Val loss: 0.6802, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 243, Train loss: 0.6376, Train Acc: 0.6403, Train f1-score: 0.8889, Val loss: 0.6842, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 244, Train loss: 0.6378, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6817, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 245, Train loss: 0.6374, Train Acc: 0.6278, Train f1-score: 0.8889, Val loss: 0.6809, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 246, Train loss: 0.6371, Train Acc: 0.6403, Train f1-score: 0.8889, Val loss: 0.6861, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 247, Train loss: 0.6379, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6828, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 248, Train loss: 0.6363, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.6872, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 249, Train loss: 0.6369, Train Acc: 0.6167, Train f1-score: 0.8317, Val loss: 0.6811, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 250, Train loss: 0.6355, Train Acc: 0.6354, Train f1-score: 0.8317, Val loss: 0.6826, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 251, Train loss: 0.6362, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6814, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 252, Train loss: 0.6354, Train Acc: 0.6292, Train f1-score: 0.8317, Val loss: 0.6863, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 253, Train loss: 0.6361, Train Acc: 0.6229, Train f1-score: 0.8317, Val loss: 0.6814, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 254, Train loss: 0.6342, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6830, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 255, Train loss: 0.6346, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6831, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 256, Train loss: 0.6333, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.6828, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 257, Train loss: 0.6336, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6854, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 258, Train loss: 0.6348, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6856, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 259, Train loss: 0.6334, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6845, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 260, Train loss: 0.6334, Train Acc: 0.6229, Train f1-score: 0.8317, Val loss: 0.6892, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 261, Train loss: 0.6350, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6857, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 262, Train loss: 0.6324, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.6858, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 263, Train loss: 0.6331, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6853, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 264, Train loss: 0.6311, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6862, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 265, Train loss: 0.6311, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6873, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 266, Train loss: 0.6318, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.6847, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 267, Train loss: 0.6320, Train Acc: 0.6118, Train f1-score: 0.7720, Val loss: 0.6854, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 268, Train loss: 0.6285, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.6802, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 269, Train loss: 0.6267, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6761, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 270, Train loss: 0.6258, Train Acc: 0.5944, Train f1-score: 0.7083, Val loss: 0.6783, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 271, Train loss: 0.6250, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6800, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 272, Train loss: 0.6305, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6784, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 273, Train loss: 0.6245, Train Acc: 0.5882, Train f1-score: 0.7083, Val loss: 0.6804, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 274, Train loss: 0.6250, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6788, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 275, Train loss: 0.6247, Train Acc: 0.5944, Train f1-score: 0.7083, Val loss: 0.6773, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 276, Train loss: 0.6220, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6809, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 277, Train loss: 0.6242, Train Acc: 0.5944, Train f1-score: 0.7083, Val loss: 0.6705, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 278, Train loss: 0.6215, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6733, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 279, Train loss: 0.6212, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6837, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 280, Train loss: 0.6233, Train Acc: 0.5944, Train f1-score: 0.7083, Val loss: 0.6804, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 281, Train loss: 0.6220, Train Acc: 0.5944, Train f1-score: 0.7083, Val loss: 0.6819, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 282, Train loss: 0.6210, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6811, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 283, Train loss: 0.6219, Train Acc: 0.5819, Train f1-score: 0.7083, Val loss: 0.6794, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 284, Train loss: 0.6206, Train Acc: 0.5833, Train f1-score: 0.6051, Val loss: 0.6733, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 285, Train loss: 0.6174, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6734, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 286, Train loss: 0.6193, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6738, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 287, Train loss: 0.6195, Train Acc: 0.6194, Train f1-score: 0.6869, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 288, Train loss: 0.6199, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6771, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 289, Train loss: 0.6203, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6754, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 290, Train loss: 0.6184, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6775, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 291, Train loss: 0.6188, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6773, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 292, Train loss: 0.6174, Train Acc: 0.6007, Train f1-score: 0.6869, Val loss: 0.6766, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 293, Train loss: 0.6170, Train Acc: 0.6069, Train f1-score: 0.6869, Val loss: 0.6770, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 294, Train loss: 0.6165, Train Acc: 0.6132, Train f1-score: 0.6869, Val loss: 0.6758, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 295, Train loss: 0.6143, Train Acc: 0.6132, Train f1-score: 0.6869, Val loss: 0.6790, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 296, Train loss: 0.6158, Train Acc: 0.6021, Train f1-score: 0.6051, Val loss: 0.6776, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 297, Train loss: 0.6141, Train Acc: 0.6132, Train f1-score: 0.6869, Val loss: 0.6797, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 298, Train loss: 0.6160, Train Acc: 0.6021, Train f1-score: 0.6051, Val loss: 0.6805, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 299, Train loss: 0.6133, Train Acc: 0.6083, Train f1-score: 0.6051, Val loss: 0.6806, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 300, Train loss: 0.6124, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.6821, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 301, Train loss: 0.6120, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.6814, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 302, Train loss: 0.6098, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6833, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 303, Train loss: 0.6125, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 304, Train loss: 0.6084, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6852, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 305, Train loss: 0.6126, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6846, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 306, Train loss: 0.6086, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6847, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 307, Train loss: 0.6075, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6875, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 308, Train loss: 0.6110, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6870, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 309, Train loss: 0.6088, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6873, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 310, Train loss: 0.6082, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6877, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 311, Train loss: 0.6063, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6912, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 312, Train loss: 0.6100, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.6901, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 313, Train loss: 0.6059, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6919, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 314, Train loss: 0.6093, Train Acc: 0.6146, Train f1-score: 0.6051, Val loss: 0.6886, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 315, Train loss: 0.6028, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6942, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 316, Train loss: 0.6070, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6905, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 317, Train loss: 0.6030, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6919, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 318, Train loss: 0.6057, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.6917, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 319, Train loss: 0.6018, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6935, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 320, Train loss: 0.6023, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6935, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 321, Train loss: 0.6025, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6942, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 322, Train loss: 0.5966, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6960, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 323, Train loss: 0.5977, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6959, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 324, Train loss: 0.5923, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6977, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 325, Train loss: 0.5960, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.6982, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 326, Train loss: 0.5880, Train Acc: 0.6521, Train f1-score: 0.6051, Val loss: 0.7001, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 327, Train loss: 0.5895, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.6996, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 328, Train loss: 0.5806, Train Acc: 0.6819, Train f1-score: 0.6869, Val loss: 0.7044, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 329, Train loss: 0.5959, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.7029, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 330, Train loss: 0.5794, Train Acc: 0.7167, Train f1-score: 0.8250, Val loss: 0.7108, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 331, Train loss: 0.6178, Train Acc: 0.6208, Train f1-score: 0.6051, Val loss: 0.7025, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 332, Train loss: 0.5903, Train Acc: 0.6333, Train f1-score: 0.6051, Val loss: 0.7060, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 333, Train loss: 0.5886, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.7069, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 334, Train loss: 0.5817, Train Acc: 0.6396, Train f1-score: 0.6051, Val loss: 0.7082, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 335, Train loss: 0.5853, Train Acc: 0.6271, Train f1-score: 0.6051, Val loss: 0.7095, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 336, Train loss: 0.5825, Train Acc: 0.6458, Train f1-score: 0.6051, Val loss: 0.7102, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 337, Train loss: 0.5744, Train Acc: 0.7153, Train f1-score: 0.8860, Val loss: 0.7188, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 338, Train loss: 0.6063, Train Acc: 0.6521, Train f1-score: 0.6051, Val loss: 0.7118, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 339, Train loss: 0.5726, Train Acc: 0.7278, Train f1-score: 0.8860, Val loss: 0.7180, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 340, Train loss: 0.6058, Train Acc: 0.6521, Train f1-score: 0.6051, Val loss: 0.7098, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 341, Train loss: 0.5808, Train Acc: 0.6458, Train f1-score: 0.6051, Val loss: 0.7149, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 342, Train loss: 0.5841, Train Acc: 0.6396, Train f1-score: 0.6051, Val loss: 0.7161, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 343, Train loss: 0.5783, Train Acc: 0.6507, Train f1-score: 0.6869, Val loss: 0.7185, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 344, Train loss: 0.5791, Train Acc: 0.6444, Train f1-score: 0.6869, Val loss: 0.7196, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 345, Train loss: 0.5703, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7230, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 346, Train loss: 0.5753, Train Acc: 0.6396, Train f1-score: 0.6051, Val loss: 0.7351, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 347, Train loss: 0.5791, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.8686, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 348, Train loss: 0.6789, Train Acc: 0.6278, Train f1-score: 0.8860, Val loss: 0.7270, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 349, Train loss: 0.5897, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.7403, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 350, Train loss: 0.5935, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.7456, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 351, Train loss: 0.5952, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.7397, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 352, Train loss: 0.5921, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.7335, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 353, Train loss: 0.5877, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.7330, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 354, Train loss: 0.5843, Train Acc: 0.7028, Train f1-score: 0.8860, Val loss: 0.7325, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 355, Train loss: 0.5777, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7320, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 356, Train loss: 0.5755, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7323, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 357, Train loss: 0.5717, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.7362, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 358, Train loss: 0.5768, Train Acc: 0.6806, Train f1-score: 0.7593, Val loss: 0.7341, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 359, Train loss: 0.5658, Train Acc: 0.6667, Train f1-score: 0.8250, Val loss: 0.7363, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 360, Train loss: 0.5741, Train Acc: 0.6444, Train f1-score: 0.6869, Val loss: 0.7381, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 361, Train loss: 0.5627, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.8355, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 362, Train loss: 0.6567, Train Acc: 0.6465, Train f1-score: 0.8860, Val loss: 0.7443, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 363, Train loss: 0.5895, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.7453, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 364, Train loss: 0.5846, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.7453, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 365, Train loss: 0.5818, Train Acc: 0.6965, Train f1-score: 0.8860, Val loss: 0.7523, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 366, Train loss: 0.5847, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.7523, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 367, Train loss: 0.5827, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.7518, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 368, Train loss: 0.5829, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.7497, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 369, Train loss: 0.5789, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.7506, Val Acc: 0.4375, Val f1-score: 0.4353,\n",
      "Epoch: 370, Train loss: 0.5714, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7481, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 371, Train loss: 0.5663, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7492, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 372, Train loss: 0.5626, Train Acc: 0.6965, Train f1-score: 0.8860, Val loss: 0.7506, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 373, Train loss: 0.5613, Train Acc: 0.6854, Train f1-score: 0.8250, Val loss: 0.7524, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 374, Train loss: 0.5515, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.8137, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 375, Train loss: 0.6344, Train Acc: 0.6715, Train f1-score: 0.8860, Val loss: 0.7572, Val Acc: 0.4375, Val f1-score: 0.4353,\n",
      "Epoch: 376, Train loss: 0.5718, Train Acc: 0.6965, Train f1-score: 0.8860, Val loss: 0.7607, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 377, Train loss: 0.5730, Train Acc: 0.7028, Train f1-score: 0.8860, Val loss: 0.7544, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 378, Train loss: 0.5629, Train Acc: 0.7153, Train f1-score: 0.8860, Val loss: 0.7580, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 379, Train loss: 0.5667, Train Acc: 0.7153, Train f1-score: 0.8860, Val loss: 0.7551, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 380, Train loss: 0.5544, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7582, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 381, Train loss: 0.5665, Train Acc: 0.6819, Train f1-score: 0.6869, Val loss: 0.7611, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 382, Train loss: 0.5547, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.8508, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 383, Train loss: 0.6358, Train Acc: 0.6653, Train f1-score: 0.8860, Val loss: 0.7542, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 384, Train loss: 0.5624, Train Acc: 0.7090, Train f1-score: 0.8860, Val loss: 0.7674, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 385, Train loss: 0.5714, Train Acc: 0.7028, Train f1-score: 0.8860, Val loss: 0.7645, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 386, Train loss: 0.5625, Train Acc: 0.7153, Train f1-score: 0.8860, Val loss: 0.7616, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 387, Train loss: 0.5523, Train Acc: 0.7215, Train f1-score: 0.8860, Val loss: 0.7670, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 388, Train loss: 0.5641, Train Acc: 0.6819, Train f1-score: 0.6869, Val loss: 0.7666, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 389, Train loss: 0.5486, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.8632, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 390, Train loss: 0.6291, Train Acc: 0.6639, Train f1-score: 0.9439, Val loss: 0.7688, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 391, Train loss: 0.5635, Train Acc: 0.6965, Train f1-score: 0.8860, Val loss: 0.7692, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 392, Train loss: 0.5591, Train Acc: 0.7042, Train f1-score: 0.8250, Val loss: 0.7684, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 393, Train loss: 0.5490, Train Acc: 0.7167, Train f1-score: 0.8317, Val loss: 0.7750, Val Acc: 0.5625, Val f1-score: 0.5608,\n",
      "Epoch: 394, Train loss: 0.5749, Train Acc: 0.6632, Train f1-score: 0.6869, Val loss: 0.7703, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 395, Train loss: 0.5456, Train Acc: 0.7306, Train f1-score: 0.7778, Val loss: 0.7933, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 396, Train loss: 0.5903, Train Acc: 0.6528, Train f1-score: 0.8860, Val loss: 0.7708, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 397, Train loss: 0.5545, Train Acc: 0.7278, Train f1-score: 0.8860, Val loss: 0.7758, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 398, Train loss: 0.5446, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.7866, Val Acc: 0.5000, Val f1-score: 0.4921,\n",
      "Epoch: 399, Train loss: 0.5790, Train Acc: 0.6556, Train f1-score: 0.7593, Val loss: 0.7796, Val Acc: 0.5625, Val f1-score: 0.5608,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Train loss: 0.5407, Train Acc: 0.7417, Train f1-score: 0.8318, Val loss: 0.8403, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "GIN accuracy: 0.3684210479259491\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  69  78  79  81  82  84  85\n",
      "  87  88  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [65 66 67 68 70 71 72 73 74 75 76 77 80 83 86 89]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 0.7317, Train Acc: 0.5049, Train f1-score: 0.5440, Val loss: 0.6939, Val Acc: 0.4375, Val f1-score: 0.3043,\n",
      "Epoch: 001, Train loss: 0.6942, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6964, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.6927, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6971, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.6925, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6971, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.6923, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6971, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.6922, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6969, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.6919, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6969, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.6916, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6968, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.6914, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6975, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6911, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6973, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6911, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6974, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6908, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6984, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6906, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6984, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6904, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6904, Train Acc: 0.5646, Train f1-score: 0.6051, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6900, Train Acc: 0.5583, Train f1-score: 0.6051, Val loss: 0.6989, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6898, Train Acc: 0.5535, Train f1-score: 0.5916, Val loss: 0.6994, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6897, Train Acc: 0.5597, Train f1-score: 0.6074, Val loss: 0.7008, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6897, Train Acc: 0.5535, Train f1-score: 0.6074, Val loss: 0.7006, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6896, Train Acc: 0.5597, Train f1-score: 0.6123, Val loss: 0.7020, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6899, Train Acc: 0.5486, Train f1-score: 0.5556, Val loss: 0.7019, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6893, Train Acc: 0.5597, Train f1-score: 0.6123, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6883, Train Acc: 0.5722, Train f1-score: 0.6074, Val loss: 0.6996, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6888, Train Acc: 0.5361, Train f1-score: 0.5556, Val loss: 0.7030, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6885, Train Acc: 0.5708, Train f1-score: 0.6667, Val loss: 0.6997, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6875, Train Acc: 0.5424, Train f1-score: 0.5556, Val loss: 0.7035, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6888, Train Acc: 0.5361, Train f1-score: 0.5444, Val loss: 0.7008, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 027, Train loss: 0.6883, Train Acc: 0.5361, Train f1-score: 0.5444, Val loss: 0.7011, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 028, Train loss: 0.6869, Train Acc: 0.5535, Train f1-score: 0.6075, Val loss: 0.7066, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 029, Train loss: 0.6867, Train Acc: 0.5486, Train f1-score: 0.5556, Val loss: 0.7025, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 030, Train loss: 0.6868, Train Acc: 0.5424, Train f1-score: 0.5444, Val loss: 0.7045, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 031, Train loss: 0.6866, Train Acc: 0.5549, Train f1-score: 0.5444, Val loss: 0.7019, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 032, Train loss: 0.6861, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.7093, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 033, Train loss: 0.6874, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7079, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 034, Train loss: 0.6855, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.7085, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 035, Train loss: 0.6854, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.7093, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6853, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.7116, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6854, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.7110, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 038, Train loss: 0.6848, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.7124, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 039, Train loss: 0.6848, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.7131, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 040, Train loss: 0.6838, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.7150, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 041, Train loss: 0.6841, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7160, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 042, Train loss: 0.6836, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.7137, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 043, Train loss: 0.6835, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7149, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 044, Train loss: 0.6829, Train Acc: 0.5549, Train f1-score: 0.4815, Val loss: 0.7139, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 045, Train loss: 0.6827, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7168, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 046, Train loss: 0.6823, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.7160, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 047, Train loss: 0.6832, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7165, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 048, Train loss: 0.6819, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.7172, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 049, Train loss: 0.6819, Train Acc: 0.5674, Train f1-score: 0.4815, Val loss: 0.7211, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 050, Train loss: 0.6806, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.7229, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 051, Train loss: 0.6824, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7247, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 052, Train loss: 0.6806, Train Acc: 0.5847, Train f1-score: 0.5656, Val loss: 0.7234, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 053, Train loss: 0.6807, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7271, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 054, Train loss: 0.6818, Train Acc: 0.5674, Train f1-score: 0.4815, Val loss: 0.7236, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 055, Train loss: 0.6804, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7261, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 056, Train loss: 0.6779, Train Acc: 0.6007, Train f1-score: 0.7090, Val loss: 0.7285, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 057, Train loss: 0.6799, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7406, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 058, Train loss: 0.6805, Train Acc: 0.5958, Train f1-score: 0.6407, Val loss: 0.7265, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 059, Train loss: 0.6809, Train Acc: 0.5674, Train f1-score: 0.4815, Val loss: 0.7362, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 060, Train loss: 0.6773, Train Acc: 0.5944, Train f1-score: 0.7090, Val loss: 0.7277, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 061, Train loss: 0.6753, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.7479, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 062, Train loss: 0.6779, Train Acc: 0.5882, Train f1-score: 0.7090, Val loss: 0.7421, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 063, Train loss: 0.6760, Train Acc: 0.5597, Train f1-score: 0.5656, Val loss: 0.7552, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 064, Train loss: 0.6754, Train Acc: 0.5882, Train f1-score: 0.7090, Val loss: 0.7431, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 065, Train loss: 0.6749, Train Acc: 0.5549, Train f1-score: 0.4815, Val loss: 0.7455, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 066, Train loss: 0.6746, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.7349, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 067, Train loss: 0.6719, Train Acc: 0.5597, Train f1-score: 0.5656, Val loss: 0.7503, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 068, Train loss: 0.6748, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.7512, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 069, Train loss: 0.6747, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.7377, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 070, Train loss: 0.6688, Train Acc: 0.5847, Train f1-score: 0.5656, Val loss: 0.7741, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 071, Train loss: 0.6754, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.7624, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 072, Train loss: 0.6737, Train Acc: 0.5736, Train f1-score: 0.4815, Val loss: 0.7785, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 073, Train loss: 0.6724, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.7586, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 074, Train loss: 0.6678, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.7590, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 075, Train loss: 0.6694, Train Acc: 0.5861, Train f1-score: 0.4815, Val loss: 0.7725, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 076, Train loss: 0.6698, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.7713, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 077, Train loss: 0.6665, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.7754, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 078, Train loss: 0.6654, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.7847, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 079, Train loss: 0.6671, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.7775, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 080, Train loss: 0.6665, Train Acc: 0.5736, Train f1-score: 0.4815, Val loss: 0.7888, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 081, Train loss: 0.6689, Train Acc: 0.5861, Train f1-score: 0.4815, Val loss: 0.7757, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 082, Train loss: 0.6660, Train Acc: 0.6035, Train f1-score: 0.5656, Val loss: 0.7760, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 083, Train loss: 0.6651, Train Acc: 0.5924, Train f1-score: 0.4815, Val loss: 0.7856, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 084, Train loss: 0.6655, Train Acc: 0.5861, Train f1-score: 0.4815, Val loss: 0.7752, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 085, Train loss: 0.6623, Train Acc: 0.5799, Train f1-score: 0.4815, Val loss: 0.8035, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 086, Train loss: 0.6660, Train Acc: 0.5910, Train f1-score: 0.5656, Val loss: 0.7922, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 087, Train loss: 0.6595, Train Acc: 0.5986, Train f1-score: 0.4815, Val loss: 0.8078, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 088, Train loss: 0.6613, Train Acc: 0.5924, Train f1-score: 0.4815, Val loss: 0.8086, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 089, Train loss: 0.6589, Train Acc: 0.6146, Train f1-score: 0.6407, Val loss: 0.7975, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 090, Train loss: 0.6619, Train Acc: 0.5861, Train f1-score: 0.4815, Val loss: 0.8207, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 091, Train loss: 0.6600, Train Acc: 0.6257, Train f1-score: 0.7090, Val loss: 0.7914, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 092, Train loss: 0.6552, Train Acc: 0.5986, Train f1-score: 0.4815, Val loss: 0.8260, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 093, Train loss: 0.6547, Train Acc: 0.6431, Train f1-score: 0.7722, Val loss: 0.8107, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 094, Train loss: 0.6477, Train Acc: 0.6618, Train f1-score: 0.7722, Val loss: 0.8100, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 095, Train loss: 0.6448, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8018, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 096, Train loss: 0.6398, Train Acc: 0.6653, Train f1-score: 0.8889, Val loss: 0.8314, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 097, Train loss: 0.6464, Train Acc: 0.6465, Train f1-score: 0.8889, Val loss: 0.8241, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 098, Train loss: 0.6411, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.8037, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 099, Train loss: 0.6292, Train Acc: 0.6681, Train f1-score: 0.7720, Val loss: 0.8418, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 100, Train loss: 0.6510, Train Acc: 0.6181, Train f1-score: 0.7593, Val loss: 0.8065, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 101, Train loss: 0.6285, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8803, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 102, Train loss: 0.6472, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.8206, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 103, Train loss: 0.6299, Train Acc: 0.6778, Train f1-score: 0.8889, Val loss: 0.8649, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 104, Train loss: 0.6400, Train Acc: 0.6431, Train f1-score: 0.7720, Val loss: 0.8258, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 105, Train loss: 0.6283, Train Acc: 0.6493, Train f1-score: 0.7720, Val loss: 0.8415, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 106, Train loss: 0.6249, Train Acc: 0.6382, Train f1-score: 0.7083, Val loss: 0.8594, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 107, Train loss: 0.6396, Train Acc: 0.6083, Train f1-score: 0.6051, Val loss: 0.8264, Val Acc: 0.3125, Val f1-score: 0.2381,\n",
      "Epoch: 108, Train loss: 0.6663, Train Acc: 0.5674, Train f1-score: 0.4815, Val loss: 0.8515, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 109, Train loss: 0.6420, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8866, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 110, Train loss: 0.6505, Train Acc: 0.6618, Train f1-score: 0.7722, Val loss: 0.8663, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 111, Train loss: 0.6424, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8675, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 112, Train loss: 0.6417, Train Acc: 0.6368, Train f1-score: 0.7722, Val loss: 0.8496, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 113, Train loss: 0.6360, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8672, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 114, Train loss: 0.6362, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8734, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 115, Train loss: 0.6363, Train Acc: 0.6431, Train f1-score: 0.7722, Val loss: 0.8653, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 116, Train loss: 0.6393, Train Acc: 0.6396, Train f1-score: 0.6407, Val loss: 0.8729, Val Acc: 0.5000, Val f1-score: 0.4182,\n",
      "Epoch: 117, Train loss: 0.6357, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8588, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 118, Train loss: 0.6347, Train Acc: 0.6618, Train f1-score: 0.7722, Val loss: 0.8727, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 119, Train loss: 0.6335, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8728, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 120, Train loss: 0.6315, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8731, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 121, Train loss: 0.6308, Train Acc: 0.6618, Train f1-score: 0.7722, Val loss: 0.8781, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 122, Train loss: 0.6338, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.8670, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 123, Train loss: 0.6299, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8771, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 124, Train loss: 0.6273, Train Acc: 0.6431, Train f1-score: 0.7722, Val loss: 0.8806, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 125, Train loss: 0.6264, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8888, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 126, Train loss: 0.6233, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.8651, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 127, Train loss: 0.6341, Train Acc: 0.6271, Train f1-score: 0.6407, Val loss: 0.8768, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 128, Train loss: 0.6260, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8728, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 129, Train loss: 0.6255, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.8900, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 130, Train loss: 0.6250, Train Acc: 0.6604, Train f1-score: 0.8318, Val loss: 0.8833, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 131, Train loss: 0.6210, Train Acc: 0.6604, Train f1-score: 0.8318, Val loss: 0.9005, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 132, Train loss: 0.6225, Train Acc: 0.6653, Train f1-score: 0.8889, Val loss: 0.8929, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 133, Train loss: 0.6240, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.8878, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 134, Train loss: 0.6260, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.8858, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 135, Train loss: 0.6227, Train Acc: 0.6729, Train f1-score: 0.8318, Val loss: 0.8846, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 136, Train loss: 0.6238, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.8899, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 137, Train loss: 0.6238, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.8868, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 138, Train loss: 0.6263, Train Acc: 0.6257, Train f1-score: 0.7090, Val loss: 0.8895, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 139, Train loss: 0.6214, Train Acc: 0.6778, Train f1-score: 0.8889, Val loss: 0.8904, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 140, Train loss: 0.6207, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.8951, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 141, Train loss: 0.6215, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.8968, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 142, Train loss: 0.6211, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.9084, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 143, Train loss: 0.6152, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.8923, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 144, Train loss: 0.6240, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.8960, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 145, Train loss: 0.6189, Train Acc: 0.6826, Train f1-score: 0.9446, Val loss: 0.9054, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 146, Train loss: 0.6189, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.9111, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 147, Train loss: 0.6198, Train Acc: 0.6826, Train f1-score: 0.9446, Val loss: 0.9127, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 148, Train loss: 0.6185, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.9084, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 149, Train loss: 0.6203, Train Acc: 0.6715, Train f1-score: 0.8889, Val loss: 0.8954, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 150, Train loss: 0.6161, Train Acc: 0.6729, Train f1-score: 0.8318, Val loss: 0.9072, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 151, Train loss: 0.6188, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.9088, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 152, Train loss: 0.6120, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9178, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 153, Train loss: 0.6198, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.9174, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 154, Train loss: 0.6120, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9233, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 155, Train loss: 0.6161, Train Acc: 0.6556, Train f1-score: 0.7722, Val loss: 0.9198, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 156, Train loss: 0.6207, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.9112, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 157, Train loss: 0.6157, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9161, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 158, Train loss: 0.6133, Train Acc: 0.6826, Train f1-score: 0.9446, Val loss: 0.9310, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 159, Train loss: 0.6141, Train Acc: 0.6618, Train f1-score: 0.7722, Val loss: 0.9173, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 160, Train loss: 0.6165, Train Acc: 0.6715, Train f1-score: 0.8889, Val loss: 0.9198, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 161, Train loss: 0.6086, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9341, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 162, Train loss: 0.6108, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9441, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 163, Train loss: 0.6034, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9504, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 164, Train loss: 0.6093, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9553, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 165, Train loss: 0.6118, Train Acc: 0.6826, Train f1-score: 0.9446, Val loss: 0.9459, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 166, Train loss: 0.6188, Train Acc: 0.6604, Train f1-score: 0.8318, Val loss: 0.9229, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 167, Train loss: 0.6076, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9323, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 168, Train loss: 0.6077, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9378, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 169, Train loss: 0.6079, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9397, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 170, Train loss: 0.6067, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9431, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 171, Train loss: 0.6061, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9531, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 172, Train loss: 0.6014, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9415, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 173, Train loss: 0.6062, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9626, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 174, Train loss: 0.6044, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9456, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 175, Train loss: 0.6006, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9604, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 176, Train loss: 0.6161, Train Acc: 0.6778, Train f1-score: 0.8889, Val loss: 0.9422, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 177, Train loss: 0.6058, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9513, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 178, Train loss: 0.6004, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9536, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 179, Train loss: 0.6073, Train Acc: 0.6778, Train f1-score: 0.8889, Val loss: 0.9543, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 180, Train loss: 0.6017, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9639, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 181, Train loss: 0.6086, Train Acc: 0.6715, Train f1-score: 0.8889, Val loss: 0.9573, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 182, Train loss: 0.5979, Train Acc: 0.6778, Train f1-score: 0.8889, Val loss: 0.9559, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 183, Train loss: 0.6015, Train Acc: 0.6826, Train f1-score: 0.9446, Val loss: 0.9623, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 184, Train loss: 0.6057, Train Acc: 0.6826, Train f1-score: 0.9446, Val loss: 0.9560, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 185, Train loss: 0.6073, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9463, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 186, Train loss: 0.6063, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9602, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 187, Train loss: 0.6029, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9711, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 188, Train loss: 0.5967, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9598, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 189, Train loss: 0.6005, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9678, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 190, Train loss: 0.6049, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9690, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 191, Train loss: 0.6041, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9697, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 192, Train loss: 0.5972, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9632, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 193, Train loss: 0.6036, Train Acc: 0.6715, Train f1-score: 0.8889, Val loss: 0.9718, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 194, Train loss: 0.6039, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9642, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 195, Train loss: 0.5996, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9694, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 196, Train loss: 0.6097, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9606, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 197, Train loss: 0.6096, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9500, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 198, Train loss: 0.6078, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9606, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 199, Train loss: 0.6048, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9584, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 200, Train loss: 0.6029, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9680, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 201, Train loss: 0.5986, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9873, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 202, Train loss: 0.5982, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9858, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 203, Train loss: 0.6009, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9844, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 204, Train loss: 0.6029, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9838, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 205, Train loss: 0.5979, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9807, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 206, Train loss: 0.5969, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9664, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 207, Train loss: 0.5988, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9747, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 208, Train loss: 0.6081, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 0.9674, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 209, Train loss: 0.6056, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9683, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 210, Train loss: 0.6034, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9703, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 211, Train loss: 0.5979, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9819, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 212, Train loss: 0.5943, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9907, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 213, Train loss: 0.5967, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9824, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 214, Train loss: 0.5986, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9851, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 215, Train loss: 0.6006, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9748, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 216, Train loss: 0.6016, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9823, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 217, Train loss: 0.5978, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9727, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 218, Train loss: 0.5990, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9756, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 219, Train loss: 0.6019, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 0.9702, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 220, Train loss: 0.5961, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9693, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 221, Train loss: 0.5976, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9891, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 222, Train loss: 0.5927, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 0.9658, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 223, Train loss: 0.6005, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9935, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 224, Train loss: 0.5941, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9894, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 225, Train loss: 0.6015, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9738, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 226, Train loss: 0.6049, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9881, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 227, Train loss: 0.5962, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 1.0059, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 228, Train loss: 0.5944, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 1.0028, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 229, Train loss: 0.6053, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9816, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 230, Train loss: 0.5995, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9932, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 231, Train loss: 0.6032, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9719, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 232, Train loss: 0.6020, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9880, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 233, Train loss: 0.5997, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.9936, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 234, Train loss: 0.5948, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9790, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 235, Train loss: 0.5989, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9841, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 236, Train loss: 0.6031, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.9828, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 237, Train loss: 0.6038, Train Acc: 0.6778, Train f1-score: 0.8889, Val loss: 1.0000, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 238, Train loss: 0.5924, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9968, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 239, Train loss: 0.5933, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9701, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 240, Train loss: 0.6024, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9793, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 241, Train loss: 0.6059, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 0.9876, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 242, Train loss: 0.5987, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 0.9985, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 243, Train loss: 0.5961, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9963, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 244, Train loss: 0.6037, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0050, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 245, Train loss: 0.5966, Train Acc: 0.6889, Train f1-score: 0.9446, Val loss: 0.9974, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 246, Train loss: 0.5981, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0017, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 247, Train loss: 0.6022, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9780, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 248, Train loss: 0.6055, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9789, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 249, Train loss: 0.6031, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0019, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 250, Train loss: 0.5945, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0157, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 251, Train loss: 0.5898, Train Acc: 0.7201, Train f1-score: 0.9446, Val loss: 0.9994, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 252, Train loss: 0.6060, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9746, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 253, Train loss: 0.5941, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9835, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 254, Train loss: 0.5970, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0026, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 255, Train loss: 0.5942, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0208, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 256, Train loss: 0.5886, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 0.9967, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 257, Train loss: 0.6046, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.9782, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 258, Train loss: 0.6016, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.9733, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 259, Train loss: 0.6031, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.9900, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 260, Train loss: 0.6061, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 1.0044, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 261, Train loss: 0.5962, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 1.0176, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 262, Train loss: 0.5859, Train Acc: 0.6979, Train f1-score: 0.8317, Val loss: 0.9867, Val Acc: 0.3125, Val f1-score: 0.3098,\n",
      "Epoch: 263, Train loss: 0.6069, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.9931, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 264, Train loss: 0.6042, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 1.0067, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 265, Train loss: 0.5951, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 1.0124, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 266, Train loss: 0.5962, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9859, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 267, Train loss: 0.6057, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9728, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 268, Train loss: 0.5940, Train Acc: 0.7201, Train f1-score: 0.9446, Val loss: 1.0251, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 269, Train loss: 0.5855, Train Acc: 0.6917, Train f1-score: 0.8317, Val loss: 0.9871, Val Acc: 0.3125, Val f1-score: 0.3098,\n",
      "Epoch: 270, Train loss: 0.6061, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9842, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 271, Train loss: 0.6047, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.9730, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 272, Train loss: 0.5967, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 1.0091, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 273, Train loss: 0.6007, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0132, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 274, Train loss: 0.5941, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 1.0023, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 275, Train loss: 0.5953, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0191, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 276, Train loss: 0.6070, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 1.0143, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 277, Train loss: 0.5880, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9846, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 278, Train loss: 0.5944, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0049, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 279, Train loss: 0.6087, Train Acc: 0.6604, Train f1-score: 0.8318, Val loss: 0.9999, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 280, Train loss: 0.5956, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 1.0247, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 281, Train loss: 0.5948, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 1.0224, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 282, Train loss: 0.5923, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9935, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 283, Train loss: 0.5956, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0145, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 284, Train loss: 0.6058, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 1.0013, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 285, Train loss: 0.5974, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0289, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 286, Train loss: 0.5898, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9897, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 287, Train loss: 0.6033, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.9918, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 288, Train loss: 0.5949, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9898, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 289, Train loss: 0.6025, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 1.0000, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 290, Train loss: 0.5967, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 1.0375, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 291, Train loss: 0.5876, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 0.9891, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 292, Train loss: 0.6021, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.9986, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 293, Train loss: 0.5961, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9901, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 294, Train loss: 0.5982, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0144, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 295, Train loss: 0.6020, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 1.0128, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 296, Train loss: 0.5869, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 1.0062, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 297, Train loss: 0.5956, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0225, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 298, Train loss: 0.6060, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.9820, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 299, Train loss: 0.5915, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9838, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 300, Train loss: 0.5988, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 1.0197, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 301, Train loss: 0.5998, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0015, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 302, Train loss: 0.6034, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.9804, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 303, Train loss: 0.5945, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 1.0150, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 304, Train loss: 0.6030, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 0.9845, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 305, Train loss: 0.5885, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9904, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 306, Train loss: 0.6008, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0014, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 307, Train loss: 0.6042, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 1.0009, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 308, Train loss: 0.5943, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0019, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 309, Train loss: 0.6051, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.9759, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 310, Train loss: 0.5926, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0038, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 311, Train loss: 0.6041, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.9786, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 312, Train loss: 0.5902, Train Acc: 0.6951, Train f1-score: 0.9446, Val loss: 0.9817, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 313, Train loss: 0.5931, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9931, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 314, Train loss: 0.6005, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.9827, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 315, Train loss: 0.5929, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9978, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 316, Train loss: 0.6037, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 1.0063, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 317, Train loss: 0.5856, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.9843, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 318, Train loss: 0.6026, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 0.9827, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 319, Train loss: 0.5884, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9956, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 320, Train loss: 0.5975, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0209, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 321, Train loss: 0.6037, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.9964, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 322, Train loss: 0.6030, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.9846, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 323, Train loss: 0.5891, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9926, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 324, Train loss: 0.6031, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 1.0182, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 325, Train loss: 0.5867, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9886, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 326, Train loss: 0.5931, Train Acc: 0.7014, Train f1-score: 0.9446, Val loss: 0.9980, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 327, Train loss: 0.6053, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.9836, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 328, Train loss: 0.5891, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9928, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 329, Train loss: 0.5966, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0283, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 330, Train loss: 0.5885, Train Acc: 0.7139, Train f1-score: 0.9446, Val loss: 0.9893, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 331, Train loss: 0.5939, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 1.0234, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 332, Train loss: 0.6015, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 1.0087, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 333, Train loss: 0.5867, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.9899, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 334, Train loss: 0.6001, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.9876, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 335, Train loss: 0.5891, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 1.0067, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 336, Train loss: 0.6077, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.9779, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 337, Train loss: 0.5880, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0043, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 338, Train loss: 0.6048, Train Acc: 0.6604, Train f1-score: 0.8338, Val loss: 0.9764, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 339, Train loss: 0.5939, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.9881, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 340, Train loss: 0.5924, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0031, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 341, Train loss: 0.5993, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.9914, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 342, Train loss: 0.5880, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.9931, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 343, Train loss: 0.6001, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.9892, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 344, Train loss: 0.5864, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 1.0035, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 345, Train loss: 0.6009, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.9912, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 346, Train loss: 0.5875, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 0.9968, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 347, Train loss: 0.5902, Train Acc: 0.6840, Train f1-score: 0.8889, Val loss: 1.0148, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 348, Train loss: 0.6016, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.9967, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 349, Train loss: 0.5885, Train Acc: 0.7076, Train f1-score: 0.9446, Val loss: 1.0235, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 350, Train loss: 0.6019, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 1.0101, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 351, Train loss: 0.5938, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0156, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 352, Train loss: 0.5988, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.9900, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 353, Train loss: 0.5902, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0257, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 354, Train loss: 0.5986, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 1.0098, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 355, Train loss: 0.5938, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0120, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 356, Train loss: 0.5970, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.9930, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 357, Train loss: 0.5854, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0205, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 358, Train loss: 0.6006, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.9879, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 359, Train loss: 0.5859, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 1.0019, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 360, Train loss: 0.5932, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0084, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 361, Train loss: 0.5940, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0160, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 362, Train loss: 0.5986, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.9924, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 363, Train loss: 0.5874, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 1.0051, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 364, Train loss: 0.5995, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.9957, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 365, Train loss: 0.5851, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0303, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 366, Train loss: 0.6024, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.9949, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 367, Train loss: 0.5857, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 1.0224, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 368, Train loss: 0.5966, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 1.0119, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 369, Train loss: 0.5853, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 1.0192, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 370, Train loss: 0.5960, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.9971, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 371, Train loss: 0.5849, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 1.0236, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 372, Train loss: 0.5966, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.9989, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 373, Train loss: 0.5852, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 1.0082, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 374, Train loss: 0.5967, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0177, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 375, Train loss: 0.5922, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0259, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 376, Train loss: 0.5836, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 1.0207, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 377, Train loss: 0.5924, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 1.0453, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 378, Train loss: 0.5935, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0169, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 379, Train loss: 0.5967, Train Acc: 0.7042, Train f1-score: 0.8338, Val loss: 1.0109, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 380, Train loss: 0.5902, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0353, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 381, Train loss: 0.5955, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 1.0280, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 382, Train loss: 0.5912, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0400, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 383, Train loss: 0.5841, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 1.0441, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 384, Train loss: 0.5807, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 1.0130, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 385, Train loss: 0.5850, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0399, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 386, Train loss: 0.5891, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0445, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 387, Train loss: 0.5863, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0358, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 388, Train loss: 0.5905, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0376, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 389, Train loss: 0.5895, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0341, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 390, Train loss: 0.5907, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 1.0383, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 391, Train loss: 0.5970, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 1.0398, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 392, Train loss: 0.5837, Train Acc: 0.6917, Train f1-score: 0.8317, Val loss: 1.0464, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 393, Train loss: 0.5938, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 1.0488, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 394, Train loss: 0.5835, Train Acc: 0.6917, Train f1-score: 0.8317, Val loss: 1.0506, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 395, Train loss: 0.5965, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0313, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 396, Train loss: 0.5876, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 1.0497, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 397, Train loss: 0.5826, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 1.0386, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 398, Train loss: 0.5796, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 1.0236, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "Epoch: 399, Train loss: 0.5854, Train Acc: 0.6903, Train f1-score: 0.8889, Val loss: 1.0629, Val Acc: 0.5000, Val f1-score: 0.4667,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Train loss: 0.5919, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 1.0378, Val Acc: 0.4375, Val f1-score: 0.4170,\n",
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  80  83  86  89  92  93  95  97  98 101 102 104\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [ 78  79  81  82  84  85  87  88  90  91  94  96  99 100 103 105]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 0.9830, Train Acc: 0.5028, Train f1-score: 0.3582, Val loss: 0.7172, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 001, Train loss: 0.7144, Train Acc: 0.4639, Train f1-score: 0.2735, Val loss: 0.7075, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 002, Train loss: 0.7044, Train Acc: 0.4701, Train f1-score: 0.2735, Val loss: 0.7063, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 003, Train loss: 0.7034, Train Acc: 0.4701, Train f1-score: 0.2735, Val loss: 0.7052, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 004, Train loss: 0.7026, Train Acc: 0.4764, Train f1-score: 0.2735, Val loss: 0.7043, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 005, Train loss: 0.7018, Train Acc: 0.4764, Train f1-score: 0.2735, Val loss: 0.7035, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 006, Train loss: 0.7012, Train Acc: 0.4764, Train f1-score: 0.2735, Val loss: 0.7028, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 007, Train loss: 0.7007, Train Acc: 0.4764, Train f1-score: 0.2735, Val loss: 0.7022, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 008, Train loss: 0.7001, Train Acc: 0.4764, Train f1-score: 0.2735, Val loss: 0.7017, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 009, Train loss: 0.6996, Train Acc: 0.4764, Train f1-score: 0.2735, Val loss: 0.7014, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 010, Train loss: 0.6992, Train Acc: 0.4826, Train f1-score: 0.2735, Val loss: 0.7009, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 011, Train loss: 0.6986, Train Acc: 0.4826, Train f1-score: 0.2735, Val loss: 0.7005, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 012, Train loss: 0.6982, Train Acc: 0.4889, Train f1-score: 0.2735, Val loss: 0.7000, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 013, Train loss: 0.6977, Train Acc: 0.5000, Train f1-score: 0.3855, Val loss: 0.6995, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 014, Train loss: 0.6972, Train Acc: 0.5062, Train f1-score: 0.3855, Val loss: 0.6992, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 015, Train loss: 0.6969, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.6988, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 016, Train loss: 0.6965, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.6984, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 017, Train loss: 0.6961, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.6981, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 018, Train loss: 0.6958, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.6978, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 019, Train loss: 0.6953, Train Acc: 0.5111, Train f1-score: 0.5209, Val loss: 0.6974, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 020, Train loss: 0.6950, Train Acc: 0.5111, Train f1-score: 0.5209, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 021, Train loss: 0.6946, Train Acc: 0.5347, Train f1-score: 0.5926, Val loss: 0.6970, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 022, Train loss: 0.6944, Train Acc: 0.5236, Train f1-score: 0.5209, Val loss: 0.6968, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 023, Train loss: 0.6940, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6965, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 024, Train loss: 0.6937, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 025, Train loss: 0.6934, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6960, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 026, Train loss: 0.6931, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6958, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 027, Train loss: 0.6925, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6969, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 028, Train loss: 0.6924, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6968, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 029, Train loss: 0.6921, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6967, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 030, Train loss: 0.6919, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6966, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 031, Train loss: 0.6915, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.6962, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 032, Train loss: 0.6911, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.6960, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 033, Train loss: 0.6909, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.6975, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 034, Train loss: 0.6907, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6939, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 035, Train loss: 0.6901, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.6968, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 036, Train loss: 0.6899, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6949, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 037, Train loss: 0.6894, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6948, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 038, Train loss: 0.6890, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6946, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 039, Train loss: 0.6887, Train Acc: 0.5472, Train f1-score: 0.5926, Val loss: 0.6943, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 040, Train loss: 0.6883, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.6959, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 041, Train loss: 0.6882, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6939, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 042, Train loss: 0.6877, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6938, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 043, Train loss: 0.6875, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6936, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 044, Train loss: 0.6869, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6933, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 045, Train loss: 0.6867, Train Acc: 0.5410, Train f1-score: 0.5926, Val loss: 0.6956, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 046, Train loss: 0.6867, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.6937, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 047, Train loss: 0.6863, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.6932, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 048, Train loss: 0.6858, Train Acc: 0.5535, Train f1-score: 0.5926, Val loss: 0.6953, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 049, Train loss: 0.6857, Train Acc: 0.5722, Train f1-score: 0.5926, Val loss: 0.6927, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 050, Train loss: 0.6852, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.6929, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 051, Train loss: 0.6849, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.6947, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 052, Train loss: 0.6847, Train Acc: 0.5722, Train f1-score: 0.5926, Val loss: 0.6928, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 053, Train loss: 0.6842, Train Acc: 0.5722, Train f1-score: 0.5926, Val loss: 0.6950, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 054, Train loss: 0.6841, Train Acc: 0.5674, Train f1-score: 0.5209, Val loss: 0.6926, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 055, Train loss: 0.6837, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6923, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 056, Train loss: 0.6835, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6946, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 057, Train loss: 0.6835, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6920, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 058, Train loss: 0.6827, Train Acc: 0.5674, Train f1-score: 0.5209, Val loss: 0.6942, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 059, Train loss: 0.6828, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6918, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 060, Train loss: 0.6824, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6940, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 061, Train loss: 0.6822, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6929, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 062, Train loss: 0.6818, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6927, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 063, Train loss: 0.6818, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6956, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 064, Train loss: 0.6813, Train Acc: 0.5486, Train f1-score: 0.5209, Val loss: 0.6929, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 065, Train loss: 0.6811, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6967, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 066, Train loss: 0.6810, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6929, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 067, Train loss: 0.6812, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6964, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 068, Train loss: 0.6806, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6942, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 069, Train loss: 0.6802, Train Acc: 0.5549, Train f1-score: 0.5209, Val loss: 0.6909, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 070, Train loss: 0.6798, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.7002, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 071, Train loss: 0.6804, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6950, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 072, Train loss: 0.6799, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6952, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 073, Train loss: 0.6794, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6920, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 074, Train loss: 0.6786, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6930, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 075, Train loss: 0.6776, Train Acc: 0.5910, Train f1-score: 0.5656, Val loss: 0.6969, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 076, Train loss: 0.6788, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6929, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 077, Train loss: 0.6788, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6945, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 078, Train loss: 0.6781, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6909, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 079, Train loss: 0.6781, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.7005, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 080, Train loss: 0.6785, Train Acc: 0.5674, Train f1-score: 0.5209, Val loss: 0.6919, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 081, Train loss: 0.6778, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.6991, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 082, Train loss: 0.6774, Train Acc: 0.5736, Train f1-score: 0.5209, Val loss: 0.6921, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 083, Train loss: 0.6771, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.6956, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 084, Train loss: 0.6779, Train Acc: 0.5847, Train f1-score: 0.5656, Val loss: 0.6926, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 085, Train loss: 0.6753, Train Acc: 0.5799, Train f1-score: 0.5209, Val loss: 0.6961, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 086, Train loss: 0.6763, Train Acc: 0.5611, Train f1-score: 0.5209, Val loss: 0.6914, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 087, Train loss: 0.6760, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6903, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 088, Train loss: 0.6745, Train Acc: 0.5847, Train f1-score: 0.5656, Val loss: 0.6996, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 089, Train loss: 0.6758, Train Acc: 0.5674, Train f1-score: 0.5209, Val loss: 0.6913, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 090, Train loss: 0.6753, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6939, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 091, Train loss: 0.6751, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6979, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 092, Train loss: 0.6751, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6895, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 093, Train loss: 0.6741, Train Acc: 0.5847, Train f1-score: 0.5656, Val loss: 0.6948, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 094, Train loss: 0.6743, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6922, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 095, Train loss: 0.6745, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6979, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 096, Train loss: 0.6750, Train Acc: 0.5722, Train f1-score: 0.5926, Val loss: 0.6895, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 097, Train loss: 0.6735, Train Acc: 0.5486, Train f1-score: 0.5209, Val loss: 0.6969, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 098, Train loss: 0.6744, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.6915, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 099, Train loss: 0.6726, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.6970, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 100, Train loss: 0.6741, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.6892, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 101, Train loss: 0.6720, Train Acc: 0.5660, Train f1-score: 0.5926, Val loss: 0.6973, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 102, Train loss: 0.6737, Train Acc: 0.5722, Train f1-score: 0.5926, Val loss: 0.6899, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 103, Train loss: 0.6715, Train Acc: 0.5972, Train f1-score: 0.5926, Val loss: 0.6941, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 104, Train loss: 0.6726, Train Acc: 0.5771, Train f1-score: 0.6583, Val loss: 0.6937, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 105, Train loss: 0.6711, Train Acc: 0.5958, Train f1-score: 0.6583, Val loss: 0.6942, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 106, Train loss: 0.6715, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6898, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 107, Train loss: 0.6695, Train Acc: 0.5972, Train f1-score: 0.5926, Val loss: 0.6993, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 108, Train loss: 0.6716, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6856, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 109, Train loss: 0.6709, Train Acc: 0.5597, Train f1-score: 0.5926, Val loss: 0.6986, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 110, Train loss: 0.6717, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6854, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 111, Train loss: 0.6704, Train Acc: 0.5771, Train f1-score: 0.6583, Val loss: 0.6881, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 112, Train loss: 0.6682, Train Acc: 0.6208, Train f1-score: 0.6583, Val loss: 0.6964, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 113, Train loss: 0.6722, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6873, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 114, Train loss: 0.6691, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6888, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 115, Train loss: 0.6688, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.6958, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 116, Train loss: 0.6701, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6877, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 117, Train loss: 0.6700, Train Acc: 0.6035, Train f1-score: 0.5656, Val loss: 0.7048, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 118, Train loss: 0.6686, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.6851, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 119, Train loss: 0.6680, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6849, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 120, Train loss: 0.6686, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6887, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 121, Train loss: 0.6691, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6829, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 122, Train loss: 0.6654, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.6874, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 123, Train loss: 0.6673, Train Acc: 0.6132, Train f1-score: 0.7196, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 124, Train loss: 0.6676, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6872, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 125, Train loss: 0.6674, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.6859, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 126, Train loss: 0.6665, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.6862, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 127, Train loss: 0.6670, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6836, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 128, Train loss: 0.6644, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6856, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 129, Train loss: 0.6669, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6894, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 130, Train loss: 0.6691, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6832, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 131, Train loss: 0.6653, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6797, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 132, Train loss: 0.6670, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6883, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 133, Train loss: 0.6638, Train Acc: 0.6132, Train f1-score: 0.7196, Val loss: 0.6861, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 134, Train loss: 0.6655, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6859, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 135, Train loss: 0.6658, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6974, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 136, Train loss: 0.6686, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6838, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 137, Train loss: 0.6642, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6834, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 138, Train loss: 0.6641, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6840, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 139, Train loss: 0.6644, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6922, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 140, Train loss: 0.6644, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6857, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 141, Train loss: 0.6621, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.6832, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 142, Train loss: 0.6626, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6822, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 143, Train loss: 0.6628, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6826, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 144, Train loss: 0.6629, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6829, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 145, Train loss: 0.6621, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6829, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 146, Train loss: 0.6626, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 147, Train loss: 0.6617, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6828, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 148, Train loss: 0.6623, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6817, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 149, Train loss: 0.6609, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6824, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 150, Train loss: 0.6624, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6855, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 151, Train loss: 0.6602, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.6946, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 152, Train loss: 0.6647, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.6837, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 153, Train loss: 0.6640, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6886, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 154, Train loss: 0.6593, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.6794, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 155, Train loss: 0.6618, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6880, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 156, Train loss: 0.6623, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6920, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 157, Train loss: 0.6647, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6774, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 158, Train loss: 0.6625, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6903, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 159, Train loss: 0.6647, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6833, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 160, Train loss: 0.6618, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6891, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 161, Train loss: 0.6631, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6830, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 162, Train loss: 0.6600, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6841, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 163, Train loss: 0.6609, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6829, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 164, Train loss: 0.6618, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6881, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 165, Train loss: 0.6623, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6823, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 166, Train loss: 0.6612, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6853, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 167, Train loss: 0.6666, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.6979, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 168, Train loss: 0.6612, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6781, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 169, Train loss: 0.6598, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6819, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 170, Train loss: 0.6591, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6768, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 171, Train loss: 0.6582, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6798, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 172, Train loss: 0.6582, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6780, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 173, Train loss: 0.6592, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6824, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 174, Train loss: 0.6589, Train Acc: 0.5681, Train f1-score: 0.7778, Val loss: 0.6800, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 175, Train loss: 0.6594, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6885, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 176, Train loss: 0.6582, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6812, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 177, Train loss: 0.6587, Train Acc: 0.5632, Train f1-score: 0.7196, Val loss: 0.6817, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 178, Train loss: 0.6595, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6780, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 179, Train loss: 0.6599, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6819, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 180, Train loss: 0.6584, Train Acc: 0.5681, Train f1-score: 0.7778, Val loss: 0.6777, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 181, Train loss: 0.6594, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6828, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 182, Train loss: 0.6564, Train Acc: 0.5681, Train f1-score: 0.7778, Val loss: 0.6826, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 183, Train loss: 0.6581, Train Acc: 0.5694, Train f1-score: 0.7196, Val loss: 0.6834, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 184, Train loss: 0.6586, Train Acc: 0.5618, Train f1-score: 0.7778, Val loss: 0.6768, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 185, Train loss: 0.6576, Train Acc: 0.5743, Train f1-score: 0.7778, Val loss: 0.6800, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 186, Train loss: 0.6569, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.6881, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 187, Train loss: 0.6577, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6824, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 188, Train loss: 0.6550, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6816, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 189, Train loss: 0.6567, Train Acc: 0.5681, Train f1-score: 0.7778, Val loss: 0.6785, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 190, Train loss: 0.6576, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6836, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 191, Train loss: 0.6579, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6796, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 192, Train loss: 0.6571, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6828, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 193, Train loss: 0.6586, Train Acc: 0.5757, Train f1-score: 0.7196, Val loss: 0.6854, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 194, Train loss: 0.6559, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.6808, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 195, Train loss: 0.6564, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6886, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 196, Train loss: 0.6545, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.6758, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 197, Train loss: 0.6571, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6935, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 198, Train loss: 0.6550, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.6758, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 199, Train loss: 0.6566, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6832, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 200, Train loss: 0.6554, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6867, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 201, Train loss: 0.6545, Train Acc: 0.6292, Train f1-score: 0.8338, Val loss: 0.6767, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 202, Train loss: 0.6551, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6896, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 203, Train loss: 0.6537, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6764, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 204, Train loss: 0.6538, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6893, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 205, Train loss: 0.6529, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6772, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 206, Train loss: 0.6564, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6805, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 207, Train loss: 0.6549, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6828, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 208, Train loss: 0.6533, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6851, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 209, Train loss: 0.6521, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6780, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 210, Train loss: 0.6513, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6995, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 211, Train loss: 0.6546, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6772, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 212, Train loss: 0.6529, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6781, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 213, Train loss: 0.6563, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.6836, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 214, Train loss: 0.6556, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6805, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 215, Train loss: 0.6542, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.6794, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 216, Train loss: 0.6545, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6800, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 217, Train loss: 0.6517, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6746, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 218, Train loss: 0.6510, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6792, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 219, Train loss: 0.6519, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6822, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 220, Train loss: 0.6524, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6889, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 221, Train loss: 0.6508, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6901, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 222, Train loss: 0.6499, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6889, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 223, Train loss: 0.6497, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6880, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 224, Train loss: 0.6511, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6807, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 225, Train loss: 0.6502, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.6899, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 226, Train loss: 0.6504, Train Acc: 0.6417, Train f1-score: 0.8338, Val loss: 0.6971, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 227, Train loss: 0.6532, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6769, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 228, Train loss: 0.6515, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6809, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 229, Train loss: 0.6505, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6930, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 230, Train loss: 0.6502, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.6871, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 231, Train loss: 0.6502, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.7003, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 232, Train loss: 0.6510, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.6772, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 233, Train loss: 0.6497, Train Acc: 0.6167, Train f1-score: 0.8338, Val loss: 0.6928, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 234, Train loss: 0.6494, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6795, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 235, Train loss: 0.6511, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.7024, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 236, Train loss: 0.6497, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.6753, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 237, Train loss: 0.6505, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.7005, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 238, Train loss: 0.6497, Train Acc: 0.6181, Train f1-score: 0.7778, Val loss: 0.6778, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 239, Train loss: 0.6500, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.7031, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 240, Train loss: 0.6480, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6778, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 241, Train loss: 0.6494, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6996, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 242, Train loss: 0.6482, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6742, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 243, Train loss: 0.6498, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6978, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 244, Train loss: 0.6477, Train Acc: 0.6354, Train f1-score: 0.8338, Val loss: 0.6964, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 245, Train loss: 0.6466, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6930, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 246, Train loss: 0.6472, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6922, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 247, Train loss: 0.6528, Train Acc: 0.6257, Train f1-score: 0.7090, Val loss: 0.7149, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 248, Train loss: 0.6504, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6737, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 249, Train loss: 0.6473, Train Acc: 0.6056, Train f1-score: 0.7778, Val loss: 0.6923, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 250, Train loss: 0.6467, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6884, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 251, Train loss: 0.6494, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.6918, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 252, Train loss: 0.6466, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6878, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 253, Train loss: 0.6508, Train Acc: 0.6306, Train f1-score: 0.7722, Val loss: 0.7076, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 254, Train loss: 0.6469, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6712, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 255, Train loss: 0.6458, Train Acc: 0.6229, Train f1-score: 0.8338, Val loss: 0.6978, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 256, Train loss: 0.6445, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6849, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 257, Train loss: 0.6455, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7006, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 258, Train loss: 0.6442, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6932, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 259, Train loss: 0.6429, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6884, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 260, Train loss: 0.6448, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7034, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 261, Train loss: 0.6446, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6801, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 262, Train loss: 0.6440, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6995, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 263, Train loss: 0.6442, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6864, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 264, Train loss: 0.6434, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7030, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 265, Train loss: 0.6446, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6761, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 266, Train loss: 0.6451, Train Acc: 0.6118, Train f1-score: 0.7778, Val loss: 0.7004, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 267, Train loss: 0.6424, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6788, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 268, Train loss: 0.6430, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7074, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 269, Train loss: 0.6456, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7057, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 270, Train loss: 0.6442, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6845, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 271, Train loss: 0.6429, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.7037, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 272, Train loss: 0.6414, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6809, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 273, Train loss: 0.6415, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6961, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 274, Train loss: 0.6422, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6919, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 275, Train loss: 0.6402, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6789, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 276, Train loss: 0.6402, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6999, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 277, Train loss: 0.6400, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 278, Train loss: 0.6394, Train Acc: 0.6542, Train f1-score: 0.8338, Val loss: 0.7152, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 279, Train loss: 0.6402, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.6980, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 280, Train loss: 0.6397, Train Acc: 0.6667, Train f1-score: 0.8338, Val loss: 0.6968, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 281, Train loss: 0.6422, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.7087, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 282, Train loss: 0.6400, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6804, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 283, Train loss: 0.6430, Train Acc: 0.6368, Train f1-score: 0.7722, Val loss: 0.7136, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 284, Train loss: 0.6411, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6896, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 285, Train loss: 0.6395, Train Acc: 0.6444, Train f1-score: 0.7196, Val loss: 0.6981, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 286, Train loss: 0.6382, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6894, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 287, Train loss: 0.6409, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6868, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 288, Train loss: 0.6369, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.6980, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 289, Train loss: 0.6378, Train Acc: 0.6243, Train f1-score: 0.7778, Val loss: 0.7001, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 290, Train loss: 0.6359, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6854, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 291, Train loss: 0.6361, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 0.6986, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 292, Train loss: 0.6364, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6994, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 293, Train loss: 0.6359, Train Acc: 0.6368, Train f1-score: 0.7778, Val loss: 0.6899, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 294, Train loss: 0.6343, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 0.7133, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 295, Train loss: 0.6377, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6949, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 296, Train loss: 0.6360, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6787, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 297, Train loss: 0.6364, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.7150, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 298, Train loss: 0.6373, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6827, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 299, Train loss: 0.6341, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7018, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 300, Train loss: 0.6344, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6827, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 301, Train loss: 0.6382, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.7242, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 302, Train loss: 0.6370, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6754, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 303, Train loss: 0.6508, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.7211, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 304, Train loss: 0.6377, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6859, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 305, Train loss: 0.6332, Train Acc: 0.6306, Train f1-score: 0.7778, Val loss: 0.6791, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 306, Train loss: 0.6294, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.6923, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 307, Train loss: 0.6303, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 0.6986, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 308, Train loss: 0.6303, Train Acc: 0.6556, Train f1-score: 0.7778, Val loss: 0.6822, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 309, Train loss: 0.6287, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.7088, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 310, Train loss: 0.6323, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 311, Train loss: 0.6298, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.7170, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 312, Train loss: 0.6343, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6646, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 313, Train loss: 0.6356, Train Acc: 0.6431, Train f1-score: 0.7722, Val loss: 0.7318, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 314, Train loss: 0.6328, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.6867, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 315, Train loss: 0.6285, Train Acc: 0.6431, Train f1-score: 0.7778, Val loss: 0.7059, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 316, Train loss: 0.6296, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6846, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 317, Train loss: 0.6262, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6819, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 318, Train loss: 0.6257, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.7130, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 319, Train loss: 0.6310, Train Acc: 0.6618, Train f1-score: 0.7720, Val loss: 0.6425, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 320, Train loss: 0.6501, Train Acc: 0.6465, Train f1-score: 0.8889, Val loss: 0.6682, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 321, Train loss: 0.6279, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.7339, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 322, Train loss: 0.6262, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6700, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 323, Train loss: 0.6275, Train Acc: 0.6806, Train f1-score: 0.7778, Val loss: 0.7128, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 324, Train loss: 0.6244, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6855, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 325, Train loss: 0.6191, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 0.6914, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 326, Train loss: 0.6201, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.6794, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 327, Train loss: 0.6181, Train Acc: 0.6792, Train f1-score: 0.8317, Val loss: 0.6727, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 328, Train loss: 0.6216, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.7445, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 329, Train loss: 0.6248, Train Acc: 0.6792, Train f1-score: 0.8317, Val loss: 0.6589, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 330, Train loss: 0.6237, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 0.7369, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 331, Train loss: 0.6237, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6505, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 332, Train loss: 0.6336, Train Acc: 0.6368, Train f1-score: 0.7722, Val loss: 0.7330, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 333, Train loss: 0.6218, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6566, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 334, Train loss: 0.6245, Train Acc: 0.6493, Train f1-score: 0.7778, Val loss: 0.7302, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 335, Train loss: 0.6186, Train Acc: 0.6681, Train f1-score: 0.7720, Val loss: 0.6569, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 336, Train loss: 0.6123, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.7210, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 337, Train loss: 0.6199, Train Acc: 0.6917, Train f1-score: 0.8317, Val loss: 0.6419, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 338, Train loss: 0.6338, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.7436, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 339, Train loss: 0.6232, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 0.6427, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 340, Train loss: 0.6249, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.7634, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 341, Train loss: 0.6249, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6395, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 342, Train loss: 0.6254, Train Acc: 0.6604, Train f1-score: 0.8318, Val loss: 0.7632, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 343, Train loss: 0.6178, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6316, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 344, Train loss: 0.6234, Train Acc: 0.6604, Train f1-score: 0.8318, Val loss: 0.7304, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 345, Train loss: 0.6170, Train Acc: 0.6458, Train f1-score: 0.6389, Val loss: 0.6076, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 346, Train loss: 0.6444, Train Acc: 0.6292, Train f1-score: 0.8318, Val loss: 0.7203, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 347, Train loss: 0.6116, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6245, Val Acc: 0.5625, Val f1-score: 0.5466,\n",
      "Epoch: 348, Train loss: 0.6239, Train Acc: 0.6729, Train f1-score: 0.8318, Val loss: 0.7201, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 349, Train loss: 0.6097, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 0.6320, Val Acc: 0.5000, Val f1-score: 0.4667,\n",
      "Epoch: 350, Train loss: 0.6131, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.7298, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 351, Train loss: 0.6110, Train Acc: 0.6743, Train f1-score: 0.7720, Val loss: 0.6224, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 352, Train loss: 0.6129, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.7275, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 353, Train loss: 0.6073, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 0.6304, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 354, Train loss: 0.6167, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.7540, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 355, Train loss: 0.6109, Train Acc: 0.6792, Train f1-score: 0.8317, Val loss: 0.6379, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 356, Train loss: 0.6186, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.6993, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 357, Train loss: 0.6048, Train Acc: 0.6681, Train f1-score: 0.7720, Val loss: 0.6140, Val Acc: 0.6250, Val f1-score: 0.6000,\n",
      "Epoch: 358, Train loss: 0.6180, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.7480, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 359, Train loss: 0.6118, Train Acc: 0.6569, Train f1-score: 0.7083, Val loss: 0.6027, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 360, Train loss: 0.6261, Train Acc: 0.6479, Train f1-score: 0.8318, Val loss: 0.7206, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 361, Train loss: 0.5996, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6320, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 362, Train loss: 0.6010, Train Acc: 0.7056, Train f1-score: 0.7778, Val loss: 0.7271, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 363, Train loss: 0.6038, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.6021, Val Acc: 0.6250, Val f1-score: 0.6190,\n",
      "Epoch: 364, Train loss: 0.6193, Train Acc: 0.6681, Train f1-score: 0.7722, Val loss: 0.7418, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 365, Train loss: 0.6071, Train Acc: 0.6632, Train f1-score: 0.7083, Val loss: 0.5938, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 366, Train loss: 0.6243, Train Acc: 0.6444, Train f1-score: 0.7196, Val loss: 0.7106, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 367, Train loss: 0.5980, Train Acc: 0.6618, Train f1-score: 0.7720, Val loss: 0.6207, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 368, Train loss: 0.6015, Train Acc: 0.7056, Train f1-score: 0.7778, Val loss: 0.7252, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 369, Train loss: 0.6046, Train Acc: 0.6521, Train f1-score: 0.6389, Val loss: 0.5791, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 370, Train loss: 0.6353, Train Acc: 0.6382, Train f1-score: 0.7196, Val loss: 0.7139, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 371, Train loss: 0.5965, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6155, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 372, Train loss: 0.6063, Train Acc: 0.6632, Train f1-score: 0.7196, Val loss: 0.7253, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 373, Train loss: 0.5954, Train Acc: 0.6493, Train f1-score: 0.7720, Val loss: 0.6068, Val Acc: 0.5625, Val f1-score: 0.5152,\n",
      "Epoch: 374, Train loss: 0.6020, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.7142, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 375, Train loss: 0.5964, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.5888, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 376, Train loss: 0.6218, Train Acc: 0.6743, Train f1-score: 0.7722, Val loss: 0.7260, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 377, Train loss: 0.5968, Train Acc: 0.6431, Train f1-score: 0.7720, Val loss: 0.5858, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 378, Train loss: 0.6121, Train Acc: 0.6632, Train f1-score: 0.7196, Val loss: 0.7086, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 379, Train loss: 0.5906, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6134, Val Acc: 0.6250, Val f1-score: 0.5636,\n",
      "Epoch: 380, Train loss: 0.5951, Train Acc: 0.7007, Train f1-score: 0.7196, Val loss: 0.7341, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 381, Train loss: 0.5968, Train Acc: 0.6507, Train f1-score: 0.7083, Val loss: 0.5892, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 382, Train loss: 0.6161, Train Acc: 0.6743, Train f1-score: 0.7722, Val loss: 0.7169, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 383, Train loss: 0.5916, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.5895, Val Acc: 0.6875, Val f1-score: 0.6761,\n",
      "Epoch: 384, Train loss: 0.5994, Train Acc: 0.6757, Train f1-score: 0.7196, Val loss: 0.7159, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 385, Train loss: 0.5903, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.5867, Val Acc: 0.6875, Val f1-score: 0.6863,\n",
      "Epoch: 386, Train loss: 0.6096, Train Acc: 0.6868, Train f1-score: 0.7722, Val loss: 0.7294, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 387, Train loss: 0.5898, Train Acc: 0.6618, Train f1-score: 0.7720, Val loss: 0.6026, Val Acc: 0.6875, Val f1-score: 0.6761,\n",
      "Epoch: 388, Train loss: 0.5950, Train Acc: 0.7056, Train f1-score: 0.7722, Val loss: 0.7294, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 389, Train loss: 0.5957, Train Acc: 0.6507, Train f1-score: 0.7083, Val loss: 0.5601, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 390, Train loss: 0.6242, Train Acc: 0.6667, Train f1-score: 0.8318, Val loss: 0.7161, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 391, Train loss: 0.5895, Train Acc: 0.6681, Train f1-score: 0.7720, Val loss: 0.5819, Val Acc: 0.7500, Val f1-score: 0.7460,\n",
      "Epoch: 392, Train loss: 0.5981, Train Acc: 0.6819, Train f1-score: 0.7196, Val loss: 0.7148, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 393, Train loss: 0.5887, Train Acc: 0.6507, Train f1-score: 0.7083, Val loss: 0.5617, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 394, Train loss: 0.6176, Train Acc: 0.6681, Train f1-score: 0.7722, Val loss: 0.7325, Val Acc: 0.5000, Val f1-score: 0.3333,\n",
      "Epoch: 395, Train loss: 0.5912, Train Acc: 0.6569, Train f1-score: 0.7083, Val loss: 0.5645, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 396, Train loss: 0.6183, Train Acc: 0.6569, Train f1-score: 0.7090, Val loss: 0.7303, Val Acc: 0.5000, Val f1-score: 0.3333,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 397, Train loss: 0.5853, Train Acc: 0.6556, Train f1-score: 0.7720, Val loss: 0.5784, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 398, Train loss: 0.5977, Train Acc: 0.6819, Train f1-score: 0.7196, Val loss: 0.6973, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "Epoch: 399, Train loss: 0.5904, Train Acc: 0.6472, Train f1-score: 0.5616, Val loss: 0.5628, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 400, Train loss: 0.6183, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.6961, Val Acc: 0.5625, Val f1-score: 0.4589,\n",
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  94  96  99 100 103 105 110 114 115 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [ 92  93  95  97  98 101 102 104 106 107 108 109 111 112 113 116]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.5191, Train Acc: 0.5188, Train f1-score: 0.3704, Val loss: 0.6961, Val Acc: 0.3750, Val f1-score: 0.3125,\n",
      "Epoch: 001, Train loss: 0.6945, Train Acc: 0.5049, Train f1-score: 0.3968, Val loss: 0.6890, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 002, Train loss: 0.6893, Train Acc: 0.5174, Train f1-score: 0.3968, Val loss: 0.6854, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 003, Train loss: 0.6875, Train Acc: 0.5521, Train f1-score: 0.6051, Val loss: 0.6852, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 004, Train loss: 0.6868, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.6850, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 005, Train loss: 0.6864, Train Acc: 0.5375, Train f1-score: 0.4952, Val loss: 0.6852, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 006, Train loss: 0.6856, Train Acc: 0.5361, Train f1-score: 0.5556, Val loss: 0.6858, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 007, Train loss: 0.6851, Train Acc: 0.5549, Train f1-score: 0.5556, Val loss: 0.6868, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 008, Train loss: 0.6839, Train Acc: 0.5347, Train f1-score: 0.5103, Val loss: 0.6828, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 009, Train loss: 0.6828, Train Acc: 0.5438, Train f1-score: 0.4954, Val loss: 0.6926, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 010, Train loss: 0.6889, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6940, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 011, Train loss: 0.7049, Train Acc: 0.5062, Train f1-score: 0.3855, Val loss: 0.7024, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 012, Train loss: 0.6877, Train Acc: 0.5458, Train f1-score: 0.6051, Val loss: 0.6813, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 013, Train loss: 0.6826, Train Acc: 0.5312, Train f1-score: 0.4762, Val loss: 0.6893, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 014, Train loss: 0.6830, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6809, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 015, Train loss: 0.6888, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.7009, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 016, Train loss: 0.6870, Train Acc: 0.5361, Train f1-score: 0.3968, Val loss: 0.6813, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 017, Train loss: 0.6902, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.6985, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 018, Train loss: 0.6851, Train Acc: 0.5424, Train f1-score: 0.3968, Val loss: 0.6793, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 019, Train loss: 0.6857, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6961, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 020, Train loss: 0.6836, Train Acc: 0.5535, Train f1-score: 0.5103, Val loss: 0.6787, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 021, Train loss: 0.6863, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6963, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 022, Train loss: 0.6829, Train Acc: 0.5535, Train f1-score: 0.5103, Val loss: 0.6781, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 023, Train loss: 0.6852, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6956, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 024, Train loss: 0.6823, Train Acc: 0.5535, Train f1-score: 0.5103, Val loss: 0.6774, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 025, Train loss: 0.6852, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6975, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 026, Train loss: 0.6821, Train Acc: 0.5583, Train f1-score: 0.6051, Val loss: 0.6763, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 027, Train loss: 0.6830, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6943, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 028, Train loss: 0.6808, Train Acc: 0.5521, Train f1-score: 0.6051, Val loss: 0.6759, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 029, Train loss: 0.6850, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6958, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 030, Train loss: 0.6806, Train Acc: 0.5521, Train f1-score: 0.6051, Val loss: 0.6754, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 031, Train loss: 0.6837, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6967, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 032, Train loss: 0.6800, Train Acc: 0.5521, Train f1-score: 0.6051, Val loss: 0.6741, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 033, Train loss: 0.6808, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6956, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 034, Train loss: 0.6793, Train Acc: 0.5521, Train f1-score: 0.6051, Val loss: 0.6734, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 035, Train loss: 0.6817, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6967, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 036, Train loss: 0.6786, Train Acc: 0.5521, Train f1-score: 0.6051, Val loss: 0.6724, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 037, Train loss: 0.6792, Train Acc: 0.5736, Train f1-score: 0.4815, Val loss: 0.6956, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 038, Train loss: 0.6780, Train Acc: 0.5646, Train f1-score: 0.6051, Val loss: 0.6717, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 039, Train loss: 0.6811, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6961, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 040, Train loss: 0.6777, Train Acc: 0.5583, Train f1-score: 0.6051, Val loss: 0.6708, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 041, Train loss: 0.6792, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6939, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 042, Train loss: 0.6760, Train Acc: 0.5632, Train f1-score: 0.6869, Val loss: 0.6698, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 043, Train loss: 0.6781, Train Acc: 0.5736, Train f1-score: 0.4815, Val loss: 0.6948, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 044, Train loss: 0.6759, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 045, Train loss: 0.6791, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.6997, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 046, Train loss: 0.6764, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.6682, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 047, Train loss: 0.6759, Train Acc: 0.5674, Train f1-score: 0.4815, Val loss: 0.6929, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 048, Train loss: 0.6743, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.6676, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 049, Train loss: 0.6782, Train Acc: 0.5549, Train f1-score: 0.4815, Val loss: 0.6952, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 050, Train loss: 0.6740, Train Acc: 0.5694, Train f1-score: 0.6869, Val loss: 0.6665, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 051, Train loss: 0.6741, Train Acc: 0.5549, Train f1-score: 0.4815, Val loss: 0.6959, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 052, Train loss: 0.6737, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.6662, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 053, Train loss: 0.6768, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.6963, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 054, Train loss: 0.6729, Train Acc: 0.5819, Train f1-score: 0.6869, Val loss: 0.6653, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 055, Train loss: 0.6707, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.6903, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 056, Train loss: 0.6704, Train Acc: 0.5757, Train f1-score: 0.6869, Val loss: 0.6641, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 057, Train loss: 0.6725, Train Acc: 0.5549, Train f1-score: 0.4815, Val loss: 0.6984, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 058, Train loss: 0.6717, Train Acc: 0.5597, Train f1-score: 0.5916, Val loss: 0.6643, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 059, Train loss: 0.6648, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6878, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 060, Train loss: 0.6684, Train Acc: 0.5882, Train f1-score: 0.6869, Val loss: 0.6624, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 061, Train loss: 0.6812, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6994, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 062, Train loss: 0.6701, Train Acc: 0.5646, Train f1-score: 0.6389, Val loss: 0.6626, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 063, Train loss: 0.6635, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6841, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 064, Train loss: 0.6655, Train Acc: 0.5882, Train f1-score: 0.6869, Val loss: 0.6598, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 065, Train loss: 0.6751, Train Acc: 0.5549, Train f1-score: 0.4815, Val loss: 0.7015, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 066, Train loss: 0.6691, Train Acc: 0.5722, Train f1-score: 0.5916, Val loss: 0.6612, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 067, Train loss: 0.6605, Train Acc: 0.5847, Train f1-score: 0.5926, Val loss: 0.6811, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 068, Train loss: 0.6630, Train Acc: 0.5882, Train f1-score: 0.6869, Val loss: 0.6572, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 069, Train loss: 0.6719, Train Acc: 0.5611, Train f1-score: 0.4815, Val loss: 0.7019, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 070, Train loss: 0.6675, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.6588, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 071, Train loss: 0.6597, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6880, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 072, Train loss: 0.6633, Train Acc: 0.5833, Train f1-score: 0.6389, Val loss: 0.6557, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 073, Train loss: 0.6670, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.6989, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 074, Train loss: 0.6652, Train Acc: 0.5896, Train f1-score: 0.6389, Val loss: 0.6552, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 075, Train loss: 0.6611, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6909, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 076, Train loss: 0.6625, Train Acc: 0.5896, Train f1-score: 0.6389, Val loss: 0.6530, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 077, Train loss: 0.6634, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6997, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 078, Train loss: 0.6638, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6540, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 079, Train loss: 0.6588, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6892, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 080, Train loss: 0.6604, Train Acc: 0.5944, Train f1-score: 0.7083, Val loss: 0.6526, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 081, Train loss: 0.6605, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 082, Train loss: 0.6620, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6522, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 083, Train loss: 0.6592, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6929, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 084, Train loss: 0.6600, Train Acc: 0.5944, Train f1-score: 0.6869, Val loss: 0.6468, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 085, Train loss: 0.6670, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6992, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 086, Train loss: 0.6605, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6514, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 087, Train loss: 0.6566, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6877, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 088, Train loss: 0.6569, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6515, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 089, Train loss: 0.6557, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.6914, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 090, Train loss: 0.6571, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.6461, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 091, Train loss: 0.6596, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6955, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 092, Train loss: 0.6579, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6460, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 093, Train loss: 0.6569, Train Acc: 0.5833, Train f1-score: 0.6407, Val loss: 0.6918, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 094, Train loss: 0.6564, Train Acc: 0.6007, Train f1-score: 0.7083, Val loss: 0.6453, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 095, Train loss: 0.6567, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6925, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 096, Train loss: 0.6559, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.6435, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 097, Train loss: 0.6581, Train Acc: 0.5958, Train f1-score: 0.6407, Val loss: 0.6927, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 098, Train loss: 0.6553, Train Acc: 0.6069, Train f1-score: 0.7083, Val loss: 0.6441, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 099, Train loss: 0.6564, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6952, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 100, Train loss: 0.6555, Train Acc: 0.6132, Train f1-score: 0.7083, Val loss: 0.6411, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 101, Train loss: 0.6583, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 102, Train loss: 0.6550, Train Acc: 0.6181, Train f1-score: 0.7720, Val loss: 0.6419, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 103, Train loss: 0.6523, Train Acc: 0.5958, Train f1-score: 0.6407, Val loss: 0.6919, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 104, Train loss: 0.6531, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.6395, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 105, Train loss: 0.6541, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6954, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 106, Train loss: 0.6534, Train Acc: 0.6132, Train f1-score: 0.7083, Val loss: 0.6366, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 107, Train loss: 0.6559, Train Acc: 0.6146, Train f1-score: 0.6407, Val loss: 0.6940, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 108, Train loss: 0.6520, Train Acc: 0.6306, Train f1-score: 0.7720, Val loss: 0.6426, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 109, Train loss: 0.6425, Train Acc: 0.6319, Train f1-score: 0.7090, Val loss: 0.6782, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 110, Train loss: 0.6496, Train Acc: 0.6181, Train f1-score: 0.7593, Val loss: 0.6337, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 111, Train loss: 0.6565, Train Acc: 0.6035, Train f1-score: 0.5656, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 112, Train loss: 0.6526, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.6370, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 113, Train loss: 0.6411, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.6784, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 114, Train loss: 0.6480, Train Acc: 0.6181, Train f1-score: 0.7593, Val loss: 0.6282, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 115, Train loss: 0.6580, Train Acc: 0.5660, Train f1-score: 0.5656, Val loss: 0.7047, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 116, Train loss: 0.6524, Train Acc: 0.6243, Train f1-score: 0.7720, Val loss: 0.6335, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 117, Train loss: 0.6434, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.6748, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 118, Train loss: 0.6447, Train Acc: 0.6306, Train f1-score: 0.7593, Val loss: 0.6262, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 119, Train loss: 0.6623, Train Acc: 0.5597, Train f1-score: 0.5656, Val loss: 0.6960, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 120, Train loss: 0.6482, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.6319, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 121, Train loss: 0.6429, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6791, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 122, Train loss: 0.6434, Train Acc: 0.6257, Train f1-score: 0.7083, Val loss: 0.6280, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 123, Train loss: 0.6492, Train Acc: 0.6146, Train f1-score: 0.6407, Val loss: 0.6888, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 124, Train loss: 0.6457, Train Acc: 0.6368, Train f1-score: 0.7720, Val loss: 0.6306, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 125, Train loss: 0.6427, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6839, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 126, Train loss: 0.6439, Train Acc: 0.6368, Train f1-score: 0.7593, Val loss: 0.6265, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 127, Train loss: 0.6497, Train Acc: 0.6208, Train f1-score: 0.6407, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 128, Train loss: 0.6452, Train Acc: 0.6493, Train f1-score: 0.7720, Val loss: 0.6283, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 129, Train loss: 0.6433, Train Acc: 0.6333, Train f1-score: 0.6407, Val loss: 0.6842, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 130, Train loss: 0.6418, Train Acc: 0.6319, Train f1-score: 0.7083, Val loss: 0.6254, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 131, Train loss: 0.6463, Train Acc: 0.6208, Train f1-score: 0.6407, Val loss: 0.6862, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 132, Train loss: 0.6431, Train Acc: 0.6306, Train f1-score: 0.7593, Val loss: 0.6226, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 133, Train loss: 0.6477, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.6823, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 134, Train loss: 0.6421, Train Acc: 0.6368, Train f1-score: 0.7593, Val loss: 0.6223, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 135, Train loss: 0.6441, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.6813, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 136, Train loss: 0.6412, Train Acc: 0.6368, Train f1-score: 0.7593, Val loss: 0.6221, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 137, Train loss: 0.6419, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6870, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 138, Train loss: 0.6428, Train Acc: 0.6181, Train f1-score: 0.7593, Val loss: 0.6196, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 139, Train loss: 0.6490, Train Acc: 0.5896, Train f1-score: 0.6407, Val loss: 0.6819, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 140, Train loss: 0.6413, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.6182, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 141, Train loss: 0.6442, Train Acc: 0.6257, Train f1-score: 0.7090, Val loss: 0.6784, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 142, Train loss: 0.6401, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.6178, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 143, Train loss: 0.6408, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.6787, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 144, Train loss: 0.6391, Train Acc: 0.6354, Train f1-score: 0.8250, Val loss: 0.6155, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 145, Train loss: 0.6471, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.6792, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 146, Train loss: 0.6396, Train Acc: 0.6354, Train f1-score: 0.8250, Val loss: 0.6157, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 147, Train loss: 0.6408, Train Acc: 0.6257, Train f1-score: 0.7090, Val loss: 0.6737, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 148, Train loss: 0.6397, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.6152, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 149, Train loss: 0.6524, Train Acc: 0.5785, Train f1-score: 0.5656, Val loss: 0.6782, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 150, Train loss: 0.6375, Train Acc: 0.6479, Train f1-score: 0.8250, Val loss: 0.6187, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 151, Train loss: 0.6330, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.6723, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 152, Train loss: 0.6368, Train Acc: 0.6417, Train f1-score: 0.8250, Val loss: 0.6138, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 153, Train loss: 0.6485, Train Acc: 0.6021, Train f1-score: 0.6407, Val loss: 0.6748, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 154, Train loss: 0.6373, Train Acc: 0.6417, Train f1-score: 0.8250, Val loss: 0.6131, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 155, Train loss: 0.6450, Train Acc: 0.6083, Train f1-score: 0.6407, Val loss: 0.6698, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 156, Train loss: 0.6338, Train Acc: 0.6715, Train f1-score: 0.8860, Val loss: 0.6173, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 157, Train loss: 0.6240, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.6613, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 158, Train loss: 0.6350, Train Acc: 0.6243, Train f1-score: 0.7593, Val loss: 0.6133, Val Acc: 0.6875, Val f1-score: 0.6887,\n",
      "Epoch: 159, Train loss: 0.6557, Train Acc: 0.5722, Train f1-score: 0.5656, Val loss: 0.6664, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 160, Train loss: 0.6332, Train Acc: 0.6479, Train f1-score: 0.8250, Val loss: 0.6112, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 161, Train loss: 0.6348, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6720, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 162, Train loss: 0.6353, Train Acc: 0.6417, Train f1-score: 0.8250, Val loss: 0.6108, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 163, Train loss: 0.6478, Train Acc: 0.6208, Train f1-score: 0.6407, Val loss: 0.6667, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 164, Train loss: 0.6323, Train Acc: 0.6542, Train f1-score: 0.8250, Val loss: 0.6125, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 165, Train loss: 0.6337, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6737, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 166, Train loss: 0.6357, Train Acc: 0.6354, Train f1-score: 0.8250, Val loss: 0.6119, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 167, Train loss: 0.6459, Train Acc: 0.6146, Train f1-score: 0.6407, Val loss: 0.6672, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 168, Train loss: 0.6343, Train Acc: 0.6229, Train f1-score: 0.8250, Val loss: 0.6115, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 169, Train loss: 0.6419, Train Acc: 0.6257, Train f1-score: 0.7090, Val loss: 0.6617, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 170, Train loss: 0.6309, Train Acc: 0.6417, Train f1-score: 0.8250, Val loss: 0.6118, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 171, Train loss: 0.6396, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6621, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 172, Train loss: 0.6302, Train Acc: 0.6479, Train f1-score: 0.8250, Val loss: 0.6144, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 173, Train loss: 0.6361, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.6707, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 174, Train loss: 0.6324, Train Acc: 0.6354, Train f1-score: 0.8250, Val loss: 0.6105, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 175, Train loss: 0.6479, Train Acc: 0.6035, Train f1-score: 0.5656, Val loss: 0.6726, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 176, Train loss: 0.6322, Train Acc: 0.6417, Train f1-score: 0.8250, Val loss: 0.6128, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 177, Train loss: 0.6338, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.6759, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 178, Train loss: 0.6313, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6163, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 179, Train loss: 0.6218, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.6687, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 180, Train loss: 0.6290, Train Acc: 0.6729, Train f1-score: 0.8250, Val loss: 0.6111, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 181, Train loss: 0.6318, Train Acc: 0.6569, Train f1-score: 0.7090, Val loss: 0.6746, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 182, Train loss: 0.6312, Train Acc: 0.6604, Train f1-score: 0.8250, Val loss: 0.6110, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 183, Train loss: 0.6394, Train Acc: 0.6382, Train f1-score: 0.7090, Val loss: 0.6735, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 184, Train loss: 0.6283, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.6144, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 185, Train loss: 0.6165, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.6647, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 186, Train loss: 0.6249, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.6107, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 187, Train loss: 0.6259, Train Acc: 0.6569, Train f1-score: 0.7090, Val loss: 0.6743, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 188, Train loss: 0.6291, Train Acc: 0.6792, Train f1-score: 0.8250, Val loss: 0.6121, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 189, Train loss: 0.6329, Train Acc: 0.6444, Train f1-score: 0.7090, Val loss: 0.6740, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 190, Train loss: 0.6265, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6093, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 191, Train loss: 0.6248, Train Acc: 0.6632, Train f1-score: 0.7090, Val loss: 0.6681, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 192, Train loss: 0.6261, Train Acc: 0.6792, Train f1-score: 0.8250, Val loss: 0.6128, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 193, Train loss: 0.6292, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.6749, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 194, Train loss: 0.6256, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6101, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 195, Train loss: 0.6171, Train Acc: 0.6979, Train f1-score: 0.8318, Val loss: 0.6609, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 196, Train loss: 0.6221, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6094, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 197, Train loss: 0.6293, Train Acc: 0.6632, Train f1-score: 0.7090, Val loss: 0.6769, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 198, Train loss: 0.6257, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6093, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 199, Train loss: 0.6207, Train Acc: 0.6806, Train f1-score: 0.7722, Val loss: 0.6645, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 200, Train loss: 0.6230, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6119, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 201, Train loss: 0.6167, Train Acc: 0.6792, Train f1-score: 0.8318, Val loss: 0.6608, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 202, Train loss: 0.6220, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6101, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 203, Train loss: 0.6172, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.6603, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 204, Train loss: 0.6226, Train Acc: 0.6729, Train f1-score: 0.8250, Val loss: 0.6095, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 205, Train loss: 0.6276, Train Acc: 0.6694, Train f1-score: 0.7090, Val loss: 0.6855, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 206, Train loss: 0.6267, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6137, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 207, Train loss: 0.6106, Train Acc: 0.6854, Train f1-score: 0.8318, Val loss: 0.6653, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 208, Train loss: 0.6216, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6118, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 209, Train loss: 0.6234, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.6784, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 210, Train loss: 0.6238, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.6111, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 211, Train loss: 0.6189, Train Acc: 0.6694, Train f1-score: 0.7090, Val loss: 0.6718, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 212, Train loss: 0.6215, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6120, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 213, Train loss: 0.6149, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.6679, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 214, Train loss: 0.6193, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6158, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 215, Train loss: 0.6057, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6571, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 216, Train loss: 0.6162, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6110, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 217, Train loss: 0.6216, Train Acc: 0.6507, Train f1-score: 0.7090, Val loss: 0.6747, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 218, Train loss: 0.6200, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6117, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 219, Train loss: 0.6105, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.6537, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 220, Train loss: 0.6137, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6174, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 221, Train loss: 0.6021, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6492, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 222, Train loss: 0.6116, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6097, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 223, Train loss: 0.6168, Train Acc: 0.6757, Train f1-score: 0.7090, Val loss: 0.6781, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 224, Train loss: 0.6200, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6109, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 225, Train loss: 0.6123, Train Acc: 0.6931, Train f1-score: 0.7722, Val loss: 0.6655, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 226, Train loss: 0.6147, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6137, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 227, Train loss: 0.6048, Train Acc: 0.6979, Train f1-score: 0.8318, Val loss: 0.6604, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 228, Train loss: 0.6148, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6107, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 229, Train loss: 0.6098, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6679, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 230, Train loss: 0.6153, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6088, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 231, Train loss: 0.6134, Train Acc: 0.6694, Train f1-score: 0.7090, Val loss: 0.6685, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 232, Train loss: 0.6146, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6160, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 233, Train loss: 0.6043, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6564, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 234, Train loss: 0.6108, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6115, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 235, Train loss: 0.6058, Train Acc: 0.6979, Train f1-score: 0.8318, Val loss: 0.6584, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 236, Train loss: 0.6112, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6192, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 237, Train loss: 0.5975, Train Acc: 0.6931, Train f1-score: 0.7778, Val loss: 0.6378, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 238, Train loss: 0.6041, Train Acc: 0.6854, Train f1-score: 0.8317, Val loss: 0.6264, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 239, Train loss: 0.6004, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.6083, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 240, Train loss: 0.6031, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6739, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 241, Train loss: 0.6178, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6056, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 242, Train loss: 0.6190, Train Acc: 0.6694, Train f1-score: 0.7090, Val loss: 0.6718, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 243, Train loss: 0.6148, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6090, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 244, Train loss: 0.6038, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.6634, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 245, Train loss: 0.6103, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6159, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 246, Train loss: 0.5985, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6502, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 247, Train loss: 0.6061, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6107, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 248, Train loss: 0.6035, Train Acc: 0.6979, Train f1-score: 0.8318, Val loss: 0.6682, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 249, Train loss: 0.6110, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6090, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 250, Train loss: 0.6030, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.6657, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 251, Train loss: 0.6095, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6117, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 252, Train loss: 0.6016, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6626, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 253, Train loss: 0.6081, Train Acc: 0.6604, Train f1-score: 0.8317, Val loss: 0.6096, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 254, Train loss: 0.6017, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6659, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 255, Train loss: 0.6083, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.6106, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 256, Train loss: 0.6024, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.6632, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 257, Train loss: 0.6071, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.6345, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 258, Train loss: 0.5967, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 0.6259, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 259, Train loss: 0.5965, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6504, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 260, Train loss: 0.6032, Train Acc: 0.6903, Train f1-score: 0.8860, Val loss: 0.6065, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 261, Train loss: 0.6137, Train Acc: 0.6694, Train f1-score: 0.7090, Val loss: 0.6558, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 262, Train loss: 0.6068, Train Acc: 0.6778, Train f1-score: 0.8860, Val loss: 0.6201, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 263, Train loss: 0.5973, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6652, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 264, Train loss: 0.6065, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6117, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 265, Train loss: 0.6089, Train Acc: 0.6757, Train f1-score: 0.7090, Val loss: 0.6782, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 266, Train loss: 0.6086, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6161, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 267, Train loss: 0.5997, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6644, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 268, Train loss: 0.6039, Train Acc: 0.6840, Train f1-score: 0.8860, Val loss: 0.6125, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 269, Train loss: 0.6048, Train Acc: 0.6868, Train f1-score: 0.7722, Val loss: 0.6627, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 270, Train loss: 0.6028, Train Acc: 0.6667, Train f1-score: 0.8317, Val loss: 0.6171, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 271, Train loss: 0.6016, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6801, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 272, Train loss: 0.6066, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6213, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 273, Train loss: 0.5989, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6704, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 274, Train loss: 0.6029, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6287, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 275, Train loss: 0.5952, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6670, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 276, Train loss: 0.6014, Train Acc: 0.6792, Train f1-score: 0.8317, Val loss: 0.6187, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 277, Train loss: 0.6014, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6770, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 278, Train loss: 0.6040, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6344, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 279, Train loss: 0.5942, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6642, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 280, Train loss: 0.5989, Train Acc: 0.6729, Train f1-score: 0.8317, Val loss: 0.6197, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 281, Train loss: 0.6005, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6791, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 282, Train loss: 0.6035, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.6406, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 283, Train loss: 0.5931, Train Acc: 0.7056, Train f1-score: 0.7778, Val loss: 0.6548, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 284, Train loss: 0.5952, Train Acc: 0.6681, Train f1-score: 0.7778, Val loss: 0.6211, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 285, Train loss: 0.5964, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6759, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 286, Train loss: 0.6021, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6276, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 287, Train loss: 0.5960, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6719, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 288, Train loss: 0.6001, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6245, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 289, Train loss: 0.5993, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6786, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 290, Train loss: 0.6015, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.6360, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 291, Train loss: 0.5935, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6661, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 292, Train loss: 0.5967, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.6395, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 293, Train loss: 0.5911, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6663, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 294, Train loss: 0.5964, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.6203, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 295, Train loss: 0.5972, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6871, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 296, Train loss: 0.6033, Train Acc: 0.6729, Train f1-score: 0.8338, Val loss: 0.6367, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 297, Train loss: 0.5936, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6656, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 298, Train loss: 0.5950, Train Acc: 0.6979, Train f1-score: 0.8338, Val loss: 0.6454, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 299, Train loss: 0.5920, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.6651, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 300, Train loss: 0.5947, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.6291, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 301, Train loss: 0.5954, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6787, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 302, Train loss: 0.5974, Train Acc: 0.6979, Train f1-score: 0.8338, Val loss: 0.6462, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 303, Train loss: 0.5894, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.6638, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 304, Train loss: 0.5924, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.6354, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 305, Train loss: 0.5950, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6815, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 306, Train loss: 0.5979, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.6471, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 307, Train loss: 0.5909, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6704, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 308, Train loss: 0.5931, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.6357, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 309, Train loss: 0.5924, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6747, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 310, Train loss: 0.5943, Train Acc: 0.6979, Train f1-score: 0.8338, Val loss: 0.6488, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 311, Train loss: 0.5887, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.6629, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 312, Train loss: 0.5916, Train Acc: 0.7042, Train f1-score: 0.8338, Val loss: 0.6437, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 313, Train loss: 0.5931, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6794, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 314, Train loss: 0.5940, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.6375, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 315, Train loss: 0.5910, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6822, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 316, Train loss: 0.5952, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.6491, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 317, Train loss: 0.5899, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6710, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 318, Train loss: 0.5905, Train Acc: 0.7104, Train f1-score: 0.8338, Val loss: 0.6544, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 319, Train loss: 0.5864, Train Acc: 0.7118, Train f1-score: 0.7778, Val loss: 0.6621, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 320, Train loss: 0.5876, Train Acc: 0.7104, Train f1-score: 0.8338, Val loss: 0.6473, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 321, Train loss: 0.5878, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6735, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 322, Train loss: 0.5891, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.6385, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 323, Train loss: 0.5873, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6877, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 324, Train loss: 0.5937, Train Acc: 0.6792, Train f1-score: 0.8338, Val loss: 0.6381, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 325, Train loss: 0.5937, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6985, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 326, Train loss: 0.5951, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.6455, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 327, Train loss: 0.5868, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6813, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 328, Train loss: 0.5898, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.6636, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 329, Train loss: 0.5864, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6674, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 330, Train loss: 0.5862, Train Acc: 0.7056, Train f1-score: 0.7778, Val loss: 0.6556, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 331, Train loss: 0.5867, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6844, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 332, Train loss: 0.5881, Train Acc: 0.6806, Train f1-score: 0.7778, Val loss: 0.6622, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 333, Train loss: 0.5871, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.6830, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 334, Train loss: 0.5882, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6663, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 335, Train loss: 0.5824, Train Acc: 0.7056, Train f1-score: 0.7778, Val loss: 0.6690, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 336, Train loss: 0.5865, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6891, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 337, Train loss: 0.5863, Train Acc: 0.7042, Train f1-score: 0.8338, Val loss: 0.6526, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 338, Train loss: 0.5834, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.6954, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 339, Train loss: 0.5877, Train Acc: 0.6979, Train f1-score: 0.8338, Val loss: 0.6601, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 340, Train loss: 0.5802, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6807, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 341, Train loss: 0.5827, Train Acc: 0.6993, Train f1-score: 0.7778, Val loss: 0.6746, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 342, Train loss: 0.5873, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6968, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 343, Train loss: 0.5864, Train Acc: 0.6931, Train f1-score: 0.7778, Val loss: 0.6743, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 344, Train loss: 0.5876, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.7034, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 345, Train loss: 0.5906, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6871, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 346, Train loss: 0.5853, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6817, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 347, Train loss: 0.5812, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6768, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 348, Train loss: 0.5772, Train Acc: 0.7056, Train f1-score: 0.7778, Val loss: 0.6719, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 349, Train loss: 0.5846, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.7096, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 350, Train loss: 0.5873, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6820, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 351, Train loss: 0.5799, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6831, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 352, Train loss: 0.5792, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6836, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 353, Train loss: 0.5798, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6884, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 354, Train loss: 0.5798, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6853, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 355, Train loss: 0.5812, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.7028, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 356, Train loss: 0.5813, Train Acc: 0.6993, Train f1-score: 0.7778, Val loss: 0.6754, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 357, Train loss: 0.5742, Train Acc: 0.6993, Train f1-score: 0.7778, Val loss: 0.6770, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 358, Train loss: 0.5758, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6971, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 359, Train loss: 0.5772, Train Acc: 0.7229, Train f1-score: 0.8338, Val loss: 0.6681, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 360, Train loss: 0.5750, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.7111, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 361, Train loss: 0.5784, Train Acc: 0.7042, Train f1-score: 0.8338, Val loss: 0.6480, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 362, Train loss: 0.5981, Train Acc: 0.6646, Train f1-score: 0.6407, Val loss: 0.6950, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 363, Train loss: 0.5792, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6914, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 364, Train loss: 0.5773, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6912, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 365, Train loss: 0.5782, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.7043, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 366, Train loss: 0.5724, Train Acc: 0.7104, Train f1-score: 0.8338, Val loss: 0.6474, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 367, Train loss: 0.5946, Train Acc: 0.6708, Train f1-score: 0.6407, Val loss: 0.6981, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 368, Train loss: 0.5796, Train Acc: 0.7104, Train f1-score: 0.8318, Val loss: 0.6863, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 369, Train loss: 0.5749, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.6934, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 370, Train loss: 0.5722, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.6805, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 371, Train loss: 0.5763, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.7146, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 372, Train loss: 0.5772, Train Acc: 0.6993, Train f1-score: 0.7778, Val loss: 0.6750, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 373, Train loss: 0.5837, Train Acc: 0.7056, Train f1-score: 0.7722, Val loss: 0.7185, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 374, Train loss: 0.5813, Train Acc: 0.6979, Train f1-score: 0.8318, Val loss: 0.6824, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 375, Train loss: 0.5783, Train Acc: 0.7229, Train f1-score: 0.8318, Val loss: 0.7232, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 376, Train loss: 0.5780, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6861, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 377, Train loss: 0.5737, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.7098, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 378, Train loss: 0.5722, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.7004, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 379, Train loss: 0.5745, Train Acc: 0.7292, Train f1-score: 0.8318, Val loss: 0.7079, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 380, Train loss: 0.5745, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.7068, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 381, Train loss: 0.5702, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.6953, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 382, Train loss: 0.5758, Train Acc: 0.7354, Train f1-score: 0.8318, Val loss: 0.7466, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 383, Train loss: 0.5781, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.6710, Val Acc: 0.3750, Val f1-score: 0.3068,\n",
      "Epoch: 384, Train loss: 0.5973, Train Acc: 0.6583, Train f1-score: 0.6407, Val loss: 0.7365, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 385, Train loss: 0.5740, Train Acc: 0.7042, Train f1-score: 0.8318, Val loss: 0.6922, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 386, Train loss: 0.5736, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.7566, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 387, Train loss: 0.5743, Train Acc: 0.6917, Train f1-score: 0.8318, Val loss: 0.7198, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 388, Train loss: 0.5717, Train Acc: 0.7354, Train f1-score: 0.8318, Val loss: 0.7782, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 389, Train loss: 0.5797, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 0.6912, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 390, Train loss: 0.6130, Train Acc: 0.6535, Train f1-score: 0.5656, Val loss: 0.7422, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 391, Train loss: 0.5641, Train Acc: 0.6993, Train f1-score: 0.7778, Val loss: 0.6979, Val Acc: 0.3750, Val f1-score: 0.3068,\n",
      "Epoch: 392, Train loss: 0.5826, Train Acc: 0.6958, Train f1-score: 0.6407, Val loss: 0.7531, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 393, Train loss: 0.5726, Train Acc: 0.6806, Train f1-score: 0.7778, Val loss: 0.6901, Val Acc: 0.3750, Val f1-score: 0.3068,\n",
      "Epoch: 394, Train loss: 0.5874, Train Acc: 0.6771, Train f1-score: 0.6407, Val loss: 0.7445, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 395, Train loss: 0.5696, Train Acc: 0.6993, Train f1-score: 0.7778, Val loss: 0.6905, Val Acc: 0.3750, Val f1-score: 0.3068,\n",
      "Epoch: 396, Train loss: 0.5803, Train Acc: 0.6833, Train f1-score: 0.6407, Val loss: 0.7401, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "Epoch: 397, Train loss: 0.5682, Train Acc: 0.7167, Train f1-score: 0.8318, Val loss: 0.7106, Val Acc: 0.4375, Val f1-score: 0.3424,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 398, Train loss: 0.5644, Train Acc: 0.7354, Train f1-score: 0.8318, Val loss: 0.7481, Val Acc: 0.4375, Val f1-score: 0.3424,\n",
      "Epoch: 399, Train loss: 0.5669, Train Acc: 0.7229, Train f1-score: 0.8338, Val loss: 0.6818, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 400, Train loss: 0.5938, Train Acc: 0.6521, Train f1-score: 0.6407, Val loss: 0.7274, Val Acc: 0.5000, Val f1-score: 0.3750,\n",
      "GIN accuracy: 0.3684210479259491\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 111 112 113 116 128 130 132 133 134 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [110 114 115 117 118 119 120 121 122 123 124 125 126 127 129 131]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.0408, Train Acc: 0.5222, Train f1-score: 0.5916, Val loss: 1.0469, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 001, Train loss: 0.8224, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.7001, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 002, Train loss: 0.6989, Train Acc: 0.5299, Train f1-score: 0.3968, Val loss: 0.6960, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 003, Train loss: 0.6984, Train Acc: 0.5187, Train f1-score: 0.3704, Val loss: 0.6947, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 004, Train loss: 0.6986, Train Acc: 0.5076, Train f1-score: 0.3981, Val loss: 0.6933, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 005, Train loss: 0.6987, Train Acc: 0.4632, Train f1-score: 0.2222, Val loss: 0.6920, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 006, Train loss: 0.6989, Train Acc: 0.4743, Train f1-score: 0.2434, Val loss: 0.6905, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 007, Train loss: 0.6991, Train Acc: 0.5187, Train f1-score: 0.3855, Val loss: 0.6890, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 008, Train loss: 0.6992, Train Acc: 0.5076, Train f1-score: 0.2735, Val loss: 0.6874, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 009, Train loss: 0.6994, Train Acc: 0.5076, Train f1-score: 0.2735, Val loss: 0.6859, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 010, Train loss: 0.6994, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.6842, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 011, Train loss: 0.6994, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 012, Train loss: 0.6994, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6809, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 013, Train loss: 0.6994, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6792, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 014, Train loss: 0.6993, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6777, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 015, Train loss: 0.6992, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6763, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 016, Train loss: 0.6990, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6748, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 017, Train loss: 0.6988, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6733, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 018, Train loss: 0.6986, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6713, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 019, Train loss: 0.6983, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6687, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 020, Train loss: 0.6981, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6678, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 021, Train loss: 0.6978, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6665, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 022, Train loss: 0.6975, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6639, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 023, Train loss: 0.6974, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6631, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 024, Train loss: 0.6970, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6618, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 025, Train loss: 0.6967, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6606, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 026, Train loss: 0.6964, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6583, Val Acc: 0.6250, Val f1-score: 0.5312,\n",
      "Epoch: 027, Train loss: 0.6963, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6575, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 028, Train loss: 0.6959, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6565, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 029, Train loss: 0.6956, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6551, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 030, Train loss: 0.6953, Train Acc: 0.5486, Train f1-score: 0.4815, Val loss: 0.6528, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 031, Train loss: 0.6951, Train Acc: 0.5424, Train f1-score: 0.4815, Val loss: 0.6523, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 032, Train loss: 0.6947, Train Acc: 0.5361, Train f1-score: 0.4815, Val loss: 0.6511, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 033, Train loss: 0.6945, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.6490, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 034, Train loss: 0.6943, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6485, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 035, Train loss: 0.6940, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6474, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 036, Train loss: 0.6938, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6454, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 037, Train loss: 0.6937, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6450, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 038, Train loss: 0.6934, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.6431, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 039, Train loss: 0.6933, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6430, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 040, Train loss: 0.6931, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6424, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 041, Train loss: 0.6930, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.6405, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 042, Train loss: 0.6928, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6402, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 043, Train loss: 0.6925, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.6385, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 044, Train loss: 0.6924, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.6384, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 045, Train loss: 0.6922, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.6377, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 046, Train loss: 0.6920, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6362, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 047, Train loss: 0.6919, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.6358, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 048, Train loss: 0.6915, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6343, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 049, Train loss: 0.6915, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.6340, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 050, Train loss: 0.6912, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6334, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 051, Train loss: 0.6910, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6319, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 052, Train loss: 0.6909, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6316, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 053, Train loss: 0.6906, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6301, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 054, Train loss: 0.6905, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6299, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 055, Train loss: 0.6902, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6283, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 056, Train loss: 0.6902, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6282, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 057, Train loss: 0.6899, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6267, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 058, Train loss: 0.6898, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6265, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 059, Train loss: 0.6896, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6252, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 060, Train loss: 0.6895, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6249, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 061, Train loss: 0.6892, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6244, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 062, Train loss: 0.6890, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6231, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 063, Train loss: 0.6889, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6229, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 064, Train loss: 0.6887, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6216, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 065, Train loss: 0.6885, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6212, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 066, Train loss: 0.6882, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6201, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 067, Train loss: 0.6881, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6197, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 068, Train loss: 0.6878, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6187, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 069, Train loss: 0.6877, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6182, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 070, Train loss: 0.6873, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6174, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 071, Train loss: 0.6871, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6167, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 072, Train loss: 0.6869, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6160, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 073, Train loss: 0.6866, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6155, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 074, Train loss: 0.6864, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6149, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 075, Train loss: 0.6862, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6142, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 076, Train loss: 0.6859, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6137, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 077, Train loss: 0.6857, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6130, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 078, Train loss: 0.6863, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6123, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 079, Train loss: 0.6858, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6118, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 080, Train loss: 0.6855, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6113, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 081, Train loss: 0.6848, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.6106, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 082, Train loss: 0.6850, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.6100, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 083, Train loss: 0.6844, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6095, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 084, Train loss: 0.6841, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.6089, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 085, Train loss: 0.6842, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.6082, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 086, Train loss: 0.6836, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.6079, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 087, Train loss: 0.6833, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.6073, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 088, Train loss: 0.6831, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6068, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 089, Train loss: 0.6832, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6063, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 090, Train loss: 0.6824, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.6060, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 091, Train loss: 0.6826, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.6055, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 092, Train loss: 0.6819, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6050, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 093, Train loss: 0.6818, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6045, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 094, Train loss: 0.6816, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6040, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 095, Train loss: 0.6812, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6038, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 096, Train loss: 0.6811, Train Acc: 0.5222, Train f1-score: 0.5656, Val loss: 0.6028, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 097, Train loss: 0.6809, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.6021, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 098, Train loss: 0.6804, Train Acc: 0.5333, Train f1-score: 0.6407, Val loss: 0.6020, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 099, Train loss: 0.6804, Train Acc: 0.5271, Train f1-score: 0.6407, Val loss: 0.6009, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 100, Train loss: 0.6801, Train Acc: 0.5333, Train f1-score: 0.6407, Val loss: 0.6003, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 101, Train loss: 0.6797, Train Acc: 0.5333, Train f1-score: 0.6407, Val loss: 0.5996, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 102, Train loss: 0.6794, Train Acc: 0.5333, Train f1-score: 0.6407, Val loss: 0.5995, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 103, Train loss: 0.6794, Train Acc: 0.5333, Train f1-score: 0.6407, Val loss: 0.5984, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 104, Train loss: 0.6789, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5980, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 105, Train loss: 0.6788, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5974, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 106, Train loss: 0.6785, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5974, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 107, Train loss: 0.6784, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5963, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 108, Train loss: 0.6779, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5957, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 109, Train loss: 0.6778, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5950, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 110, Train loss: 0.6772, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5944, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 111, Train loss: 0.6773, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.5937, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 112, Train loss: 0.6767, Train Acc: 0.5396, Train f1-score: 0.6407, Val loss: 0.5937, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 113, Train loss: 0.6765, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5927, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 114, Train loss: 0.6761, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5924, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 115, Train loss: 0.6760, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5927, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 116, Train loss: 0.6759, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5912, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 117, Train loss: 0.6752, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5905, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 118, Train loss: 0.6748, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5903, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 119, Train loss: 0.6747, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5894, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 120, Train loss: 0.6746, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5888, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 121, Train loss: 0.6742, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5884, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 122, Train loss: 0.6740, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5877, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 123, Train loss: 0.6736, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5873, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 124, Train loss: 0.6733, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5867, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 125, Train loss: 0.6729, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5869, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 126, Train loss: 0.6723, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5863, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 127, Train loss: 0.6721, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5864, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 128, Train loss: 0.6719, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5855, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 129, Train loss: 0.6716, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5857, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 130, Train loss: 0.6712, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5846, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 131, Train loss: 0.6706, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5851, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 132, Train loss: 0.6705, Train Acc: 0.5472, Train f1-score: 0.5656, Val loss: 0.5835, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 133, Train loss: 0.6702, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5842, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 134, Train loss: 0.6699, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5827, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 135, Train loss: 0.6697, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5828, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 136, Train loss: 0.6694, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5818, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 137, Train loss: 0.6688, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5813, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 138, Train loss: 0.6684, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5806, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 139, Train loss: 0.6681, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5798, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 140, Train loss: 0.6679, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5794, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 141, Train loss: 0.6673, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5791, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 142, Train loss: 0.6669, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5788, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 143, Train loss: 0.6663, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5767, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 144, Train loss: 0.6661, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5788, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 145, Train loss: 0.6660, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5776, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 146, Train loss: 0.6652, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5774, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 147, Train loss: 0.6651, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5761, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 148, Train loss: 0.6645, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5770, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 149, Train loss: 0.6645, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5752, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 150, Train loss: 0.6638, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5793, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 151, Train loss: 0.6637, Train Acc: 0.5222, Train f1-score: 0.5656, Val loss: 0.5773, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 152, Train loss: 0.6633, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5745, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 153, Train loss: 0.6634, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5759, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 154, Train loss: 0.6627, Train Acc: 0.5222, Train f1-score: 0.5656, Val loss: 0.5743, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 155, Train loss: 0.6622, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5715, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 156, Train loss: 0.6619, Train Acc: 0.5236, Train f1-score: 0.4815, Val loss: 0.5718, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 157, Train loss: 0.6618, Train Acc: 0.5285, Train f1-score: 0.5656, Val loss: 0.5743, Val Acc: 0.6875, Val f1-score: 0.6347,\n",
      "Epoch: 158, Train loss: 0.6611, Train Acc: 0.5222, Train f1-score: 0.5656, Val loss: 0.5709, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 159, Train loss: 0.6608, Train Acc: 0.5174, Train f1-score: 0.4815, Val loss: 0.5732, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 160, Train loss: 0.6608, Train Acc: 0.5222, Train f1-score: 0.5656, Val loss: 0.5719, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 161, Train loss: 0.6599, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.5734, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 162, Train loss: 0.6592, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.5701, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 163, Train loss: 0.6597, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.5715, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 164, Train loss: 0.6591, Train Acc: 0.5111, Train f1-score: 0.4815, Val loss: 0.5715, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 165, Train loss: 0.6590, Train Acc: 0.5174, Train f1-score: 0.4815, Val loss: 0.5705, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 166, Train loss: 0.6576, Train Acc: 0.5174, Train f1-score: 0.4815, Val loss: 0.5698, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 167, Train loss: 0.6576, Train Acc: 0.5236, Train f1-score: 0.4815, Val loss: 0.5746, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 168, Train loss: 0.6571, Train Acc: 0.5174, Train f1-score: 0.4815, Val loss: 0.5706, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 169, Train loss: 0.6576, Train Acc: 0.5174, Train f1-score: 0.4815, Val loss: 0.5686, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 170, Train loss: 0.6562, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5697, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 171, Train loss: 0.6559, Train Acc: 0.5236, Train f1-score: 0.4815, Val loss: 0.5683, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 172, Train loss: 0.6554, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5694, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 173, Train loss: 0.6558, Train Acc: 0.5236, Train f1-score: 0.4815, Val loss: 0.5691, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 174, Train loss: 0.6544, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5696, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 175, Train loss: 0.6550, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5698, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 176, Train loss: 0.6537, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5718, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 177, Train loss: 0.6531, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5667, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 178, Train loss: 0.6521, Train Acc: 0.5299, Train f1-score: 0.4815, Val loss: 0.5629, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 179, Train loss: 0.6527, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5609, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 180, Train loss: 0.6537, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5699, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 181, Train loss: 0.6503, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5632, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 182, Train loss: 0.6497, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5615, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 183, Train loss: 0.6497, Train Acc: 0.5347, Train f1-score: 0.5656, Val loss: 0.5706, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 184, Train loss: 0.6510, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5628, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 185, Train loss: 0.6485, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5594, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 186, Train loss: 0.6499, Train Acc: 0.5410, Train f1-score: 0.5656, Val loss: 0.5679, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 187, Train loss: 0.6473, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5589, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 188, Train loss: 0.6483, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5584, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 189, Train loss: 0.6482, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5575, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 190, Train loss: 0.6482, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5714, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 191, Train loss: 0.6458, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5561, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 192, Train loss: 0.6468, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5567, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 193, Train loss: 0.6464, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5621, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 194, Train loss: 0.6469, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5582, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 195, Train loss: 0.6448, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5539, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 196, Train loss: 0.6445, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5659, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 197, Train loss: 0.6439, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5553, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 198, Train loss: 0.6442, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5666, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 199, Train loss: 0.6429, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5644, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 200, Train loss: 0.6420, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5578, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 201, Train loss: 0.6433, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5551, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 202, Train loss: 0.6417, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5590, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 203, Train loss: 0.6406, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5572, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 204, Train loss: 0.6410, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5644, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 205, Train loss: 0.6403, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5561, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 206, Train loss: 0.6399, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5596, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 207, Train loss: 0.6384, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5604, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 208, Train loss: 0.6393, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.5583, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 209, Train loss: 0.6386, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5593, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 210, Train loss: 0.6378, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5602, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 211, Train loss: 0.6362, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.5613, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 212, Train loss: 0.6363, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5642, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 213, Train loss: 0.6349, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5616, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 214, Train loss: 0.6347, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5665, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 215, Train loss: 0.6342, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5617, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 216, Train loss: 0.6344, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.5618, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 217, Train loss: 0.6331, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5628, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 218, Train loss: 0.6323, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.5618, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 219, Train loss: 0.6331, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5617, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 220, Train loss: 0.6326, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.5615, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 221, Train loss: 0.6327, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.5630, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 222, Train loss: 0.6320, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5701, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 223, Train loss: 0.6292, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5724, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 224, Train loss: 0.6293, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.5730, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 225, Train loss: 0.6279, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.5752, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 226, Train loss: 0.6277, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5742, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 227, Train loss: 0.6259, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5743, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 228, Train loss: 0.6262, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5761, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 229, Train loss: 0.6249, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5762, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 230, Train loss: 0.6246, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5744, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 231, Train loss: 0.6258, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5767, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 232, Train loss: 0.6239, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5793, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 233, Train loss: 0.6247, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5909, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 234, Train loss: 0.6242, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5758, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 235, Train loss: 0.6245, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5740, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 236, Train loss: 0.6244, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5749, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 237, Train loss: 0.6226, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5704, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 238, Train loss: 0.6241, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5759, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 239, Train loss: 0.6230, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5642, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 240, Train loss: 0.6235, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5910, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 241, Train loss: 0.6197, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5753, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 242, Train loss: 0.6228, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5736, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 243, Train loss: 0.6208, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5723, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 244, Train loss: 0.6204, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5718, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 245, Train loss: 0.6208, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5874, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 246, Train loss: 0.6161, Train Acc: 0.5771, Train f1-score: 0.6407, Val loss: 0.5684, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 247, Train loss: 0.6199, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5948, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 248, Train loss: 0.6175, Train Acc: 0.5708, Train f1-score: 0.6407, Val loss: 0.5567, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 249, Train loss: 0.6228, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5637, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 250, Train loss: 0.6156, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5610, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 251, Train loss: 0.6189, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5609, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 252, Train loss: 0.6167, Train Acc: 0.5458, Train f1-score: 0.6407, Val loss: 0.5583, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 253, Train loss: 0.6182, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5567, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 254, Train loss: 0.6172, Train Acc: 0.5521, Train f1-score: 0.6407, Val loss: 0.5612, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 255, Train loss: 0.6151, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.5681, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 256, Train loss: 0.6126, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5866, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 257, Train loss: 0.6110, Train Acc: 0.5882, Train f1-score: 0.7090, Val loss: 0.5649, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 258, Train loss: 0.6145, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5849, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 259, Train loss: 0.6090, Train Acc: 0.5882, Train f1-score: 0.7090, Val loss: 0.5664, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 260, Train loss: 0.6146, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5598, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 261, Train loss: 0.6109, Train Acc: 0.5694, Train f1-score: 0.7090, Val loss: 0.5569, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 262, Train loss: 0.6154, Train Acc: 0.5646, Train f1-score: 0.6407, Val loss: 0.5599, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 263, Train loss: 0.6084, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.5650, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 264, Train loss: 0.6122, Train Acc: 0.5583, Train f1-score: 0.6407, Val loss: 0.5607, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 265, Train loss: 0.6092, Train Acc: 0.5757, Train f1-score: 0.7090, Val loss: 0.5605, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 266, Train loss: 0.6090, Train Acc: 0.5743, Train f1-score: 0.7722, Val loss: 0.5532, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 267, Train loss: 0.6091, Train Acc: 0.5868, Train f1-score: 0.7722, Val loss: 0.5540, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 268, Train loss: 0.6107, Train Acc: 0.5806, Train f1-score: 0.7722, Val loss: 0.5624, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 269, Train loss: 0.6047, Train Acc: 0.5882, Train f1-score: 0.7090, Val loss: 0.5633, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 270, Train loss: 0.6091, Train Acc: 0.5868, Train f1-score: 0.7722, Val loss: 0.5813, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 271, Train loss: 0.6067, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5534, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 272, Train loss: 0.6081, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5656, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 273, Train loss: 0.6067, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5600, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 274, Train loss: 0.6010, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5641, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 275, Train loss: 0.6016, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.5819, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 276, Train loss: 0.5989, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.5624, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 277, Train loss: 0.6020, Train Acc: 0.5944, Train f1-score: 0.7090, Val loss: 0.5825, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 278, Train loss: 0.5956, Train Acc: 0.6118, Train f1-score: 0.7722, Val loss: 0.5950, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 279, Train loss: 0.5969, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.5700, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 280, Train loss: 0.6066, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.6061, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 281, Train loss: 0.5977, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.5799, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 282, Train loss: 0.5980, Train Acc: 0.5931, Train f1-score: 0.7722, Val loss: 0.5795, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 283, Train loss: 0.5977, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5788, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 284, Train loss: 0.5983, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.6073, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 285, Train loss: 0.5927, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.5723, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 286, Train loss: 0.5953, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.5818, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 287, Train loss: 0.5939, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.5526, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 288, Train loss: 0.6048, Train Acc: 0.6118, Train f1-score: 0.7722, Val loss: 0.5949, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 289, Train loss: 0.5955, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.5650, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 290, Train loss: 0.6009, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.5903, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 291, Train loss: 0.5944, Train Acc: 0.5819, Train f1-score: 0.7196, Val loss: 0.5651, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 292, Train loss: 0.6002, Train Acc: 0.5944, Train f1-score: 0.7196, Val loss: 0.5952, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 293, Train loss: 0.5902, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.5788, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 294, Train loss: 0.5965, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5892, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 295, Train loss: 0.5929, Train Acc: 0.5882, Train f1-score: 0.7196, Val loss: 0.5477, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 296, Train loss: 0.6000, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.5835, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 297, Train loss: 0.5850, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.5764, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 298, Train loss: 0.5907, Train Acc: 0.6056, Train f1-score: 0.7722, Val loss: 0.5987, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 299, Train loss: 0.5890, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.5805, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 300, Train loss: 0.5874, Train Acc: 0.6069, Train f1-score: 0.7196, Val loss: 0.5754, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 301, Train loss: 0.5843, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.5823, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 302, Train loss: 0.5882, Train Acc: 0.6132, Train f1-score: 0.7196, Val loss: 0.5615, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 303, Train loss: 0.5910, Train Acc: 0.5993, Train f1-score: 0.7722, Val loss: 0.6266, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 304, Train loss: 0.5919, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.5585, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 305, Train loss: 0.5863, Train Acc: 0.6007, Train f1-score: 0.7196, Val loss: 0.5650, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 306, Train loss: 0.5863, Train Acc: 0.6194, Train f1-score: 0.7196, Val loss: 0.5945, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 307, Train loss: 0.5865, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.5768, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 308, Train loss: 0.5805, Train Acc: 0.6382, Train f1-score: 0.7196, Val loss: 0.5671, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 309, Train loss: 0.5851, Train Acc: 0.6306, Train f1-score: 0.7722, Val loss: 0.5843, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 310, Train loss: 0.5799, Train Acc: 0.6382, Train f1-score: 0.7196, Val loss: 0.5834, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 311, Train loss: 0.5760, Train Acc: 0.6444, Train f1-score: 0.7196, Val loss: 0.5887, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 312, Train loss: 0.5809, Train Acc: 0.6507, Train f1-score: 0.7196, Val loss: 0.5566, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 313, Train loss: 0.5844, Train Acc: 0.6368, Train f1-score: 0.7722, Val loss: 0.6123, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 314, Train loss: 0.5850, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.5627, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 315, Train loss: 0.5843, Train Acc: 0.6257, Train f1-score: 0.7196, Val loss: 0.5932, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 316, Train loss: 0.5797, Train Acc: 0.6618, Train f1-score: 0.7722, Val loss: 0.5919, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 317, Train loss: 0.5689, Train Acc: 0.6569, Train f1-score: 0.7196, Val loss: 0.5927, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 318, Train loss: 0.5726, Train Acc: 0.6569, Train f1-score: 0.7196, Val loss: 0.6014, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 319, Train loss: 0.5703, Train Acc: 0.6882, Train f1-score: 0.7196, Val loss: 0.5899, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 320, Train loss: 0.5725, Train Acc: 0.6694, Train f1-score: 0.7196, Val loss: 0.6267, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 321, Train loss: 0.5845, Train Acc: 0.6569, Train f1-score: 0.7196, Val loss: 0.5613, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 322, Train loss: 0.5866, Train Acc: 0.6181, Train f1-score: 0.7722, Val loss: 0.5955, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 323, Train loss: 0.5731, Train Acc: 0.6382, Train f1-score: 0.7196, Val loss: 0.5689, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 324, Train loss: 0.5732, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.5640, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 325, Train loss: 0.5808, Train Acc: 0.6431, Train f1-score: 0.7722, Val loss: 0.5934, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 326, Train loss: 0.5719, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.5702, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 327, Train loss: 0.5666, Train Acc: 0.6507, Train f1-score: 0.7196, Val loss: 0.5922, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 328, Train loss: 0.5633, Train Acc: 0.6819, Train f1-score: 0.7196, Val loss: 0.5831, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 329, Train loss: 0.5620, Train Acc: 0.6757, Train f1-score: 0.7196, Val loss: 0.5670, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 330, Train loss: 0.5522, Train Acc: 0.7194, Train f1-score: 0.7196, Val loss: 0.5939, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 331, Train loss: 0.5589, Train Acc: 0.7167, Train f1-score: 0.8338, Val loss: 0.5866, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 332, Train loss: 0.6059, Train Acc: 0.6493, Train f1-score: 0.7722, Val loss: 0.5852, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 333, Train loss: 0.5617, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.5654, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 334, Train loss: 0.5817, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.5794, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 335, Train loss: 0.5591, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.5756, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 336, Train loss: 0.5758, Train Acc: 0.6319, Train f1-score: 0.7196, Val loss: 0.5785, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 337, Train loss: 0.5641, Train Acc: 0.6569, Train f1-score: 0.7196, Val loss: 0.5676, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 338, Train loss: 0.5912, Train Acc: 0.6618, Train f1-score: 0.7778, Val loss: 0.5747, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 339, Train loss: 0.5580, Train Acc: 0.6819, Train f1-score: 0.7196, Val loss: 0.5636, Val Acc: 0.7500, Val f1-score: 0.7421,\n",
      "Epoch: 340, Train loss: 0.5879, Train Acc: 0.6854, Train f1-score: 0.8338, Val loss: 0.5696, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 341, Train loss: 0.5776, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.5755, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 342, Train loss: 0.5732, Train Acc: 0.6694, Train f1-score: 0.7196, Val loss: 0.5951, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 343, Train loss: 0.5549, Train Acc: 0.6917, Train f1-score: 0.8338, Val loss: 0.5757, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 344, Train loss: 0.6055, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.5596, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 345, Train loss: 0.5631, Train Acc: 0.6694, Train f1-score: 0.7196, Val loss: 0.5717, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 346, Train loss: 0.5606, Train Acc: 0.6757, Train f1-score: 0.7196, Val loss: 0.5831, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 347, Train loss: 0.5639, Train Acc: 0.6806, Train f1-score: 0.7778, Val loss: 0.6017, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 348, Train loss: 0.5523, Train Acc: 0.6819, Train f1-score: 0.7196, Val loss: 0.5908, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 349, Train loss: 0.5550, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.5809, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 350, Train loss: 0.5933, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.5676, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 351, Train loss: 0.5664, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.5833, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 352, Train loss: 0.5652, Train Acc: 0.7042, Train f1-score: 0.8338, Val loss: 0.5930, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 353, Train loss: 0.5520, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.5997, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 354, Train loss: 0.5496, Train Acc: 0.6868, Train f1-score: 0.7778, Val loss: 0.5800, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 355, Train loss: 0.5896, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.5687, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 356, Train loss: 0.5577, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.5822, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 357, Train loss: 0.5884, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.5706, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 358, Train loss: 0.5546, Train Acc: 0.7104, Train f1-score: 0.8338, Val loss: 0.5827, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 359, Train loss: 0.5840, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.5711, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 360, Train loss: 0.5588, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.5865, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 361, Train loss: 0.5852, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5746, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 362, Train loss: 0.5520, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5875, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 363, Train loss: 0.5808, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.5745, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 364, Train loss: 0.5580, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5904, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 365, Train loss: 0.5595, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5923, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 366, Train loss: 0.5691, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.6069, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 367, Train loss: 0.5447, Train Acc: 0.7167, Train f1-score: 0.8317, Val loss: 0.5828, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 368, Train loss: 0.5788, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 0.5856, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 369, Train loss: 0.5479, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5854, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 370, Train loss: 0.5612, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5897, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 371, Train loss: 0.5663, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.5913, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 372, Train loss: 0.5482, Train Acc: 0.7167, Train f1-score: 0.8338, Val loss: 0.5855, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 373, Train loss: 0.5697, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.5945, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 374, Train loss: 0.5522, Train Acc: 0.7056, Train f1-score: 0.7720, Val loss: 0.6136, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 375, Train loss: 0.5789, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5840, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 376, Train loss: 0.5536, Train Acc: 0.7056, Train f1-score: 0.7720, Val loss: 0.6118, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 377, Train loss: 0.5873, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.5781, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 378, Train loss: 0.5494, Train Acc: 0.7118, Train f1-score: 0.7720, Val loss: 0.5923, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 379, Train loss: 0.5693, Train Acc: 0.7465, Train f1-score: 0.8889, Val loss: 0.5953, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 380, Train loss: 0.5501, Train Acc: 0.7118, Train f1-score: 0.7720, Val loss: 0.5900, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 381, Train loss: 0.5770, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.5749, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 382, Train loss: 0.5494, Train Acc: 0.6993, Train f1-score: 0.7720, Val loss: 0.5920, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 383, Train loss: 0.5686, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5968, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 384, Train loss: 0.5431, Train Acc: 0.7229, Train f1-score: 0.8317, Val loss: 0.5958, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 385, Train loss: 0.5754, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.5774, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 386, Train loss: 0.5498, Train Acc: 0.7118, Train f1-score: 0.7720, Val loss: 0.5947, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 387, Train loss: 0.5706, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.6035, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 388, Train loss: 0.5445, Train Acc: 0.7056, Train f1-score: 0.7720, Val loss: 0.6053, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 389, Train loss: 0.5691, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.6015, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 390, Train loss: 0.5458, Train Acc: 0.7118, Train f1-score: 0.7720, Val loss: 0.5937, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 391, Train loss: 0.5669, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.6295, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 392, Train loss: 0.5369, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.6479, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 393, Train loss: 0.5351, Train Acc: 0.7167, Train f1-score: 0.8338, Val loss: 0.6424, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 394, Train loss: 0.5421, Train Acc: 0.7465, Train f1-score: 0.8889, Val loss: 0.5939, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 395, Train loss: 0.5453, Train Acc: 0.7167, Train f1-score: 0.8338, Val loss: 0.6245, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 396, Train loss: 0.5397, Train Acc: 0.7181, Train f1-score: 0.7778, Val loss: 0.5956, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 397, Train loss: 0.5681, Train Acc: 0.7104, Train f1-score: 0.8338, Val loss: 0.6245, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 398, Train loss: 0.5356, Train Acc: 0.7354, Train f1-score: 0.8317, Val loss: 0.6104, Val Acc: 0.6875, Val f1-score: 0.6685,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 399, Train loss: 0.5789, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.5868, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 400, Train loss: 0.5454, Train Acc: 0.7167, Train f1-score: 0.8338, Val loss: 0.5976, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "GIN accuracy: 0.4736842215061188\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 129 131 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161] TEST: [128 130 132 133 134 135 136 137 138 139 140 141 142 143 144 145]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 0.8662, Train Acc: 0.5146, Train f1-score: 0.6667, Val loss: 0.7604, Val Acc: 0.4375, Val f1-score: 0.2663,\n",
      "Epoch: 001, Train loss: 0.7123, Train Acc: 0.4847, Train f1-score: 0.5786, Val loss: 0.6991, Val Acc: 0.4375, Val f1-score: 0.2663,\n",
      "Epoch: 002, Train loss: 0.6913, Train Acc: 0.5660, Train f1-score: 0.6099, Val loss: 0.6942, Val Acc: 0.6250, Val f1-score: 0.5875,\n",
      "Epoch: 003, Train loss: 0.6915, Train Acc: 0.5396, Train f1-score: 0.6625, Val loss: 0.6912, Val Acc: 0.5000, Val f1-score: 0.4841,\n",
      "Epoch: 004, Train loss: 0.6903, Train Acc: 0.5472, Train f1-score: 0.6099, Val loss: 0.6931, Val Acc: 0.6250, Val f1-score: 0.5875,\n",
      "Epoch: 005, Train loss: 0.6900, Train Acc: 0.5535, Train f1-score: 0.6099, Val loss: 0.6926, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 006, Train loss: 0.6892, Train Acc: 0.5521, Train f1-score: 0.6667, Val loss: 0.6924, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 007, Train loss: 0.6892, Train Acc: 0.5535, Train f1-score: 0.6099, Val loss: 0.6914, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 008, Train loss: 0.6889, Train Acc: 0.5569, Train f1-score: 0.7214, Val loss: 0.6903, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 009, Train loss: 0.6880, Train Acc: 0.5632, Train f1-score: 0.7214, Val loss: 0.6910, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 010, Train loss: 0.6874, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6927, Val Acc: 0.6250, Val f1-score: 0.5875,\n",
      "Epoch: 011, Train loss: 0.6873, Train Acc: 0.5694, Train f1-score: 0.7214, Val loss: 0.6905, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 012, Train loss: 0.6868, Train Acc: 0.5694, Train f1-score: 0.7214, Val loss: 0.6907, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 013, Train loss: 0.6871, Train Acc: 0.5583, Train f1-score: 0.6667, Val loss: 0.6908, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 014, Train loss: 0.6868, Train Acc: 0.5583, Train f1-score: 0.6667, Val loss: 0.6901, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 015, Train loss: 0.6872, Train Acc: 0.5458, Train f1-score: 0.6667, Val loss: 0.6893, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 016, Train loss: 0.6863, Train Acc: 0.5632, Train f1-score: 0.7214, Val loss: 0.6883, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 017, Train loss: 0.6864, Train Acc: 0.5507, Train f1-score: 0.7214, Val loss: 0.6884, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 018, Train loss: 0.6864, Train Acc: 0.5507, Train f1-score: 0.7214, Val loss: 0.6892, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 019, Train loss: 0.6861, Train Acc: 0.5458, Train f1-score: 0.6625, Val loss: 0.6877, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 020, Train loss: 0.6852, Train Acc: 0.5583, Train f1-score: 0.6625, Val loss: 0.6874, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 021, Train loss: 0.6846, Train Acc: 0.5646, Train f1-score: 0.6625, Val loss: 0.6879, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 022, Train loss: 0.6847, Train Acc: 0.5569, Train f1-score: 0.7214, Val loss: 0.6854, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 023, Train loss: 0.6831, Train Acc: 0.5694, Train f1-score: 0.7214, Val loss: 0.6898, Val Acc: 0.6875, Val f1-score: 0.6685,\n",
      "Epoch: 024, Train loss: 0.6849, Train Acc: 0.5382, Train f1-score: 0.7214, Val loss: 0.6852, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 025, Train loss: 0.6822, Train Acc: 0.5632, Train f1-score: 0.7214, Val loss: 0.6853, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 026, Train loss: 0.6846, Train Acc: 0.5694, Train f1-score: 0.7214, Val loss: 0.6843, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 027, Train loss: 0.6836, Train Acc: 0.5583, Train f1-score: 0.6625, Val loss: 0.6838, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 028, Train loss: 0.6816, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6837, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 029, Train loss: 0.6818, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6830, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 030, Train loss: 0.6815, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6811, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 031, Train loss: 0.6802, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6853, Val Acc: 0.7500, Val f1-score: 0.7421,\n",
      "Epoch: 032, Train loss: 0.6833, Train Acc: 0.5569, Train f1-score: 0.7214, Val loss: 0.6797, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 033, Train loss: 0.6790, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6792, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 034, Train loss: 0.6812, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6842, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 035, Train loss: 0.6813, Train Acc: 0.5646, Train f1-score: 0.6625, Val loss: 0.6805, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 036, Train loss: 0.6789, Train Acc: 0.5694, Train f1-score: 0.7214, Val loss: 0.6776, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 037, Train loss: 0.6797, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6767, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 038, Train loss: 0.6788, Train Acc: 0.5632, Train f1-score: 0.7214, Val loss: 0.6785, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 039, Train loss: 0.6759, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6799, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 040, Train loss: 0.6749, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6766, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 041, Train loss: 0.6773, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6782, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 042, Train loss: 0.6767, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6764, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 043, Train loss: 0.6739, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6768, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 044, Train loss: 0.6735, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6786, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 045, Train loss: 0.6778, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6773, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 046, Train loss: 0.6748, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6788, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 047, Train loss: 0.6757, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6761, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 048, Train loss: 0.6721, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6771, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 049, Train loss: 0.6752, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6769, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 050, Train loss: 0.6728, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6759, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 051, Train loss: 0.6720, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6797, Val Acc: 0.7500, Val f1-score: 0.7421,\n",
      "Epoch: 052, Train loss: 0.6725, Train Acc: 0.5757, Train f1-score: 0.7214, Val loss: 0.6718, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 053, Train loss: 0.6748, Train Acc: 0.5646, Train f1-score: 0.6625, Val loss: 0.6741, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 054, Train loss: 0.6704, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6741, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 055, Train loss: 0.6728, Train Acc: 0.5882, Train f1-score: 0.7214, Val loss: 0.6756, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 056, Train loss: 0.6702, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6760, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 057, Train loss: 0.6718, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6770, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 058, Train loss: 0.6718, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6776, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 059, Train loss: 0.6703, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6775, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 060, Train loss: 0.6698, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6762, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 061, Train loss: 0.6709, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6771, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 062, Train loss: 0.6697, Train Acc: 0.5931, Train f1-score: 0.7778, Val loss: 0.6791, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 063, Train loss: 0.6700, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6760, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 064, Train loss: 0.6701, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6774, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 065, Train loss: 0.6698, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6761, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 066, Train loss: 0.6700, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6783, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 067, Train loss: 0.6681, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6736, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 068, Train loss: 0.6719, Train Acc: 0.5993, Train f1-score: 0.7778, Val loss: 0.6762, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 069, Train loss: 0.6679, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6775, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 070, Train loss: 0.6666, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6760, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 071, Train loss: 0.6690, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6777, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 072, Train loss: 0.6673, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6773, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 073, Train loss: 0.6667, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6747, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 074, Train loss: 0.6692, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6739, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 075, Train loss: 0.6656, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6769, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 076, Train loss: 0.6690, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6761, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 077, Train loss: 0.6669, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 078, Train loss: 0.6665, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6734, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 079, Train loss: 0.6685, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6753, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 080, Train loss: 0.6667, Train Acc: 0.5757, Train f1-score: 0.7143, Val loss: 0.6759, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 081, Train loss: 0.6649, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6746, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 082, Train loss: 0.6653, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6750, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 083, Train loss: 0.6640, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6756, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 084, Train loss: 0.6649, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6757, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 085, Train loss: 0.6657, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6744, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 086, Train loss: 0.6641, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6757, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 087, Train loss: 0.6656, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6755, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 088, Train loss: 0.6639, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6727, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 089, Train loss: 0.6646, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6745, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 090, Train loss: 0.6645, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6741, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 091, Train loss: 0.6628, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6752, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 092, Train loss: 0.6639, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6719, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 093, Train loss: 0.6616, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6724, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 094, Train loss: 0.6664, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6705, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 095, Train loss: 0.6641, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6729, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 096, Train loss: 0.6630, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6715, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 097, Train loss: 0.6642, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6728, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 098, Train loss: 0.6619, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6719, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 099, Train loss: 0.6609, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6709, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 100, Train loss: 0.6620, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6712, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 101, Train loss: 0.6621, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6710, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 102, Train loss: 0.6618, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6720, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 103, Train loss: 0.6608, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6728, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 104, Train loss: 0.6624, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6704, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 105, Train loss: 0.6612, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6720, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 106, Train loss: 0.6605, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6699, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 107, Train loss: 0.6606, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6693, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 108, Train loss: 0.6600, Train Acc: 0.5806, Train f1-score: 0.7778, Val loss: 0.6673, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 109, Train loss: 0.6596, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6716, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 110, Train loss: 0.6618, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6715, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 111, Train loss: 0.6600, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6683, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 112, Train loss: 0.6600, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6708, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 113, Train loss: 0.6587, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6687, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 114, Train loss: 0.6600, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6696, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 115, Train loss: 0.6596, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6715, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 116, Train loss: 0.6589, Train Acc: 0.5868, Train f1-score: 0.7778, Val loss: 0.6673, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 117, Train loss: 0.6576, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6679, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 118, Train loss: 0.6594, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6710, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 119, Train loss: 0.6578, Train Acc: 0.6042, Train f1-score: 0.8328, Val loss: 0.6698, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 120, Train loss: 0.6584, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6700, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 121, Train loss: 0.6596, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6717, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 122, Train loss: 0.6590, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6681, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 123, Train loss: 0.6573, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6667, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 124, Train loss: 0.6583, Train Acc: 0.5868, Train f1-score: 0.7750, Val loss: 0.6693, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 125, Train loss: 0.6587, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6678, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 126, Train loss: 0.6575, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6657, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 127, Train loss: 0.6574, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6643, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 128, Train loss: 0.6607, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6651, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 129, Train loss: 0.6609, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6667, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 130, Train loss: 0.6605, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6674, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 131, Train loss: 0.6592, Train Acc: 0.5743, Train f1-score: 0.7750, Val loss: 0.6663, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 132, Train loss: 0.6568, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6692, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 133, Train loss: 0.6567, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6673, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 134, Train loss: 0.6572, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6668, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 135, Train loss: 0.6578, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6661, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 136, Train loss: 0.6588, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6645, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 137, Train loss: 0.6607, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6671, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 138, Train loss: 0.6568, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6666, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 139, Train loss: 0.6544, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6658, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 140, Train loss: 0.6561, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6661, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 141, Train loss: 0.6569, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6650, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 142, Train loss: 0.6583, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6657, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 143, Train loss: 0.6577, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6654, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 144, Train loss: 0.6597, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6622, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 145, Train loss: 0.6592, Train Acc: 0.5632, Train f1-score: 0.7143, Val loss: 0.6635, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 146, Train loss: 0.6544, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6626, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 147, Train loss: 0.6581, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6623, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 148, Train loss: 0.6580, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6652, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 149, Train loss: 0.6555, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6639, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 150, Train loss: 0.6555, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6646, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 151, Train loss: 0.6558, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6647, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 152, Train loss: 0.6556, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6640, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 153, Train loss: 0.6536, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6653, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 154, Train loss: 0.6548, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6688, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 155, Train loss: 0.6541, Train Acc: 0.5757, Train f1-score: 0.7143, Val loss: 0.6669, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 156, Train loss: 0.6548, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6647, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 157, Train loss: 0.6552, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6628, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 158, Train loss: 0.6538, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6612, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 159, Train loss: 0.6591, Train Acc: 0.5729, Train f1-score: 0.8328, Val loss: 0.6621, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 160, Train loss: 0.6548, Train Acc: 0.5868, Train f1-score: 0.7750, Val loss: 0.6639, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 161, Train loss: 0.6546, Train Acc: 0.5681, Train f1-score: 0.7750, Val loss: 0.6677, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 162, Train loss: 0.6533, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6633, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 163, Train loss: 0.6552, Train Acc: 0.5729, Train f1-score: 0.8328, Val loss: 0.6650, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 164, Train loss: 0.6519, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6654, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 165, Train loss: 0.6537, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6683, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 166, Train loss: 0.6524, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6652, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 167, Train loss: 0.6547, Train Acc: 0.5743, Train f1-score: 0.7750, Val loss: 0.6678, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 168, Train loss: 0.6540, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6672, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 169, Train loss: 0.6530, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6691, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 170, Train loss: 0.6509, Train Acc: 0.6104, Train f1-score: 0.8328, Val loss: 0.6647, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 171, Train loss: 0.6534, Train Acc: 0.5694, Train f1-score: 0.7143, Val loss: 0.6635, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 172, Train loss: 0.6541, Train Acc: 0.5681, Train f1-score: 0.7750, Val loss: 0.6645, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 173, Train loss: 0.6531, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6635, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 174, Train loss: 0.6520, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6659, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 175, Train loss: 0.6536, Train Acc: 0.5792, Train f1-score: 0.8328, Val loss: 0.6628, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 176, Train loss: 0.6525, Train Acc: 0.5681, Train f1-score: 0.7750, Val loss: 0.6637, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 177, Train loss: 0.6521, Train Acc: 0.5743, Train f1-score: 0.7750, Val loss: 0.6650, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 178, Train loss: 0.6525, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6673, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 179, Train loss: 0.6512, Train Acc: 0.5868, Train f1-score: 0.7750, Val loss: 0.6667, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 180, Train loss: 0.6514, Train Acc: 0.5806, Train f1-score: 0.7750, Val loss: 0.6668, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 181, Train loss: 0.6507, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6633, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 182, Train loss: 0.6513, Train Acc: 0.5632, Train f1-score: 0.7143, Val loss: 0.6626, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 183, Train loss: 0.6533, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6639, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 184, Train loss: 0.6533, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6680, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 185, Train loss: 0.6505, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6689, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 186, Train loss: 0.6501, Train Acc: 0.6042, Train f1-score: 0.8328, Val loss: 0.6644, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 187, Train loss: 0.6521, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6693, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 188, Train loss: 0.6495, Train Acc: 0.6042, Train f1-score: 0.8328, Val loss: 0.6628, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 189, Train loss: 0.6530, Train Acc: 0.5729, Train f1-score: 0.8328, Val loss: 0.6626, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 190, Train loss: 0.6501, Train Acc: 0.5632, Train f1-score: 0.7143, Val loss: 0.6649, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 191, Train loss: 0.6529, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6684, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 192, Train loss: 0.6491, Train Acc: 0.5917, Train f1-score: 0.8328, Val loss: 0.6630, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 193, Train loss: 0.6530, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6685, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 194, Train loss: 0.6478, Train Acc: 0.6042, Train f1-score: 0.8328, Val loss: 0.6635, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 195, Train loss: 0.6516, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6700, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 196, Train loss: 0.6477, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6651, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 197, Train loss: 0.6529, Train Acc: 0.5632, Train f1-score: 0.7143, Val loss: 0.6687, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 198, Train loss: 0.6482, Train Acc: 0.6042, Train f1-score: 0.8328, Val loss: 0.6621, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 199, Train loss: 0.6515, Train Acc: 0.5507, Train f1-score: 0.7143, Val loss: 0.6686, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 200, Train loss: 0.6463, Train Acc: 0.6167, Train f1-score: 0.8328, Val loss: 0.6626, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 201, Train loss: 0.6498, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6697, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 202, Train loss: 0.6461, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6653, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 203, Train loss: 0.6521, Train Acc: 0.5569, Train f1-score: 0.7143, Val loss: 0.6687, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 204, Train loss: 0.6455, Train Acc: 0.6167, Train f1-score: 0.8328, Val loss: 0.6622, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 205, Train loss: 0.6499, Train Acc: 0.5507, Train f1-score: 0.7143, Val loss: 0.6689, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 206, Train loss: 0.6450, Train Acc: 0.6167, Train f1-score: 0.8328, Val loss: 0.6632, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 207, Train loss: 0.6481, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6644, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 208, Train loss: 0.6417, Train Acc: 0.6229, Train f1-score: 0.8328, Val loss: 0.6625, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 209, Train loss: 0.6463, Train Acc: 0.5757, Train f1-score: 0.7143, Val loss: 0.6614, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 210, Train loss: 0.6391, Train Acc: 0.6167, Train f1-score: 0.8328, Val loss: 0.6624, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 211, Train loss: 0.6485, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6630, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 212, Train loss: 0.6414, Train Acc: 0.6167, Train f1-score: 0.8328, Val loss: 0.6622, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 213, Train loss: 0.6521, Train Acc: 0.5618, Train f1-score: 0.7750, Val loss: 0.6702, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 214, Train loss: 0.6446, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6642, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 215, Train loss: 0.6409, Train Acc: 0.6104, Train f1-score: 0.8328, Val loss: 0.6623, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 216, Train loss: 0.6530, Train Acc: 0.5507, Train f1-score: 0.7143, Val loss: 0.6670, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 217, Train loss: 0.6455, Train Acc: 0.6104, Train f1-score: 0.8328, Val loss: 0.6665, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 218, Train loss: 0.6442, Train Acc: 0.5979, Train f1-score: 0.8328, Val loss: 0.6641, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 219, Train loss: 0.6404, Train Acc: 0.5896, Train f1-score: 0.6494, Val loss: 0.6631, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 220, Train loss: 0.6482, Train Acc: 0.5729, Train f1-score: 0.8328, Val loss: 0.6627, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 221, Train loss: 0.6398, Train Acc: 0.6069, Train f1-score: 0.6990, Val loss: 0.6621, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 222, Train loss: 0.6462, Train Acc: 0.5729, Train f1-score: 0.8328, Val loss: 0.6622, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 223, Train loss: 0.6374, Train Acc: 0.6229, Train f1-score: 0.8328, Val loss: 0.6605, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 224, Train loss: 0.6486, Train Acc: 0.5396, Train f1-score: 0.6494, Val loss: 0.6609, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 225, Train loss: 0.6463, Train Acc: 0.5507, Train f1-score: 0.7143, Val loss: 0.6622, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 226, Train loss: 0.6422, Train Acc: 0.5521, Train f1-score: 0.6494, Val loss: 0.6628, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 227, Train loss: 0.6373, Train Acc: 0.5833, Train f1-score: 0.6494, Val loss: 0.6627, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 228, Train loss: 0.6435, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.6632, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 229, Train loss: 0.6487, Train Acc: 0.5556, Train f1-score: 0.7750, Val loss: 0.6648, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 230, Train loss: 0.6360, Train Acc: 0.5958, Train f1-score: 0.6494, Val loss: 0.6638, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 231, Train loss: 0.6477, Train Acc: 0.5632, Train f1-score: 0.6990, Val loss: 0.6640, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 232, Train loss: 0.6471, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6661, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 233, Train loss: 0.6359, Train Acc: 0.6056, Train f1-score: 0.7750, Val loss: 0.6649, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 234, Train loss: 0.6485, Train Acc: 0.5632, Train f1-score: 0.6990, Val loss: 0.6661, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 235, Train loss: 0.6334, Train Acc: 0.6181, Train f1-score: 0.7750, Val loss: 0.6672, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 236, Train loss: 0.6477, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6641, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 237, Train loss: 0.6340, Train Acc: 0.6243, Train f1-score: 0.7750, Val loss: 0.6661, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 238, Train loss: 0.6478, Train Acc: 0.5743, Train f1-score: 0.7750, Val loss: 0.6673, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 239, Train loss: 0.6361, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6642, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 240, Train loss: 0.6425, Train Acc: 0.5681, Train f1-score: 0.7750, Val loss: 0.6650, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 241, Train loss: 0.6444, Train Acc: 0.5569, Train f1-score: 0.6990, Val loss: 0.6651, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 242, Train loss: 0.6311, Train Acc: 0.6243, Train f1-score: 0.7750, Val loss: 0.6673, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 243, Train loss: 0.6469, Train Acc: 0.5694, Train f1-score: 0.6990, Val loss: 0.6654, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 244, Train loss: 0.6306, Train Acc: 0.6243, Train f1-score: 0.7750, Val loss: 0.6651, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 245, Train loss: 0.6433, Train Acc: 0.5632, Train f1-score: 0.6990, Val loss: 0.6662, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 246, Train loss: 0.6299, Train Acc: 0.6306, Train f1-score: 0.7750, Val loss: 0.6662, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 247, Train loss: 0.6413, Train Acc: 0.5854, Train f1-score: 0.8286, Val loss: 0.6671, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 248, Train loss: 0.6430, Train Acc: 0.5632, Train f1-score: 0.6990, Val loss: 0.6665, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 249, Train loss: 0.6293, Train Acc: 0.6306, Train f1-score: 0.7750, Val loss: 0.6668, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 250, Train loss: 0.6426, Train Acc: 0.5854, Train f1-score: 0.8328, Val loss: 0.6662, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 251, Train loss: 0.6349, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6642, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 252, Train loss: 0.6420, Train Acc: 0.5917, Train f1-score: 0.8286, Val loss: 0.6681, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 253, Train loss: 0.6276, Train Acc: 0.6292, Train f1-score: 0.8286, Val loss: 0.6649, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 254, Train loss: 0.6402, Train Acc: 0.5743, Train f1-score: 0.7662, Val loss: 0.6669, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 255, Train loss: 0.6423, Train Acc: 0.5694, Train f1-score: 0.6990, Val loss: 0.6662, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 256, Train loss: 0.6264, Train Acc: 0.6479, Train f1-score: 0.8286, Val loss: 0.6655, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 257, Train loss: 0.6309, Train Acc: 0.6069, Train f1-score: 0.6990, Val loss: 0.6634, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 258, Train loss: 0.6301, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6637, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 259, Train loss: 0.6284, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.6614, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 260, Train loss: 0.6309, Train Acc: 0.6257, Train f1-score: 0.6990, Val loss: 0.6619, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 261, Train loss: 0.6413, Train Acc: 0.5917, Train f1-score: 0.8286, Val loss: 0.6709, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 262, Train loss: 0.6321, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6629, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 263, Train loss: 0.6296, Train Acc: 0.6007, Train f1-score: 0.6990, Val loss: 0.6636, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 264, Train loss: 0.6306, Train Acc: 0.6194, Train f1-score: 0.6990, Val loss: 0.6614, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 265, Train loss: 0.6311, Train Acc: 0.6007, Train f1-score: 0.6990, Val loss: 0.6651, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 266, Train loss: 0.6296, Train Acc: 0.6021, Train f1-score: 0.6250, Val loss: 0.6625, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 267, Train loss: 0.6269, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.6632, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 268, Train loss: 0.6254, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.6619, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 269, Train loss: 0.6264, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.6622, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 270, Train loss: 0.6339, Train Acc: 0.6021, Train f1-score: 0.6250, Val loss: 0.6648, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 271, Train loss: 0.6263, Train Acc: 0.6257, Train f1-score: 0.6990, Val loss: 0.6660, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 272, Train loss: 0.6262, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6641, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 273, Train loss: 0.6269, Train Acc: 0.6194, Train f1-score: 0.6990, Val loss: 0.6638, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 274, Train loss: 0.6405, Train Acc: 0.6167, Train f1-score: 0.8286, Val loss: 0.6719, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 275, Train loss: 0.6278, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6631, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 276, Train loss: 0.6226, Train Acc: 0.6319, Train f1-score: 0.6990, Val loss: 0.6647, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 277, Train loss: 0.6355, Train Acc: 0.6007, Train f1-score: 0.6990, Val loss: 0.6708, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 278, Train loss: 0.6286, Train Acc: 0.6257, Train f1-score: 0.6990, Val loss: 0.6631, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 279, Train loss: 0.6263, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.6615, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 280, Train loss: 0.6381, Train Acc: 0.6229, Train f1-score: 0.8286, Val loss: 0.6717, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 281, Train loss: 0.6313, Train Acc: 0.6292, Train f1-score: 0.8286, Val loss: 0.6683, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 282, Train loss: 0.6336, Train Acc: 0.5931, Train f1-score: 0.7662, Val loss: 0.6713, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 283, Train loss: 0.6231, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6625, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 284, Train loss: 0.6364, Train Acc: 0.6167, Train f1-score: 0.8286, Val loss: 0.6677, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 285, Train loss: 0.6327, Train Acc: 0.6007, Train f1-score: 0.6990, Val loss: 0.6642, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 286, Train loss: 0.6201, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6617, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 287, Train loss: 0.6317, Train Acc: 0.6229, Train f1-score: 0.8286, Val loss: 0.6709, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 288, Train loss: 0.6328, Train Acc: 0.6181, Train f1-score: 0.7662, Val loss: 0.6664, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 289, Train loss: 0.6197, Train Acc: 0.6319, Train f1-score: 0.6990, Val loss: 0.6607, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 290, Train loss: 0.6301, Train Acc: 0.6167, Train f1-score: 0.8286, Val loss: 0.6662, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 291, Train loss: 0.6186, Train Acc: 0.6306, Train f1-score: 0.7662, Val loss: 0.6626, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 292, Train loss: 0.6336, Train Acc: 0.6104, Train f1-score: 0.8286, Val loss: 0.6720, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 293, Train loss: 0.6213, Train Acc: 0.6257, Train f1-score: 0.6990, Val loss: 0.6626, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 294, Train loss: 0.6160, Train Acc: 0.6319, Train f1-score: 0.6990, Val loss: 0.6631, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 295, Train loss: 0.6148, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.6629, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 296, Train loss: 0.6273, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6658, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 297, Train loss: 0.6132, Train Acc: 0.6319, Train f1-score: 0.6990, Val loss: 0.6623, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 298, Train loss: 0.6281, Train Acc: 0.6354, Train f1-score: 0.8286, Val loss: 0.6776, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 299, Train loss: 0.6301, Train Acc: 0.6229, Train f1-score: 0.8286, Val loss: 0.6726, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 300, Train loss: 0.6148, Train Acc: 0.6368, Train f1-score: 0.7662, Val loss: 0.6653, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 301, Train loss: 0.6144, Train Acc: 0.6444, Train f1-score: 0.6990, Val loss: 0.6665, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 302, Train loss: 0.6121, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6674, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 303, Train loss: 0.6112, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6683, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 304, Train loss: 0.6145, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6727, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 305, Train loss: 0.6138, Train Acc: 0.6194, Train f1-score: 0.6990, Val loss: 0.6689, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 306, Train loss: 0.6122, Train Acc: 0.6507, Train f1-score: 0.6990, Val loss: 0.6693, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 307, Train loss: 0.6195, Train Acc: 0.6257, Train f1-score: 0.6990, Val loss: 0.6696, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 308, Train loss: 0.6158, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6670, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 309, Train loss: 0.6128, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.6684, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 310, Train loss: 0.6145, Train Acc: 0.6194, Train f1-score: 0.6990, Val loss: 0.6693, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 311, Train loss: 0.6261, Train Acc: 0.6132, Train f1-score: 0.6990, Val loss: 0.6783, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 312, Train loss: 0.6155, Train Acc: 0.6729, Train f1-score: 0.8286, Val loss: 0.6697, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 313, Train loss: 0.6128, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6686, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 314, Train loss: 0.6121, Train Acc: 0.6431, Train f1-score: 0.7662, Val loss: 0.6720, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 315, Train loss: 0.6109, Train Acc: 0.6556, Train f1-score: 0.7662, Val loss: 0.6686, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 316, Train loss: 0.6077, Train Acc: 0.6347, Train f1-score: 0.5418, Val loss: 0.6679, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 317, Train loss: 0.6149, Train Acc: 0.6097, Train f1-score: 0.5418, Val loss: 0.6650, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 318, Train loss: 0.6053, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6706, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 319, Train loss: 0.6033, Train Acc: 0.6472, Train f1-score: 0.5418, Val loss: 0.6682, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 320, Train loss: 0.6151, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.6727, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 321, Train loss: 0.6083, Train Acc: 0.6222, Train f1-score: 0.5418, Val loss: 0.6694, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 322, Train loss: 0.6065, Train Acc: 0.6604, Train f1-score: 0.8286, Val loss: 0.6744, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 323, Train loss: 0.6115, Train Acc: 0.6479, Train f1-score: 0.8286, Val loss: 0.6817, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 324, Train loss: 0.6165, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6762, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 325, Train loss: 0.6071, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.6753, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 326, Train loss: 0.6056, Train Acc: 0.6285, Train f1-score: 0.5418, Val loss: 0.6720, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 327, Train loss: 0.6054, Train Acc: 0.6319, Train f1-score: 0.6990, Val loss: 0.6747, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 328, Train loss: 0.6024, Train Acc: 0.6410, Train f1-score: 0.5418, Val loss: 0.6759, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 329, Train loss: 0.6029, Train Acc: 0.6285, Train f1-score: 0.5418, Val loss: 0.6735, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 330, Train loss: 0.6025, Train Acc: 0.6458, Train f1-score: 0.6250, Val loss: 0.6720, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 331, Train loss: 0.5971, Train Acc: 0.6694, Train f1-score: 0.6990, Val loss: 0.6788, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 332, Train loss: 0.5987, Train Acc: 0.6472, Train f1-score: 0.5418, Val loss: 0.6813, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 333, Train loss: 0.6036, Train Acc: 0.6472, Train f1-score: 0.5418, Val loss: 0.6788, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 334, Train loss: 0.5949, Train Acc: 0.6694, Train f1-score: 0.6990, Val loss: 0.6769, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 335, Train loss: 0.5810, Train Acc: 0.6854, Train f1-score: 0.8286, Val loss: 0.6825, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 336, Train loss: 0.6373, Train Acc: 0.6354, Train f1-score: 0.8286, Val loss: 0.6808, Val Acc: 0.4375, Val f1-score: 0.4397,\n",
      "Epoch: 337, Train loss: 0.6126, Train Acc: 0.6479, Train f1-score: 0.8286, Val loss: 0.6765, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 338, Train loss: 0.5982, Train Acc: 0.6569, Train f1-score: 0.6990, Val loss: 0.6770, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 339, Train loss: 0.5915, Train Acc: 0.6806, Train f1-score: 0.7662, Val loss: 0.6736, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 340, Train loss: 0.5849, Train Acc: 0.6917, Train f1-score: 0.8286, Val loss: 0.6779, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 341, Train loss: 0.6020, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.6782, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 342, Train loss: 0.5953, Train Acc: 0.6444, Train f1-score: 0.6990, Val loss: 0.6789, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 343, Train loss: 0.6013, Train Acc: 0.6597, Train f1-score: 0.5418, Val loss: 0.6776, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 344, Train loss: 0.5916, Train Acc: 0.7042, Train f1-score: 0.8286, Val loss: 0.6823, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 345, Train loss: 0.5898, Train Acc: 0.6993, Train f1-score: 0.7662, Val loss: 0.6839, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 346, Train loss: 0.5858, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.6817, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 347, Train loss: 0.5953, Train Acc: 0.6285, Train f1-score: 0.5418, Val loss: 0.6885, Val Acc: 0.5000, Val f1-score: 0.4455,\n",
      "Epoch: 348, Train loss: 0.5880, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.6825, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 349, Train loss: 0.5809, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.6812, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 350, Train loss: 0.5789, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.6799, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 351, Train loss: 0.5880, Train Acc: 0.6771, Train f1-score: 0.6250, Val loss: 0.6930, Val Acc: 0.5625, Val f1-score: 0.4885,\n",
      "Epoch: 352, Train loss: 0.5811, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.7041, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 353, Train loss: 0.6336, Train Acc: 0.6354, Train f1-score: 0.8286, Val loss: 0.6916, Val Acc: 0.4375, Val f1-score: 0.4397,\n",
      "Epoch: 354, Train loss: 0.6033, Train Acc: 0.6792, Train f1-score: 0.8286, Val loss: 0.6831, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 355, Train loss: 0.5869, Train Acc: 0.6569, Train f1-score: 0.6990, Val loss: 0.6847, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 356, Train loss: 0.5790, Train Acc: 0.7042, Train f1-score: 0.8286, Val loss: 0.6811, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 357, Train loss: 0.5738, Train Acc: 0.7229, Train f1-score: 0.8286, Val loss: 0.6845, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 358, Train loss: 0.5739, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.6857, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 359, Train loss: 0.5694, Train Acc: 0.7229, Train f1-score: 0.8286, Val loss: 0.6865, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 360, Train loss: 0.5787, Train Acc: 0.6743, Train f1-score: 0.7778, Val loss: 0.7189, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 361, Train loss: 0.6598, Train Acc: 0.6528, Train f1-score: 0.8875, Val loss: 0.7451, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 362, Train loss: 0.6054, Train Acc: 0.6653, Train f1-score: 0.8875, Val loss: 0.7192, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 363, Train loss: 0.6051, Train Acc: 0.6778, Train f1-score: 0.8875, Val loss: 0.7370, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 364, Train loss: 0.6104, Train Acc: 0.6903, Train f1-score: 0.8875, Val loss: 0.7214, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 365, Train loss: 0.6050, Train Acc: 0.6965, Train f1-score: 0.8875, Val loss: 0.7294, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 366, Train loss: 0.6055, Train Acc: 0.6792, Train f1-score: 0.8286, Val loss: 0.6907, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 367, Train loss: 0.5869, Train Acc: 0.6854, Train f1-score: 0.8286, Val loss: 0.6972, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 368, Train loss: 0.5866, Train Acc: 0.6743, Train f1-score: 0.7662, Val loss: 0.6801, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 369, Train loss: 0.5884, Train Acc: 0.6604, Train f1-score: 0.8286, Val loss: 0.6856, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 370, Train loss: 0.5812, Train Acc: 0.6917, Train f1-score: 0.8286, Val loss: 0.6842, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 371, Train loss: 0.5802, Train Acc: 0.6917, Train f1-score: 0.8286, Val loss: 0.6864, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 372, Train loss: 0.5717, Train Acc: 0.7292, Train f1-score: 0.8286, Val loss: 0.7066, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 373, Train loss: 0.5925, Train Acc: 0.6729, Train f1-score: 0.8286, Val loss: 0.6863, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 374, Train loss: 0.5672, Train Acc: 0.7278, Train f1-score: 0.8875, Val loss: 0.7278, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 375, Train loss: 0.6118, Train Acc: 0.6729, Train f1-score: 0.8286, Val loss: 0.6839, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 376, Train loss: 0.5633, Train Acc: 0.7215, Train f1-score: 0.8875, Val loss: 0.7066, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 377, Train loss: 0.5901, Train Acc: 0.6854, Train f1-score: 0.8286, Val loss: 0.6832, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 378, Train loss: 0.5668, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.6858, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 379, Train loss: 0.5657, Train Acc: 0.7229, Train f1-score: 0.8286, Val loss: 0.7265, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 380, Train loss: 0.6216, Train Acc: 0.6590, Train f1-score: 0.8875, Val loss: 0.7045, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 381, Train loss: 0.5866, Train Acc: 0.6903, Train f1-score: 0.8875, Val loss: 0.7214, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 382, Train loss: 0.5998, Train Acc: 0.7090, Train f1-score: 0.8875, Val loss: 0.7224, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 383, Train loss: 0.6022, Train Acc: 0.7028, Train f1-score: 0.8875, Val loss: 0.7120, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 384, Train loss: 0.5923, Train Acc: 0.6917, Train f1-score: 0.8286, Val loss: 0.6980, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 385, Train loss: 0.5674, Train Acc: 0.7167, Train f1-score: 0.8286, Val loss: 0.6842, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 386, Train loss: 0.5656, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.6861, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 387, Train loss: 0.5611, Train Acc: 0.7278, Train f1-score: 0.8875, Val loss: 0.7414, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 388, Train loss: 0.6167, Train Acc: 0.6778, Train f1-score: 0.8875, Val loss: 0.7065, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 389, Train loss: 0.5795, Train Acc: 0.6917, Train f1-score: 0.8286, Val loss: 0.7013, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 390, Train loss: 0.5569, Train Acc: 0.7403, Train f1-score: 0.8875, Val loss: 0.6876, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 391, Train loss: 0.5566, Train Acc: 0.7215, Train f1-score: 0.8875, Val loss: 0.7387, Val Acc: 0.5625, Val f1-score: 0.5574,\n",
      "Epoch: 392, Train loss: 0.5995, Train Acc: 0.7042, Train f1-score: 0.8286, Val loss: 0.6993, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 393, Train loss: 0.5625, Train Acc: 0.7042, Train f1-score: 0.8286, Val loss: 0.6889, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 394, Train loss: 0.5641, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.7029, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 395, Train loss: 0.5567, Train Acc: 0.7417, Train f1-score: 0.8286, Val loss: 0.6899, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 396, Train loss: 0.5656, Train Acc: 0.7042, Train f1-score: 0.8328, Val loss: 0.8457, Val Acc: 0.5625, Val f1-score: 0.4962,\n",
      "Epoch: 397, Train loss: 0.6720, Train Acc: 0.6465, Train f1-score: 0.8875, Val loss: 0.7532, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 398, Train loss: 0.5906, Train Acc: 0.7215, Train f1-score: 0.8875, Val loss: 0.7038, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 399, Train loss: 0.5681, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.6882, Val Acc: 0.5625, Val f1-score: 0.5572,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Train loss: 0.5586, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.6921, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "GIN accuracy: 0.5789473652839661\n",
      "TRAIN:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145] TEST: [146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161]\n",
      "146\n",
      "16\n",
      "Epoch: 000, Train loss: 1.4584, Train Acc: 0.4861, Train f1-score: 0.5500, Val loss: 0.6847, Val Acc: 0.5625, Val f1-score: 0.4050,\n",
      "Epoch: 001, Train loss: 0.6999, Train Acc: 0.4799, Train f1-score: 0.5325, Val loss: 0.6908, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 002, Train loss: 0.6980, Train Acc: 0.5347, Train f1-score: 0.6099, Val loss: 0.6895, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 003, Train loss: 0.6979, Train Acc: 0.5472, Train f1-score: 0.6099, Val loss: 0.6886, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 004, Train loss: 0.6977, Train Acc: 0.5486, Train f1-score: 0.5500, Val loss: 0.6880, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 005, Train loss: 0.6974, Train Acc: 0.5535, Train f1-score: 0.6000, Val loss: 0.6871, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 006, Train loss: 0.6973, Train Acc: 0.5410, Train f1-score: 0.5418, Val loss: 0.6863, Val Acc: 0.5625, Val f1-score: 0.5359,\n",
      "Epoch: 007, Train loss: 0.6973, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6853, Val Acc: 0.6250, Val f1-score: 0.6131,\n",
      "Epoch: 008, Train loss: 0.6974, Train Acc: 0.5236, Train f1-score: 0.4462, Val loss: 0.6844, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 009, Train loss: 0.6975, Train Acc: 0.5424, Train f1-score: 0.4462, Val loss: 0.6834, Val Acc: 0.6875, Val f1-score: 0.6838,\n",
      "Epoch: 010, Train loss: 0.6975, Train Acc: 0.5549, Train f1-score: 0.4462, Val loss: 0.6822, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 011, Train loss: 0.6975, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6816, Val Acc: 0.8125, Val f1-score: 0.8132,\n",
      "Epoch: 012, Train loss: 0.6976, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6806, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 013, Train loss: 0.6975, Train Acc: 0.4986, Train f1-score: 0.4462, Val loss: 0.6797, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 014, Train loss: 0.6973, Train Acc: 0.4986, Train f1-score: 0.4462, Val loss: 0.6788, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 015, Train loss: 0.6972, Train Acc: 0.5049, Train f1-score: 0.4462, Val loss: 0.6778, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 016, Train loss: 0.6970, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6769, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 017, Train loss: 0.6967, Train Acc: 0.5174, Train f1-score: 0.4462, Val loss: 0.6762, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 018, Train loss: 0.6965, Train Acc: 0.5174, Train f1-score: 0.4462, Val loss: 0.6754, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 019, Train loss: 0.6962, Train Acc: 0.5174, Train f1-score: 0.4462, Val loss: 0.6745, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 020, Train loss: 0.6961, Train Acc: 0.5174, Train f1-score: 0.4462, Val loss: 0.6733, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 021, Train loss: 0.6957, Train Acc: 0.5049, Train f1-score: 0.4462, Val loss: 0.6729, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 022, Train loss: 0.6956, Train Acc: 0.5174, Train f1-score: 0.4462, Val loss: 0.6719, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 023, Train loss: 0.6952, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6709, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 024, Train loss: 0.6951, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6701, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 025, Train loss: 0.6947, Train Acc: 0.5049, Train f1-score: 0.4462, Val loss: 0.6692, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 026, Train loss: 0.6945, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6684, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 027, Train loss: 0.6942, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6676, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 028, Train loss: 0.6940, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6666, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 029, Train loss: 0.6938, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6660, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 030, Train loss: 0.6936, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6649, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 031, Train loss: 0.6933, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6643, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 032, Train loss: 0.6930, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6635, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 033, Train loss: 0.6928, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6627, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 034, Train loss: 0.6925, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6620, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 035, Train loss: 0.6922, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6612, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 036, Train loss: 0.6920, Train Acc: 0.5111, Train f1-score: 0.4462, Val loss: 0.6604, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 037, Train loss: 0.6917, Train Acc: 0.5222, Train f1-score: 0.5418, Val loss: 0.6594, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 038, Train loss: 0.6916, Train Acc: 0.5174, Train f1-score: 0.4462, Val loss: 0.6588, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 039, Train loss: 0.6913, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6582, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 040, Train loss: 0.6910, Train Acc: 0.5285, Train f1-score: 0.5418, Val loss: 0.6572, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 041, Train loss: 0.6907, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6564, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 042, Train loss: 0.6905, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6556, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 043, Train loss: 0.6903, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6547, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 044, Train loss: 0.6899, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6540, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 045, Train loss: 0.6898, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6531, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 046, Train loss: 0.6895, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6522, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 047, Train loss: 0.6895, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6515, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 048, Train loss: 0.6892, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6508, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 049, Train loss: 0.6889, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6499, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 050, Train loss: 0.6887, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6491, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 051, Train loss: 0.6886, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6485, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 052, Train loss: 0.6883, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6476, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 053, Train loss: 0.6880, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6468, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 054, Train loss: 0.6878, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6457, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 055, Train loss: 0.6875, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6450, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 056, Train loss: 0.6873, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6443, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 057, Train loss: 0.6870, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6435, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 058, Train loss: 0.6868, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6422, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 059, Train loss: 0.6865, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6416, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 060, Train loss: 0.6863, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6410, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 061, Train loss: 0.6860, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6402, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 062, Train loss: 0.6858, Train Acc: 0.5333, Train f1-score: 0.6250, Val loss: 0.6393, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 063, Train loss: 0.6856, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6380, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 064, Train loss: 0.6855, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6372, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 065, Train loss: 0.6852, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6367, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 066, Train loss: 0.6849, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6354, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 067, Train loss: 0.6847, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6349, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 068, Train loss: 0.6844, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6343, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 069, Train loss: 0.6842, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6333, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 070, Train loss: 0.6841, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6326, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 071, Train loss: 0.6839, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6317, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 072, Train loss: 0.6836, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6310, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 073, Train loss: 0.6836, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6300, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 074, Train loss: 0.6831, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6294, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 075, Train loss: 0.6829, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6292, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 076, Train loss: 0.6825, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6283, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 077, Train loss: 0.6823, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6274, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 078, Train loss: 0.6822, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6268, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 079, Train loss: 0.6819, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6261, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 080, Train loss: 0.6817, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6253, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 081, Train loss: 0.6815, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6247, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 082, Train loss: 0.6813, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6238, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 083, Train loss: 0.6813, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6231, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 084, Train loss: 0.6810, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6222, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 085, Train loss: 0.6806, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6216, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 086, Train loss: 0.6804, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6209, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 087, Train loss: 0.6804, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6199, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 088, Train loss: 0.6801, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6197, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 089, Train loss: 0.6797, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6190, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 090, Train loss: 0.6796, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6170, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 091, Train loss: 0.6795, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6175, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 092, Train loss: 0.6793, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6182, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 093, Train loss: 0.6789, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6148, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 094, Train loss: 0.6788, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6158, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 095, Train loss: 0.6783, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6149, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 096, Train loss: 0.6781, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6142, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 097, Train loss: 0.6780, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6141, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 098, Train loss: 0.6777, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6117, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 099, Train loss: 0.6782, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6121, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 100, Train loss: 0.6775, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6117, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 101, Train loss: 0.6769, Train Acc: 0.5382, Train f1-score: 0.6990, Val loss: 0.6118, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 102, Train loss: 0.6768, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6100, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 103, Train loss: 0.6765, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6098, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 104, Train loss: 0.6763, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6080, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 105, Train loss: 0.6764, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6091, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 106, Train loss: 0.6758, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6070, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 107, Train loss: 0.6760, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6056, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 108, Train loss: 0.6752, Train Acc: 0.5444, Train f1-score: 0.6990, Val loss: 0.6056, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 109, Train loss: 0.6753, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6022, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 110, Train loss: 0.6748, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6048, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 111, Train loss: 0.6748, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6029, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 112, Train loss: 0.6740, Train Acc: 0.5569, Train f1-score: 0.6990, Val loss: 0.6040, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 113, Train loss: 0.6742, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.6029, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 114, Train loss: 0.6739, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.5997, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 115, Train loss: 0.6737, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6016, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 116, Train loss: 0.6732, Train Acc: 0.5507, Train f1-score: 0.6990, Val loss: 0.6008, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 117, Train loss: 0.6732, Train Acc: 0.5333, Train f1-score: 0.6250, Val loss: 0.6010, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 118, Train loss: 0.6725, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.5979, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 119, Train loss: 0.6734, Train Acc: 0.5333, Train f1-score: 0.6250, Val loss: 0.5968, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 120, Train loss: 0.6716, Train Acc: 0.5569, Train f1-score: 0.6990, Val loss: 0.6001, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 121, Train loss: 0.6719, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.5965, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 122, Train loss: 0.6718, Train Acc: 0.5458, Train f1-score: 0.6250, Val loss: 0.5947, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 123, Train loss: 0.6710, Train Acc: 0.5333, Train f1-score: 0.6250, Val loss: 0.5952, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 124, Train loss: 0.6710, Train Acc: 0.5396, Train f1-score: 0.6250, Val loss: 0.5931, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 125, Train loss: 0.6705, Train Acc: 0.5458, Train f1-score: 0.6250, Val loss: 0.5940, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 126, Train loss: 0.6703, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5900, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 127, Train loss: 0.6700, Train Acc: 0.5458, Train f1-score: 0.6250, Val loss: 0.5962, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 128, Train loss: 0.6699, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5919, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 129, Train loss: 0.6691, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5922, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 130, Train loss: 0.6687, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5861, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 131, Train loss: 0.6690, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5913, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 132, Train loss: 0.6681, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5890, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 133, Train loss: 0.6675, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5884, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 134, Train loss: 0.6676, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5900, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 135, Train loss: 0.6678, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5832, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 136, Train loss: 0.6665, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5873, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 137, Train loss: 0.6680, Train Acc: 0.5458, Train f1-score: 0.6250, Val loss: 0.5846, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 138, Train loss: 0.6663, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5866, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 139, Train loss: 0.6665, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5844, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 140, Train loss: 0.6660, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5835, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 141, Train loss: 0.6669, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5855, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 142, Train loss: 0.6654, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5825, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 143, Train loss: 0.6654, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5804, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 144, Train loss: 0.6654, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5759, Val Acc: 0.7500, Val f1-score: 0.7227,\n",
      "Epoch: 145, Train loss: 0.6643, Train Acc: 0.5708, Train f1-score: 0.6250, Val loss: 0.5828, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 146, Train loss: 0.6639, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5780, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 147, Train loss: 0.6661, Train Acc: 0.5458, Train f1-score: 0.6250, Val loss: 0.5833, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 148, Train loss: 0.6625, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5800, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 149, Train loss: 0.6649, Train Acc: 0.5458, Train f1-score: 0.6250, Val loss: 0.5786, Val Acc: 0.8750, Val f1-score: 0.8750,\n",
      "Epoch: 150, Train loss: 0.6651, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5755, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 151, Train loss: 0.6624, Train Acc: 0.5708, Train f1-score: 0.6250, Val loss: 0.5794, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 152, Train loss: 0.6656, Train Acc: 0.5521, Train f1-score: 0.6250, Val loss: 0.5800, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 153, Train loss: 0.6609, Train Acc: 0.5583, Train f1-score: 0.6250, Val loss: 0.5749, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 154, Train loss: 0.6635, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5771, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 155, Train loss: 0.6605, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5786, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 156, Train loss: 0.6604, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5731, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 157, Train loss: 0.6640, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5701, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 158, Train loss: 0.6584, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5663, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 159, Train loss: 0.6585, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5755, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 160, Train loss: 0.6602, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5773, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 161, Train loss: 0.6599, Train Acc: 0.5708, Train f1-score: 0.6250, Val loss: 0.5765, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 162, Train loss: 0.6631, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5674, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 163, Train loss: 0.6572, Train Acc: 0.5646, Train f1-score: 0.6250, Val loss: 0.5773, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 164, Train loss: 0.6586, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5725, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 165, Train loss: 0.6586, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5754, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 166, Train loss: 0.6577, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5744, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 167, Train loss: 0.6585, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5716, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 168, Train loss: 0.6552, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5741, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 169, Train loss: 0.6578, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5711, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 170, Train loss: 0.6555, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5730, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 171, Train loss: 0.6549, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5700, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 172, Train loss: 0.6564, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5706, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 173, Train loss: 0.6562, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5685, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 174, Train loss: 0.6553, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5708, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 175, Train loss: 0.6545, Train Acc: 0.5771, Train f1-score: 0.6250, Val loss: 0.5463, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 176, Train loss: 0.6603, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5419, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 177, Train loss: 0.6591, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5497, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 178, Train loss: 0.6527, Train Acc: 0.5833, Train f1-score: 0.6250, Val loss: 0.5744, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 179, Train loss: 0.6525, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5556, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 180, Train loss: 0.6504, Train Acc: 0.5833, Train f1-score: 0.6250, Val loss: 0.5581, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 181, Train loss: 0.6487, Train Acc: 0.5958, Train f1-score: 0.6250, Val loss: 0.5608, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 182, Train loss: 0.6537, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5485, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 183, Train loss: 0.6543, Train Acc: 0.5833, Train f1-score: 0.6250, Val loss: 0.5411, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 184, Train loss: 0.6504, Train Acc: 0.5833, Train f1-score: 0.6250, Val loss: 0.5599, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 185, Train loss: 0.6488, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5527, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 186, Train loss: 0.6525, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.5411, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 187, Train loss: 0.6479, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5614, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 188, Train loss: 0.6452, Train Acc: 0.6021, Train f1-score: 0.6250, Val loss: 0.5620, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 189, Train loss: 0.6496, Train Acc: 0.6021, Train f1-score: 0.6250, Val loss: 0.5401, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 190, Train loss: 0.6441, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.5549, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 191, Train loss: 0.6482, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5418, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 192, Train loss: 0.6451, Train Acc: 0.5896, Train f1-score: 0.6250, Val loss: 0.5612, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 193, Train loss: 0.6451, Train Acc: 0.6021, Train f1-score: 0.6250, Val loss: 0.5442, Val Acc: 0.8750, Val f1-score: 0.8708,\n",
      "Epoch: 194, Train loss: 0.6431, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5531, Val Acc: 0.6875, Val f1-score: 0.6887,\n",
      "Epoch: 195, Train loss: 0.6431, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5515, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 196, Train loss: 0.6447, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5409, Val Acc: 0.8125, Val f1-score: 0.8102,\n",
      "Epoch: 197, Train loss: 0.6414, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5433, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 198, Train loss: 0.6413, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5528, Val Acc: 0.6875, Val f1-score: 0.6887,\n",
      "Epoch: 199, Train loss: 0.6415, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5496, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 200, Train loss: 0.6424, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5506, Val Acc: 0.6875, Val f1-score: 0.6887,\n",
      "Epoch: 201, Train loss: 0.6407, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5570, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 202, Train loss: 0.6432, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5373, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 203, Train loss: 0.6379, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5579, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 204, Train loss: 0.6407, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5431, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 205, Train loss: 0.6396, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.5570, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 206, Train loss: 0.6406, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.5488, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 207, Train loss: 0.6384, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5611, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 208, Train loss: 0.6383, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5395, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 209, Train loss: 0.6383, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5485, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 210, Train loss: 0.6379, Train Acc: 0.6396, Train f1-score: 0.6250, Val loss: 0.5374, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 211, Train loss: 0.6372, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.5574, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 212, Train loss: 0.6410, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5572, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 213, Train loss: 0.6352, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.5370, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 214, Train loss: 0.6302, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5524, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 215, Train loss: 0.6325, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.5523, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 216, Train loss: 0.6315, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5575, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 217, Train loss: 0.6301, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5598, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 218, Train loss: 0.6325, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5516, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 219, Train loss: 0.6276, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.5531, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 220, Train loss: 0.6283, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5553, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 221, Train loss: 0.6288, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5543, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 222, Train loss: 0.6305, Train Acc: 0.6083, Train f1-score: 0.6250, Val loss: 0.5623, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 223, Train loss: 0.6275, Train Acc: 0.6396, Train f1-score: 0.6250, Val loss: 0.5585, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 224, Train loss: 0.6270, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5558, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 225, Train loss: 0.6284, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5512, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 226, Train loss: 0.6193, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5516, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 227, Train loss: 0.6340, Train Acc: 0.6146, Train f1-score: 0.6250, Val loss: 0.5412, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 228, Train loss: 0.6211, Train Acc: 0.6458, Train f1-score: 0.6250, Val loss: 0.5506, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 229, Train loss: 0.6280, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5492, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 230, Train loss: 0.6237, Train Acc: 0.6208, Train f1-score: 0.6250, Val loss: 0.5464, Val Acc: 0.8125, Val f1-score: 0.8003,\n",
      "Epoch: 231, Train loss: 0.6210, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.5562, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 232, Train loss: 0.6183, Train Acc: 0.6271, Train f1-score: 0.6250, Val loss: 0.5596, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 233, Train loss: 0.6251, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5508, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 234, Train loss: 0.6123, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.5572, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 235, Train loss: 0.6227, Train Acc: 0.6396, Train f1-score: 0.6250, Val loss: 0.5535, Val Acc: 0.7500, Val f1-score: 0.7417,\n",
      "Epoch: 236, Train loss: 0.6146, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.5597, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 237, Train loss: 0.6126, Train Acc: 0.6382, Train f1-score: 0.6990, Val loss: 0.5640, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 238, Train loss: 0.6092, Train Acc: 0.6819, Train f1-score: 0.6990, Val loss: 0.5612, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 239, Train loss: 0.6094, Train Acc: 0.6507, Train f1-score: 0.6990, Val loss: 0.5695, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 240, Train loss: 0.6145, Train Acc: 0.6333, Train f1-score: 0.6250, Val loss: 0.5727, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 241, Train loss: 0.6101, Train Acc: 0.6694, Train f1-score: 0.6990, Val loss: 0.5720, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 242, Train loss: 0.6106, Train Acc: 0.6458, Train f1-score: 0.6250, Val loss: 0.5707, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 243, Train loss: 0.6059, Train Acc: 0.6708, Train f1-score: 0.6250, Val loss: 0.5692, Val Acc: 0.6875, Val f1-score: 0.6672,\n",
      "Epoch: 244, Train loss: 0.6035, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.5759, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 245, Train loss: 0.6013, Train Acc: 0.6882, Train f1-score: 0.6990, Val loss: 0.5886, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 246, Train loss: 0.6009, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.5789, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 247, Train loss: 0.5891, Train Acc: 0.6944, Train f1-score: 0.6990, Val loss: 0.5871, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 248, Train loss: 0.5927, Train Acc: 0.6771, Train f1-score: 0.6250, Val loss: 0.5958, Val Acc: 0.6875, Val f1-score: 0.6837,\n",
      "Epoch: 249, Train loss: 0.5942, Train Acc: 0.6896, Train f1-score: 0.6250, Val loss: 0.6005, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 250, Train loss: 0.5937, Train Acc: 0.6819, Train f1-score: 0.6990, Val loss: 0.5958, Val Acc: 0.7500, Val f1-score: 0.7500,\n",
      "Epoch: 251, Train loss: 0.5975, Train Acc: 0.6771, Train f1-score: 0.6250, Val loss: 0.5987, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 252, Train loss: 0.6092, Train Acc: 0.6646, Train f1-score: 0.6250, Val loss: 0.5962, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 253, Train loss: 0.5836, Train Acc: 0.6882, Train f1-score: 0.6990, Val loss: 0.6025, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 254, Train loss: 0.5923, Train Acc: 0.6771, Train f1-score: 0.6250, Val loss: 0.6025, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 255, Train loss: 0.5774, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.5944, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 256, Train loss: 0.5884, Train Acc: 0.6896, Train f1-score: 0.6250, Val loss: 0.6042, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 257, Train loss: 0.5754, Train Acc: 0.7118, Train f1-score: 0.7662, Val loss: 0.6094, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 258, Train loss: 0.6201, Train Acc: 0.6396, Train f1-score: 0.6250, Val loss: 0.5960, Val Acc: 0.6250, Val f1-score: 0.5841,\n",
      "Epoch: 259, Train loss: 0.5871, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6086, Val Acc: 0.6875, Val f1-score: 0.6887,\n",
      "Epoch: 260, Train loss: 0.5964, Train Acc: 0.6833, Train f1-score: 0.6250, Val loss: 0.6061, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 261, Train loss: 0.5746, Train Acc: 0.6882, Train f1-score: 0.6990, Val loss: 0.6186, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 262, Train loss: 0.5870, Train Acc: 0.6833, Train f1-score: 0.6250, Val loss: 0.6147, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 263, Train loss: 0.5695, Train Acc: 0.6819, Train f1-score: 0.6990, Val loss: 0.6133, Val Acc: 0.6875, Val f1-score: 0.6887,\n",
      "Epoch: 264, Train loss: 0.5868, Train Acc: 0.6958, Train f1-score: 0.6250, Val loss: 0.6164, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 265, Train loss: 0.5772, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.6324, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 266, Train loss: 0.5811, Train Acc: 0.6833, Train f1-score: 0.6250, Val loss: 0.6174, Val Acc: 0.6250, Val f1-score: 0.6125,\n",
      "Epoch: 267, Train loss: 0.5778, Train Acc: 0.6944, Train f1-score: 0.6990, Val loss: 0.6390, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 268, Train loss: 0.5830, Train Acc: 0.6896, Train f1-score: 0.6250, Val loss: 0.6295, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 269, Train loss: 0.5722, Train Acc: 0.6944, Train f1-score: 0.6990, Val loss: 0.6180, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 270, Train loss: 0.5726, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6378, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 271, Train loss: 0.5733, Train Acc: 0.6882, Train f1-score: 0.6990, Val loss: 0.6416, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 272, Train loss: 0.5679, Train Acc: 0.7132, Train f1-score: 0.6990, Val loss: 0.6403, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 273, Train loss: 0.5660, Train Acc: 0.7132, Train f1-score: 0.6990, Val loss: 0.6446, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 274, Train loss: 0.5719, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6652, Val Acc: 0.5625, Val f1-score: 0.5341,\n",
      "Epoch: 275, Train loss: 0.5584, Train Acc: 0.6646, Train f1-score: 0.6494, Val loss: 0.6964, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 276, Train loss: 0.6178, Train Acc: 0.6694, Train f1-score: 0.6990, Val loss: 0.6421, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 277, Train loss: 0.5921, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6394, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 278, Train loss: 0.5816, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6365, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 279, Train loss: 0.5646, Train Acc: 0.7194, Train f1-score: 0.6990, Val loss: 0.6244, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 280, Train loss: 0.5491, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6606, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 281, Train loss: 0.6023, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.6313, Val Acc: 0.5000, Val f1-score: 0.4833,\n",
      "Epoch: 282, Train loss: 0.5586, Train Acc: 0.7257, Train f1-score: 0.6990, Val loss: 0.6332, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 283, Train loss: 0.5596, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6298, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 284, Train loss: 0.5389, Train Acc: 0.6819, Train f1-score: 0.7214, Val loss: 0.7416, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 285, Train loss: 0.6236, Train Acc: 0.6507, Train f1-score: 0.6990, Val loss: 0.6471, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 286, Train loss: 0.5657, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6362, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 287, Train loss: 0.5452, Train Acc: 0.7069, Train f1-score: 0.7143, Val loss: 0.6830, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 288, Train loss: 0.5890, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.6447, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 289, Train loss: 0.5568, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6536, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 290, Train loss: 0.5651, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6535, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 291, Train loss: 0.5335, Train Acc: 0.7132, Train f1-score: 0.7214, Val loss: 0.7217, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 292, Train loss: 0.6061, Train Acc: 0.6569, Train f1-score: 0.6990, Val loss: 0.6400, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 293, Train loss: 0.5425, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6417, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 294, Train loss: 0.5405, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6440, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 295, Train loss: 0.5363, Train Acc: 0.7181, Train f1-score: 0.7662, Val loss: 0.6728, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 296, Train loss: 0.5619, Train Acc: 0.6944, Train f1-score: 0.6990, Val loss: 0.6506, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 297, Train loss: 0.5328, Train Acc: 0.7181, Train f1-score: 0.7662, Val loss: 0.6796, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 298, Train loss: 0.5746, Train Acc: 0.6757, Train f1-score: 0.6990, Val loss: 0.6487, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 299, Train loss: 0.5325, Train Acc: 0.7243, Train f1-score: 0.7662, Val loss: 0.6738, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 300, Train loss: 0.5613, Train Acc: 0.6944, Train f1-score: 0.6990, Val loss: 0.6406, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 301, Train loss: 0.5387, Train Acc: 0.7243, Train f1-score: 0.7662, Val loss: 0.6792, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 302, Train loss: 0.5568, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6454, Val Acc: 0.5625, Val f1-score: 0.5572,\n",
      "Epoch: 303, Train loss: 0.5512, Train Acc: 0.7132, Train f1-score: 0.6990, Val loss: 0.6557, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 304, Train loss: 0.5479, Train Acc: 0.7118, Train f1-score: 0.7662, Val loss: 0.6986, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 305, Train loss: 0.5668, Train Acc: 0.6944, Train f1-score: 0.6990, Val loss: 0.6655, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 306, Train loss: 0.5451, Train Acc: 0.7181, Train f1-score: 0.7662, Val loss: 0.6677, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 307, Train loss: 0.5585, Train Acc: 0.7007, Train f1-score: 0.6990, Val loss: 0.6561, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 308, Train loss: 0.5572, Train Acc: 0.6993, Train f1-score: 0.7662, Val loss: 0.6747, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 309, Train loss: 0.5616, Train Acc: 0.7069, Train f1-score: 0.6990, Val loss: 0.6467, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 310, Train loss: 0.5517, Train Acc: 0.7056, Train f1-score: 0.7662, Val loss: 0.6891, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 311, Train loss: 0.5479, Train Acc: 0.7181, Train f1-score: 0.7750, Val loss: 0.6747, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 312, Train loss: 0.5523, Train Acc: 0.7118, Train f1-score: 0.7662, Val loss: 0.6999, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 313, Train loss: 0.5537, Train Acc: 0.7181, Train f1-score: 0.7662, Val loss: 0.6630, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 314, Train loss: 0.5401, Train Acc: 0.7181, Train f1-score: 0.7750, Val loss: 0.7265, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 315, Train loss: 0.5594, Train Acc: 0.7229, Train f1-score: 0.8286, Val loss: 0.6654, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 316, Train loss: 0.5362, Train Acc: 0.7181, Train f1-score: 0.7750, Val loss: 0.7554, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 317, Train loss: 0.5694, Train Acc: 0.6819, Train f1-score: 0.7143, Val loss: 0.7088, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 318, Train loss: 0.5534, Train Acc: 0.7340, Train f1-score: 0.8889, Val loss: 0.6882, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 319, Train loss: 0.5489, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.7123, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 320, Train loss: 0.5561, Train Acc: 0.7069, Train f1-score: 0.7143, Val loss: 0.7465, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 321, Train loss: 0.5595, Train Acc: 0.6993, Train f1-score: 0.7750, Val loss: 0.7645, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 322, Train loss: 0.5628, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 0.7462, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 323, Train loss: 0.5664, Train Acc: 0.7090, Train f1-score: 0.8889, Val loss: 0.7673, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 324, Train loss: 0.5667, Train Acc: 0.6965, Train f1-score: 0.8889, Val loss: 0.7807, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 325, Train loss: 0.5568, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.7885, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 326, Train loss: 0.5697, Train Acc: 0.6757, Train f1-score: 0.7143, Val loss: 0.8242, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 327, Train loss: 0.5595, Train Acc: 0.7153, Train f1-score: 0.8889, Val loss: 0.7415, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 328, Train loss: 0.5420, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.7917, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 329, Train loss: 0.5539, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.7812, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 330, Train loss: 0.5408, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.7995, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 331, Train loss: 0.5445, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.7680, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 332, Train loss: 0.5506, Train Acc: 0.7007, Train f1-score: 0.7143, Val loss: 0.8461, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 333, Train loss: 0.5542, Train Acc: 0.6993, Train f1-score: 0.7750, Val loss: 0.8206, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 334, Train loss: 0.5535, Train Acc: 0.7153, Train f1-score: 0.8889, Val loss: 0.8431, Val Acc: 0.6250, Val f1-score: 0.6250,\n",
      "Epoch: 335, Train loss: 0.5671, Train Acc: 0.7167, Train f1-score: 0.8328, Val loss: 0.7983, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 336, Train loss: 0.5260, Train Acc: 0.7354, Train f1-score: 0.8328, Val loss: 0.7926, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 337, Train loss: 0.5420, Train Acc: 0.7229, Train f1-score: 0.8328, Val loss: 0.8085, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 338, Train loss: 0.5521, Train Acc: 0.7042, Train f1-score: 0.8328, Val loss: 0.7855, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 339, Train loss: 0.5307, Train Acc: 0.7118, Train f1-score: 0.7778, Val loss: 0.9251, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 340, Train loss: 0.5697, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.7205, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 341, Train loss: 0.5226, Train Acc: 0.7479, Train f1-score: 0.8328, Val loss: 0.8827, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 342, Train loss: 0.5546, Train Acc: 0.6944, Train f1-score: 0.7143, Val loss: 0.8608, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 343, Train loss: 0.5457, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.8400, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 344, Train loss: 0.5339, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.8764, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 345, Train loss: 0.5508, Train Acc: 0.6931, Train f1-score: 0.7750, Val loss: 0.8488, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 346, Train loss: 0.5417, Train Acc: 0.7104, Train f1-score: 0.8328, Val loss: 0.8575, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 347, Train loss: 0.5295, Train Acc: 0.7167, Train f1-score: 0.8328, Val loss: 0.8781, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 348, Train loss: 0.5496, Train Acc: 0.6993, Train f1-score: 0.7750, Val loss: 0.8575, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 349, Train loss: 0.5306, Train Acc: 0.7167, Train f1-score: 0.8328, Val loss: 0.9011, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 350, Train loss: 0.5479, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.8826, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 351, Train loss: 0.5324, Train Acc: 0.7167, Train f1-score: 0.8328, Val loss: 0.8816, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 352, Train loss: 0.5405, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9215, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 353, Train loss: 0.5433, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.8567, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 354, Train loss: 0.5236, Train Acc: 0.7181, Train f1-score: 0.7750, Val loss: 0.8912, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 355, Train loss: 0.5366, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9202, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 356, Train loss: 0.5493, Train Acc: 0.7153, Train f1-score: 0.8889, Val loss: 0.9420, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 357, Train loss: 0.5553, Train Acc: 0.7028, Train f1-score: 0.8889, Val loss: 0.8983, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 358, Train loss: 0.5501, Train Acc: 0.6868, Train f1-score: 0.7750, Val loss: 0.8911, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 359, Train loss: 0.5309, Train Acc: 0.7403, Train f1-score: 0.8889, Val loss: 0.9489, Val Acc: 0.5625, Val f1-score: 0.5642,\n",
      "Epoch: 360, Train loss: 0.5489, Train Acc: 0.7153, Train f1-score: 0.8889, Val loss: 0.9172, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 361, Train loss: 0.5479, Train Acc: 0.6931, Train f1-score: 0.7750, Val loss: 0.9351, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 362, Train loss: 0.5366, Train Acc: 0.7153, Train f1-score: 0.8889, Val loss: 0.9263, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 363, Train loss: 0.5477, Train Acc: 0.6868, Train f1-score: 0.7750, Val loss: 0.8800, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 364, Train loss: 0.5238, Train Acc: 0.7215, Train f1-score: 0.8889, Val loss: 0.9788, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 365, Train loss: 0.5533, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.8926, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 366, Train loss: 0.5148, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.9140, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 367, Train loss: 0.5236, Train Acc: 0.7104, Train f1-score: 0.8328, Val loss: 0.9785, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 368, Train loss: 0.5405, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9543, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 369, Train loss: 0.5369, Train Acc: 0.6993, Train f1-score: 0.7750, Val loss: 0.8876, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 370, Train loss: 0.5139, Train Acc: 0.7278, Train f1-score: 0.8889, Val loss: 0.9962, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 371, Train loss: 0.5467, Train Acc: 0.6993, Train f1-score: 0.7750, Val loss: 0.9167, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 372, Train loss: 0.5208, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9811, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 373, Train loss: 0.5458, Train Acc: 0.6979, Train f1-score: 0.8286, Val loss: 0.8839, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 374, Train loss: 0.5086, Train Acc: 0.7118, Train f1-score: 0.7750, Val loss: 0.9463, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 375, Train loss: 0.5289, Train Acc: 0.7181, Train f1-score: 0.7750, Val loss: 0.9117, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 376, Train loss: 0.5229, Train Acc: 0.6993, Train f1-score: 0.7750, Val loss: 0.9492, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 377, Train loss: 0.5241, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9675, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 378, Train loss: 0.5410, Train Acc: 0.6931, Train f1-score: 0.7750, Val loss: 0.9251, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 379, Train loss: 0.5261, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9256, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 380, Train loss: 0.5304, Train Acc: 0.7104, Train f1-score: 0.8328, Val loss: 0.9781, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 381, Train loss: 0.5458, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9371, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 382, Train loss: 0.5197, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.9628, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 383, Train loss: 0.5479, Train Acc: 0.7042, Train f1-score: 0.8286, Val loss: 0.8738, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 384, Train loss: 0.5073, Train Acc: 0.7306, Train f1-score: 0.7750, Val loss: 1.0317, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 385, Train loss: 0.5604, Train Acc: 0.6729, Train f1-score: 0.8286, Val loss: 0.9113, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 386, Train loss: 0.5048, Train Acc: 0.7493, Train f1-score: 0.7778, Val loss: 1.0193, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 387, Train loss: 0.5583, Train Acc: 0.7167, Train f1-score: 0.8286, Val loss: 0.8084, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 388, Train loss: 0.5064, Train Acc: 0.7604, Train f1-score: 0.8328, Val loss: 1.0333, Val Acc: 0.4375, Val f1-score: 0.4397,\n",
      "Epoch: 389, Train loss: 0.5549, Train Acc: 0.7104, Train f1-score: 0.8286, Val loss: 0.8473, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 390, Train loss: 0.5026, Train Acc: 0.7604, Train f1-score: 0.8328, Val loss: 1.0225, Val Acc: 0.4375, Val f1-score: 0.4397,\n",
      "Epoch: 391, Train loss: 0.5374, Train Acc: 0.7056, Train f1-score: 0.7750, Val loss: 0.8792, Val Acc: 0.5000, Val f1-score: 0.5000,\n",
      "Epoch: 392, Train loss: 0.5018, Train Acc: 0.7542, Train f1-score: 0.8328, Val loss: 1.0306, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 393, Train loss: 0.5318, Train Acc: 0.7465, Train f1-score: 0.8875, Val loss: 0.8663, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 394, Train loss: 0.5070, Train Acc: 0.7257, Train f1-score: 0.7143, Val loss: 1.0362, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 395, Train loss: 0.5553, Train Acc: 0.7292, Train f1-score: 0.8286, Val loss: 0.8123, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 396, Train loss: 0.5017, Train Acc: 0.7542, Train f1-score: 0.8328, Val loss: 1.0205, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 397, Train loss: 0.5494, Train Acc: 0.7292, Train f1-score: 0.8286, Val loss: 0.8085, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 398, Train loss: 0.5023, Train Acc: 0.7257, Train f1-score: 0.7143, Val loss: 1.0356, Val Acc: 0.3750, Val f1-score: 0.3750,\n",
      "Epoch: 399, Train loss: 0.5510, Train Acc: 0.7042, Train f1-score: 0.8286, Val loss: 0.8103, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "Epoch: 400, Train loss: 0.5006, Train Acc: 0.7653, Train f1-score: 0.8875, Val loss: 1.0441, Val Acc: 0.4375, Val f1-score: 0.4307,\n",
      "GIN accuracy: 0.3684210479259491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.5176470637321472\n",
      "Test accuracy: 0.48947368562221527\n",
      "Test f1-score: 0.4489321205110679\n",
      "Val stv: 0.05991181380550802\n",
      "Test stv: 0.08822660429020095\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAB77ElEQVR4nO2ddXxcxfbAv7OSjXvSNE2b1N2dlirUKFK0xXnwcOfBA97DHw97uDsUihcrUBegpdRdk1TSJI27rM/vj9ndZJNNjYaWX+b7+exnr8y999y5u3PunHPmjJBSotFoNJqWi+FEC6DRaDSaE4tWBBqNRtPC0YpAo9FoWjhaEWg0Gk0LRysCjUajaeGYTrQAR0t8fLxMS0s70WJoNBrNX4p169YVSSkTAu37yymCtLQ01q5de6LF0Gg0mr8UQoj9Te3TpiGNRqNp4WhFoNFoNC0crQg0Go2mhfOX8xFoNBpNS8fhcJCdnY3Vam20Lzg4mJSUFMxm8xGfTysCjUaj+YuRnZ1NREQEaWlpCCF826WUFBcXk52dTfv27Y/4fNo0pNFoNH8xrFYrcXFxfkoAQAhBXFxcwJ7CodCKQKPRaP6CNFQCh9t+KFqOIijbCpsfBGvBiZZEo9FoTipajiKo2AFbH9OKQKPRaBrQchSB71b1RDwajeavT1OTih3LZGMtRxEIz61K94mVQ6PRaP4gwcHBFBcXN2r0vVFDwcHBR3W+lhM+qhWBRqP5f0JKSgrZ2dkUFhY22ucdR3A0tBxF4Ov8aEWg0Wj+2pjN5qMaJ3A4tGlIo9FoWjhaEWg0Gk0Lp9kUgRCirRBiqRBiuxBimxDitgBlxgghyoUQGz2fB5tLHt+takWg0Wg0fjSnj8AJ3CWlXC+EiADWCSEWSim3Nyj3q5RyajPKoRDaR6DRaDSBaLYegZTyoJRyvWe5EtgBtGmu6x0WbRrSaDSagPwpPgIhRBrQH1gVYPdwIcQmIcRcIUTPJo6/VgixVgixNlC41JEJoRWBRqPRBKLZFYEQIhyYDdwupaxosHs9kCql7Au8DHwb6BxSyreklIOklIMSEgLOvXwEaNOQRqPRBKJZFYEQwoxSArOklF833C+lrJBSVnmWfwLMQoj45hFG9wg0Go0mEM0ZNSSAd4EdUsrnmiiT5CmHEGKIR57i5hFIKwKNRqMJRHNGDY0ALgO2CCE2erbdD7QDkFK+AZwP3CCEcAK1wHR5LBmTjgitCDQajSYQzaYIpJTLgUPOkCClfAV4pblk8EOHj2o0Gk1A9MhijUajaeFoRaDRaDQtnJajCHT4qEaj0QSk5SgC3SPQaDSagGhFoNFoNC2clqMItGlIo9FoAtJyFIHuEWg0Gk1AtCLQaDSaFk7LUQR6ZLFGo9EEpOUoAj2yWKPRaALS8hSB7hFoNBqNH1oRaDQaTQun5SgCHT6q0Wg0AWk5ikD3CDQajSYgWhFoNBpNC6flKAJtGtJoNJqAtBhFsH/FQT564jLKDjhOtCgajUZzUtFiFEFVvpU9Wztir3adaFE0Go3mpKLFKAJhVLfaXDMiazQazV+VlqcI3NpHoNFoNPVpOYrAEzUkXVoRaDQaTX1ajiIw6KghjUajCUSLUQQYvD0C7STQaDSa+rQYRSAMRkD7CDQajaYhLUgReKOGtCLQaDSa+rQ8RaBNQxqNRuNHy1EERp1rSKPRaALRYhQBQgC6R6DRaDQNaTGKwDegTIePajQajR8tRxEYdI9Ao9FoAtFyFIHXNKTDRzUajcaPlqMIPD0CnXVOo9Fo/GlxikD3CDQajcafFqMI8HYItI9Ao9Fo/Gg2RSCEaCuEWCqE2C6E2CaEuC1AGSGEeEkIkSGE2CyEGNBs8nh7BNo0pNFoNH6YmvHcTuAuKeV6IUQEsE4IsVBKub1emclAZ89nKPC65/u4o53FGo1GE5hm6xFIKQ9KKdd7liuBHUCbBsXOBmZKxe9AtBCidXPIo53FGo1GE5g/xUcghEgD+gOrGuxqAxyot55NY2WBEOJaIcRaIcTawsLCY5NBjyPQaDSagDS7IhBChAOzgdullBXHcg4p5VtSykFSykEJCQnHKIjvXMd2vEaj0fw/pVkVgRDCjFICs6SUXwcokgO0rbee4tl2/GXR4aMajUYTkOaMGhLAu8AOKeVzTRT7HrjcEz00DCiXUh5sJnkAkG7dI9BoNJr6NGfU0AjgMmCLEGKjZ9v9QDsAKeUbwE/AFCADqAGuai5htLNYo9FoAtNsikBKuRyfZb7JMhK4qblkqE+daUgrAo1Go6lPyxtZrBWBRqPR+NFiFIF2Fms0Gk1gWp4i0D4CjUaj8aPlKAIdNaTRaDQBaTmKwBs1pBWBRqPR+NFiFIEeWazRaDSBaTGKQIePajQaTWC0ItBoNJoWTstRBF5nsdYDGo1G40fLUQTaWazRaDQBaTGKQI8s1mg0msC0GEWgB5RpNBpNYFqeItAZJjQajcaPlqMI9MhijUajCUjLUQReZzFaEWg0Gk19Wpwi0D0CjUaj8afFKIK6qKETK4ZGo9GcbLQYRaCjhjQajSYwLUcRaGexRqPRBKTlKAI9slij0WgCclhFIIQ4Uwjxl1cYdaahEyyIRqPRnGQcSQN/EZAuhHhaCNGtuQVqNnSKCY1GownIYRWBlPJSoD+QCXwghFgphLhWCBHR7NIdR7SzWKPRaAJzRCYfKWUF8BXwGdAamAasF0Lc0oyyHVfqnMUnWBCNRqM5yTgSH8FZQohvgGWAGRgipZwM9AXual7xjh8615BGo9EExnQEZc4DnpdS/lJ/o5SyRghxdfOIdfzxRQ1p05BGo9H4cSSK4GHgoHdFCBECtJJS7pNSLm4uwY47emSxRqPRBORIfARfAvWbT5dn218Kn49AJ53TaDQaP45EEZiklHbvimc5qPlEaj6EQeoegUaj0TTgSBRBoRDiLO+KEOJsoKj5RGpGhB5HoNFoNA05Eh/B9cAsIcQrKEv7AeDyZpWqmRACPR2BRqPRNOCwikBKmQkME0KEe9arml2qZkII7SzWaDSahhxJjwAhxBlATyDY53SV8tFmlKtZEELqkcUajUbTgCMZUPYGKt/QLSjT0AVAajPL1SwIg+4RaDQaTUOOxFl8ipTycqBUSvkIMBzocriDhBDvCSEKhBBbm9g/RghRLoTY6Pk8eHSiHyUl65h02Y+YLbXNehmNRqP5q3EkisDq+a4RQiQDDlS+ocPxATDpMGV+lVL283ya19RUtYcBY9YRFGRr1stoNBrNX40j8RHMEUJEA88A61FxN28f7iAp5S9CiLQ/JN3xRBjVt/YRaDQajR+HVASeCWkWSynLgNlCiB+AYCll+XG6/nAhxCYgF/iHlHJbE3JcC1wL0K5du2O7klcRaDQajcaPQ5qGpJRu4NV667bjqATWA6lSyr7Ay8C3h5DjLSnlICnloISEhGO8nPdWdY9Ao9Fo6nMkPoLFQojzhDdu9DghpazwjkmQUv4EmIUQ8cfzGn7Y1GBoo8l+mIIajUbTsjgSRXAdKsmcTQhRIYSoFEJU/NELCyGSvMpFCDHEI0vxHz1vk1RmABAcbD1MQY1Go2lZHMnI4mOaklII8SkwBogXQmQDD6EmtkFK+QZwPnCDEMIJ1ALTZXOO9qrcDYBEDyTQaDSa+hxWEQghRgXa3nCimgD7Zxxm/yvAK4e7/nHD4yw2CO0j0Gg0mvocSfjo3fWWg4EhwDpgXLNI1FwIs/oSrhMsiEaj0ZxcHIlp6Mz660KItsALzSVQs2Ewe751j0Cj0WjqcyTO4oZkA92PtyDNjlA6T2jTkEaj0fhxJD6Cl6kLvjcA/VBjAP5aGDyKAKkyz4lj0YEajUbz/48j8RGsrbfsBD6VUq5oJnmaD4PXRyBBurQi0Gg0Gg9Hogi+AqxSSheAEMIohAiVUtY0r2jHGa8iMHgUAeYTK49Go9GcJBzRyGIgpN56CLCoecRpRgxBQL0egUaj0WiAI1MEwfWnp/QshzafSM2Et0cAWhFoNBpNPY5EEVQLIQZ4V4QQA1Ejgf9aCNUjwKB7BBqNRlOfI/ER3A58KYTIRb1QJ6GmrvxrYVQ9AoOQ4NaKQKPRaLwcyYCyNUKIbkBXz6ZdUkpH84rVDHh8BGgfgUaj0fhxJJPX3wSESSm3Sim3AuFCiBubX7TjjNdZrE1DGo1G48eR+Aj+7pmhDAApZSnw92aTqLkwWAAdNaTRaDQNORJFYKw/KY0QwggENZ9IzYRRh49qNBpNII7EWTwP+FwI8aZn/TpgbvOJ1EwI3SPQaDSaQByJIvgnauL46z3rm1GRQ38t/HoEzhMsjEaj0Zw8HNY05JnAfhWwDzUXwThgR/OK1Qx4fQQGdI9Ao9Fo6tFkj0AI0QWY4fkUAZ8DSCnH/jmiHWeMXtOQWysCjUajqcehTEM7gV+BqVLKDAAhxB1/ilTNgur8CIFWBBqNRlOPQ5mGzgUOAkuFEG8LIcbjSdXzl6RopfrWzmKNRqPxo0lFIKX8Vko5HegGLEWlmkgUQrwuhJjwJ8l3/DCqBKpCp5jQaDQaP47EWVwtpfzEM3dxCrABFUn018KoEqYa9MhijUaj8eOopumSUpZKKd+SUo5vLoGaDbMnc7Y2DWk0Go0fLWe+xvqmIa0INBqNxkcLUgSqR6AVgUaj0fjTghRBMKDDRzUajaYhLUcRmHSPQKPRaALRchSBwYyUWhFoNBpNQ1qUIgB01JBGo9E0oOUogso9ABhNLq0INBqNph4tRxHUZCEEGI066ZxGo/lrUba/jNI9pc12/iOZj+D/B8YQpESbhjQazUmNlJLiXcW4XW7CEsIIjQ/lxbQXAXjQ/SD1Jow8brQYRbBtTiHtQ0Nw2k1aEWg0fwJOqxO3001Q+F9vZtvjyZ5Fe1j9ymou/OpCDCYDxbuLWfHMCjpP7kz2qmysZVaG3zmc0PhQMudnsvj+xZTvL/cdnzYmzbe89N9LGff4uOMuY4tRBAZXOdItEAYJbj1DmUZzKKSUuOwuTJZDNxEuhwuj2QhAbUktuWtz6TihIwDvDn+X/M35POh6sNnlrU/2qmziusQREhPyh87jtDqRbok51NxkmfzN+RSnF9PjvB4B99cU1fDR6R8BsPnjzSy6dxHV+dUAbHhng6/c+rfW+5bDWoWR1D+JvA15AOxbts+3L3NRZrMogmbzEQgh3hNCFAghtjaxXwghXhJCZAghNgshBjSXLADG4BDcbs/t6h6BpgVRtKsI6ZaAsjV/fenX1JbW+vbnrs0lZ02O3zHr317P48GPU5VfBYB0S5xWJ8ufWs6+n/cBkLUii8eDH+fjiR9TW1LLJ1M/4eOJH1OVX4WUkryNeb7jnFYnZfvLyP49m3eHv0ttSS3LHllG0a4iaktqsZZZj+qefn3iV7Z8ugWAvUv3krNayW8ts/LusHd5OvZp3uj7ht99HgopJaV7S/n2ym+ZffFs8jblMWvyLJ5v+zxul5utn29lzWtrAKjKq/LZ6xfft5gvz/+SmafNZN7t81j9ympe7/06Wz/fyp7Fe3gm4RnfNb676jufEkgelAyAwWSg50U9fWViO8dSnV/tUwJtR7b1k7PDuA5HVU9HSnP2CD4AXgFmNrF/MtDZ8xkKvO75bhZMoWHIGo9tTSsCzV+A4vRictfk0u2cbod8K61P6Z5SrGVWEnsnYjQbyZiXwazJsxh6+1AmPT+Jnx/9mS2zttBmSBuG3jqUytxK3h78NgC37rmVry/5mvCkcMqzlGniwG8HSOqbxMeTPqYkvcR3nQu+uoCV/1uJdEsyF2TydNzTvn3ZK7NJ6JngWy/YVsDql1azaeYm37ZVL63i50d+5vfnf8dR48ASYeGe4nuwV9lx2V2Yw8yU7Ssjvmu875jdP+4mrnMcwTHBLLl/CQA9zuvBzHGqiXlIPsT+X/f7yudvzmfpA0s59V+nsvuH3aSOSiUsIYyg8CDs1XZCYkJw2pxYS63sWbSHby77xnfs1k/r3l8fMz3mW45Oi+brS7/GaDZy1ntnkTEvA4C9i/eyd/FeX7nZ02djCjFhCjHRfmx7bBU2spZnkToqlRk/zGD9O+vJXZuL2+lm2+fbfMfVr2OAA8sP+K2HtQpr+MiPC82mCKSUvwgh0g5R5GxgppRSAr8LIaKFEK2llAebQx5jcCjuKoOaWUcrAs0JwlpuxRJpadLhV55VTuneUlJPTWX2jNkcXHeQrmd1ZeT9I2kzuA0Z8zJoO6ItRrORD0Z/QGhCKOd+fC7VBdXMvWUuexbt8Z1r+nfTWfCPBQCsenEVfS7pw+aZmwHYNHMTQ28dyvw75/vKvzPkHWqKagCIahcFKEWQtyHP10CZQ804ahx8ef6XAHQ9qyu7vt/ldw9r31hLbOdY3/rbg5SiCQoPQhgFtnIbK55eAYCt3AYos9Kc6+b4mUgAbt9/O+VZ5eSsyWHBnQuI6xLHkFuH+PYveWCJb/ndU94lqm2U3/Hr3lrHts+3+e4rqV8SoQmh7Fm0hymvTGHt62sp2Frgd0zamDSfOSaqXZRPKQJ8csYnhLUKozq/mk+nfup33Ih/jmDFUyt86zHtY7hi6RWEJYbhqHGw+pXVdJzQEUuEhbiucRwLR/pCcLQI1Q43Dx5F8IOUsleAfT8AT0opl3vWFwP/lFKuDVD2WuBagHbt2g3cv39/wyKHJfuz/xGW9zhSQuwZj0OXG4/6HBrNochakcW8W+cR2ymWVn1b0e7UdqSemurbn7kwk8/O+oyYDjF0PqMz7U5tR/LAZCKSIyjJKOG9ke9RW1yL2+kmMiWSiuwKTCEmnLXKpxUUHoS9yk5QeBBRqVEUbisEYOhtQ9kxewcV2RUkD07GHGpm/891/5GR941k+RPLAWWKGH7XcFY8tYLxT45n8b2L6XNpHzZ/rBTE6IdG8/MjP/uONVqMuGwukgclc+6scwmOCeZ/if8DoMNpHTjr3bP45rJvsFXYGPHPEax8biW5a3IB6DK1C7t/2O0719UrryZlWArvDH2HnNU5BMcEYy31Nwl1OL0D+5btw+1wA2AOM+OodjSq64QeCVjLrFTmVjb5PAbfPJg1r6w53GMDQBgEQ24ZQk1hDdM+nsa7w94lZ3UOdxfezcrnV7L8v8t9Ze8pvoeXOr6EtcxK21PaYgoxkdgnkUnPTeIR8QgA/f7Wj/GPjyc8KTzg9bZ9sY2vLvrqiGSrz7SPptHn0j5HfRyAEGKdlHJQoH1/CWexlPIt4C2AQYMGHZPmMolK3G6Dnrxec1RIKdn57U5ShqZQkV1BVV4VYa3CyN+UT1K/JGI7x/qckkv/vZSSzBJqS2vZ9oXq7kenRdPvb/1I7JnIt1d+i9PqpHB7IYXbC/ntmd8ASBubRtneMp/9GKAiu4KINhFc9ctVvNrjVVw2F/YqOwazAXuVncJthXQ7pxtl+8pY9eIqgqODuX7T9bTq0wpQb8q//udXLJEWRj0wik0zN1GZU0n/a/oz+qHRbHx/I4vvXUx463DOeOMM4rrFEdcljp4X9GTXd7vI25hH2tg0incVU5lbSfKQZOK6qLfYc2edy46vd3DBFxcgDILLF18OKCXTqk8r8jbl4bK76HF+D/b/vJ+Q2BCcVicpw1IA6DixIzmrcxh802AOrj1IxrwMOpzegeRByYx9dCyrX13N/NtVT8WrBCLaRDDj+xl8f/X3FKcXc+4n52KvsrPonkVMeG4CZXvLOLjhIHsW7uHC2RdyYMUBek3vRdezupIxN4Pfn//dV7fhSeFcsewKKg5UUJ5VTuroVMwhZiKSI3xlLpl7Cfmb8wmND2Xcf8Yx4u4RbJ+9nVZ9WhESG8It6bew45sd/HDtD1y/+Xre6PMGEa3rjt/43kZ6nNeDzlM6I6XEVm6jurCaV7q8wiXzLsFafnQ+ES//H3sEbwLLpJSfetZ3AWMOZxoaNGiQXLu2UafhsBT+8Bxi538xGF3ETn4Iut1+1OfQ/LWQUjkqzSGN/zwbP9xIZU4lofGh9LyoJ8FRwWTMy2D5k8vpd1U/9v+ynx7n9aAko4R5t81r8hrx3eIZ88gYtn+5ne1fbWfCsxMYfudwrOVW3hrwlt8goLDEMP6+5u9Eto1k9Sur2bt4L8W7iqkuqKa2pM6peemCS9n4/kaG3zWc5IHJOK1O1r6xlm2fb+PyJZdzYMUB2p3aDpPFxJrX1rD4vsVcMu8S2g6vcyxay61s/WwryYOSSR6YTObCTDIXZDL+8fEYg4wc+O0ASx9YytDbhtL1rK5+91S6t5SvL/6aM98+E0ukha8v+ZqJz0/0OTj/KPWfi9PmpKaohsg2kb79jhoHvz7xK93P7U5tSS1pY9IQBuEzp0m3RBiOLpa+aFcRNUU1ZP2aRd/L+/o1+sfKxxM/JnNBJqMfHs3PD//caP+U16Yw+IbB/HTzT6x5dQ2TX57M3FvmAhDeOpyqg1VHfc2Lf7qYzpM7H5O8h+oRnEhFcAZwMzAF5SR+SUo5pGG5hhyrIihZ+i7ONfdhMjuInfRv6H7XUZ9D89chb1Mec66ZQ+neUq5YegWteqs35exV2Xx35XcU7SzyK+81xQQiqX8SlbmVjHpgFHGd49j66VYi20ZStKOIXd/vwmVXPczOUzpz0TcXYQxS4ZTlB8op3l2MwWTAYDKQ1DcpYEy9y+GibG8ZlkgLexbvoffFvY9q0JDL7vJdU9N8uF1uVr+8mn5X9SM4KphPzviE9J/S6TatGzu/2dmo/Ih/jqDv5X15redrgOr57Vu67w/JcMWyK0gbnXZMx54Q05AQ4lNgDBAvhMgGHgLMAFLKN4CfUEogA6gBrmouWQCM4bE43Dpq6P8zUkqEEOxbto+PJ35McHQwBpOBOdfMYex/xrLujXWkz0332dzrE9s5lkE3DqL3xb0p2lFEbKdYfrzxR/I25HHJT5cQ1irM1zh74+QBdn2/i7Wvr2XKa1OIaR/jd86otlGNnJeBMJqNPrNLn0uO3v6rlUDzsvXzrSx/YjnjnxjP/Dvmk/5TOhOfm4gwqt9D1q9ZAY9b8dQKP+fxH1UC0HymoeaMGppxmP0SuKm5rt8QU2ikZxyB0Irg/wlul5usX7NI6JmAvcrOzHEzGX7XcH557BdiO8Vy5c9Xsvnjzcy/Yz4fT/iYiOQI+lzah14zelGSXkL3c7vjdrnZ/cNu+l3RD4NJjTOJTo0G4NJ5l2KvsmOJtDQpQ9ezujYyrWhOXmwVNnZ9v+uwDle30421zEpofCizp88GYPcc5fjes3APr/d+3WeeqimqQRiEb6xGILymIG/U1bESyMx5PPhLOIuPB8awSKRbADrX0F8Ft8uNwWjA7XKT/mM69io73c/tjjAKFt69kM0fbaa2pBaD2YAlwkJtSS1zb5mLMAouXXApofGh9Lm0D0v+tYS2I9oy4/sZmILVT7792Pa+6wy4OvBYRmEQh1QCmr8ec/4+h21fbCOxdyJJfZOaLnfdHDa+t5FrVl/j27Zl1ha/MvUb/pThKRxY4R/zX5+eF/Vk3RvrmPTSJEJiQvjivC+OSf6/XI/gZMOoewQnFeVZ5VQXVpM8MLADcutnW/nxxh85d9a5/PLYL2SvzAZU42wKMeGodpA6OpVOkzux9dOtFO0sYtQDo6jKr6LbOd18f/LQ+FDuzL3zkLH7mpZDSYYaD+H16zTk4IaDGEwGNr63EYBVL6wCz/ujrcKGMcjI0NuGUr6/3BcZBsqP5FUEfS7rw+aPNvv2DbtzGBOfncik5ycBcGBl0wrjcGhF8AcxhoZ7egRoRfAHkW5JVX6VX7jcoXA5XOxbto8O4zsg3ZJNH21i3q3zsFfZGf3QaHpN70XRziIcNQ4qcirY+fVOsn9XDf8nUz7BYDZwzofn4HK4mHPNHBzVDi746gLVOxCCYbcNw15tJzQuNOD1g6OCj9u9a/7auBzqv9+UGeetAW/5rW/5ZAttR7QlJDaE3XN20+7Udpz+9On89r/f/BTBgKsH+MYsnPn2mWz7fBsuu4u//fY32gxp43fO+hFLly+53Dcy+kgwhTRPk91iFIEhKAwpD68Idu+Gigro0AFiY5ss1iIo3F7Izu92MvLekX5v02teW8PcW+Zyw5YbIDGR+HgJbokwqhA/t9NNdWE1GXMzaNWnFfPvmE/W8iyG3DuGirxqdn5QN8hn2SM/8+Mjawinxrctun00Y/8zlvCkcHZ8tYPh/xhOh/Eqx0qNK5gOwxJJ7lOXesAUbKLKakLUQkiAPGNFRRAdDTU16vnWJzhYPWuHA4qL1bbISMjJgd69oaoKTJ5/SW4uxMRAWBhUV0PcsQ0O1ZxAvAPV5vx9DoOuH0SvGb2oKawhql0UG97bEPCYLlO70POinjhqHPS7qh+gfqNeht81nKR+SXSc2JHM+ZmYLCai06Ip3l1Mqz6tMBj9U7rVH2RWP2z2SNA9gj9KdRYRMZUcykewbRv08gS6Dh0Kv/8esFiL4ZMzPqFsXxkpw1JoPaC17816x9c7AHhtzBc8UXEj13ZeRvz2XzGYDLQf157MhZlQ74UrKEKFTN7/ZCQVpPC3kA2Me3wcQ28dyuP31/C/p8P56YXd9B4aSkzHGMIS6vKp1LffSwkXPNSDG2+EBxr4+kaNUp9XXvHfbrVCp07w2GMwfz78+GPj++zQAdxu2LdPrbdqBfn58P77cNVVkJYGPXrAvHlKEXgVhs0GQS07w/JfDm+PoGBLAUsfXMr6d9aTtyGPU/91Kr8+/isAyYOTiU6NZvtX2wFoP749Me1juHzR5b7zdJzQkdTRqUx6cZLPDDn9u+nYq+yAGguSszqHoLDGPxBvRtewVmGYw46uYfdmej3etBxFULGLmMQyyosjmlQEmz1mvWHDYNMmPJPd/4kynmR4BznNHDeTtqe0pctZXajKq6Jwu0ptkF9swo6BXdtdxKMiLTIXZNJxYkfaj2tP0c4iclblcMncS9j1/S4+uCUaR0wiN6y+gdhOqru1fKN6OxJdu5Ay7NDyHDwIeXmw3j8dDTYbbN0K4QFG8+/ZA+Xl6pjNm+G00+C229Q+ux3OO0+VqU9+vvre5MmRtm8fGAxKWXiVAKjeQkvvNf7VqO8bqC2upbZY/ca9SgBgxvczCE8K96WLaN2/daPzWCIsXLnsSr9tJovJ18hHp0b7os8a4na5uWb1NUSmRPqCF7yc8cYZxHeL58MxHx71vf0RWo4iCIoGwGCQ4A6sCDJUIkHOP1/1BnJzoU2bgEX/33Nww0Hf2xOo5GM5a3J8Xesz3zmTTdmxvPEwRPVrz/2/jaEqr4rVL69m1AOjGuWCH3LzEOLed5N70EBsp7o3frPnhchuP7xM3ueTnu6/fe9epbS9++vjLbtlCxw4ANdcA1On1u33vv0H4rff6pZLShrv14rg5GbbF9uoKa4hJCaEbtO6YbKYfL/fpmg7sq3PdDP+yfEqrYfp+Gbr/2DUB2SvyuZB54ONnNbVhdUMum4QD8mHfIqoPlV5VU3mL/ojtJw5i81qYI84xFSVGRmQkqJsw971loTb6Wbbl9uoyq/irQFvNRp4Vf9P1PWsrkT0VAnVIvumYQ4xE9M+honPTWxyQpDqGgNVDUbVe00rNTWNyzfE26hnZqq3cy/e51RYqN7+6+Pdt26d+u7UyX9//fWQkDofQ3w8rF5dt68yQG6zhveiObn46qKv+OnGn5g9YzZrX1fZCOq/3HgzpJ721Gl0nqLSNtQfXzDynyMZ91jjSWC2fLqFZQ8vO2a5Dvx2AOmSSCl9WVG9HG6cwG/P/nbI/cdKy1EEQR5FYJAgA89Qlp6uGobOnlQe/98Vwe4fd7Pm9TU83/Z5CrcXsumjTXx14Vc8m/RswPKDblSj003BJsISwigtVXaziuoj61hWValP/awmXkVQegTzcnufh9WqemsNt4NSEoGO8dK5QZqW+oqgc+e69UmT/Mu5Arw7HI0icNQe+yCiw+F2uv0auJZIeVY5H0/6uFHD6qUkU3Xp6r/MnHL3Kfx97d8Zcc8IwpLCGu1viq8v/tovQ+uhKNtXxut9Xqdop5ocqH5KnxXPrOC5Ns/5lV/4j4W4XU3L4HYeXr5joeWYhszKOy+ERLpcBDL9Z2TAOedA27bKZHH//fD882rfuefChg3w6aeBbdFeVqyAV1+Fjz6CtWvh+utVRMrJg8qEWF4pKCnvQCg1BJPKU33A7WqDnduwYSGcKiqIJIIKrOZIOra18c534Xz7VXdue6YtH3eHnZ70KvXt5qAa+ssvh4EDVZ198IHytXiVQG0thHoiPb2moRtvVI37vHnQvbuqs65dIStLNcJt28KTT9ZdY/Ro9fZutSqTj5epU/3NNVkNRv8fqkdQWAg9eyplcuqp8PHHh67Jf/1L+Q+6dIHvvlPRRbNmKV/EU0/VlUv/KZ2Hz1hNef+xPP949SGThrmdbpY+tJT4rvGkh/Zl1So4e1A2D70Yy1vPVdFxWCL2arvKTRRlYcN7G8iYm0FVXhUdJ3Rk5H0jG6W68CKlZMusLbQf357qgmqCwoOI7Xjy2ra8KUOaIm9jHpYoCzHtY1h490Iy52ey/p31jLx3pGowPfH/APkb80n/KR1bhc13fHB0cN04Fk/7WltaS9GuIt4f+T5R7aK4ZtU1TZqGZl88m1PvP5XEXokA2CptWCIs5G3K46PTP0K6pM/PtvTBpRxcf9CXlgLg54d/9qX5rk/+pnzK9pcFvGaglNzHgxakCOp6BLYqOw0jy8vLVUPQqZP6Qz/2GKzxRDkuXKjWQUWdXHRR05eZPVspi8cfV2U3b4Zp047/7RwLeRsPUpJZihmopS0uIpBAPEWYTCacLiel4e0orwohnkKKSKBdjwg2bLeweY8aYftbbgdWrPI/b0P7eVmZakQ3blRO3GeegYSEujfoqqo6RVBfSf7nP+r7UDkFX3tN7feagHbsUP6FCy+EL75Q5z7llLry3brBhAlKQaekqKif+lxyiVJMNhs8+yycdZZ6XlOnqn0rVzZ2JntZtEh9Z2RAdraKLvroI/j1V6W0hFCOwXVvrmMrvdi8IZk+U57gcde9CIMgZ00ONUU1pI5K5cCKA2TM80+X/GNsGFtKU8iQa1jCNJ4Y/gnDhkLOqpyA8qx/ez35m/Lpfn53LBHqeeWuyyWxZyLJg5PZt3QfSx9Y6itvtBjpPq07KcNTCIkLoddFvShOL6Y6v5p1b63DFGKi4+kdCY4JJjwpnKCwIJw2J1s/20pE6wgG3TCI4t3FLLx7IaFxoYz77zhC40NJ/zHdF0LsTUEd2ymWmA4xSLdk4wcbGXb7MDa+v5Fu53QjMqUuhLJ0TynCKEj/MZ2Vz61k0guT+P2F3xn171HsXbKXhB4JhCWGUZlb6ZtRbNgdwyjarZIILr5vMYl9Eln4j4Ugofv53dnx1Q6ylmfxyRmf+NWXEIKMeRkcWHmAwh0qAGLNa2uwRFqoKapR2UpXZBGRHEHW8iwKtxdSsLluEputn27lwIoDXL3yarZ+vpUFdy7gnA/PYf8v+6kp9O+ZbP9ye6Pn5ax1cv2m6/lw7Ie4nW6fkvrtf7/5zZAGENk2kooDFYx+aHTAZ/9HaTmKwBjiiQKS2CqsjRSB16TgfUP85z/r9o0YUec4DOQ0rI/XFJGRoT6pqfDV0c8/8YdJn5tOZU4l+5btY/LLk9nyyRbmzq5LgfuC9XqqSiGWUh6bsYOz3z+b1S+v5sXfOvHFN3DtPbE8+DRcenUwG+olal21qvG1GtaJd/2gJ6F4RgZERYHTY5GrqoLExLrlI6V/f7jhhrp1p9XJJRc52L49hHBZAURiMTh4+voDhMaHEpUaxcF1B8nbmMeIqVFUZFeQPjeenFU5GMwG4rvGk7cpj7OTw/nqxxCgNzlrcrhuaAEFCwSPXR3FDykmbn2qbVMi+fji6nkMGRXM5pWDqakJ4/lhn2HbvtcXTljCCM93DI8aH/VNMtMUnSZ3wromFKsMxh0dB2VQSwg5q+psXcIg6H91fzIXZBIaH4qjxkHO6hzf/L2HoteMXpRklLD1s61s/Uw1OnNvnus3d7ApxOQbYRuITTM3Ubi9EHuluo+NHzRdFpRJ0WlVP4Kl/1YKae4tc4nvFk9ofCgdJnRg2YPL/I759Ew1C1j9aSC9BMcE0+2cbn7KE+DTM+pmDtvx1Q4MJkNAk8rXl37texsPjlYtQnVeNWtfW4slyoKjxnHY6J3yrHI/8863V3wLqDmJc9cq+2VUahTl+9Wby1XLr+L9ke/7yrfq04p7iu/huZTnsFXYMIea2frpVkITQjGHmn3HVRyoQBjEcUmfHYiWowiEwO0yIAxu7JW2Rru9DXhD0wH4DxzKzj70ZeorgvT0xjbp44mUkvXvrKciu4KcVTlM/246u77fRfbv2fz+XN2fo36OlFPuOYXBNw/jvo7KJmpu04opr07BZDFxyj9O4T9TVLm8qnC/+/GycWNjOZpSBN639u2bHSRHWQH1I85YkQd7arBX28nfkwIcWRSEpfAAH0/8GWuZFWuZlbJ9Zay0Xw60Y8GX5UAkpeWCj07/6NAnqmcy8LKaMQBsXW/n+79979u+j3YcSWLc7F01VC1ZQz6jAMirCGfsVf0IjgmmYEsBVQuSoBpqIpNJ6ihoPbA1MR1iEEKw67tdDLpxENUF1dgqbNSW1DLl5Sm8MBgoglbnngLvwdCHJnPmqHLyN+fTZWoXzKFqMpX6JpS8TXlIl8QcZiYoLIjwpHAy5mXgsrsoTi8mqV8SKcNSfGNCCncUsnfJXiLbRLL1062knJKCo8ZB6qhUEronULqnFHuVnYJtBexdtJfItpGMfnA0v/73V/Ys3EOH0zow4dkJFO0sYtWLq8j6NYsz3jiDhB4JhLcKp2BbAQajgYKtBWz7fJtvxHj952CrtFGRXUHW8izCEsOoLqgmpkMMU9+cSs6aHNoMbsOeRXuITosma3kWyYOTsURY6HB6B8JbhbNv6T5lSgkwWHjY7cPof01/frzhx0ZZQuubaXwKUEDx7mJ6nN8DRN2bvHc2NUuUxTe9ZlBkEPYKpQRbD2zNgGsGkDk/k/S56fS4oIdPEVw4+0I+GPUBRovRzwfh9bnZq+y+mdbCW4eDULPR5W/0D2cLiQ1ptjQpLUYR7Fmyh8iCGCJjK3DWNFYE3oiUjh0b7fKzOR/Kgexy1fUs0tPV55JL/oDQh6FoZxE/XPuDb/3F9i/6JrtoN7Id8T3iMQYZyfoli8i2kSBhzENjyM4343Co2PhqVzAhHnOJlNJj7xds32QHgti6phaoiwLatcNNwxiD6mp4a8SHYLVhr7azpTgZOBenUwKCj25YyTbWA7cD8PnlP9IO1SDk8Hf8FYE6JhARNflYy6wERwcTnRZN17O78vybraECCkxtwAkuTFzw1QXYq+xYS62EtQojbUwaBVsKSOiRQNGuIhJ6JOCsdVKVX0VC9wTK9pex84lE+BycbVK56rOrfLNK7d4fxAc3H/5ZjHnpXLq2n8pjA1TddP3HVCZfrfaVlUGZp4673TOVa+8Xfn/okfeODHhOr0Ldd8DzN42Npf24WNqPa+9Xrv65AiVS6zK1S5NyJ3RPIKG7mmi+2zndGu0PiVXPPm1MGkNuqpsuZOJzE/3KxbSPodOkTjhrnX6jX71mnw6ndWDY7cNw1DioLa2leFcx7U5tR/pP6XSe3Jnqwmo2f7yZQdcPoiqviojkCNXYn9bBdzzAoOtV4+myu5h3xzxs5TbK9pUx/fvpzL15LuVZ5fS+pDf7f95PRbYypQRHB3PZwsuYc80c35ScoFJ+l2SWkPVLlq/HEJ4UTnV+NZ2ndqbX9F70v7o/yYOSCYkNoba4lorcCt7s+yagQqL7XdmPsr1lvtTkg64fhHRL0ufWxTivfX0tN2y7ASRkzK1rQNa+tpaKrAqKdhbRRmZTThTGzAKKUN1lYRRIl9Ju4/47jiGz/wmvhSmH2nGmxSiCzHmZJFa2ISKmEpctcI8gOVmlD2hIfUWwahX873+Ny+TlKTOHNx5+7lz1RnwkPYK8PGXrHjs28P7yrHIOrDzA6pdXc+7H5xISG8Ka19fUTYbhebPacLAVI8elctE74wlvFc6eLZV8MktQO3AQzmoH9hoHP0/dy4G8ICCNjpGF7M2P5eUur5NZFIWrrIIMOR2IY+OKaiCILWut1FcETndgx9kP2f0odkZiMhlo3aYWiryCQVbiIKyxfcEjbodbp9IqSZDQyoD5wRioZ8mIj1ehpIHCSTtPH0TrKYPYoQY207MnlDyjlu3OOrnmZPTA6B2AmQPMAoiAzQCR4MskEAMrAJJY5QkVzc4x8PnKdr6BhA3DUZvi5ZchNrZuFOlTT8E3yoTtF3r66GMGCovUeXv0UC8PRmOd4xuUQ/2cc+oUgfclpbgYvvwS9u9XDuqQEOjbV5nZfvxROa5HjlR+l0H1ph+ZMwfGjQv82z6eCCHI2G/GZoN+/fz37d2rxmsMG2bGHGr2pVbodnY3Nm0CszmSkf9UCrF+bigpVT1OnQrfXvwFbYa0YcQ9I9g0cxNrX1POpI4TO9L1zK58fcnXAPS7sh8Tnp1A1q9ZPpOPyWJi2kfTGHL/WN7p8SIAW9/+jXaTenFL+i28OeBNrKVWIttEctu+2zAFqaYx/cd0jGYj7ce1x1HjoDKn7mEaTAY2LCpm9be59PpiG464RApqIxjax+Y3Uc2Gdzew4d0NBAk7DmnEHBbsc/oWLd1EUvUeLuBLX/ntcSPJHXIOhbFd6TXrPjbQHyuTsaxbCRec/YefUyCadYay5uBYZyjb9uU27Isupfvg7eSXDCX1nl/89p96qnpD/jlAVNh//gMPPHBk1zGZVHqKFSvUH/yXX/ydl4H497+Vo7KmRjkYpZT89sxvtBvZDqPFyMxxM/2iHRrS48IeFGY7uPm3GYy1rGCsXIbL7mIZo1hGYO0SbLAzOn4b8wv689F533Df4tNoFWMnIz+S8po/ls/EOwoXvPfjv99kUv4Ci0U5aY8G77H1l2NjD++7ORJGjYLly/3HKNS/bmwsFBQ03tccTJ8On33mv23GDBWIAOq3JSXcfbf6fZobPDJvne/apRzmM2bAJ/6+0uOKrcLGvDvm8V72BPLLQxqlZ/nb32DZssCO9xEjVH6nuXMb7/Omffn8c8mOix4F4CH3g7zW63XfCPfp302n61ldeTzkcZxWJ13P7srI+0bSZkibut6SzYatpIpJAwoYk6dSQF/Ha3w/8DH+vvrvPGZ+zJeIzhxmJm10GpNfncxL7V8C4M6cO3mhzTOcFrGK5ZV9sGNhAOtYwhhmciV3J37IwwU3YMHOrbyMKdjs6QUNIW9jPpUHyhj13hVUdR9Cxj4jCwv6cfZ/h9Dl/vMJJvCfIIMOdGIPmXTgN4ZzGbNUGOLrrx/l01H85SevPx6kddnGrgUCEEhn4B7BlCmBj/X2CKZNU1EhgXTniBGqAVmzRjVw1dWq8QgOkPhSSkltcS1VeVVU5laybXEoVmtrPpz8KWaTm6LtRZTtLTv8TQn1VnJw7UFyRTISgTOlPcPOV7bM1T/0onW6g5+/KiI4NpjQ2FCCIoIQQhAUFMRHH/Vn/jUw4plp5HcFQyRUNjGndmGhivypT/2GqT71G9JAdeVtyAMpgQkTVORVQ+bMgYsvVse+/rp6+/WGaE6YoBrN2FiVLM57/qMlPFxFEAUaM2A2qzEP1dVquW1bVScNG+yICBXOWlvb+HizWTXKXif6okUq5UV9goPVi0P9wWxevI56b4QUqCR6DUNk6+PtWW3b1kSB2iYy9TVFba0SUgjVhbFYYO9e1r2znY3vbSQ6OYxdEac1Oqy0tMFYkZdeguRkKuLbU7q/E64wFxCrujNSqoe4eDG5iwVBTCD947qEcBXGGArlHZhDzZxy1zC6TFADGy+dfykfjH6f7O/WkfHdG2zFQmxqNDXdBzDSuhDzqpWE1NbNA5BEAQfXHWTOtXN8SsCAC4GJfQt28m37haQhKSeC5W0uoD1xDK9cgJsqFjGB1QwjkWJ+5VQ6921Pm4XrmcHnODp3xzpgBMV9O8C50+g5sAMRxXvZXxlG3OpfGUwNQ5mDuP/QVd0JpTU7socwqgE4kGvg8KELR0+LUQRWawIGoxskCKf/v7SyUplnmjLjeBVBbKx/99rtciOEQEpJdRW4HJKijQexllspzyqntqiWovQiSjNKqc6vxl5jx15hx1Zp83Ns7eEcoDXb5x8gDCWbKdiEy+FCuiSJvRMZfudwIpIjCE9WMx2ljk4Ft2eaQgGffSbgYqiJTua0J1VejLu/gx59oPOoxrlS6t/Xxo3q/3eoBqVh2CWo9AxNERysegZHMmK4PomJgcdpeJMBgjIJ1W+7Jk6sUwSBFO/RcLg20StbeLhSBJMm+SuCTp1UhFRUEzNU9ulTpwjKy/17OKB+X127wpIljY/1vk2fcUadIvBGpzXEtvAX9lbG4UjpCYA9Yz+URamHXVGhusAbNsD48epVfdgw1S295RalzX77TQ2k+fFHpQGXLVPbhw+HJ54gJ743bf4+VWXlmzkT6RoKTMBlc1JVWw3b90OPHjwb+Si9x8VRuXky11d8gfPGHOzzlxC6RzlhI4ELeYiddIPrl6kQu5IS3xtEW7rwBGdQOaeuQtfLfgD0q/mVHh9+g3hsLYSF0e7Ci7iN2URTz563H9hf1/j/k6dZRt1o4fP5guR3XyBa9CEqIYjkgg2EVNcSQi3GBt5n7/tNL7aSSUdiKGMSczHjhIXpeKdkNKfvwJy+gzc+j2E0IaQt/Q4nJj7k34BSNmNYyqksb/zg6l1LABvpR0cySUI5jsvyarUi+CNsnS+JNTkxmNw4a6tYfOUdhCWFYwqysH5bJHArzsUvMOf3dCpKEnC7BC5pxi3NbMzrBEzjwA/rebXbMlwuE7XFtVjLPa/PbsjnTiSCd4e/e0TyCKOaYCUyJZKQ6gQ4AIPvGUu0LCMkPoSgsCAsERbCW4dTW1JLWEIYhTsK2f3TbnW9Tfnkrs+lKreKvI15bO95HtCZretsfHf1ApCSHZsnM7Z3MZ+f+4tKiBVqwlpqxVZhI6JNBMuWSuBcPn08EwjgJfcQaraz8B9LAP/htvnzNwL9fOsGXIDAjQGLrCXcVU0N8RwNUeFOSjIqWP3qanpf3JvEnol8f/X3JI/pDKjh/5074+l2GEgIr8W9djswkKhwFyue/p2B1w4kKDwIW6UNYRAERwVTfqCcyJRIhBC4HC5qCqsJvvsWjKePx3DmGSor3eDBKl+1B78BTQ6HasHbtQPqFMK4BhkIOpEBOSGNklRJt8SVuY/ObVoxHzWIIuPed0D+jfrOd1lVRadV3wGBowwMws3Iku+Bc9Q5drlY/b/lwGi6dnGza7c6V/mE81jJVCLvvg4Yhq3GxcYRNxG9fQVp7FdNXJs2CKDskReIPG0ohn/9i9LZiwke1Jva7xcwL68ffS9/kp5f/8dfiPvuw4yne/i+CoX0uqtNxXk8xk24T/kOW+deVFWexsrviniNSXQhHV5v3Og8jCenzpuN77cDe1VDW49fGE0INUxmPiLL01hXVyPef4/ogLVWx2h+oQu7KfeU7IlSSKPkL3AYs5/3KUVRweUcOjItl9bcyKuEedKrlxLNaSxkEGs4QFs64T8E/iBJtCbPt55OJxYwCQOSPJKYzDwAkkIqDnOHx0aLUQR5mwoxmqPJ2NSJ0Iga+vaaSVhUNSaTi+6pQZw1/r9EBlVgNjrUvAXCk5cION8RzBUFXUiKzCMhvACkQBjcSGnA7RK43QZS1mRhc1i4uP8nuN0GXE4jLpcB6TJgdwSBW+J2GbDbg6ipDsUknLhcBqzWYJZvjKXC3Y/yta8TGpaLzW2gJD8WDGAyOik8mIjB6EJKQWVZJG6XAYPJTXVFGC6nEZPZzYaVqidhJZhlH2WAS1DhDqJm9RZ2ih2YLRK3S+J2GohoBXsXA6FqVOXqdYdObWtxVrP6pdU0VATWHZlAP4w4cWEiijKshFBLKBZbBZEUk3OUimDbm8t5+Q3lqFnzwm8EY6WGMDWIiTRsBDN73DtU780DHqVr1RrMr74FfEz5xkwWbVxEyT+fIIwaVjGEEAuY2qdQtTObM6N+RYaGElqURbJjP2Zs1HzyJY6QSKJq88mIHMCqrlcgEuJxVtcSsWYJad1CSHIeIDZrI5ayAvbd9SJ06IQoH06osGAbfRawyCd/+w2zqez+IjVPv0pBehlBc74mNBS2ZZjZV51IqogAniGcSn5Pj8XZMALLZiR2/XyaUgQp8gAJd1xKJNlUEE2t3ciGhUWEUk1kxg5AmYBzSGYGs/j0WYBh1BBK8vb5GJCUEaXemnNykIBcuoxVS/MYChjWr+X79bFMI4PJHCTy67qGx4mJL7mAU/mFlPoefsCKGsA2mDVcxYdQDjVrdwDKTNSFdEqIIRb/XCISeJ8rySWF01jIMJT9y42BCiJ4kTsa1YHEQHv2IJCHiDHzv0YOrTHgxoWZnxmFBSvd2OlXzo3A4DnndnpgxIULQTd2Y/T0ByoJJwL/wS+b6EMhiYxFdeOMuElGdft20pVu7CKBIhIoYi9ppLIfJ0ZMKBvkD0xlL2m0Ip825FJBBKupS8U7mNVspSch1FJy0EIDC+1xocUogojWESx+9TQa/mxMQQ5kiMAY6iI+tIjg0FpCwmoJCa8lOKyW0IgazOEOckOToQJsRgsmsxNzsIOgIDtGsxOT2cVFAz/HZHZiMjsxGlyIo8ji9NmEQ8eYSolvdjWJQLoFRqMLl8uIlOByGXlAPILB5MZmtYABpDDwgOsxDA43Rpw4HSZcLiNul1JSUgocTjPnOj/C7rTgcJqpdYRgdQRjs1uocYTicJioskdgsjvoZ9vE1da3mL9lEk67iaLaBHq22Ua67EJhYQKFtgQ6haSTbu1MrTuUCCqJp9jTSwA3XmUT6K/rJoRaagmjQCbwM6diCXFxiXEmn1RNp9wUwxZnT1zCSJCwU7SjkHlMQuDmN06hCxlEUcZe2pNJBwy4SCKPEGxU2iJw7ywCQviqfAITyudjE5HkMJgsUsmgM+1r99Cd7QRXWGm95ls2in70kluZwEJYD1m0ZROplNIX8ewczDiJ5FG6Ekba3qV+dxJGNfZKG6tveJed9OBKVgLQhQgmsY+Z8lIA0tjHN5xb/ykDAhshXEXTM1ZlkUospViw+Y75mvMIwsYad50fcACbSKCAQrcKRSwhlr10xIKNKsIZyQqWM4JTWc46BhBMLRFUsZyRXIQaARlEGdvpTg928Dj3M4Uf2U1XyomkGzuJp5BenjfqDNQAnFhK+JWRpLGfcuoGP2XQkb5sYhYX04vtdCQDiWA1g/g3j3MdbzOfyTzGA3zHWXzFBeyie6P778tGNtGPL7iA/bSjJ9uwY2EUvxBDGSVEE0UFlYSzlw58x1nYsNCJTGZxMdmksIEB5NGK1QzChZFECqkgksWcRg+2sYH+OAnyja4Po4pU9nEBX1FGNLm0Jo4S4lG5VdYymGzaso0eJFCIDQtG3IRTxRZ60Zl0urMDCzZ6oELebuM5HuIxYimljChu5DX+w4PsoCdJHiUCkEAB/dnA/7gbOxY6FRYxuMlfx7HTYhTB0NuHUrSzkLjWFVTuP4DbXoPT6mT3wVTSCzrS2ZGOKAe71YwMECIphWSLuS9GiwuMEpPBhdstMBucOF0GXA4TdmsQ0m0kPLqCmsowjCYnRpMLk9mF0eRs8N14W1CIDaPRhRAcQXmnZ5v6mILqtnkVktno8O0PCbNiCmrsBU3lyOdPncx8v3W3W/CQ61FcbiMOhxkjLuxOM1W2CIxuJ06rGZdJ9YIM0k2tOwSny0RuaTLW2mBqakNxuYx0idyNMEhyypKJtFdixIUEasrDudr6HjXWYAocraiQ4QSVOUkwFnJKyQo6ujOw11hIJpu3uJqL+AozNmIpodQYjVnaMbttmHFiMjkoc8axgIn1/DNqYS9pZNOGQaylnChsMoiddEMAtVjYSwdakU8V4XQigyrCGcRaOpHB95zNdbxOT7bjRpkaMulIPknUEMY2epJAEV9xIUP4nS7s4l6e4Cy+4WfGsJk+dGUXbTmAHQsb6E850ZixY8JJDCWk04XOpLONnnQkk7mcgQMTF/Alo/mZ7zgLIy66sx07wTyNGhZf6IlHBwilhqHUeaCzacMnXAzAO1xNGvuoIYzfGUZ/NnIdbzCXyZQTwY28xttcRySqdxBONRvoTzRlJFBEKwrIpCOhWCkhjt2o8QjmetEwhcQzkuX8xkg2MYB4CikmFomRc/jOVy6Mav7Lv5FN5MPsxzpM2MmkPXvoSDUqDDUIB5OZy8+MYRu91G8RCwIIxkE27Rjtscn/j3v8zhlCDWYchFPFJvrhJIiR/MoIVvATUyglhgw68ST3EISdG3mDu3iGV7mFNQxiAvOoJZSvuIB4ikmnM0kcZADriaCSEGqYzflUE8Lz3EUurXmJOziPbxjFr/zCqVzKLDqym/t5gq+ZRjwllBPOnpAOmC9zEjmzFKNV0i2yecLWWkz4aFP8+98qL0xNjfKJOe1O8jbksf/X/Rxcd5DCbYWU7S3DXmXHgYn9pBJOFeFUEUZ1wG5pLcGYg6HCEQwhEBlRQY0MJchkJyGpkBJnNCII4oOKECaIMFdgL7ZAJSQkFhIcWktEbCVms5PgUCsSCAm3UlUajjAoE1NxXhwxiaVYQmyEhtdSXhxFcV4ccUnFWGsslBXGEBxWS0iYFbs1CLNFDXBwuwwYTS5K82MIi65GGNyUFcTgsJkJstgxmlwEh1mx28y4XUaCgu1YQmzYbWYMBondFoTR4CY8RsVTG00uhJAEh1rViEjPOSwhNkxBTqRbqHME2zBbHJiDHJgtxxjWEwCH3URhTgIxCaVUlESSf6AV4VFVxCUVk7OnDTWVoSAFDruJ8qJo3G5BRUkkoeG12GothEbU0LFvBjkZbVi/dCA1laEEh9USnVBGwYFE3C4jdT2YIzFEHBsmHFiwUUOorxEUuJGIJq85nkWMZDn7aUcqytO/kT70Z1OjsiHUUEMYs7iEUKqxE8Q3TONzpnMm3xOEg9mcxxiWMoNPOUA7agkhjGoMHoUpcCExEksxDkxUEoURB23IIYvUAHLW1dcU5vATZx5lrUhPT7HxXNQOTLgw0o0dHKQ1diz0YgsxlJJHEnYsjGUJX3I+0/iOtmRxOy8wja8BQScyeZO/czOvUUUIB0jlNBbzKdPZTVfiKORmXvNd7xdO5XrewIyDTb37QSJsW9yDbziXXFrzHWeTTQoCaEsW8RQxyWPXn8tkNtGP8/iKr7jA94xSOMDNvML9/JeOZJJBJyQGnuJuTLjJpAOXnT2TYReuZtHscbi+NhEdbWVo6ZFlPm2IDh89BN58QN50yKYgEylDU0gZmuJXriq/ijkfl/P4P+qcgAMNGzjT/T3lhPMDZxJOFYkUYMRNN2MWWG2Yq5xQJYj02BUrs6Mwe/5YxSRQRTi1xnDKXBEMHBlCUhcISYnEFB2Mq7YaQ1QhIrorpQfyESHbqaxsg9teS5V9I/tXR9O6cxW5W504rW6cDiORsRVUlkYSGlFNdUUYcUklhEVWExxmxVodjNGkejIhYVas1SGERVYTn1wEUlCYG090bDkgSe6Yi3QLHDazr7dhDnJgNDtx2MzqfDXBhEWoc9tqg7HVBmE2O4mIqcRkdlJTFUJVWThBFjtV5eGU5sdQWRaO2y0Ij64mIbmQkIhaaqtCKC+KAiTxySXKv+I04nYJqsrDcTlNmMxOhMFNaHgtLqcRS6gNU5CD8KgqYhJKqa0JJiyqmi5xu3G7DbhdBroN2qlmJpUCg8HdpLnOYTfRbeAuxl+0BIfdhMHgxmhy43YJJAKX00jxwViCLA4soTaK82IxmZw4HGYswTaKD8ZTWx2M3RpEbKsSTGYne7Z1QCCpLImgujKcqrIILKFWouLK6NI/nS2/9aZ9z71ICVtX9CE4zAouSUVFJEajC7PFSVlhFG0dWSR0LyTb1pbohDIqiiOpaBNBZn4nEtLzoRqfEgCQYeCJNPTDSjDvGa8gR7bDEO4kvKKSElTY2A664UANRNhODz7nIsw4sGCngghKiaYD++jLZhwYKSaO2ZzLaSwimgp+YjKpZBHR6MJ1iuEHzjxkzvuddCGWYlI54Gv4YyjhFl5hLYPoxG5qCMNKCOGUcS9P04ZcrmAm+2nHt5xNNGWMZRnvcSV/4wMA7uJ59tAeF0ZeRQ0Rf5UbOI3FPMG/KCOKj7iURE9UzkFaA4J9pDWQrxuxlLKCEXCv2nbh4s+ZxndUEEUubTiL77mCD8mmLfm0YiP9/c6xhHH8ygjmeBRiNm25FxUDnU4XT425KSWWYOzspT0OqRomi8XOJroz0dR0pNEfQSuCjMD5hRoS3iqc2hj/uMY9Uf25fn03+rcv5SDK8RqEDTsWwmu+8NkDvbgQVBFOSKiB0pogXJgwGaHGHUw0ZVSvz2LjitoAOVN2ExQRRGSbSCJTHES0iSFq0FSSE8MISwij23UhWCItmEPNhMaFUplXSUhMCEHhQRTtKEIYBOUHyln1wipO/fepRLYyU7Alhy2fp1NQaOLA8v0kt8rGYTaz5bc+IJtrfk7vjdWd32yx43QYkW7lQ4iILScyppKS/Bhqq0JVWeEmMaWAotwEpdQ8vaRIT69ECImt1oLZYqcwJ5Ho+DKkFISEVxOTWI7bZaC6MoSouDLik4uRUlBTEUp0QhkgcDqMxCcXERpRQ0iYFaPJhbXWgiXYjtnTw0lKzfcNjguP8m/wWqc1nuKscz9PVIgbcAG1QAXQBnBAn+Qtal8xjLhsJTiBFGA1sA2403Ps06iR0LM81bcc+A6oQjX4KYA3fU8o9LxjBzQI8lE1b+DCt74i1FyDwSjhBXh/jcqBceqo5YRaqnl14S3YTSacsUZ6FW5jnpzI6XELSfDkGQ+NrSKkXw3FSxI5N+QbDLXqefYybAe3wGhx4LIpheI2CPbLduwydmGScyEGoIwo1jGAfmwg2liO0ZM+IYQa7uA5hrAWiaCQOD7jYi7iUwSSwag0wDGUU2mOIcJRyvtczVZUaGwqWdzGy57qFj4lcFC0wi4tPMJDfDjsSkiER75/kJ+Ywk2oQVlPci8h2DwKAPJoRRhWwqlRdWuEB/c/jBHl/6hPaXQspWUx1HpG3v/AmRykNcHUkkQe+/BPBVJKLBfzKefydeMH5KEn2wlG9d7tmFnNEE5lOZmmjixhHEMHNBGX/AdpUYpg6VK44466kb5PP62G71ut8PbbamzM5Z75qZ94Qg3qOf98FS++ZQssWOB/vrIy6NI3hIp6KRjsnuiJ783n85O9mlhKGD/SxvblpURQSRFxRNhtlBBOMrnEuMr4ggsBOL1mASNYiQScpmBKjfFkO1vR3niAImsc4RlViF01hFNAiKzxRTI0xImRWkMYtSIMuzmMoNgwcspCqXT2ZM4NlZTbQmndNoGM3FRMlaXEuJNxFQUjh3TjwkkzydsMKd13sGV9b+6e8T9eX3wDqen7MLVzUZYfzSXps/g25GyyrB0ZJFaxydnvCJ9AYwXjsPlP7l1ZEsUvJaMJxkp3b1SHNFBwIIlt9KCmNISs0nZYsBOdU0obcmjPft/xmbRnVdlQurKbPJJIJJ9Qan1hggB5JLKUsaSSRR6tMOFkKj/6TCBrGEQUZXShXoC+cGM0ukFIDAY3ydG5iGgXFUTSpUMGllArdreZCZWLIREOpLXBjZHUrCyIAcxAEJRWRxGdUo7o4Dmv9yXEm8JpEjBc9VLMFifc53mmW4zYfzYT2t2KfaAJEkFugPKx0YR8baXWHULiE4UE0XS++mnPf8N5g2ez+UAfunbbRVVWOEHFNn5YdwYm4cKAmxucb2EpUA3RxXwGxdBj2FYiUyoYdfqvBAXb+Dp8GjtW9EDWegIAPIEMI89YTm5JMgWVidx628sYjG6e/fEOkkryiA4u48tfzufZm+4iQlbSrfsuFs4ez8NfP4QLE+DmOe7CFWwgJMjK9RVv0GpSEY4YIyM//ZUDpHInzxLtKGcuk+nHRsqJYjI/EUItbcjhKe7lae4hnGoKwhOYFDufzVl9AfjfFf8gIbKI15bewNC01WTuaU9udRs+4Apu4C2fIigkgTAOqF+qZ8Ci5So7TnsQsfhPvNGjzXa+KzuLsnpBq9vpQRzFxFHSSBGAZFr/b4jZXILB5aoXQFHHMH73GdTacJCECOUTMIfZ2UZPlgWFN4uzuEX5CC65xH+Y/aOPwoMP1q136aKG5DudamCSy6XywWz3tCHekacxMSonzk7/6DM/UlLU+bwDg9q0UcPod/h3EjAIidvzBh5vKOHUlL2E2MuxOKrYVNWB9bZenMZCFnE6AGbsOAgCJKFU05YDhGDFgRkzDkKpJZwqQqgljGrCqCbGUO5zmjZFBRFIYUQEWyi2hVHlDqWWYCYxl5lcwVBWUUws2+nBOgYxnc9YwQgOkkw/1lNDOF9yPrfxEk6M/Id/E9wlivDde0gijxlJn+HIM3FZyEe0ObOQvB9jWVc9kFpCiKKcqKBypF0ZDx7mIc/3I34yvsU15OIfn9+TrVxA3VDkLzmPbfTyK5NMDtfyDgAdyeAjLmFBg1DYm3iVBJUgiae4m2RyuYxZhFOJCyO1hBJLMeNZxDoGMZF5JFJIpcdjZMBNGNWEe8wjEpU2OpQGQ4yBVRGDWZc6iEprBDuiu3Fl9Ae0icuhc0kmGFFvol3B08nEd4oGg93W7exP9pq25CYlExZczb6iVD7/7SJqS0KQEYJ9hWl4o9+jQstIjs5hR656i04L2sO6Jwfx7S/nsPHb/kRQSSkxtPIE01cR5ruXPpdvICaylNm7z2dM96WcN+QbBv5zDRfyFRGU09WyE8cIC5177qZjyl4G/3sVT0y/n9N6LUZcotoXOStwL3Nnbld+3z2U1rF5OF0mhnZYRWxECZkHOtA5VfWqlm0fzeYDfSivieKUzr/xv5/+wQVDvqSiNpK9u9O4+uz3yMjvxBVvfUi4tZLh/M7vDPP10gE+vXk604d/zvs/X0Fawj5W7RrCfV89xchOyzktYwnfciZ92UzEmAr+PfFxPn7qUu56tS699COXPIwdMx+bL2b/B6qBf+P7a1m+dyQ/bjqDSlsUrcnFhZEBbCCeQiqJYNyoJezf1Y6l+eMY2nMVr9x/C798M4p/ffU4Fqzk04rkkBxmv3g+d7zzHMmr8ygijlhKMeFi7PWLGXXqr6zf1p+J/53P/EeuYMCDPwWsy8OhfQQeGo7A3L3bf33vXonTKchaX4TLpeLfc7Prsm0mJysz0o8/KoVyqMyil13mn7I6Li7wKFt3PTNMuTGW2ftiEQvmg1Uy4/2OrP9O2XB95TEQG+2ipMxIPMW8G3En9jvu4Z53u7E2R73VpLKP/fVsnL3dm9lCb4/d10YwNrqzjRzaYsFKHMUkUMQguZagWhuRhGEjGAMuiklgKuqHl0Ax3UjncR6gi8igvdzLC9zOaH6hmjBWMZQoypjIfGoJYfvuJGbwCyHU4sqDIKwYuvRi0v7PWFWbx1W8jwUrQ1jN2fZvWcdA5jPZJ/csZiARGHCTSAF5NM6seZDW7KMdPdtuZdWB4eQ0UBQAxcSxg270ZjOX8jE/1ruGl9hRRRjLHYhNLkKopToojJGDl3HqihWAatgNSMw4fSa/57mdjmQynJVEU8om+nIHL/Av8TiT5HxCqaWABPqwGRNOVjOEWEoYW7mM2q11DtByEc23chrPczs38SpmnMztOIF28Qco2R3LNeVvYxUhtO+yj4SIQm6f/AJ7C9ozuP0azr5Mpcx2uwUGg+T+s57AuNfFhwcu57FvHiCpJJ+QoFoePe9BCvcnMufgmQgpSbHn8PKdt6nfJiXkk0gtISzgNPJIopg4sh5OpfbhYFrNLOCNNtfxSs4tpCXsA+DKcR9y68yXeazr/bQbdIAuMzPIeUU1vMFBVk5/YgFt4w7QNi6LrJdSeXbOHUyIW0hYSRXrEgbxwMxHuXryewxIW88Z/X6kqDqBWnsIu/M78/PPozmt52I2Le3N7pIudB28mytHfUBkiDIFju9Vb9j1ZMgtbU2ftC2cO/QbMvI6kleehM1hIcxSxRerLuL5uXdSUqX8IVP6zaX73Tv4/JYZzLrhEgZ3WkNySA6LbhxLdWgYnSLSadWuwE8JAJx/6xesXzKQUwpW+rZdf9ZbXM9bACxYfDor31NzTpwydTmbfu2L22Xkputeo7QgmrA7rJzWR0XdnXr2L7zR+joO7ktixQ8jaNcum/Cwav536d28sPpOup+yjZqt4dRWhBEcqQatJsYW0JNtZNf2Y0CjX+8fp0UrggMNIicdDkHW6MtI/60APKGS5RV1DXVODkyaKEFCp45wqAiSkhJ1PQMu5jOR5TvG8rj81yHlC3eU4Oo4FFNZMZSWks4aYBA11OW16MsmnLYISujC2XxHz8rfsDx7IYm2j8HTvd3fwNGVTQogcBCEgyCqiGATfaloMA7zZW6mDSqH+jwmYsPCGgbyEnfQlixu5hVCqKWQBMJlBdGUEUMZ4VRRThSlxDKAjRTSikJU/omXPKmnvaF7Bza5eY5TCDPYuJY36cF22rOPVuSTaKlgr609OaRgxM1L3IIAbuVFljMSE85G3ekS4ujDRobnruNungn4RGwEk08C55LuWbf49nVlJ/fzX6LTy0iz7aMn27iDF7nX/gTDtq/xM7W4QgWl7aKI2VlODSHczTMkUuDrpdzN/1jOqWySfZnEfNLpyFiWke9RYCP5lWLiG0XB/CzVrFN38hy/M4zPmMHk2xcgg0G8DMmVeSxzjiVrh3quX62+wHOkpFfcFnJtbaiyhtM+YS8PjHiMnvbtDO/8O/8IfY6C4lZgg4UfTUQIN10jdlFTEUZYfCXVRRFEJ5Qy5cqfeHD5I2zM6EfbpAPs2dIBE04u+e4jbkh9gx3m7swW5wEQ6RnZeuaAOdz3+RPcc9//CDI7aP1jLlVW5UPr024L43su4cV5tzGyq3ruwzquwpEfRNK4fKb//TPacoB7Pn2G8R0XUJIZzwZP83Y3T/N+6JU8/OUj9JJbCbLY+P3rUwBJ19a7cLjMXDP2HSprI5iz4UzGtFrK/I0TOb3TQmK7lXJK29+IDK+gb/wm4pOKfXVVUhXLnPVncEb/n8h6qR3hwf5+nk+fupiUlBxWLDoFt0tQWhhNXFIpbrdK7ftx5sWY2jsRUoVgP/PDP5jQYT7bFvbitPMWMWH8QtqE5bB3WwdyMtrQqW8G51ynwmJjEsuYcMl8X94tYYCew7bTfcgO9u9MI6616omGRtQQnVDKzTe9zu7tnfn08UsIj1BBJvGxRYwVS9n3Uy08EeBH/gdpMYqgpKRxhsqcLSUoA25d85GxuYaMcdfhGSToCd+DxAQ3BYUGOs15Hl6+i07EQAPnkd/18uwM3DiTXrg5jcWc5lhMLUae9oYcBGA8izDtzfBct26QTil1ebBv4lWW1Y5hsye2PIoKRDV0YTs/MREDLmZyOZcyi35sYDs9/I730lAJgBp05FUEkzyKcDddqCSC7fTkcmb6hszXnSeCSOpS8+6iC+sYSAURdCKDfbSnPXuxYaGUGCKopIBW5LqT6cZObAT7GgFsMImFvnOtZhip7OMKZlJLCAYkObShhFgSKKSMaMqJIokC2rsy+I3hvMTtpLKfuUyiBzsYyDoEbk5jEZFUkUcrruBDxrMYgDP4iTT2U3AwkVCqMeJmL+2VAvMfBIujJoidO7synNV8zoW4MHGQZKoJJYwa3/Pyfm+hDznURZ/tpSMmHAxiDWvrWXq9z0diIMJTlyvvHUJVbSSnuxfRiQyWMZZBYi1r/Xr2gq3FfQilhkgq2HuwA2u/GkSGJwLFaHZiHm2lwhnFb3uG8+WdFxITW0rmlk50HbCLsqIoouIqMJpcfNrvYt9ZrXYLhZUJxISV8vZrf2dXRRfW7hmIxWylVxs1yVHbuAO8dtWNBJmVohzUYS1Ot2pO7pn6NKnxWbSOPsjvGWqErBk7c945iznvnEXHyAwioyvZn5VGx8x9WH0vOpIQrAwP+p05NWcxmXl8Yz2HOIqoIZRdB1XP+P7P61pC9wEDV8Z8yNydk1m+81Q6ksFlzGKJcTyZce2ZWXCF+m1Xx5JYWEBuZmvadMzFVhvE16+dS1R8OaddtIiUlBzycxMZcZqaijAuST38T/83gxn/+JTbR77E+qUDaNVZZTx9Z9k1/P7pMPqwlQW7J/DK4zfTc9h2eg7bTnVFKGGR/v+T4VNWYrfVpYj98YPJjL9wCYPGr8UdrNoYc5CTioFKmaZ0zMYw0kl0dBk2RxDBFhspAw/wu2EEzUGLUQSeHr4fe0oiPcPU6xTBZ/ZpbN4xtFFZY+FBbuZrJux7k+10x5IQRUxhScBGFmDndzu4wNOYvsgtxFAawHnkz37SeJO/48LINnr48qHU534ep7Vn5OEDPMoIltOdnTg9jzKUGnI8ttE4imnPXnbRjRjqZO1ABns8jZU3PQTAFXzAVH7gWe7yvH0b/N6IL+QL9pHKlbzPx1zKHjoSTSm5pBBKDX/jHV7ypAQ4jQWkcICN9COWItLpSjHx/I13ac8eEjlICFZ+YgqZtKczmYCkNQf5kTMZxxIs2JAI5UOggkWcRiwl9GEzyeSyn1TMOMikE7vphgk73diNARfnegYpVXtGt37LeX71aMCJALbRkyf4J8kUYMaGGSsP8RjjWcIMZlFKDFFU4MKIBRsujOyhI19QN3H1W1xLaw6S7UkHtpohfMn5/MgZBGHHjcH3fNLYRzd2+hSBgTqnoQkHHdiDGwP7q9szGZWXuZPHaT1Vfs86BiAxYMJBd3bSkUz6sNnn6AaIoIIyonjX8XcO/NzOt/2UZ36je5sd3H/WfzEY3WTu7Mipb/3C53dO5+yBdbOyrds3kGCzlbZx2dxx5wsAPFz4COHhVUSGVPLesqvIK0/i/rPrGuRR3X6hdbT6XabGq3DW68a/RZ92aiIYk9nFNnowMHkN/znz30wYuJC+929CFrtxS0FCZAFPXvhPdnzWneryEHqmbGWfqy0lB2OJpYRgaqkOtbH4/vG8suBmPl5+KTHhpVww8gvGd15Mx+pM3uh8PXe//zS7d3YiW7bBYVIN74C0dQzr+DuvvHojUbKSCRctoHNqBmWFMWxa34+vl04jNLKGsg5RXNDxS1olFZKTn0zrrjlYHcF8/tx0hl70O92n7CC+ooidBzqztyCNYGFl0JjVRAWVsWFLX6pkOL26bCMpoS5nUH2CLA7ychJ587HrOPO278kuTqbvqZv9ytx7sfJQh1pq6dAnk5jwUt5aci2XjvyYyVfO5cXnAkyGchxoMc7i225TmW8V9QcGSTqTzjgW48LIO1wLQHv2sBcV2hFGFZcxk9e5ye+cE5lHFu3YSXeMuDDixI6F1uT6Oarqo/74BkBgwInb00B4w04PRQwljKbxYJJIyqnAP6xsE3098jceBNWFnb7Rn4FoTS5uDOSTRDI5WLB5RtfmEUkF2aQwnsXkkcRT/JMHeZQc2tCbLSzkdJyY+IZpvMH1/MhUANqQzTB+J4pynuRe3yjVdQwkhWyKiKeARIaw2i8fjTcniwTfufuwiRRyqSaEYGzUEsxG+rOLbvRgG78zhNbkk8o+HuYhNjCABIpwYSKYWqIopxMZtCMbN4IckmnryZ3jwoANCz8zigksZA2DfflvNtMbgaQ3W1nr6cUsZSwxlJFAASFY6cVWbFhwYSSCSlpRwB7as4DTGMAG+rGJaEqZz0S6s4NYStlIP8KoohUFRFNOJOX0YgupZFFMDPkk8QT3cTbfYyeIcqIIoRaLJ8xwD2kUkEgNoUznU67mfWZyKTfzKjbP7NzxFGLHTAVRJFJAjQhhhvyEdQxms7EPQSY7T064l88XXciK2lPVMRGFnN5lAUODV9NnzGbG9lgGwFNz7uHx7/5F5nMdSYgsOuRv1kt2SRsmPLmA7U/39NueVZTC1gO9aRt/gN5t1dzJNkcQFrOdl+ffzOqMwYxPWUKndhmM7F/3Njdn/VQm9ZmH2eSkyhrmM/UUV8by7E938s3ac7E6grlu3Jvce5ZqXAf+ay3JMbnM+cdZAFRbQ7jtfy+yuHA8tfYQ/n3Of5i3eRJzN03BLY0EmWwUvhTP+kUDyYzqQI0rlAe++g8Tes5jV143tmT3oWfKNjq1yuCXnaMoqYojLryIUd1+Zmr/H9iwfwCn91rIWQPnsGbPQCKDK1m9ZzA/rD+TRdvGc/Ppr/LI+Q8DkJnfnjBLDUnRjUOR7/vsP4RarDww7T+8ufQmrnv7lSOq84YcylncYhTBwX02pk2uJmdnFT8w1ZfwyYydXFozhl8BeIGbGcJaerNVTR2Hy9NouSkgkbbk+I6tJBQzLvJIIggrSxjP2/yd6XzGBvrTnr2cyfcYcRHsebtt5Rm4YsCNGwNFxFFDGLkk8x1nUeJJ0taGA+R43jCn8COP829mcx7d2HVE92vFwkb6IVFvoVZCyKcVEkE3dlBDKFm05Uem8gujfceFUcV7XI0LI1fyAe9yNalk+ZmACon3Rdh4r+XATARVfMp09pPqGyizm84sZwTn8o0vPfB6+lFEPF3ZRRtyKSXGd748WlFDKCXE8gNTsWBjOSN5nRtoVy8dxloGEksJV/IBG+lLBzLZdJRutFNYzgSPiciFgZ10pYIoBrEGMwEmJQhA45ERR45S4JGAoIIIrFjYQm+u4V3fS0h9oiijgkhMOMEgqHFbcGAignKu5y0204dVDGcrPZnLJKbxLU4MdCaTScxjP2lIJHOYyp6Rf+Ouu+DeaTsYxc9spweVRHIKK1jNMNYz0HeHfdnEJvohhJu/jX6X+esnkF2Rys0TXublK27lrln/49lL/gHA64uu54bT3gAgPa8TnZPqHHP789uR2uoQuc49rMkcREhQLb3aBp5Ewe1WA/1enn8zby65jj0FHXlg2mNk5Hfig+uu8pWzOYIwGlyYjOpZVltDCQtuOi/6jpxudG+zk2pbKG8vuQan28y1Y9/iYHkSXVun+5W1O8243EZCgpQzN+qaMs4a+D3Lto9h3j8nUV4TSWl1LFe++T4//3sMd3z8HGU1MUzsM49pg76lT7vNGA2Nw79Xpg9l0/4+bN3fi1euvq3R/t326XS5MsAkIEeAVgTAgYvu4okv2jORhYxnMTO5jBt5gyzasouunF4vgyRAGZGEUYXZE6vf8L264foe2tOBvT57Mahh8CaPCeJ44MJAFu0oJJ5W5PMN06gkAoGkLQd4jrs4hd94hrspI4oKogilmjTPyNNljMKCneH8fsjr2AhCIH1mIafPdOFiDYPII4kwqhjDzz6TRBGxZNOWfgHSG3ip9bydmnBgxkUmHUigwDfq2oaZbuxiH2n8wBRG8hvPcheP8SBnMIe+bKaSCOyYMeHEgZl1DKKTYQ/hkQZ+LevNbroe8t7akE0OKQxkLf1Z7+sVhFLDm1xHJp24mZfpwF7Gs4i1DAIEixlHZzIoIZZ0OmHCSSYdmca3HKQ1axhEOVGcz2yiqCCTDuykKyXEchFf+OpyKWMYyzKWMJZN9KbK8/yc1NmPd9EFG0E8xoMkUshG+hKEnc30wo2BSiJJSQti3766+6pv4gvEZH6iJ9t4j79RQhw9e8J556kQ6mNFCDdDOq5mVcZQLhj6JV/cehHj/vsLA9N+5+cdo0nP60zp28ocWeOKJdQY2Kd2wYtqvoDy2ihGd/uZB756DCkFI7sux2x0cPW5m7mw672YDTZySpI55ZHfiAkrZdP+fo3O9eLltzKx93xSYrP5adMU7vj4eXJK2iBnHUUWyAC8OO9W7M4g7p6qTDNOl9GnYAAWbjmN03svanTcrTNfZPHW8Wx7ulejfU2RXZJMSmxu4J2tp8DYH49OeA8nTBEIISYBL6Kio9+RUj7ZYP+VwDPUzVr7ipTynUOd81gVwdZp/6Li28V0ZxefMZ0PuIJXuYlBrAdUI2TBwZPcwyM8jJUQ3uAaEiimiASG8Dv9UI6yc/mcGsK4jrf5mnMw4aaQeFI5wL08wWb6cDfPsIyxJKKcS19yPg/wCOBJW+BpXFPIZjqfE4SNOIqZyg8sYwyDWUMkVfzEJByYOZMfMCApJJ5IKigi3ufYBZULZTS/MJC1XMkHXM5M3xv8FnrxORfxJtdRRAI92YrATSr7qcEzetfDLC5mOL8jkPzEZPaTSiWRvMQtbKIflZ4kX4AnH8srPMijvM9VPMB/eIJ7fQ3mdrpzkGR6spXL+IhvmUYuydiw8C5Xk0EnDLh9Mfg38Sr/RUVWLWMU6xnIRvoxE+Xw6852dtCDKfzoMznVx4GJTfRlAafzL09oxWiWcTbfMYNP2UB/ZnMe73INz/AP/sGzODD5fESj+JlVDGcIv3M+s/mYS9lMX7zv/UbcvufWFGFUEYKVonrpt83YEUAEKq2D1+wom3hFCKEGG5aAA45OZlpF5ZFf7h/ie9Ppr7Bhf39Wpg/n9F4LsTqCuWzkR+wp6MD+olSW7x5JVlHqYc9tMjoY1H4tB8tak12ahstVNw3qwIGwbl3DI+pe1cxm+P2hAQxov4EznvmBB6c9ytBOKgHfKQ+voE+7zWQVteOly29lf1EqhZUJhEeY+HjpVD67ZQY7crox4F/riQ4r49s7zuHmD19BSsHTM+5hXM+67LO19mBfD6G5cE/ZiSH60C87TXEoRYCUslk+qMY/E+gABAGbgB4NylyJavyP+LwDBw6Ux4Lr4kvkr5wiJcibeUneFfqatF5ypZSeLM/1P8NZIacxW7oD7JMg3SBdnm83SHd4hLTHJMo8EmUJ0dIRFimrCFVlY2PlRSOz5YD+bvnUU3Wnufpyu1y4UC1fcknd9tRWtRKkDKZGRlPi2x5BuWzFQXl+25XSQq0Et0wkT7bioGzFQc+2uvOEUO3bZ8YW6DYCfp7gHgluacB5xMdFUyKjKT5kmYbnGjPGf3+nTv7rAmeT52odWiYf5z45lJXyGe6Sd/GMfDj+JTmTS6UEuZ1uEqS8hRd8B+2ki5QgL+MDCVL2YKucxmwJ7iOum5Pp06+flDablMOGHdvxgwdLuXFj3Xr//kd2XHz8ofcPGtR4m8OhPt9+6789MbGJ34q5btlolLKmRkq7vW6bwaC+n3xSfefl+R/T8DN1qpQJkfkyNX6vb9tFwz6VwzuvaPKYZ55R3+cM+lqmJewJWCYipFxeNfpdWT6znZSzkO3i90k5CylnIT+9+SLf8ht/u1ZeNOxTOf2MnTIhMl/edPrL8uCrrXz7j+ZTteOrY2r/pGpw1zbVrjZbj0AIMRx4WEo50bN+n0fxPFGvzJXAICnlzUd63mPtEbzc5r8MzJ3DKfzOeBZxOguJoMKXc+RXRhBGFR3YV8+W3Z8reY+9dODvvMN/uZ/ZnEcsJUxmHp9zISV+4ad1denGyHv8jfUMIJAF2WxW0xQ2nNs20GTvDY9zNJ1F4KSj/kT2DfFO09hwusYjxeSxhDQ89hy+5lvOZRqz6SoyeMdwLUWuGCKN1VS4/HtAfxTv8zrUfR4J3uPrn8dgqGt2Av0u6tfb4X43gWjX7tDTkx4LgeohKkptq67239dUnYWFqbJejuXe/kwSI/OpsYdSZY2gY6sMbA4L2SVtuWPyc5iMTp754Z5Gx8SElbD4/vHERxTRNi47oP9ideZghnRc47ftrZUPce3LDx+TnCfENCSEOB+YJKW8xrN+GTC0fqPvUQRPAIXAbuAOKWWjBPlCiGtBhfO0a9du4P79+xsWOSwfn/UZl85Rs4p2Yie/MIYEijDjJI4CoimjPftoRxYz+JTfOIXnuR0bwUgERgNY3NUqCsMSTLijlCp3CBhNYFG2b6dT/bgNhrplp7Puz9quHfTtqyZt79xZzY+7YYOauzY+HoxG9acpK1PLRqMalNaxo1resQMmT1bHVFSohsDhgKIiNbH8unUqX1L9SeH791flQc2XGxmpRlQXeNKaX3aZGih36qlqcvSICPjyS7VvyRL12bxZTbJ+66115+3XDzp0gFGjYN48lX4jOxvGjFGTyZtM6rp9+qg/8bZt6hirVeVwKi2FkSMhPx+6d1eT05tMam7izZvVd6dO6pwLFqgGY+RIdY9WqzpvWpqaWXLePLDb4ayz1HU6dVLH7NypZLZYYNMmdczChSrHlN2upt8dOhSKi9Wo7/btVb1UVqpzl5SoZ2G3q1Hl8fGwdauqw/Jy+OUXdfzFF6uR4wkJ8Le/qfOdfro617Ztai7lG26ARx5RzzcoyD/VyN13q/v417/gxhvhjTfUJPdvvqnqvW1blaLk559hxgz4NICvMDpamUh+/hnOPlvNb7xhAzz3nJp++Kuvju7/0vB31BTBwep5NMRoVClavJzsjXlQkPo/lnumO46MVP+xhjS8Ly/Hen8G4cJocOFwBREdWkpCZCGtow+ybu9Aqm3hDO/8G1nF7YiPKGJK35+I6zacu54ae/QX4sSZhs5H+QW865fRwAwExAEWz/J1wJLDnfdYTUN7b1Z9vRKiZQ5JTfcjx4+X8qGHpPznP6W84gq1bdo0/zJlZVKuXy/lo49KWVl5yOvefXfdYY89dkyiHxHbt6trXHONlO3a1V2zd++65aefVmUfeKBuW21t43O1bi1lWlrj7ddeW3fcwoXNdy/NzcSJ6h6+++6PnWfCBGUKqU+7dlJeemnd+nXXSRkbK2V1dd1vwGsS9H7uuUfKl19Wy5Mnq++OHaXMzVXLSUlS9u2rlidNavqne+aZUvbooa67Y4fa9tFHSoajNR2df77/elRU4HIpKYG3X3CB/3pw8NHL8Gd+IiOl/OKLuvX58wOX69w58HYh/hw558w59t8rhzANNeeAshzwxD8qUsB/olMpZf10fu+gku42CzuihtKfIsKoZTs91KtvZaV6Te3dW73SPfSQ3+TlALzwgtqWmwu//65eV6Oi1Kt2//6NL9SA2HrjzYqLmy73R+nYUSW6O/VU9SaXng5r16qsqQMGqF7AyJGq7PDh6rtfP/VG15DRo9UbYUO8E7Y3XP6r4X0m9Z/NsdCpE8yapf6iQqg34wMH/NOad+qkehZea2anTv77DQbV6/O+fc9VY8jYt6+u15CXpz6gej9NsWOHSpIIqnfjPXdGRtNvsk3Rr59/LyI1Vf30G1JVb/re+m/FZ55Z17OEwL2Gk4mKCtXz8xIoLxg0bUrz3ndzs2sXTG0cJ/GHaU5FsAboLIRoj1IA04GL6xcQQrSWUnon6DwLGiTwP470+PuplD0OZUBYxmY4mA3ffqumJzMdohq8iiE5Gc49V32OgvqNTcMUF8eToKC63EneVNrV1eoPGB2tGgIvkyerLnBISKPTAIFND6AVQUM6dVL1WFKi3iP27lUNQufOdWW8y/Pn1x3Ttq3y9bhcyvRTXxF4cblg8eKjkycrS5nHQCnydu3qFMGkSSpZ4pHSr5//eo8ejRVBRIQynXkVwMiR8KsajsPkyap+m/M33xTHaqapb3FumJDSy5GYy5qThvnSjhfNpgiklE4hxM2o7G1G4D0p5TYhxKOoLsr3wK1CiLNQ03KUoKKImoXvPSPoDbgxdkyDjml1r8jNSP3GZt48uMkzODkmBgYPVnbnEX8gfUhpKTz+uGpwhFBvbj/8oP6IU6Yox1sgIiMDbz8UJ5sicLuVDbx/f1UP27crf8yAAdCqler5fP89LFoEEyeq+h87ts5n8tNP8O67qge0YIFqLBcvVo1gdrZ6K+zXD5Yt879uWJia02KRJ2z8nHNUg+h91l9/XZfSxNsQvvii+n7jDdVIh4Up+fPylB8hUMPjPeZIsdtVz8P7G3M61btOdTUkJjZ2wgYiIUG9PHz2mf/2Dh0gNLTuTVmIuvenuDjlp+raFdasUXK8+67qpZ4IRWAwHF3vx8v/6mVvePLJpsudSFavPnyZY6Ipm9HJ+jlWH8FNN6kwwW6x+cd0/LGyeLG/jc9o9Le3jhnzx84/c2ZgW2LfvsdDen9ee63u/IWFx//8R8vq1U3bUk87TZXp1u2P22UtFhU2GR8vZUxM3XZvGGP9chERaru3fFyceuZCqBBH7/aQEPWJjFT7hFDHGwxSBgX5H2M01m33ljObpTSZ1HqrVmrdYJAyOrruGmFhar/32Pqyes91qLDL+p+77lL+J2/4qMUiZWiolO3bS3nzzVJ26CDlN98oF1sXFakrZ8xQ/ibvOUymOp9CQ5v64WzsDe8jOLiu3oKDpUxIUOcPClLrRqPalpKi6jgoSMlrsdQdFxOjjklKqqtLg0F9vGXq15fFUvdcQkLUMcHBgeuwqftruN17PW/bcLjn0L79sf9fOISP4IQ26sfyOVZFsHtDlQQpZ170B7wtx8CGDf4PcsoUKXfurFtPSflj56/v+K3/CQuT0u0+Lrfgo77SCeRk/rOZNavpP0xampROZ+MG8Fg+//pX3TXLyuq2X3aZvzIYMkTKnj2lPOusE1cnTfH66/73NGxY3T6vo/pQn1tuUWXvv1+tv/9+09d6+21V5sEHpfzkE//zXH21alBdLinbtlXbhg5t1ls/6Vi3rq4+Nm+u2/7mm4d+Btdf/8eueyhF8MfGXf+FqMpRcWER8QG8o81IQzt05851jjxQJoiGYwmOhqZshtXVKjTzeOI1BxmNgZ3JfzaHspdmZUFmpr8D8Fipb/OPilLmE1Ahru3qknuye7e6Zv3yJwsNZarvsD4SM5+3rht+H65sw3Jz5yqTkcFQJ9PJWF/NSf02oWPHuuVAc6dHRiozMjRvPbUcRXBQpVsITww9TMnjS1yc/3qnTsqxm5paty0z89jPn5GhxibUx7uent64/B/B22BERCgb8YmmYSMTG6sip0DZ3xd6pjbw1of3u3v3Ovt2w33e7/BwZReHxn9Q73r9CKC+fZWfwGoN/Ic+0TR1DxBYEfTp47/urWvvb+pIFEF6euNyubn+9RdItv/v1FcEofWao0D1EBv759RTi5mPoCpfecnCWzXhPW0mQkNVw+99M22lJu6iUycVZQLKUXmsvYL0dJg+XZ3LOwBm8mQ1gGrx4sDhoceKN3QuKEg5BU80W7b4r3fqpByi3ilCv/5afXvrw/vdvbtypHoH0tXfd9ppatBY587KwbpnT+BGdOVKVaZTJ+U09h4PJ+cbbtu2/oPE6svYUBGEhCgHev0oob171YBDb8O+dWvTv4FtnqSh6emBR8F769MrQ0tTBBERgbd7X2Lq41UEa9ZoRXBcqCrwKILWTTyFZkKIujA+qIvz7t1bRXhUVsJdd/2xa/Tsqc63Zw8cPKjijF96SY1kfeSRwx9/tBQUwJAhx/+8x0KrVipiJTZWmWrCw1WDXF6uRkVHRqpooCefhDPOgFdfVeVAdbn79FG9g3PPVSOOBwxQo3p79VLnXr9eKYT69O6tGssOHdSy2awih7yRJt2anurhhGEwqN/JwYPq460D8G+YWrdWDVL9HkF8vKrjYcPq1rdtO/RvIC5OjZvZuFHVX1GReimqqvL/D4C/LC0Bb2+64QuDoYF9JiVFKfDeveG775RJudlkUj6Evw7HPB9Btot1v1QxZkoY4dF/rv47cEC9qXrTKYBSAMVqamJym8g4eySYTOrtrbRULeflqR/O1q3+cdHHg/x8uPpq9QN+/vnje+5jQQiV4iE/XzVmERHqz1Raqur24EH15+neXdVH797KDJeUpHpgDodq1DIyVJlt21QjfvCgel4mkzpPWpr/db0Dxzp3Vj29vXtV6OTKlcp/crIoyYbk5qpeQUNFsGmTCpMdOlSFHtvtyg/SsaO6z8xM9ZJhsyml17+/ekNtqukQQtXBunUqjNP7jCwWda4xY1SvUkpV5y1NEYDqXUdHNw7j9j6jvDz12zQY1MtNTs4f7xHo+Qg0xwVvTqMxY2Dp0hMtjeZ4kZmpGpmzz1bjDrz076/e6B2OQ4+51Pw1OJQiaDHOYs0fx2tLPhkGk2mOH0091/Bw5WPSSuD/P1oRaI4Yi0WZPrQi+P/FoRSBftYtA60INEeMEKphaCptheavSWioerYNn6t+1i0H3enTHBVPPtk4IZnmr40Q8OyzMG6c//Ybbzz+E9doTk60s1ij0WhaANpZrNFoNJom0YpAo9FoWjhaEWg0Gk0LRysCjUajaeFoRaDRaDQtHK0INBqNpoWjFYFGo9G0cLQi0Gg0mhbOX25AmRCiEDjWBMvxQNFxFOd4cbLKBSevbFquo0PLdXT8f5QrVUqZEGjHX04R/BGEEGubGll3IjlZ5YKTVzYt19Gh5To6Wppc2jSk0Wg0LRytCDQajaaF09IUwVsnWoAmOFnlgpNXNi3X0aHlOjpalFwtykeg0Wg0msa0tB6BRqPRaBqgFYFGo9G0cFqMIhBCTBJC7BJCZAgh7j3BsuwTQmwRQmwUQqz1bIsVQiwUQqR7vmP+BDneE0IUCCG21tsWUA6heMlTf5uFEAP+ZLkeFkLkeOpsoxBiSr1993nk2iWEmNiMcrUVQiwVQmwXQmwTQtzm2X5C6+wQcp3QOhNCBAshVgshNnnkesSzvb0QYpXn+p8LIYI82y2e9QzP/rQ/Wa4PhBB769VXP8/2P+2377meUQixQQjxg2e9+etLSvn//gMYgUygAxAEbAJ6nEB59gHxDbY9DdzrWb4XeOpPkGMUMADYejg5gCnAXEAAw4BVf7JcDwP/CFC2h+d5WoD2nudsbCa5WgMDPMsRwG7P9U9onR1CrhNaZ577Dvcsm4FVnnr4Apju2f4GcINn+UbgDc/ydODzZqqvpuT6ADg/QPk/7bfvud6dwCfAD571Zq+vltIjGAJkSCn3SCntwGfA2SdYpoacDXzoWf4QOKe5Lyil/AUoOUI5zgZmSsXvQLQQovWfKFdTnA18JqW0SSn3Ahmo590cch2UUq73LFcCO4A2nOA6O4RcTfGn1Jnnvqs8q2bPRwLjgK882xvWl7cevwLGCyHEnyhXU/xpv30hRApwBvCOZ13wJ9RXS1EEbYAD9dazOfQfpbmRwAIhxDohxLWeba2klAc9y3lAqxMjWpNynAx1eLOna/5ePdPZCZHL0w3vj3qbPGnqrIFccILrzGPm2AgUAAtRvY8yKaUzwLV9cnn2lwNxf4ZcUkpvfT3uqa/nhRCWhnIFkPl48wJwD+D2rMfxJ9RXS1EEJxsjpZQDgMnATUKIUfV3StXXO+FxvSeLHB5eBzoC/YCDwLMnShAhRDgwG7hdSllRf9+JrLMAcp3wOpNSuqSU/YAUVK+j258tQyAayiWE6AXch5JvMBAL/PPPlEkIMRUokFKu+zOvCy1HEeQAbeutp3i2nRCklDme7wLgG9QfJN/b3fR8F5wg8ZqS44TWoZQy3/PndQNvU2fK+FPlEkKYUY3tLCnl157NJ7zOAsl1stSZR5YyYCkwHGVaMQW4tk8uz/4ooPhPkmuSx8QmpZQ24H3+/PoaAZwlhNiHMl+PA17kT6ivlqII1gCdPd73IJRj5fsTIYgQIkwIEeFdBiYAWz3yXOEpdgXw3YmQ7xByfA9c7omgGAaU1zOHNDsNbLLTUHXmlWu6J4KiPdAZWN1MMgjgXWCHlPK5ertOaJ01JdeJrjMhRIIQItqzHAKcjvJfLAXO9xRrWF/eejwfWOLpYf0Zcu2sp8wFyg5fv76a/TlKKe+TUqZIKdNQbdQSKeUl/Bn1dbw83Sf7B+X5342yUf7rBMrRARWxsQnY5pUFZdtbDKQDi4DYP0GWT1EmAwfK9nh1U3KgIiZe9dTfFmDQnyzXR57rbvb8AVrXK/8vj1y7gMnNKNdIlNlnM7DR85lyouvsEHKd0DoD+gAbPNffCjxY7z+wGuWk/hKweLYHe9YzPPs7/MlyLfHU11bgY+oii/603349GcdQFzXU7PWlU0xoNBpNC6elmIY0Go1G0wRaEWg0Gk0LRysCjUajaeFoRaDRaDQtHK0INBqNpoWjFYFG0wAhhKteBsqN4jhmqxVCpIl6WVU1mpMB0+GLaDQtjlqp0g9oNC0C3SPQaI4QoeaReFqouSRWCyE6ebanCSGWeJKVLRZCtPNsbyWE+EaovPebhBCneE5lFEK8LVQu/AWe0a0azQlDKwKNpjEhDUxDF9XbVy6l7A28gsoUCfAy8KGUsg8wC3jJs/0l4GcpZV/U/ArbPNs7A69KKXsCZcB5zXo3Gs1h0COLNZoGCCGqpJThAbbvA8ZJKfd4krzlSSnjhBBFqPQNDs/2g1LKeCFEIZAiVRIz7znSUGmPO3vW/wmYpZT/+RNuTaMJiO4RaDRHh2xi+Wiw1Vt2oX11mhOMVgQazdFxUb3vlZ7l31DZIgEuAX71LC8GbgDfRChRf5aQGs3RoN9ENJrGhHhmr/IyT0rpDSGNEUJsRr3Vz/BsuwV4XwhxN1AIXOXZfhvwlhDiatSb/w2orKoazUmF9hFoNEeIx0cwSEpZdKJl0WiOJ9o0pNFoNC0c3SPQaDSaFo7uEWg0Gk0LRysCjUajaeFoRaDRaDQtHK0INBqNpoWjFYFGo9G0cP4PVBtvzYRzLQgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_avg = []\n",
    "test_avg = []\n",
    "test_f1_score = []\n",
    "for train_index, val_index in kf.split(train_data, Y_train):\n",
    "    train_dataset=[]\n",
    "    val_dataset=[]\n",
    "    print(\"TRAIN: \", train_index, \"TEST:\", val_index)\n",
    "    for i in train_index:\n",
    "        train_dataset.append(train_data[i])\n",
    "    for i in val_index:\n",
    "        val_dataset.append(train_data[i])\n",
    "\n",
    "    print(len(train_dataset))\n",
    "    print(len(val_dataset))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = GIN(dim_h=8)\n",
    "    model.train()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.6)\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=0.7)\n",
    "    train_epoch=[]\n",
    "    val_epoch=[]\n",
    "    train_loss_=[]\n",
    "    val_loss_=[]\n",
    "    epochs = 400\n",
    "    train_acc=0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        train_loss, train_acc, train_f1score = train(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc, val_f1score = validation(model, val_loader, criterion)\n",
    "\n",
    "        train_loss = train_loss.detach().numpy()\n",
    "        train_loss_.append(train_loss)\n",
    "        val_loss_.append(val_loss.detach().numpy())\n",
    "        train_epoch.append(train_acc)\n",
    "        val_epoch.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Train loss: {train_loss:.4f}, '\n",
    "            f'Train Acc: {train_acc:.4f}, Train f1-score: {train_f1score:.4f}, Val loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val f1-score: {val_f1score:.4f},')\n",
    "\n",
    "    test_acc, test_f1score = test(model, test_data)\n",
    "    print(\"GIN accuracy: \" + str(test_acc))\n",
    "\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # ax1.plot(train_epoch, color=\"red\", label=\"train acc\")\n",
    "    # ax1.plot(val_epoch, color=\"blue\", label=\"test acc\")\n",
    "    # ax2.plot(train_loss_, color=\"orange\", label=\"train loss\")\n",
    "    # ax2.plot(val_loss_, color=\"purple\", label=\"test acc\")\n",
    "    # ax1.set_xlabel(\"Epoch\")\n",
    "    # ax1.set_ylabel(\"Accuracy\")\n",
    "    # ax2.set_xlabel(\"Epoch\")\n",
    "    # ax2.set_ylabel(\"Loss\")\n",
    "    # ax1.legend()\n",
    "    # ax2.legend()\n",
    "\n",
    "    plt.plot(train_epoch, color=\"red\")\n",
    "    plt.plot(val_epoch, color=\"blue\")\n",
    "    plt.plot(train_loss_, color=\"orange\")\n",
    "    plt.plot(val_loss_, color=\"purple\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    val_avg.append(val_acc)\n",
    "    test_avg.append(test_acc)\n",
    "    test_f1_score.append(test_f1score)\n",
    "\n",
    "print('Val accuracy: '+ str(np.array(val_avg).mean()))\n",
    "print('Test accuracy: '+ str(np.array(test_avg).mean()))\n",
    "print('Test f1-score: '+ str(np.array(test_f1_score).mean()))\n",
    "\n",
    "print('Val stv: '+ str(np.array(val_avg).std()))\n",
    "print('Test stv: '+ str(np.array(test_avg).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2bebc7e1a30>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_epoch, color=\"red\", label=\"train accuracy\")\n",
    "plt.plot(val_epoch, color=\"blue\", label=\"val accuracy\")\n",
    "plt.plot(train_loss_, color=\"orange\", label=\"train loss\")\n",
    "plt.plot(val_loss_, color=\"purple\", label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy and loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
