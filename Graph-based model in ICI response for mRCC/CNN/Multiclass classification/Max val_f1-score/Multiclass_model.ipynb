{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjVxSG4yt-o"
      },
      "source": [
        "#Import libraies and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVA_ZA7c5BE0",
        "outputId": "4b789e7f-bdc5-43c8-d704-8aded21e01b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.1.0-cp37-cp37m-manylinux2014_x86_64.whl (59.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.1 MB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.16.7-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 62.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.50.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray) (1.15.0)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (4.13.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray) (3.10.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.19.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Installing collected packages: platformdirs, distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 platformdirs-2.5.4 ray-2.1.0 virtualenv-20.16.7\n"
          ]
        }
      ],
      "source": [
        "pip install ray torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlaA55u5HNx",
        "outputId": "80948648-70ce-4082-af85-2275f0d88b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.3.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU9kk9xU5K4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46150aa-d25a-4f9e-bcca-dc2cd0165707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvgorDkMN429"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "0eb16ccb-76ba-4d10-8cca-ed6f8e66fe1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUYbBj2yxpO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(43893, 1))\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block1_filters'], kernel_size=(8), strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(3,tf.keras.layers.Activation('softmax'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv1D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv1D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(3,tf.keras.layers.Activation('softmax'))(x)\n",
        "    print(predictions)\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vViFfkzJTH"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "import random\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    recall = recall_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    precision = precision_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    f1 = f1_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oss9TBkZzMYA"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist(config):\n",
        "  path ='/content/drive/MyDrive/ART_Inv/CNN/Ray_Tune/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame.iloc[:,28:43921  ]   \n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      elif data_frame.PFS[i]<6:\n",
        "          Y.append(1)\n",
        "      else:\n",
        "          Y.append(2)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, stratify = Y)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 43893 , 1)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 43893, 1)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # Create model\n",
        "  model = ConvNet(config)\n",
        "  # Compile model with losses and metrics\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =config['lr']),\n",
        "                # tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy', f1_m, precision_m, recall_m], run_eagerly=True)\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      epochs=100,\n",
        "                      validation_data=(X_test, yTest))\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0],\n",
        "  \"val_f1_m\": history_m.history[\"val_f1_m\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QP5Zl8izRcd"
      },
      "source": [
        "# Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        " 'conv_block1_filters': 32,\n",
        " 'dropout_rate': 0.4,\n",
        " 'fc1_units': 64,\n",
        " 'fc_layer_type': 'convolution',\n",
        " 'lr': 0.01,\n",
        " 'pool_type': 'average'}"
      ],
      "metadata": {
        "id": "aLNKDqS6irI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  history = train_mnist(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyV830YbioOZ",
        "outputId": "999e823a-4a90-437c-90c5-ddf181f822d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense/activation_2/Softmax:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 43886, 32)         288       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 43886, 32)        128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 43886, 32)         0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 43886, 64)         2112      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 43886, 64)        256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 43886, 2)          130       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 43886, 2)          0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 43886, 2)         8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 2)                0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,931\n",
            "Trainable params: 2,735\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 14s 503ms/step - loss: 1.0960 - accuracy: 0.3264 - f1_m: 0.2161 - precision_m: 0.6722 - recall_m: 0.3125 - val_loss: 1.0952 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 1.0762 - accuracy: 0.4236 - f1_m: 0.3483 - precision_m: 0.7026 - recall_m: 0.4437 - val_loss: 1.0868 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 1.0599 - accuracy: 0.5139 - f1_m: 0.4751 - precision_m: 0.6427 - recall_m: 0.5250 - val_loss: 1.0751 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 1.0455 - accuracy: 0.5000 - f1_m: 0.3824 - precision_m: 0.6325 - recall_m: 0.4875 - val_loss: 1.0351 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 1.0348 - accuracy: 0.4653 - f1_m: 0.3406 - precision_m: 0.7054 - recall_m: 0.4938 - val_loss: 1.0205 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 1.0263 - accuracy: 0.4653 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 - val_loss: 1.0372 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 1.0230 - accuracy: 0.4653 - f1_m: 0.2994 - precision_m: 0.7621 - recall_m: 0.4625 - val_loss: 1.0768 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 1.0156 - accuracy: 0.4653 - f1_m: 0.3178 - precision_m: 0.7688 - recall_m: 0.4750 - val_loss: 1.1439 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 1.0143 - accuracy: 0.4653 - f1_m: 0.3025 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 1.2428 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 1.0136 - accuracy: 0.4653 - f1_m: 0.2889 - precision_m: 0.7564 - recall_m: 0.4563 - val_loss: 1.2992 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 1.0107 - accuracy: 0.4653 - f1_m: 0.2861 - precision_m: 0.7625 - recall_m: 0.4500 - val_loss: 1.3499 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 1.0109 - accuracy: 0.4653 - f1_m: 0.3035 - precision_m: 0.7572 - recall_m: 0.4688 - val_loss: 1.3990 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 1.0067 - accuracy: 0.4653 - f1_m: 0.3377 - precision_m: 0.7701 - recall_m: 0.4938 - val_loss: 1.4701 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 1.0079 - accuracy: 0.4653 - f1_m: 0.2882 - precision_m: 0.7656 - recall_m: 0.4500 - val_loss: 1.5152 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 1.0051 - accuracy: 0.4653 - f1_m: 0.2941 - precision_m: 0.7658 - recall_m: 0.4563 - val_loss: 1.5772 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 1.0032 - accuracy: 0.4653 - f1_m: 0.2993 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 1.6583 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 1.0008 - accuracy: 0.4653 - f1_m: 0.3035 - precision_m: 0.7572 - recall_m: 0.4688 - val_loss: 1.7448 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 1.0029 - accuracy: 0.4722 - f1_m: 0.3063 - precision_m: 0.7259 - recall_m: 0.4688 - val_loss: 1.8034 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 1.0017 - accuracy: 0.4722 - f1_m: 0.2999 - precision_m: 0.7561 - recall_m: 0.4625 - val_loss: 1.7668 - val_accuracy: 0.4054 - val_f1_m: 0.3740 - val_precision_m: 0.7115 - val_recall_m: 0.4875\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9970 - accuracy: 0.4792 - f1_m: 0.3530 - precision_m: 0.7640 - recall_m: 0.5000 - val_loss: 1.7476 - val_accuracy: 0.4595 - val_f1_m: 0.4235 - val_precision_m: 0.7133 - val_recall_m: 0.5188\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9950 - accuracy: 0.4722 - f1_m: 0.2971 - precision_m: 0.7722 - recall_m: 0.4500 - val_loss: 1.7819 - val_accuracy: 0.5135 - val_f1_m: 0.3395 - val_precision_m: 0.6865 - val_recall_m: 0.4656\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 1.0043 - accuracy: 0.4722 - f1_m: 0.3026 - precision_m: 0.7217 - recall_m: 0.4625 - val_loss: 1.8422 - val_accuracy: 0.3784 - val_f1_m: 0.3306 - val_precision_m: 0.7742 - val_recall_m: 0.4719\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.9981 - accuracy: 0.4861 - f1_m: 0.3332 - precision_m: 0.6870 - recall_m: 0.4750 - val_loss: 1.8911 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.9950 - accuracy: 0.4792 - f1_m: 0.3890 - precision_m: 0.5666 - recall_m: 0.5000 - val_loss: 1.9702 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9991 - accuracy: 0.4653 - f1_m: 0.3626 - precision_m: 0.5696 - recall_m: 0.4688 - val_loss: 1.8392 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9925 - accuracy: 0.4861 - f1_m: 0.4030 - precision_m: 0.5263 - recall_m: 0.4938 - val_loss: 1.8072 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9916 - accuracy: 0.4861 - f1_m: 0.3982 - precision_m: 0.4844 - recall_m: 0.4938 - val_loss: 1.8084 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9972 - accuracy: 0.4653 - f1_m: 0.3621 - precision_m: 0.5014 - recall_m: 0.4563 - val_loss: 1.7956 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9912 - accuracy: 0.4792 - f1_m: 0.3951 - precision_m: 0.5780 - recall_m: 0.4750 - val_loss: 1.7543 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9918 - accuracy: 0.5000 - f1_m: 0.3833 - precision_m: 0.5657 - recall_m: 0.4812 - val_loss: 1.8753 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9873 - accuracy: 0.4861 - f1_m: 0.4281 - precision_m: 0.5478 - recall_m: 0.5063 - val_loss: 1.9446 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9882 - accuracy: 0.5000 - f1_m: 0.4235 - precision_m: 0.5978 - recall_m: 0.5063 - val_loss: 1.9539 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9811 - accuracy: 0.5000 - f1_m: 0.4308 - precision_m: 0.5842 - recall_m: 0.5000 - val_loss: 1.9515 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9820 - accuracy: 0.5139 - f1_m: 0.4440 - precision_m: 0.5937 - recall_m: 0.5063 - val_loss: 1.9808 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9817 - accuracy: 0.5069 - f1_m: 0.4382 - precision_m: 0.5949 - recall_m: 0.5063 - val_loss: 2.0223 - val_accuracy: 0.5676 - val_f1_m: 0.5278 - val_precision_m: 0.7177 - val_recall_m: 0.5813\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9761 - accuracy: 0.5069 - f1_m: 0.4487 - precision_m: 0.6146 - recall_m: 0.5125 - val_loss: 2.0036 - val_accuracy: 0.4865 - val_f1_m: 0.4670 - val_precision_m: 0.6546 - val_recall_m: 0.5344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9753 - accuracy: 0.5347 - f1_m: 0.4789 - precision_m: 0.5700 - recall_m: 0.5312 - val_loss: 2.0453 - val_accuracy: 0.5405 - val_f1_m: 0.4994 - val_precision_m: 0.6951 - val_recall_m: 0.5656\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9756 - accuracy: 0.5278 - f1_m: 0.4571 - precision_m: 0.5550 - recall_m: 0.5188 - val_loss: 1.9721 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9902 - accuracy: 0.5139 - f1_m: 0.4268 - precision_m: 0.6129 - recall_m: 0.4938 - val_loss: 1.9899 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9811 - accuracy: 0.5208 - f1_m: 0.4565 - precision_m: 0.5769 - recall_m: 0.5125 - val_loss: 2.0829 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.9745 - accuracy: 0.5278 - f1_m: 0.4722 - precision_m: 0.5677 - recall_m: 0.5188 - val_loss: 2.0839 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9791 - accuracy: 0.5208 - f1_m: 0.4765 - precision_m: 0.5940 - recall_m: 0.5188 - val_loss: 2.0307 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9702 - accuracy: 0.5486 - f1_m: 0.5135 - precision_m: 0.6379 - recall_m: 0.5625 - val_loss: 2.0930 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9808 - accuracy: 0.5347 - f1_m: 0.4862 - precision_m: 0.5703 - recall_m: 0.5375 - val_loss: 2.1364 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9875 - accuracy: 0.5486 - f1_m: 0.5204 - precision_m: 0.6614 - recall_m: 0.5750 - val_loss: 2.0711 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9720 - accuracy: 0.5139 - f1_m: 0.4496 - precision_m: 0.5448 - recall_m: 0.5063 - val_loss: 2.0445 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9612 - accuracy: 0.5347 - f1_m: 0.4851 - precision_m: 0.5720 - recall_m: 0.5375 - val_loss: 2.0528 - val_accuracy: 0.4865 - val_f1_m: 0.2845 - val_precision_m: 0.6028 - val_recall_m: 0.4500\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 0.9762 - accuracy: 0.5000 - f1_m: 0.4451 - precision_m: 0.5384 - recall_m: 0.4875 - val_loss: 2.0772 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9639 - accuracy: 0.5417 - f1_m: 0.4926 - precision_m: 0.5923 - recall_m: 0.5437 - val_loss: 2.0637 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.9713 - accuracy: 0.5347 - f1_m: 0.4676 - precision_m: 0.4960 - recall_m: 0.5188 - val_loss: 2.0646 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 0.9691 - accuracy: 0.5347 - f1_m: 0.5160 - precision_m: 0.5829 - recall_m: 0.5562 - val_loss: 2.0372 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9724 - accuracy: 0.5139 - f1_m: 0.4835 - precision_m: 0.5358 - recall_m: 0.5125 - val_loss: 1.9792 - val_accuracy: 0.4865 - val_f1_m: 0.2845 - val_precision_m: 0.6028 - val_recall_m: 0.4500\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9698 - accuracy: 0.5208 - f1_m: 0.4858 - precision_m: 0.5519 - recall_m: 0.5375 - val_loss: 1.9353 - val_accuracy: 0.5405 - val_f1_m: 0.5377 - val_precision_m: 0.6089 - val_recall_m: 0.5656\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 0.9733 - accuracy: 0.5417 - f1_m: 0.4863 - precision_m: 0.6093 - recall_m: 0.5250 - val_loss: 1.8883 - val_accuracy: 0.5135 - val_f1_m: 0.6026 - val_precision_m: 0.7134 - val_recall_m: 0.6344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9660 - accuracy: 0.5208 - f1_m: 0.4658 - precision_m: 0.6363 - recall_m: 0.5125 - val_loss: 1.9863 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9647 - accuracy: 0.5417 - f1_m: 0.4889 - precision_m: 0.6008 - recall_m: 0.5375 - val_loss: 2.3211 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9645 - accuracy: 0.5208 - f1_m: 0.4717 - precision_m: 0.5170 - recall_m: 0.5188 - val_loss: 2.4580 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9644 - accuracy: 0.5278 - f1_m: 0.4747 - precision_m: 0.5338 - recall_m: 0.5250 - val_loss: 2.4684 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9708 - accuracy: 0.5278 - f1_m: 0.4961 - precision_m: 0.5614 - recall_m: 0.5437 - val_loss: 2.2957 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9680 - accuracy: 0.5208 - f1_m: 0.4923 - precision_m: 0.5567 - recall_m: 0.5312 - val_loss: 2.1769 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9584 - accuracy: 0.5556 - f1_m: 0.5108 - precision_m: 0.6182 - recall_m: 0.5562 - val_loss: 2.0588 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9656 - accuracy: 0.5417 - f1_m: 0.5135 - precision_m: 0.5954 - recall_m: 0.5437 - val_loss: 1.9066 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9571 - accuracy: 0.5556 - f1_m: 0.5019 - precision_m: 0.5767 - recall_m: 0.5437 - val_loss: 1.9552 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9677 - accuracy: 0.5486 - f1_m: 0.5076 - precision_m: 0.5969 - recall_m: 0.5500 - val_loss: 2.0068 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9700 - accuracy: 0.5347 - f1_m: 0.4650 - precision_m: 0.5459 - recall_m: 0.5250 - val_loss: 1.9852 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9610 - accuracy: 0.5625 - f1_m: 0.5612 - precision_m: 0.6421 - recall_m: 0.5813 - val_loss: 1.9583 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 3s 701ms/step - loss: 0.9633 - accuracy: 0.5486 - f1_m: 0.5138 - precision_m: 0.5656 - recall_m: 0.5375 - val_loss: 2.1074 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 3s 547ms/step - loss: 0.9646 - accuracy: 0.5417 - f1_m: 0.5293 - precision_m: 0.6425 - recall_m: 0.5562 - val_loss: 2.3477 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9600 - accuracy: 0.5278 - f1_m: 0.4748 - precision_m: 0.5335 - recall_m: 0.5188 - val_loss: 2.1473 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 0.9579 - accuracy: 0.5486 - f1_m: 0.5254 - precision_m: 0.5809 - recall_m: 0.5625 - val_loss: 1.9688 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 0.9613 - accuracy: 0.5486 - f1_m: 0.5071 - precision_m: 0.5435 - recall_m: 0.5500 - val_loss: 1.9033 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 0.9676 - accuracy: 0.5625 - f1_m: 0.5227 - precision_m: 0.6273 - recall_m: 0.5562 - val_loss: 1.9228 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 0.9590 - accuracy: 0.6042 - f1_m: 0.5562 - precision_m: 0.6976 - recall_m: 0.6062 - val_loss: 1.7283 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9644 - accuracy: 0.5347 - f1_m: 0.4824 - precision_m: 0.5278 - recall_m: 0.5250 - val_loss: 1.7611 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9647 - accuracy: 0.5486 - f1_m: 0.4991 - precision_m: 0.5916 - recall_m: 0.5437 - val_loss: 1.6608 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9574 - accuracy: 0.5625 - f1_m: 0.5101 - precision_m: 0.5761 - recall_m: 0.5437 - val_loss: 1.5548 - val_accuracy: 0.5135 - val_f1_m: 0.4761 - val_precision_m: 0.6667 - val_recall_m: 0.5500\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9620 - accuracy: 0.5278 - f1_m: 0.4965 - precision_m: 0.6059 - recall_m: 0.5312 - val_loss: 1.4792 - val_accuracy: 0.5135 - val_f1_m: 0.4761 - val_precision_m: 0.6667 - val_recall_m: 0.5500\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.9596 - accuracy: 0.5486 - f1_m: 0.5216 - precision_m: 0.5903 - recall_m: 0.5562 - val_loss: 1.4928 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9629 - accuracy: 0.5208 - f1_m: 0.5066 - precision_m: 0.5671 - recall_m: 0.5250 - val_loss: 1.6122 - val_accuracy: 0.5405 - val_f1_m: 0.4833 - val_precision_m: 0.7052 - val_recall_m: 0.5656\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9543 - accuracy: 0.5139 - f1_m: 0.4915 - precision_m: 0.5784 - recall_m: 0.5188 - val_loss: 1.6072 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9550 - accuracy: 0.5625 - f1_m: 0.5116 - precision_m: 0.5748 - recall_m: 0.5437 - val_loss: 1.5428 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9622 - accuracy: 0.5208 - f1_m: 0.4685 - precision_m: 0.5683 - recall_m: 0.5063 - val_loss: 1.6115 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9684 - accuracy: 0.5069 - f1_m: 0.4772 - precision_m: 0.4852 - recall_m: 0.5125 - val_loss: 2.3105 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 0.9575 - accuracy: 0.5486 - f1_m: 0.4830 - precision_m: 0.6169 - recall_m: 0.5312 - val_loss: 2.5938 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9621 - accuracy: 0.5278 - f1_m: 0.4768 - precision_m: 0.5968 - recall_m: 0.5188 - val_loss: 2.2721 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9616 - accuracy: 0.5278 - f1_m: 0.4727 - precision_m: 0.5837 - recall_m: 0.5063 - val_loss: 1.8963 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9581 - accuracy: 0.5417 - f1_m: 0.5002 - precision_m: 0.5775 - recall_m: 0.5312 - val_loss: 1.6384 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9590 - accuracy: 0.5417 - f1_m: 0.5170 - precision_m: 0.6070 - recall_m: 0.5500 - val_loss: 1.4606 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9610 - accuracy: 0.5486 - f1_m: 0.4940 - precision_m: 0.5566 - recall_m: 0.5250 - val_loss: 1.5596 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9632 - accuracy: 0.5625 - f1_m: 0.5093 - precision_m: 0.6378 - recall_m: 0.5500 - val_loss: 1.3127 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9587 - accuracy: 0.5556 - f1_m: 0.5107 - precision_m: 0.5927 - recall_m: 0.5562 - val_loss: 1.4311 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9669 - accuracy: 0.5556 - f1_m: 0.5383 - precision_m: 0.6089 - recall_m: 0.5750 - val_loss: 1.6900 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9595 - accuracy: 0.5625 - f1_m: 0.5123 - precision_m: 0.6122 - recall_m: 0.5500 - val_loss: 1.7488 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9612 - accuracy: 0.5556 - f1_m: 0.5178 - precision_m: 0.5887 - recall_m: 0.5562 - val_loss: 1.5257 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9582 - accuracy: 0.5347 - f1_m: 0.4886 - precision_m: 0.5541 - recall_m: 0.5188 - val_loss: 1.5859 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9608 - accuracy: 0.5139 - f1_m: 0.4784 - precision_m: 0.5627 - recall_m: 0.5125 - val_loss: 1.3443 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9559 - accuracy: 0.5139 - f1_m: 0.4865 - precision_m: 0.5355 - recall_m: 0.5188 - val_loss: 1.3611 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9612 - accuracy: 0.5347 - f1_m: 0.5075 - precision_m: 0.5371 - recall_m: 0.5312 - val_loss: 1.1662 - val_accuracy: 0.5135 - val_f1_m: 0.3129 - val_precision_m: 0.7590 - val_recall_m: 0.4656\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.9545 - accuracy: 0.5694 - f1_m: 0.5615 - precision_m: 0.6127 - recall_m: 0.5813 - val_loss: 1.2126 - val_accuracy: 0.4324 - val_f1_m: 0.2665 - val_precision_m: 0.6529 - val_recall_m: 0.4187\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9609 - accuracy: 0.5208 - f1_m: 0.4955 - precision_m: 0.5262 - recall_m: 0.5312 - val_loss: 1.5377 - val_accuracy: 0.4865 - val_f1_m: 0.3569 - val_precision_m: 0.7567 - val_recall_m: 0.4500\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense_1/activation_5/Softmax:0', description=\"created by layer 'dense_1'\")\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 43886, 32)         288       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 43886, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 43886, 32)         0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 43886, 64)         2112      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 43886, 64)        256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 43886, 2)          130       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 43886, 2)          0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 43886, 2)         8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 2)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,931\n",
            "Trainable params: 2,735\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 493ms/step - loss: 1.0848 - accuracy: 0.4792 - f1_m: 0.4118 - precision_m: 0.4747 - recall_m: 0.4625 - val_loss: 1.0571 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 1.0573 - accuracy: 0.4931 - f1_m: 0.3845 - precision_m: 0.4892 - recall_m: 0.4812 - val_loss: 1.0259 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 1.0359 - accuracy: 0.4583 - f1_m: 0.3154 - precision_m: 0.5755 - recall_m: 0.4625 - val_loss: 1.0155 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 1.0242 - accuracy: 0.4653 - f1_m: 0.2884 - precision_m: 0.7660 - recall_m: 0.4500 - val_loss: 1.0168 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 1.0127 - accuracy: 0.4653 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 1.0444 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 1.0064 - accuracy: 0.4653 - f1_m: 0.3269 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 1.0950 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 1.0036 - accuracy: 0.4653 - f1_m: 0.2885 - precision_m: 0.7561 - recall_m: 0.4563 - val_loss: 1.1526 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 1.0023 - accuracy: 0.4653 - f1_m: 0.3028 - precision_m: 0.7564 - recall_m: 0.4688 - val_loss: 1.2053 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 1.0022 - accuracy: 0.4653 - f1_m: 0.3229 - precision_m: 0.7662 - recall_m: 0.4812 - val_loss: 1.2499 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9981 - accuracy: 0.4653 - f1_m: 0.3111 - precision_m: 0.7014 - recall_m: 0.4750 - val_loss: 1.2805 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9980 - accuracy: 0.4653 - f1_m: 0.3499 - precision_m: 0.6875 - recall_m: 0.4938 - val_loss: 1.2924 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9928 - accuracy: 0.4792 - f1_m: 0.3282 - precision_m: 0.6827 - recall_m: 0.4812 - val_loss: 1.3272 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.9926 - accuracy: 0.4861 - f1_m: 0.3494 - precision_m: 0.6711 - recall_m: 0.4938 - val_loss: 1.3592 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9900 - accuracy: 0.4931 - f1_m: 0.3535 - precision_m: 0.6658 - recall_m: 0.4938 - val_loss: 1.4137 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9849 - accuracy: 0.4861 - f1_m: 0.3656 - precision_m: 0.6350 - recall_m: 0.4938 - val_loss: 1.4767 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9930 - accuracy: 0.4931 - f1_m: 0.4229 - precision_m: 0.6206 - recall_m: 0.5063 - val_loss: 1.4874 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.9905 - accuracy: 0.5069 - f1_m: 0.4147 - precision_m: 0.5977 - recall_m: 0.5000 - val_loss: 1.4666 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.9902 - accuracy: 0.5139 - f1_m: 0.4252 - precision_m: 0.6079 - recall_m: 0.5000 - val_loss: 1.4663 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9820 - accuracy: 0.5278 - f1_m: 0.4398 - precision_m: 0.6309 - recall_m: 0.5188 - val_loss: 1.4602 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9845 - accuracy: 0.5139 - f1_m: 0.4265 - precision_m: 0.5863 - recall_m: 0.5063 - val_loss: 1.4903 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9816 - accuracy: 0.5208 - f1_m: 0.4557 - precision_m: 0.6259 - recall_m: 0.5125 - val_loss: 1.6199 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9815 - accuracy: 0.5347 - f1_m: 0.4670 - precision_m: 0.6225 - recall_m: 0.5250 - val_loss: 1.6324 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9820 - accuracy: 0.5278 - f1_m: 0.4726 - precision_m: 0.6216 - recall_m: 0.5312 - val_loss: 1.5832 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9822 - accuracy: 0.5278 - f1_m: 0.4742 - precision_m: 0.6477 - recall_m: 0.5312 - val_loss: 1.6001 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9771 - accuracy: 0.5556 - f1_m: 0.4961 - precision_m: 0.6218 - recall_m: 0.5500 - val_loss: 1.6349 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9816 - accuracy: 0.5278 - f1_m: 0.4524 - precision_m: 0.5775 - recall_m: 0.5125 - val_loss: 1.6330 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.9774 - accuracy: 0.5208 - f1_m: 0.4713 - precision_m: 0.5974 - recall_m: 0.5312 - val_loss: 1.6489 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9720 - accuracy: 0.5278 - f1_m: 0.4541 - precision_m: 0.6328 - recall_m: 0.5250 - val_loss: 1.6784 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9728 - accuracy: 0.4931 - f1_m: 0.4193 - precision_m: 0.5314 - recall_m: 0.4938 - val_loss: 1.6892 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9657 - accuracy: 0.5208 - f1_m: 0.4673 - precision_m: 0.6268 - recall_m: 0.5250 - val_loss: 1.7446 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9705 - accuracy: 0.5486 - f1_m: 0.4898 - precision_m: 0.5958 - recall_m: 0.5375 - val_loss: 1.8213 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9705 - accuracy: 0.5417 - f1_m: 0.4982 - precision_m: 0.6197 - recall_m: 0.5437 - val_loss: 1.8779 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9743 - accuracy: 0.5417 - f1_m: 0.4785 - precision_m: 0.5779 - recall_m: 0.5250 - val_loss: 1.8668 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9759 - accuracy: 0.5069 - f1_m: 0.4762 - precision_m: 0.6043 - recall_m: 0.5250 - val_loss: 1.8876 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 3s 536ms/step - loss: 0.9679 - accuracy: 0.5347 - f1_m: 0.4582 - precision_m: 0.5323 - recall_m: 0.5125 - val_loss: 1.9204 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9619 - accuracy: 0.5139 - f1_m: 0.4472 - precision_m: 0.5782 - recall_m: 0.5188 - val_loss: 1.9594 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9566 - accuracy: 0.5347 - f1_m: 0.4711 - precision_m: 0.6151 - recall_m: 0.5312 - val_loss: 1.9644 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9657 - accuracy: 0.5069 - f1_m: 0.4486 - precision_m: 0.5060 - recall_m: 0.5000 - val_loss: 1.9340 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9610 - accuracy: 0.5278 - f1_m: 0.4744 - precision_m: 0.5538 - recall_m: 0.5250 - val_loss: 1.9487 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9529 - accuracy: 0.5694 - f1_m: 0.5333 - precision_m: 0.6636 - recall_m: 0.5750 - val_loss: 1.9547 - val_accuracy: 0.4595 - val_f1_m: 0.4039 - val_precision_m: 0.6288 - val_recall_m: 0.5188\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9619 - accuracy: 0.5486 - f1_m: 0.5062 - precision_m: 0.6446 - recall_m: 0.5562 - val_loss: 1.9805 - val_accuracy: 0.5135 - val_f1_m: 0.4080 - val_precision_m: 0.6691 - val_recall_m: 0.5500\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9560 - accuracy: 0.5347 - f1_m: 0.5031 - precision_m: 0.6194 - recall_m: 0.5500 - val_loss: 2.0485 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9547 - accuracy: 0.5347 - f1_m: 0.4894 - precision_m: 0.5399 - recall_m: 0.5437 - val_loss: 2.0878 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9606 - accuracy: 0.5347 - f1_m: 0.4928 - precision_m: 0.6216 - recall_m: 0.5250 - val_loss: 2.0765 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9591 - accuracy: 0.5417 - f1_m: 0.4952 - precision_m: 0.5821 - recall_m: 0.5312 - val_loss: 2.0594 - val_accuracy: 0.5135 - val_f1_m: 0.4861 - val_precision_m: 0.6337 - val_recall_m: 0.5500\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9576 - accuracy: 0.5347 - f1_m: 0.4951 - precision_m: 0.5782 - recall_m: 0.5312 - val_loss: 2.0461 - val_accuracy: 0.4324 - val_f1_m: 0.3691 - val_precision_m: 0.5446 - val_recall_m: 0.4187\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9572 - accuracy: 0.5278 - f1_m: 0.4632 - precision_m: 0.5516 - recall_m: 0.5063 - val_loss: 2.0280 - val_accuracy: 0.5135 - val_f1_m: 0.4067 - val_precision_m: 0.7590 - val_recall_m: 0.5500\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9586 - accuracy: 0.5069 - f1_m: 0.4470 - precision_m: 0.6067 - recall_m: 0.5000 - val_loss: 2.1038 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9570 - accuracy: 0.5278 - f1_m: 0.5019 - precision_m: 0.6175 - recall_m: 0.5375 - val_loss: 2.1471 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9502 - accuracy: 0.5278 - f1_m: 0.4638 - precision_m: 0.5638 - recall_m: 0.5188 - val_loss: 2.1142 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 4s 823ms/step - loss: 0.9531 - accuracy: 0.5417 - f1_m: 0.4975 - precision_m: 0.5964 - recall_m: 0.5312 - val_loss: 2.1041 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 3s 532ms/step - loss: 0.9542 - accuracy: 0.5694 - f1_m: 0.5118 - precision_m: 0.5549 - recall_m: 0.5500 - val_loss: 2.1189 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9546 - accuracy: 0.5278 - f1_m: 0.4945 - precision_m: 0.5833 - recall_m: 0.5375 - val_loss: 2.2660 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9547 - accuracy: 0.5278 - f1_m: 0.4752 - precision_m: 0.5591 - recall_m: 0.5188 - val_loss: 2.2127 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9467 - accuracy: 0.5347 - f1_m: 0.4832 - precision_m: 0.5451 - recall_m: 0.5312 - val_loss: 2.1798 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9477 - accuracy: 0.5208 - f1_m: 0.5004 - precision_m: 0.5295 - recall_m: 0.5312 - val_loss: 2.0727 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9535 - accuracy: 0.5417 - f1_m: 0.4956 - precision_m: 0.5759 - recall_m: 0.5437 - val_loss: 2.0224 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9550 - accuracy: 0.5208 - f1_m: 0.4772 - precision_m: 0.5607 - recall_m: 0.5188 - val_loss: 2.0678 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9434 - accuracy: 0.5833 - f1_m: 0.5492 - precision_m: 0.5911 - recall_m: 0.5750 - val_loss: 2.1059 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9369 - accuracy: 0.5833 - f1_m: 0.5683 - precision_m: 0.6202 - recall_m: 0.5938 - val_loss: 1.8518 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9453 - accuracy: 0.5556 - f1_m: 0.5290 - precision_m: 0.6149 - recall_m: 0.5688 - val_loss: 1.8417 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9467 - accuracy: 0.5278 - f1_m: 0.4825 - precision_m: 0.5795 - recall_m: 0.5250 - val_loss: 2.1262 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9491 - accuracy: 0.5556 - f1_m: 0.5132 - precision_m: 0.6202 - recall_m: 0.5500 - val_loss: 2.3906 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9515 - accuracy: 0.5486 - f1_m: 0.4969 - precision_m: 0.6007 - recall_m: 0.5250 - val_loss: 2.3987 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9468 - accuracy: 0.5417 - f1_m: 0.4741 - precision_m: 0.5968 - recall_m: 0.5000 - val_loss: 2.3193 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9469 - accuracy: 0.5278 - f1_m: 0.4806 - precision_m: 0.5254 - recall_m: 0.5125 - val_loss: 2.1898 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 0.9549 - accuracy: 0.5347 - f1_m: 0.5075 - precision_m: 0.5324 - recall_m: 0.5375 - val_loss: 1.9825 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9490 - accuracy: 0.5347 - f1_m: 0.4914 - precision_m: 0.5702 - recall_m: 0.5312 - val_loss: 1.9142 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9420 - accuracy: 0.5486 - f1_m: 0.4988 - precision_m: 0.5844 - recall_m: 0.5375 - val_loss: 1.6732 - val_accuracy: 0.5135 - val_f1_m: 0.4067 - val_precision_m: 0.7590 - val_recall_m: 0.5500\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 494ms/step - loss: 0.9411 - accuracy: 0.5278 - f1_m: 0.4825 - precision_m: 0.5800 - recall_m: 0.5125 - val_loss: 1.8898 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9458 - accuracy: 0.5417 - f1_m: 0.4935 - precision_m: 0.5728 - recall_m: 0.5312 - val_loss: 1.8634 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9558 - accuracy: 0.5347 - f1_m: 0.4920 - precision_m: 0.5434 - recall_m: 0.5312 - val_loss: 1.5021 - val_accuracy: 0.5135 - val_f1_m: 0.4067 - val_precision_m: 0.7590 - val_recall_m: 0.5500\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9539 - accuracy: 0.5208 - f1_m: 0.4998 - precision_m: 0.5882 - recall_m: 0.5250 - val_loss: 1.7520 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9431 - accuracy: 0.5417 - f1_m: 0.5215 - precision_m: 0.5629 - recall_m: 0.5500 - val_loss: 2.1261 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9505 - accuracy: 0.5208 - f1_m: 0.4750 - precision_m: 0.5489 - recall_m: 0.5125 - val_loss: 2.3781 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9495 - accuracy: 0.5486 - f1_m: 0.5213 - precision_m: 0.5858 - recall_m: 0.5625 - val_loss: 2.1541 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9447 - accuracy: 0.5278 - f1_m: 0.4837 - precision_m: 0.5807 - recall_m: 0.5250 - val_loss: 1.7566 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9522 - accuracy: 0.5278 - f1_m: 0.4829 - precision_m: 0.5641 - recall_m: 0.5188 - val_loss: 1.5400 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9408 - accuracy: 0.5417 - f1_m: 0.5035 - precision_m: 0.6034 - recall_m: 0.5375 - val_loss: 1.7600 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9449 - accuracy: 0.5347 - f1_m: 0.4810 - precision_m: 0.5818 - recall_m: 0.5188 - val_loss: 2.9311 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9517 - accuracy: 0.5556 - f1_m: 0.5301 - precision_m: 0.5741 - recall_m: 0.5500 - val_loss: 3.4658 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9441 - accuracy: 0.5486 - f1_m: 0.5137 - precision_m: 0.5831 - recall_m: 0.5375 - val_loss: 3.2881 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 495ms/step - loss: 0.9326 - accuracy: 0.5486 - f1_m: 0.5349 - precision_m: 0.5704 - recall_m: 0.5625 - val_loss: 3.0124 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9372 - accuracy: 0.5486 - f1_m: 0.4948 - precision_m: 0.5181 - recall_m: 0.5312 - val_loss: 2.5818 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.9364 - accuracy: 0.5486 - f1_m: 0.5222 - precision_m: 0.5656 - recall_m: 0.5562 - val_loss: 1.6985 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9494 - accuracy: 0.5278 - f1_m: 0.4913 - precision_m: 0.5372 - recall_m: 0.5250 - val_loss: 1.3799 - val_accuracy: 0.5135 - val_f1_m: 0.4067 - val_precision_m: 0.7590 - val_recall_m: 0.5500\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9368 - accuracy: 0.5556 - f1_m: 0.5122 - precision_m: 0.6030 - recall_m: 0.5562 - val_loss: 1.6195 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9355 - accuracy: 0.5347 - f1_m: 0.4918 - precision_m: 0.5850 - recall_m: 0.5312 - val_loss: 1.9736 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9431 - accuracy: 0.5278 - f1_m: 0.4891 - precision_m: 0.5761 - recall_m: 0.5312 - val_loss: 1.9891 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9424 - accuracy: 0.5417 - f1_m: 0.4884 - precision_m: 0.5744 - recall_m: 0.5250 - val_loss: 1.5430 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9347 - accuracy: 0.5347 - f1_m: 0.5105 - precision_m: 0.6193 - recall_m: 0.5500 - val_loss: 1.3248 - val_accuracy: 0.5135 - val_f1_m: 0.4067 - val_precision_m: 0.7590 - val_recall_m: 0.5500\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9310 - accuracy: 0.5347 - f1_m: 0.4981 - precision_m: 0.5734 - recall_m: 0.5375 - val_loss: 1.7173 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9286 - accuracy: 0.5694 - f1_m: 0.5310 - precision_m: 0.5466 - recall_m: 0.5688 - val_loss: 1.7618 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9336 - accuracy: 0.5764 - f1_m: 0.5417 - precision_m: 0.6018 - recall_m: 0.5688 - val_loss: 1.7379 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9423 - accuracy: 0.5417 - f1_m: 0.5152 - precision_m: 0.6424 - recall_m: 0.5437 - val_loss: 1.7793 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 0.9524 - accuracy: 0.5347 - f1_m: 0.4766 - precision_m: 0.5419 - recall_m: 0.5188 - val_loss: 1.6558 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9555 - accuracy: 0.5139 - f1_m: 0.4985 - precision_m: 0.5611 - recall_m: 0.5312 - val_loss: 1.4061 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9450 - accuracy: 0.5000 - f1_m: 0.4719 - precision_m: 0.5934 - recall_m: 0.5063 - val_loss: 1.3542 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9342 - accuracy: 0.5694 - f1_m: 0.5555 - precision_m: 0.5895 - recall_m: 0.5875 - val_loss: 1.1515 - val_accuracy: 0.5135 - val_f1_m: 0.4080 - val_precision_m: 0.6691 - val_recall_m: 0.5500\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9499 - accuracy: 0.5556 - f1_m: 0.5383 - precision_m: 0.6522 - recall_m: 0.5625 - val_loss: 1.0904 - val_accuracy: 0.3784 - val_f1_m: 0.3978 - val_precision_m: 0.4444 - val_recall_m: 0.4719\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense_2/activation_8/Softmax:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 43886, 32)         288       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 43886, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 43886, 32)         0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 43886, 64)         2112      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 43886, 64)        256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 43886, 2)          130       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 43886, 2)          0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 43886, 2)         8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 2)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,931\n",
            "Trainable params: 2,735\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 1.0941 - accuracy: 0.3472 - f1_m: 0.3626 - precision_m: 0.4724 - recall_m: 0.3750 - val_loss: 1.0810 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 1.0720 - accuracy: 0.4792 - f1_m: 0.4285 - precision_m: 0.5749 - recall_m: 0.4688 - val_loss: 1.0773 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 1.0574 - accuracy: 0.4583 - f1_m: 0.4262 - precision_m: 0.5596 - recall_m: 0.4688 - val_loss: 1.0658 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 1.0416 - accuracy: 0.4861 - f1_m: 0.4582 - precision_m: 0.6125 - recall_m: 0.5125 - val_loss: 1.0385 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 495ms/step - loss: 1.0309 - accuracy: 0.4861 - f1_m: 0.3989 - precision_m: 0.6152 - recall_m: 0.4812 - val_loss: 1.0232 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 1.0264 - accuracy: 0.4722 - f1_m: 0.3743 - precision_m: 0.5564 - recall_m: 0.4625 - val_loss: 1.0046 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 1.0180 - accuracy: 0.4792 - f1_m: 0.3754 - precision_m: 0.5210 - recall_m: 0.4812 - val_loss: 1.0025 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 1.0158 - accuracy: 0.5000 - f1_m: 0.3638 - precision_m: 0.6618 - recall_m: 0.4875 - val_loss: 1.0376 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 1.0111 - accuracy: 0.4861 - f1_m: 0.3729 - precision_m: 0.6238 - recall_m: 0.4750 - val_loss: 1.0706 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 1.0086 - accuracy: 0.4931 - f1_m: 0.3846 - precision_m: 0.6308 - recall_m: 0.5000 - val_loss: 1.1545 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 1.0021 - accuracy: 0.5486 - f1_m: 0.4539 - precision_m: 0.7061 - recall_m: 0.5500 - val_loss: 1.1806 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 1.0020 - accuracy: 0.5139 - f1_m: 0.4037 - precision_m: 0.6856 - recall_m: 0.5063 - val_loss: 1.1702 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9982 - accuracy: 0.5208 - f1_m: 0.4302 - precision_m: 0.6674 - recall_m: 0.5312 - val_loss: 1.1759 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9939 - accuracy: 0.5556 - f1_m: 0.4795 - precision_m: 0.6813 - recall_m: 0.5625 - val_loss: 1.2487 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.9916 - accuracy: 0.5278 - f1_m: 0.4794 - precision_m: 0.6480 - recall_m: 0.5437 - val_loss: 1.2956 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9923 - accuracy: 0.5347 - f1_m: 0.4568 - precision_m: 0.6289 - recall_m: 0.5375 - val_loss: 1.2380 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 495ms/step - loss: 0.9907 - accuracy: 0.5486 - f1_m: 0.4820 - precision_m: 0.6423 - recall_m: 0.5500 - val_loss: 1.1707 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 0.9887 - accuracy: 0.5486 - f1_m: 0.4858 - precision_m: 0.6489 - recall_m: 0.5562 - val_loss: 1.1388 - val_accuracy: 0.4865 - val_f1_m: 0.2672 - val_precision_m: 0.7325 - val_recall_m: 0.3656\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9812 - accuracy: 0.5694 - f1_m: 0.4916 - precision_m: 0.6530 - recall_m: 0.5625 - val_loss: 1.1399 - val_accuracy: 0.5405 - val_f1_m: 0.5311 - val_precision_m: 0.7365 - val_recall_m: 0.5656\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9896 - accuracy: 0.5347 - f1_m: 0.4502 - precision_m: 0.6017 - recall_m: 0.5188 - val_loss: 1.1580 - val_accuracy: 0.4324 - val_f1_m: 0.2212 - val_precision_m: 0.8101 - val_recall_m: 0.3344\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9803 - accuracy: 0.5486 - f1_m: 0.4824 - precision_m: 0.6760 - recall_m: 0.5437 - val_loss: 1.1747 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9852 - accuracy: 0.5417 - f1_m: 0.4795 - precision_m: 0.6474 - recall_m: 0.5375 - val_loss: 1.1505 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9751 - accuracy: 0.5278 - f1_m: 0.4714 - precision_m: 0.6229 - recall_m: 0.5312 - val_loss: 1.1709 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9723 - accuracy: 0.5208 - f1_m: 0.4599 - precision_m: 0.6080 - recall_m: 0.5250 - val_loss: 1.2533 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9852 - accuracy: 0.5208 - f1_m: 0.4569 - precision_m: 0.6128 - recall_m: 0.5188 - val_loss: 1.2808 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9803 - accuracy: 0.5208 - f1_m: 0.4633 - precision_m: 0.6232 - recall_m: 0.5312 - val_loss: 1.3610 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9734 - accuracy: 0.5625 - f1_m: 0.4902 - precision_m: 0.6393 - recall_m: 0.5562 - val_loss: 1.3078 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9653 - accuracy: 0.5486 - f1_m: 0.4672 - precision_m: 0.6344 - recall_m: 0.5250 - val_loss: 1.3148 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9656 - accuracy: 0.5556 - f1_m: 0.4887 - precision_m: 0.6359 - recall_m: 0.5562 - val_loss: 1.3303 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9645 - accuracy: 0.5625 - f1_m: 0.5103 - precision_m: 0.6494 - recall_m: 0.5750 - val_loss: 1.4386 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9796 - accuracy: 0.5347 - f1_m: 0.4523 - precision_m: 0.6056 - recall_m: 0.5063 - val_loss: 1.3776 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9666 - accuracy: 0.5694 - f1_m: 0.4908 - precision_m: 0.6370 - recall_m: 0.5562 - val_loss: 1.0921 - val_accuracy: 0.5676 - val_f1_m: 0.4684 - val_precision_m: 0.7093 - val_recall_m: 0.5813\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.9631 - accuracy: 0.5417 - f1_m: 0.4760 - precision_m: 0.6211 - recall_m: 0.5375 - val_loss: 1.1592 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9582 - accuracy: 0.5208 - f1_m: 0.4806 - precision_m: 0.6431 - recall_m: 0.5250 - val_loss: 1.1873 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9622 - accuracy: 0.5625 - f1_m: 0.5117 - precision_m: 0.6504 - recall_m: 0.5688 - val_loss: 1.1710 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 3s 721ms/step - loss: 0.9619 - accuracy: 0.5625 - f1_m: 0.5090 - precision_m: 0.5731 - recall_m: 0.5688 - val_loss: 1.1428 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 3s 656ms/step - loss: 0.9587 - accuracy: 0.5139 - f1_m: 0.4715 - precision_m: 0.6110 - recall_m: 0.5250 - val_loss: 1.1257 - val_accuracy: 0.5676 - val_f1_m: 0.4695 - val_precision_m: 0.7297 - val_recall_m: 0.5813\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.9576 - accuracy: 0.5625 - f1_m: 0.4893 - precision_m: 0.6483 - recall_m: 0.5625 - val_loss: 1.1795 - val_accuracy: 0.3784 - val_f1_m: 0.1673 - val_precision_m: 0.8051 - val_recall_m: 0.3031\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9688 - accuracy: 0.5347 - f1_m: 0.4638 - precision_m: 0.6109 - recall_m: 0.5250 - val_loss: 1.1943 - val_accuracy: 0.4324 - val_f1_m: 0.2212 - val_precision_m: 0.8101 - val_recall_m: 0.3344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9597 - accuracy: 0.5556 - f1_m: 0.4937 - precision_m: 0.6428 - recall_m: 0.5562 - val_loss: 1.1636 - val_accuracy: 0.5405 - val_f1_m: 0.4412 - val_precision_m: 0.7505 - val_recall_m: 0.4812\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9504 - accuracy: 0.5347 - f1_m: 0.4630 - precision_m: 0.6091 - recall_m: 0.5188 - val_loss: 1.1574 - val_accuracy: 0.5405 - val_f1_m: 0.4479 - val_precision_m: 0.7159 - val_recall_m: 0.5656\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9627 - accuracy: 0.5347 - f1_m: 0.4760 - precision_m: 0.5438 - recall_m: 0.5250 - val_loss: 1.1816 - val_accuracy: 0.4865 - val_f1_m: 0.3976 - val_precision_m: 0.6612 - val_recall_m: 0.5344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9546 - accuracy: 0.5486 - f1_m: 0.5029 - precision_m: 0.6025 - recall_m: 0.5562 - val_loss: 1.1995 - val_accuracy: 0.4865 - val_f1_m: 0.4177 - val_precision_m: 0.7141 - val_recall_m: 0.4500\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9529 - accuracy: 0.5556 - f1_m: 0.4882 - precision_m: 0.5997 - recall_m: 0.5500 - val_loss: 1.2481 - val_accuracy: 0.4865 - val_f1_m: 0.4188 - val_precision_m: 0.7141 - val_recall_m: 0.4500\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9545 - accuracy: 0.5556 - f1_m: 0.4942 - precision_m: 0.5820 - recall_m: 0.5562 - val_loss: 1.2520 - val_accuracy: 0.4595 - val_f1_m: 0.4044 - val_precision_m: 0.7009 - val_recall_m: 0.4344\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9465 - accuracy: 0.5764 - f1_m: 0.5092 - precision_m: 0.6657 - recall_m: 0.5688 - val_loss: 1.2535 - val_accuracy: 0.4865 - val_f1_m: 0.4156 - val_precision_m: 0.7141 - val_recall_m: 0.4500\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 493ms/step - loss: 0.9621 - accuracy: 0.5347 - f1_m: 0.4965 - precision_m: 0.6626 - recall_m: 0.5500 - val_loss: 1.2494 - val_accuracy: 0.4595 - val_f1_m: 0.4028 - val_precision_m: 0.7007 - val_recall_m: 0.4344\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9554 - accuracy: 0.5625 - f1_m: 0.5073 - precision_m: 0.6616 - recall_m: 0.5625 - val_loss: 1.2435 - val_accuracy: 0.4865 - val_f1_m: 0.4161 - val_precision_m: 0.7181 - val_recall_m: 0.4500\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9530 - accuracy: 0.5347 - f1_m: 0.4828 - precision_m: 0.6224 - recall_m: 0.5437 - val_loss: 1.3712 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9747 - accuracy: 0.5278 - f1_m: 0.4573 - precision_m: 0.6000 - recall_m: 0.5188 - val_loss: 1.4095 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9650 - accuracy: 0.5486 - f1_m: 0.4769 - precision_m: 0.6439 - recall_m: 0.5437 - val_loss: 1.2515 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9556 - accuracy: 0.5694 - f1_m: 0.5349 - precision_m: 0.6801 - recall_m: 0.6000 - val_loss: 1.3161 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9538 - accuracy: 0.5486 - f1_m: 0.4896 - precision_m: 0.6250 - recall_m: 0.5500 - val_loss: 1.3451 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9622 - accuracy: 0.5347 - f1_m: 0.4627 - precision_m: 0.5897 - recall_m: 0.5125 - val_loss: 1.3480 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 493ms/step - loss: 0.9604 - accuracy: 0.5417 - f1_m: 0.5001 - precision_m: 0.6371 - recall_m: 0.5500 - val_loss: 1.3133 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9546 - accuracy: 0.5556 - f1_m: 0.5326 - precision_m: 0.6638 - recall_m: 0.5813 - val_loss: 1.2476 - val_accuracy: 0.5135 - val_f1_m: 0.4363 - val_precision_m: 0.6835 - val_recall_m: 0.5500\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9563 - accuracy: 0.5417 - f1_m: 0.4960 - precision_m: 0.6182 - recall_m: 0.5500 - val_loss: 1.2424 - val_accuracy: 0.5135 - val_f1_m: 0.4129 - val_precision_m: 0.5858 - val_recall_m: 0.4656\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9522 - accuracy: 0.5556 - f1_m: 0.4877 - precision_m: 0.6292 - recall_m: 0.5500 - val_loss: 1.2579 - val_accuracy: 0.4324 - val_f1_m: 0.3699 - val_precision_m: 0.5480 - val_recall_m: 0.4187\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 3s 527ms/step - loss: 0.9570 - accuracy: 0.5347 - f1_m: 0.4724 - precision_m: 0.6194 - recall_m: 0.5250 - val_loss: 1.2175 - val_accuracy: 0.5135 - val_f1_m: 0.4129 - val_precision_m: 0.5858 - val_recall_m: 0.4656\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9535 - accuracy: 0.5208 - f1_m: 0.4625 - precision_m: 0.6121 - recall_m: 0.5063 - val_loss: 1.1854 - val_accuracy: 0.5135 - val_f1_m: 0.4111 - val_precision_m: 0.5865 - val_recall_m: 0.4656\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9573 - accuracy: 0.5208 - f1_m: 0.4912 - precision_m: 0.6210 - recall_m: 0.5375 - val_loss: 1.1974 - val_accuracy: 0.5135 - val_f1_m: 0.4363 - val_precision_m: 0.6835 - val_recall_m: 0.5500\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9530 - accuracy: 0.5139 - f1_m: 0.4718 - precision_m: 0.6255 - recall_m: 0.5125 - val_loss: 1.2960 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9512 - accuracy: 0.5347 - f1_m: 0.4768 - precision_m: 0.5825 - recall_m: 0.5312 - val_loss: 1.3688 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9509 - accuracy: 0.5417 - f1_m: 0.4965 - precision_m: 0.6154 - recall_m: 0.5500 - val_loss: 1.3009 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9680 - accuracy: 0.4861 - f1_m: 0.4550 - precision_m: 0.6043 - recall_m: 0.5000 - val_loss: 1.2649 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9496 - accuracy: 0.5556 - f1_m: 0.4825 - precision_m: 0.6177 - recall_m: 0.5437 - val_loss: 1.2526 - val_accuracy: 0.4054 - val_f1_m: 0.3545 - val_precision_m: 0.5348 - val_recall_m: 0.4031\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9649 - accuracy: 0.5208 - f1_m: 0.4692 - precision_m: 0.6097 - recall_m: 0.5188 - val_loss: 1.3132 - val_accuracy: 0.3784 - val_f1_m: 0.1865 - val_precision_m: 0.6556 - val_recall_m: 0.3031\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 497ms/step - loss: 0.9600 - accuracy: 0.5625 - f1_m: 0.5017 - precision_m: 0.6467 - recall_m: 0.5562 - val_loss: 1.3317 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9587 - accuracy: 0.5347 - f1_m: 0.4788 - precision_m: 0.6258 - recall_m: 0.5250 - val_loss: 1.6300 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9635 - accuracy: 0.5139 - f1_m: 0.4553 - precision_m: 0.5828 - recall_m: 0.5125 - val_loss: 1.8168 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9563 - accuracy: 0.5417 - f1_m: 0.4795 - precision_m: 0.6172 - recall_m: 0.5375 - val_loss: 2.0425 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9511 - accuracy: 0.5278 - f1_m: 0.4560 - precision_m: 0.6054 - recall_m: 0.5188 - val_loss: 1.9150 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 496ms/step - loss: 0.9518 - accuracy: 0.5347 - f1_m: 0.4675 - precision_m: 0.6168 - recall_m: 0.5312 - val_loss: 1.5098 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 0.9483 - accuracy: 0.5556 - f1_m: 0.4905 - precision_m: 0.6401 - recall_m: 0.5500 - val_loss: 1.4361 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9639 - accuracy: 0.5417 - f1_m: 0.5101 - precision_m: 0.6260 - recall_m: 0.5562 - val_loss: 1.3482 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9548 - accuracy: 0.5208 - f1_m: 0.4771 - precision_m: 0.6175 - recall_m: 0.5312 - val_loss: 1.3540 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9622 - accuracy: 0.5486 - f1_m: 0.4842 - precision_m: 0.5899 - recall_m: 0.5437 - val_loss: 1.3794 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9602 - accuracy: 0.5417 - f1_m: 0.4842 - precision_m: 0.6457 - recall_m: 0.5437 - val_loss: 1.2390 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 495ms/step - loss: 0.9531 - accuracy: 0.5486 - f1_m: 0.5061 - precision_m: 0.6556 - recall_m: 0.5625 - val_loss: 1.4035 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9522 - accuracy: 0.5278 - f1_m: 0.4619 - precision_m: 0.6373 - recall_m: 0.5063 - val_loss: 1.4652 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9597 - accuracy: 0.5069 - f1_m: 0.4615 - precision_m: 0.6125 - recall_m: 0.5125 - val_loss: 1.2493 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9608 - accuracy: 0.5417 - f1_m: 0.4849 - precision_m: 0.6261 - recall_m: 0.5437 - val_loss: 1.1178 - val_accuracy: 0.4324 - val_f1_m: 0.3662 - val_precision_m: 0.5134 - val_recall_m: 0.4187\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 0.9523 - accuracy: 0.5417 - f1_m: 0.4938 - precision_m: 0.6308 - recall_m: 0.5500 - val_loss: 1.1441 - val_accuracy: 0.4595 - val_f1_m: 0.2691 - val_precision_m: 0.4151 - val_recall_m: 0.3500\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9584 - accuracy: 0.5347 - f1_m: 0.4747 - precision_m: 0.6326 - recall_m: 0.5375 - val_loss: 1.1145 - val_accuracy: 0.4324 - val_f1_m: 0.3924 - val_precision_m: 0.6198 - val_recall_m: 0.5031\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 500ms/step - loss: 0.9473 - accuracy: 0.5486 - f1_m: 0.4869 - precision_m: 0.6315 - recall_m: 0.5437 - val_loss: 1.2015 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.9433 - accuracy: 0.5625 - f1_m: 0.4730 - precision_m: 0.6274 - recall_m: 0.5437 - val_loss: 1.2954 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9520 - accuracy: 0.5486 - f1_m: 0.5145 - precision_m: 0.6028 - recall_m: 0.5688 - val_loss: 1.5480 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9585 - accuracy: 0.5625 - f1_m: 0.4985 - precision_m: 0.5994 - recall_m: 0.5500 - val_loss: 1.7508 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9467 - accuracy: 0.5556 - f1_m: 0.5219 - precision_m: 0.6433 - recall_m: 0.5625 - val_loss: 1.8130 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 0.9539 - accuracy: 0.5486 - f1_m: 0.5090 - precision_m: 0.6359 - recall_m: 0.5562 - val_loss: 1.3521 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9622 - accuracy: 0.5417 - f1_m: 0.4962 - precision_m: 0.6382 - recall_m: 0.5437 - val_loss: 1.1288 - val_accuracy: 0.4595 - val_f1_m: 0.3677 - val_precision_m: 0.5640 - val_recall_m: 0.5188\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 494ms/step - loss: 0.9553 - accuracy: 0.5278 - f1_m: 0.5090 - precision_m: 0.6354 - recall_m: 0.5562 - val_loss: 1.0789 - val_accuracy: 0.4324 - val_f1_m: 0.3793 - val_precision_m: 0.6054 - val_recall_m: 0.5031\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9536 - accuracy: 0.5417 - f1_m: 0.4928 - precision_m: 0.6320 - recall_m: 0.5375 - val_loss: 1.0986 - val_accuracy: 0.4865 - val_f1_m: 0.3976 - val_precision_m: 0.6612 - val_recall_m: 0.5344\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 498ms/step - loss: 0.9437 - accuracy: 0.5694 - f1_m: 0.5185 - precision_m: 0.6564 - recall_m: 0.5750 - val_loss: 1.1277 - val_accuracy: 0.4595 - val_f1_m: 0.3677 - val_precision_m: 0.5640 - val_recall_m: 0.5188\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 0.9451 - accuracy: 0.5694 - f1_m: 0.5301 - precision_m: 0.6693 - recall_m: 0.5813 - val_loss: 1.1401 - val_accuracy: 0.4595 - val_f1_m: 0.3677 - val_precision_m: 0.5640 - val_recall_m: 0.5188\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9497 - accuracy: 0.5347 - f1_m: 0.4823 - precision_m: 0.6275 - recall_m: 0.5375 - val_loss: 1.3045 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9532 - accuracy: 0.5278 - f1_m: 0.4714 - precision_m: 0.6102 - recall_m: 0.5250 - val_loss: 1.2940 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9510 - accuracy: 0.5486 - f1_m: 0.5203 - precision_m: 0.6647 - recall_m: 0.5688 - val_loss: 1.6224 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9460 - accuracy: 0.5347 - f1_m: 0.4712 - precision_m: 0.6173 - recall_m: 0.5312 - val_loss: 1.6514 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9461 - accuracy: 0.5625 - f1_m: 0.5172 - precision_m: 0.6396 - recall_m: 0.5625 - val_loss: 1.6179 - val_accuracy: 0.4865 - val_f1_m: 0.3746 - val_precision_m: 0.7555 - val_recall_m: 0.5344\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense_3/activation_11/Softmax:0', description=\"created by layer 'dense_3'\")\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 43886, 32)         288       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 43886, 32)        128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 43886, 32)         0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 43886, 64)         2112      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 43886, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 43886, 2)          130       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 43886, 2)          0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 43886, 2)         8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d_3   (None, 2)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,931\n",
            "Trainable params: 2,735\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 1.0867 - accuracy: 0.4653 - f1_m: 0.4180 - precision_m: 0.5820 - recall_m: 0.4750 - val_loss: 1.0665 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 1.0601 - accuracy: 0.5208 - f1_m: 0.4520 - precision_m: 0.6203 - recall_m: 0.5250 - val_loss: 1.0377 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 1.0411 - accuracy: 0.5069 - f1_m: 0.4312 - precision_m: 0.5947 - recall_m: 0.5063 - val_loss: 1.0167 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 1.0262 - accuracy: 0.4792 - f1_m: 0.3634 - precision_m: 0.5519 - recall_m: 0.4750 - val_loss: 1.0152 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 1.0184 - accuracy: 0.4653 - f1_m: 0.3472 - precision_m: 0.5973 - recall_m: 0.4875 - val_loss: 1.0373 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 1.0145 - accuracy: 0.4583 - f1_m: 0.2922 - precision_m: 0.6981 - recall_m: 0.4563 - val_loss: 1.0749 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 1.0112 - accuracy: 0.4653 - f1_m: 0.2945 - precision_m: 0.7646 - recall_m: 0.4563 - val_loss: 1.0909 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 1.0061 - accuracy: 0.4653 - f1_m: 0.3073 - precision_m: 0.7112 - recall_m: 0.4688 - val_loss: 1.1245 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 1.0003 - accuracy: 0.4653 - f1_m: 0.3179 - precision_m: 0.7588 - recall_m: 0.4812 - val_loss: 1.1794 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9969 - accuracy: 0.4653 - f1_m: 0.2885 - precision_m: 0.7561 - recall_m: 0.4563 - val_loss: 1.2287 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9946 - accuracy: 0.4653 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 1.2477 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9926 - accuracy: 0.4861 - f1_m: 0.3545 - precision_m: 0.7332 - recall_m: 0.5000 - val_loss: 1.2402 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9980 - accuracy: 0.5208 - f1_m: 0.4172 - precision_m: 0.6631 - recall_m: 0.5188 - val_loss: 1.2047 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 0.9904 - accuracy: 0.4931 - f1_m: 0.3946 - precision_m: 0.5855 - recall_m: 0.4938 - val_loss: 1.1856 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9962 - accuracy: 0.5000 - f1_m: 0.3904 - precision_m: 0.5701 - recall_m: 0.4812 - val_loss: 1.2013 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9952 - accuracy: 0.4861 - f1_m: 0.4010 - precision_m: 0.5605 - recall_m: 0.4875 - val_loss: 1.2325 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.9903 - accuracy: 0.5139 - f1_m: 0.4608 - precision_m: 0.6289 - recall_m: 0.5312 - val_loss: 1.2774 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9839 - accuracy: 0.5139 - f1_m: 0.4510 - precision_m: 0.5974 - recall_m: 0.5063 - val_loss: 1.2897 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 0.9904 - accuracy: 0.5069 - f1_m: 0.4390 - precision_m: 0.6154 - recall_m: 0.5125 - val_loss: 1.3339 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 3s 688ms/step - loss: 0.9809 - accuracy: 0.5347 - f1_m: 0.4454 - precision_m: 0.6056 - recall_m: 0.5125 - val_loss: 1.3750 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 3s 706ms/step - loss: 0.9754 - accuracy: 0.5417 - f1_m: 0.4866 - precision_m: 0.6406 - recall_m: 0.5437 - val_loss: 1.4250 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9760 - accuracy: 0.5347 - f1_m: 0.4904 - precision_m: 0.6368 - recall_m: 0.5437 - val_loss: 1.5033 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9727 - accuracy: 0.5278 - f1_m: 0.4577 - precision_m: 0.5726 - recall_m: 0.5125 - val_loss: 1.5325 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9727 - accuracy: 0.5208 - f1_m: 0.4553 - precision_m: 0.5653 - recall_m: 0.5188 - val_loss: 1.4845 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 498ms/step - loss: 0.9746 - accuracy: 0.5347 - f1_m: 0.4743 - precision_m: 0.5476 - recall_m: 0.5375 - val_loss: 1.4740 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9698 - accuracy: 0.5278 - f1_m: 0.4768 - precision_m: 0.5828 - recall_m: 0.5312 - val_loss: 1.4929 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9741 - accuracy: 0.5347 - f1_m: 0.4751 - precision_m: 0.6248 - recall_m: 0.5312 - val_loss: 1.5524 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 0.9714 - accuracy: 0.5208 - f1_m: 0.4791 - precision_m: 0.6135 - recall_m: 0.5312 - val_loss: 1.6013 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9672 - accuracy: 0.5417 - f1_m: 0.4751 - precision_m: 0.5970 - recall_m: 0.5250 - val_loss: 1.6684 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9719 - accuracy: 0.5208 - f1_m: 0.4802 - precision_m: 0.5651 - recall_m: 0.5250 - val_loss: 1.5789 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9655 - accuracy: 0.5417 - f1_m: 0.5069 - precision_m: 0.5815 - recall_m: 0.5562 - val_loss: 1.6906 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9704 - accuracy: 0.5208 - f1_m: 0.4897 - precision_m: 0.5652 - recall_m: 0.5312 - val_loss: 1.7057 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9742 - accuracy: 0.5208 - f1_m: 0.4753 - precision_m: 0.5944 - recall_m: 0.5188 - val_loss: 1.8616 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 0.9611 - accuracy: 0.5625 - f1_m: 0.5166 - precision_m: 0.6157 - recall_m: 0.5625 - val_loss: 1.9140 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9680 - accuracy: 0.5347 - f1_m: 0.5117 - precision_m: 0.5823 - recall_m: 0.5562 - val_loss: 1.9046 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9645 - accuracy: 0.5278 - f1_m: 0.4733 - precision_m: 0.5620 - recall_m: 0.5312 - val_loss: 1.7909 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 497ms/step - loss: 0.9642 - accuracy: 0.5139 - f1_m: 0.4616 - precision_m: 0.5313 - recall_m: 0.5125 - val_loss: 1.7627 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 3s 528ms/step - loss: 0.9737 - accuracy: 0.5069 - f1_m: 0.4569 - precision_m: 0.6030 - recall_m: 0.5063 - val_loss: 1.9123 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 494ms/step - loss: 0.9688 - accuracy: 0.5069 - f1_m: 0.4489 - precision_m: 0.5717 - recall_m: 0.4938 - val_loss: 1.8283 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 3s 535ms/step - loss: 0.9664 - accuracy: 0.5278 - f1_m: 0.4873 - precision_m: 0.5726 - recall_m: 0.5375 - val_loss: 1.5284 - val_accuracy: 0.5135 - val_f1_m: 0.4591 - val_precision_m: 0.6625 - val_recall_m: 0.4656\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9623 - accuracy: 0.5625 - f1_m: 0.5268 - precision_m: 0.6262 - recall_m: 0.5750 - val_loss: 1.4635 - val_accuracy: 0.4865 - val_f1_m: 0.5385 - val_precision_m: 0.6843 - val_recall_m: 0.6187\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9591 - accuracy: 0.5486 - f1_m: 0.5002 - precision_m: 0.5500 - recall_m: 0.5375 - val_loss: 1.5001 - val_accuracy: 0.5135 - val_f1_m: 0.5494 - val_precision_m: 0.6991 - val_recall_m: 0.6344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9668 - accuracy: 0.5486 - f1_m: 0.4994 - precision_m: 0.5922 - recall_m: 0.5437 - val_loss: 1.5509 - val_accuracy: 0.5405 - val_f1_m: 0.5781 - val_precision_m: 0.7154 - val_recall_m: 0.6500\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9612 - accuracy: 0.5069 - f1_m: 0.4475 - precision_m: 0.5418 - recall_m: 0.4875 - val_loss: 1.7044 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9639 - accuracy: 0.5278 - f1_m: 0.4739 - precision_m: 0.5485 - recall_m: 0.5063 - val_loss: 1.8025 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9690 - accuracy: 0.5139 - f1_m: 0.4929 - precision_m: 0.5114 - recall_m: 0.5312 - val_loss: 2.1765 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9795 - accuracy: 0.5139 - f1_m: 0.5059 - precision_m: 0.5891 - recall_m: 0.5375 - val_loss: 1.6647 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9593 - accuracy: 0.5278 - f1_m: 0.5016 - precision_m: 0.5838 - recall_m: 0.5437 - val_loss: 1.4418 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9537 - accuracy: 0.5139 - f1_m: 0.4685 - precision_m: 0.5429 - recall_m: 0.5000 - val_loss: 1.6178 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.9653 - accuracy: 0.5278 - f1_m: 0.4786 - precision_m: 0.5874 - recall_m: 0.5250 - val_loss: 1.7189 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9590 - accuracy: 0.5417 - f1_m: 0.4739 - precision_m: 0.5554 - recall_m: 0.5250 - val_loss: 1.5885 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9530 - accuracy: 0.5278 - f1_m: 0.4682 - precision_m: 0.5780 - recall_m: 0.5125 - val_loss: 1.4278 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 493ms/step - loss: 0.9614 - accuracy: 0.5208 - f1_m: 0.4972 - precision_m: 0.5555 - recall_m: 0.5437 - val_loss: 1.3982 - val_accuracy: 0.5405 - val_f1_m: 0.5480 - val_precision_m: 0.7444 - val_recall_m: 0.6500\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9570 - accuracy: 0.5208 - f1_m: 0.4845 - precision_m: 0.5798 - recall_m: 0.5188 - val_loss: 1.4067 - val_accuracy: 0.5135 - val_f1_m: 0.5494 - val_precision_m: 0.6991 - val_recall_m: 0.6344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9584 - accuracy: 0.5139 - f1_m: 0.4778 - precision_m: 0.5858 - recall_m: 0.5250 - val_loss: 1.4094 - val_accuracy: 0.4865 - val_f1_m: 0.4917 - val_precision_m: 0.6125 - val_recall_m: 0.6187\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9557 - accuracy: 0.5208 - f1_m: 0.4805 - precision_m: 0.4878 - recall_m: 0.5250 - val_loss: 1.4359 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9610 - accuracy: 0.5417 - f1_m: 0.5029 - precision_m: 0.5420 - recall_m: 0.5375 - val_loss: 1.4426 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9610 - accuracy: 0.5417 - f1_m: 0.4826 - precision_m: 0.5254 - recall_m: 0.5250 - val_loss: 1.4278 - val_accuracy: 0.5405 - val_f1_m: 0.5480 - val_precision_m: 0.7444 - val_recall_m: 0.6500\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9621 - accuracy: 0.5139 - f1_m: 0.4587 - precision_m: 0.5106 - recall_m: 0.5000 - val_loss: 1.4292 - val_accuracy: 0.5405 - val_f1_m: 0.5745 - val_precision_m: 0.7169 - val_recall_m: 0.6500\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9585 - accuracy: 0.5347 - f1_m: 0.4805 - precision_m: 0.5248 - recall_m: 0.5250 - val_loss: 1.4168 - val_accuracy: 0.4865 - val_f1_m: 0.5285 - val_precision_m: 0.6772 - val_recall_m: 0.6187\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9562 - accuracy: 0.5347 - f1_m: 0.4794 - precision_m: 0.5941 - recall_m: 0.5312 - val_loss: 1.4259 - val_accuracy: 0.5405 - val_f1_m: 0.5480 - val_precision_m: 0.7444 - val_recall_m: 0.6500\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9518 - accuracy: 0.5486 - f1_m: 0.5023 - precision_m: 0.5411 - recall_m: 0.5437 - val_loss: 1.4257 - val_accuracy: 0.5676 - val_f1_m: 0.5867 - val_precision_m: 0.7320 - val_recall_m: 0.6656\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9590 - accuracy: 0.5417 - f1_m: 0.5105 - precision_m: 0.5269 - recall_m: 0.5562 - val_loss: 1.4091 - val_accuracy: 0.4865 - val_f1_m: 0.4917 - val_precision_m: 0.6125 - val_recall_m: 0.6187\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9590 - accuracy: 0.5278 - f1_m: 0.4897 - precision_m: 0.5397 - recall_m: 0.5312 - val_loss: 1.4116 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 0.9523 - accuracy: 0.5347 - f1_m: 0.4852 - precision_m: 0.5657 - recall_m: 0.5375 - val_loss: 1.3394 - val_accuracy: 0.4865 - val_f1_m: 0.5285 - val_precision_m: 0.6772 - val_recall_m: 0.6187\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.9626 - accuracy: 0.5417 - f1_m: 0.4868 - precision_m: 0.5649 - recall_m: 0.5312 - val_loss: 1.6259 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9604 - accuracy: 0.5347 - f1_m: 0.4915 - precision_m: 0.5229 - recall_m: 0.5375 - val_loss: 1.7069 - val_accuracy: 0.3514 - val_f1_m: 0.1356 - val_precision_m: 0.8028 - val_recall_m: 0.2875\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9542 - accuracy: 0.5278 - f1_m: 0.5226 - precision_m: 0.5442 - recall_m: 0.5500 - val_loss: 1.6167 - val_accuracy: 0.4324 - val_f1_m: 0.2203 - val_precision_m: 0.8101 - val_recall_m: 0.3344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.9678 - accuracy: 0.5208 - f1_m: 0.5113 - precision_m: 0.5993 - recall_m: 0.5250 - val_loss: 1.6353 - val_accuracy: 0.4865 - val_f1_m: 0.4097 - val_precision_m: 0.8179 - val_recall_m: 0.4500\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9677 - accuracy: 0.5347 - f1_m: 0.5117 - precision_m: 0.5388 - recall_m: 0.5437 - val_loss: 1.4208 - val_accuracy: 0.4865 - val_f1_m: 0.5277 - val_precision_m: 0.6860 - val_recall_m: 0.6187\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 0.9604 - accuracy: 0.5208 - f1_m: 0.4780 - precision_m: 0.5190 - recall_m: 0.5188 - val_loss: 1.3814 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9556 - accuracy: 0.5486 - f1_m: 0.5071 - precision_m: 0.5574 - recall_m: 0.5437 - val_loss: 1.3039 - val_accuracy: 0.5135 - val_f1_m: 0.5494 - val_precision_m: 0.6991 - val_recall_m: 0.6344\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9545 - accuracy: 0.5347 - f1_m: 0.4918 - precision_m: 0.5616 - recall_m: 0.5500 - val_loss: 1.3048 - val_accuracy: 0.5135 - val_f1_m: 0.5242 - val_precision_m: 0.5971 - val_recall_m: 0.5500\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9533 - accuracy: 0.5417 - f1_m: 0.5002 - precision_m: 0.5888 - recall_m: 0.5437 - val_loss: 1.3441 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9711 - accuracy: 0.5208 - f1_m: 0.4778 - precision_m: 0.5777 - recall_m: 0.5125 - val_loss: 1.5661 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9572 - accuracy: 0.5347 - f1_m: 0.4883 - precision_m: 0.5662 - recall_m: 0.5375 - val_loss: 1.7368 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9677 - accuracy: 0.5208 - f1_m: 0.4749 - precision_m: 0.5754 - recall_m: 0.5250 - val_loss: 1.7852 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9539 - accuracy: 0.5278 - f1_m: 0.4730 - precision_m: 0.6153 - recall_m: 0.5312 - val_loss: 1.4036 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9588 - accuracy: 0.5486 - f1_m: 0.4860 - precision_m: 0.5323 - recall_m: 0.5437 - val_loss: 1.1005 - val_accuracy: 0.4865 - val_f1_m: 0.4917 - val_precision_m: 0.6125 - val_recall_m: 0.6187\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9640 - accuracy: 0.5208 - f1_m: 0.4753 - precision_m: 0.5307 - recall_m: 0.5312 - val_loss: 1.1441 - val_accuracy: 0.3514 - val_f1_m: 0.1338 - val_precision_m: 0.3851 - val_recall_m: 0.2031\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9579 - accuracy: 0.5417 - f1_m: 0.4867 - precision_m: 0.5626 - recall_m: 0.5375 - val_loss: 1.0276 - val_accuracy: 0.4595 - val_f1_m: 0.5274 - val_precision_m: 0.6714 - val_recall_m: 0.6031\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9509 - accuracy: 0.5417 - f1_m: 0.5188 - precision_m: 0.5502 - recall_m: 0.5500 - val_loss: 1.4388 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9566 - accuracy: 0.5000 - f1_m: 0.4637 - precision_m: 0.5344 - recall_m: 0.5063 - val_loss: 1.7646 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9611 - accuracy: 0.5139 - f1_m: 0.4817 - precision_m: 0.6320 - recall_m: 0.5250 - val_loss: 1.3934 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9534 - accuracy: 0.5208 - f1_m: 0.5013 - precision_m: 0.5736 - recall_m: 0.5375 - val_loss: 1.4677 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9593 - accuracy: 0.5139 - f1_m: 0.4959 - precision_m: 0.5833 - recall_m: 0.5188 - val_loss: 1.6274 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9553 - accuracy: 0.5486 - f1_m: 0.4867 - precision_m: 0.6071 - recall_m: 0.5250 - val_loss: 1.4902 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.9585 - accuracy: 0.5278 - f1_m: 0.4855 - precision_m: 0.5605 - recall_m: 0.5250 - val_loss: 1.1274 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9628 - accuracy: 0.5278 - f1_m: 0.5090 - precision_m: 0.5774 - recall_m: 0.5500 - val_loss: 1.0762 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9733 - accuracy: 0.5069 - f1_m: 0.4831 - precision_m: 0.5290 - recall_m: 0.5188 - val_loss: 1.2386 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 496ms/step - loss: 0.9532 - accuracy: 0.5347 - f1_m: 0.4956 - precision_m: 0.5604 - recall_m: 0.5375 - val_loss: 1.3653 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9548 - accuracy: 0.5278 - f1_m: 0.4900 - precision_m: 0.5737 - recall_m: 0.5312 - val_loss: 1.5693 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9537 - accuracy: 0.5417 - f1_m: 0.5077 - precision_m: 0.5606 - recall_m: 0.5625 - val_loss: 1.3829 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9423 - accuracy: 0.5556 - f1_m: 0.4930 - precision_m: 0.6273 - recall_m: 0.5375 - val_loss: 1.3769 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9594 - accuracy: 0.5278 - f1_m: 0.4775 - precision_m: 0.5297 - recall_m: 0.5188 - val_loss: 1.0886 - val_accuracy: 0.5135 - val_f1_m: 0.5215 - val_precision_m: 0.7096 - val_recall_m: 0.6344\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9565 - accuracy: 0.5347 - f1_m: 0.5029 - precision_m: 0.5051 - recall_m: 0.5375 - val_loss: 1.1316 - val_accuracy: 0.4595 - val_f1_m: 0.4264 - val_precision_m: 0.6118 - val_recall_m: 0.4344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9553 - accuracy: 0.5278 - f1_m: 0.5164 - precision_m: 0.5028 - recall_m: 0.5437 - val_loss: 1.0337 - val_accuracy: 0.4865 - val_f1_m: 0.5277 - val_precision_m: 0.6860 - val_recall_m: 0.6187\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 0.9526 - accuracy: 0.5278 - f1_m: 0.4730 - precision_m: 0.5287 - recall_m: 0.5000 - val_loss: 1.2104 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9493 - accuracy: 0.5347 - f1_m: 0.4847 - precision_m: 0.5468 - recall_m: 0.5312 - val_loss: 1.3179 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9548 - accuracy: 0.5556 - f1_m: 0.5603 - precision_m: 0.6064 - recall_m: 0.5938 - val_loss: 1.2700 - val_accuracy: 0.4865 - val_f1_m: 0.4887 - val_precision_m: 0.7970 - val_recall_m: 0.6187\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense_4/activation_14/Softmax:0', description=\"created by layer 'dense_4'\")\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 43886, 32)         288       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 43886, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 43886, 32)         0         \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 43886, 64)         2112      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 43886, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 43886, 64)         0         \n",
            "                                                                 \n",
            " conv1d_14 (Conv1D)          (None, 43886, 2)          130       \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 43886, 2)          0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 43886, 2)         8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d_4   (None, 2)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,931\n",
            "Trainable params: 2,735\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 3s 522ms/step - loss: 1.0958 - accuracy: 0.3611 - f1_m: 0.3293 - precision_m: 0.4490 - recall_m: 0.3688 - val_loss: 1.0709 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 1.0741 - accuracy: 0.4792 - f1_m: 0.3666 - precision_m: 0.5554 - recall_m: 0.4688 - val_loss: 1.0562 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 1.0603 - accuracy: 0.4722 - f1_m: 0.3098 - precision_m: 0.6920 - recall_m: 0.4625 - val_loss: 1.0673 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 1.0481 - accuracy: 0.4653 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 1.1027 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 1.0367 - accuracy: 0.4653 - f1_m: 0.2922 - precision_m: 0.7619 - recall_m: 0.4563 - val_loss: 1.1145 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 1.0302 - accuracy: 0.4653 - f1_m: 0.2948 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 1.0806 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 1.0257 - accuracy: 0.4722 - f1_m: 0.3086 - precision_m: 0.7585 - recall_m: 0.4688 - val_loss: 1.0325 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 1.0222 - accuracy: 0.4653 - f1_m: 0.3269 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 1.0078 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 1.0187 - accuracy: 0.4583 - f1_m: 0.2814 - precision_m: 0.5970 - recall_m: 0.4375 - val_loss: 1.0038 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 1.0189 - accuracy: 0.4583 - f1_m: 0.2983 - precision_m: 0.5785 - recall_m: 0.4375 - val_loss: 1.0031 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 1.0163 - accuracy: 0.4653 - f1_m: 0.3258 - precision_m: 0.6600 - recall_m: 0.4563 - val_loss: 1.0095 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 1.0123 - accuracy: 0.4792 - f1_m: 0.3771 - precision_m: 0.5863 - recall_m: 0.4812 - val_loss: 1.0009 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 1.0126 - accuracy: 0.4722 - f1_m: 0.3876 - precision_m: 0.5825 - recall_m: 0.4812 - val_loss: 0.9979 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 1.0163 - accuracy: 0.4931 - f1_m: 0.4319 - precision_m: 0.6261 - recall_m: 0.5125 - val_loss: 1.0084 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 1.0108 - accuracy: 0.5000 - f1_m: 0.4026 - precision_m: 0.5580 - recall_m: 0.4938 - val_loss: 1.0138 - val_accuracy: 0.5135 - val_f1_m: 0.3928 - val_precision_m: 0.5715 - val_recall_m: 0.4656\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 1.0165 - accuracy: 0.4722 - f1_m: 0.3551 - precision_m: 0.6322 - recall_m: 0.4625 - val_loss: 1.0198 - val_accuracy: 0.5405 - val_f1_m: 0.5915 - val_precision_m: 0.7271 - val_recall_m: 0.6500\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 1.0101 - accuracy: 0.4931 - f1_m: 0.4043 - precision_m: 0.6227 - recall_m: 0.5000 - val_loss: 1.0242 - val_accuracy: 0.4595 - val_f1_m: 0.5170 - val_precision_m: 0.8226 - val_recall_m: 0.6031\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 1.0114 - accuracy: 0.4792 - f1_m: 0.3609 - precision_m: 0.5761 - recall_m: 0.4625 - val_loss: 1.0292 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 1.0095 - accuracy: 0.4792 - f1_m: 0.3926 - precision_m: 0.5815 - recall_m: 0.4750 - val_loss: 1.0637 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 1.0081 - accuracy: 0.4792 - f1_m: 0.3850 - precision_m: 0.5822 - recall_m: 0.4875 - val_loss: 1.0981 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 1.0074 - accuracy: 0.4861 - f1_m: 0.3941 - precision_m: 0.5994 - recall_m: 0.4875 - val_loss: 1.0800 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 1.0052 - accuracy: 0.4861 - f1_m: 0.3902 - precision_m: 0.5499 - recall_m: 0.4812 - val_loss: 1.1017 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 1.0013 - accuracy: 0.4931 - f1_m: 0.4311 - precision_m: 0.6132 - recall_m: 0.5000 - val_loss: 1.1176 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 1.0022 - accuracy: 0.5278 - f1_m: 0.4350 - precision_m: 0.5913 - recall_m: 0.5125 - val_loss: 1.1807 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 1.0076 - accuracy: 0.4861 - f1_m: 0.4077 - precision_m: 0.5908 - recall_m: 0.4812 - val_loss: 1.2428 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 1.0044 - accuracy: 0.5139 - f1_m: 0.4289 - precision_m: 0.6392 - recall_m: 0.5188 - val_loss: 1.2619 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9989 - accuracy: 0.5069 - f1_m: 0.4166 - precision_m: 0.5986 - recall_m: 0.5000 - val_loss: 1.2587 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 1.0042 - accuracy: 0.5139 - f1_m: 0.4445 - precision_m: 0.6004 - recall_m: 0.5063 - val_loss: 1.2351 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9987 - accuracy: 0.5069 - f1_m: 0.4386 - precision_m: 0.5976 - recall_m: 0.5063 - val_loss: 1.3033 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 528ms/step - loss: 0.9957 - accuracy: 0.5347 - f1_m: 0.4528 - precision_m: 0.6200 - recall_m: 0.5250 - val_loss: 1.4392 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 494ms/step - loss: 0.9943 - accuracy: 0.5069 - f1_m: 0.4463 - precision_m: 0.6051 - recall_m: 0.5188 - val_loss: 1.3424 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 1.0029 - accuracy: 0.4792 - f1_m: 0.4070 - precision_m: 0.5898 - recall_m: 0.4750 - val_loss: 1.1079 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.9881 - accuracy: 0.5278 - f1_m: 0.4657 - precision_m: 0.6337 - recall_m: 0.5250 - val_loss: 1.0963 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9971 - accuracy: 0.5278 - f1_m: 0.4658 - precision_m: 0.6334 - recall_m: 0.5188 - val_loss: 1.0758 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9907 - accuracy: 0.5208 - f1_m: 0.4631 - precision_m: 0.6049 - recall_m: 0.5188 - val_loss: 1.1506 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9902 - accuracy: 0.5069 - f1_m: 0.4526 - precision_m: 0.5963 - recall_m: 0.5063 - val_loss: 1.1373 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9947 - accuracy: 0.5139 - f1_m: 0.4579 - precision_m: 0.6235 - recall_m: 0.5063 - val_loss: 1.1758 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9993 - accuracy: 0.5139 - f1_m: 0.4596 - precision_m: 0.6100 - recall_m: 0.5188 - val_loss: 1.1826 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 1.0005 - accuracy: 0.4792 - f1_m: 0.4215 - precision_m: 0.5758 - recall_m: 0.4688 - val_loss: 1.0982 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9945 - accuracy: 0.4861 - f1_m: 0.4205 - precision_m: 0.6043 - recall_m: 0.4688 - val_loss: 1.1437 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9881 - accuracy: 0.5208 - f1_m: 0.4728 - precision_m: 0.6396 - recall_m: 0.5312 - val_loss: 1.2463 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9950 - accuracy: 0.5139 - f1_m: 0.4249 - precision_m: 0.6007 - recall_m: 0.4750 - val_loss: 1.3138 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9919 - accuracy: 0.5208 - f1_m: 0.4531 - precision_m: 0.5782 - recall_m: 0.5125 - val_loss: 1.2976 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9941 - accuracy: 0.5208 - f1_m: 0.4786 - precision_m: 0.6320 - recall_m: 0.5250 - val_loss: 1.5294 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 0.9898 - accuracy: 0.5417 - f1_m: 0.4698 - precision_m: 0.6147 - recall_m: 0.5375 - val_loss: 1.7772 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9865 - accuracy: 0.5139 - f1_m: 0.4528 - precision_m: 0.6023 - recall_m: 0.5188 - val_loss: 1.4958 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9899 - accuracy: 0.4931 - f1_m: 0.4336 - precision_m: 0.6005 - recall_m: 0.4938 - val_loss: 1.1875 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9802 - accuracy: 0.5278 - f1_m: 0.4620 - precision_m: 0.6149 - recall_m: 0.5188 - val_loss: 1.1620 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9804 - accuracy: 0.5208 - f1_m: 0.4594 - precision_m: 0.6011 - recall_m: 0.5188 - val_loss: 1.1936 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.9889 - accuracy: 0.4861 - f1_m: 0.4151 - precision_m: 0.6033 - recall_m: 0.4812 - val_loss: 1.2342 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.9795 - accuracy: 0.5139 - f1_m: 0.4558 - precision_m: 0.6172 - recall_m: 0.5188 - val_loss: 1.0840 - val_accuracy: 0.5405 - val_f1_m: 0.5896 - val_precision_m: 0.7558 - val_recall_m: 0.6500\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9765 - accuracy: 0.5486 - f1_m: 0.4830 - precision_m: 0.6251 - recall_m: 0.5437 - val_loss: 1.0602 - val_accuracy: 0.5405 - val_f1_m: 0.4048 - val_precision_m: 0.5814 - val_recall_m: 0.4812\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.9793 - accuracy: 0.5069 - f1_m: 0.4477 - precision_m: 0.6103 - recall_m: 0.5000 - val_loss: 1.0600 - val_accuracy: 0.4865 - val_f1_m: 0.2215 - val_precision_m: 0.6438 - val_recall_m: 0.3656\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.9802 - accuracy: 0.5139 - f1_m: 0.4615 - precision_m: 0.6025 - recall_m: 0.5188 - val_loss: 1.0658 - val_accuracy: 0.5405 - val_f1_m: 0.4048 - val_precision_m: 0.5814 - val_recall_m: 0.4812\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9759 - accuracy: 0.5139 - f1_m: 0.4597 - precision_m: 0.6190 - recall_m: 0.5063 - val_loss: 1.0739 - val_accuracy: 0.5135 - val_f1_m: 0.5740 - val_precision_m: 0.7065 - val_recall_m: 0.6344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.9802 - accuracy: 0.5417 - f1_m: 0.4611 - precision_m: 0.6247 - recall_m: 0.5250 - val_loss: 1.1542 - val_accuracy: 0.4054 - val_f1_m: 0.4824 - val_precision_m: 0.7287 - val_recall_m: 0.5719\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 0.9764 - accuracy: 0.5417 - f1_m: 0.4770 - precision_m: 0.6416 - recall_m: 0.5312 - val_loss: 1.2182 - val_accuracy: 0.3784 - val_f1_m: 0.3307 - val_precision_m: 0.7742 - val_recall_m: 0.4719\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.9796 - accuracy: 0.5139 - f1_m: 0.4604 - precision_m: 0.6013 - recall_m: 0.5250 - val_loss: 1.3435 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 0.9730 - accuracy: 0.5278 - f1_m: 0.4696 - precision_m: 0.6047 - recall_m: 0.5312 - val_loss: 1.1713 - val_accuracy: 0.4054 - val_f1_m: 0.4824 - val_precision_m: 0.7287 - val_recall_m: 0.5719\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9768 - accuracy: 0.5139 - f1_m: 0.4577 - precision_m: 0.6427 - recall_m: 0.5125 - val_loss: 1.1428 - val_accuracy: 0.4595 - val_f1_m: 0.5277 - val_precision_m: 0.7343 - val_recall_m: 0.6031\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 497ms/step - loss: 0.9740 - accuracy: 0.5208 - f1_m: 0.4620 - precision_m: 0.5540 - recall_m: 0.5125 - val_loss: 1.0848 - val_accuracy: 0.5135 - val_f1_m: 0.3812 - val_precision_m: 0.5523 - val_recall_m: 0.4656\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9789 - accuracy: 0.5139 - f1_m: 0.4925 - precision_m: 0.6003 - recall_m: 0.5312 - val_loss: 1.0908 - val_accuracy: 0.5676 - val_f1_m: 0.4263 - val_precision_m: 0.6030 - val_recall_m: 0.4969\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9753 - accuracy: 0.4931 - f1_m: 0.4661 - precision_m: 0.5744 - recall_m: 0.5063 - val_loss: 1.1037 - val_accuracy: 0.4865 - val_f1_m: 0.4836 - val_precision_m: 0.6315 - val_recall_m: 0.5344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.9718 - accuracy: 0.5000 - f1_m: 0.4447 - precision_m: 0.5811 - recall_m: 0.4938 - val_loss: 1.1860 - val_accuracy: 0.4324 - val_f1_m: 0.5056 - val_precision_m: 0.7146 - val_recall_m: 0.5875\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9775 - accuracy: 0.5208 - f1_m: 0.4510 - precision_m: 0.6106 - recall_m: 0.5000 - val_loss: 1.1634 - val_accuracy: 0.4865 - val_f1_m: 0.5533 - val_precision_m: 0.7193 - val_recall_m: 0.6187\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9756 - accuracy: 0.5069 - f1_m: 0.4651 - precision_m: 0.6057 - recall_m: 0.5188 - val_loss: 1.1616 - val_accuracy: 0.4324 - val_f1_m: 0.5171 - val_precision_m: 0.7049 - val_recall_m: 0.5875\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9777 - accuracy: 0.5069 - f1_m: 0.4383 - precision_m: 0.6011 - recall_m: 0.5125 - val_loss: 1.1593 - val_accuracy: 0.5405 - val_f1_m: 0.5874 - val_precision_m: 0.7170 - val_recall_m: 0.6500\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9801 - accuracy: 0.5069 - f1_m: 0.4566 - precision_m: 0.6095 - recall_m: 0.5250 - val_loss: 1.2150 - val_accuracy: 0.5676 - val_f1_m: 0.6022 - val_precision_m: 0.7324 - val_recall_m: 0.6656\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9766 - accuracy: 0.4931 - f1_m: 0.4270 - precision_m: 0.5361 - recall_m: 0.4812 - val_loss: 1.2442 - val_accuracy: 0.4865 - val_f1_m: 0.3694 - val_precision_m: 0.5428 - val_recall_m: 0.4500\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 469ms/step - loss: 0.9765 - accuracy: 0.5208 - f1_m: 0.4845 - precision_m: 0.6261 - recall_m: 0.5375 - val_loss: 1.2719 - val_accuracy: 0.4595 - val_f1_m: 0.5351 - val_precision_m: 0.7050 - val_recall_m: 0.6031\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9747 - accuracy: 0.5139 - f1_m: 0.4636 - precision_m: 0.6160 - recall_m: 0.5250 - val_loss: 1.1990 - val_accuracy: 0.5405 - val_f1_m: 0.4149 - val_precision_m: 0.5878 - val_recall_m: 0.4812\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.9754 - accuracy: 0.4931 - f1_m: 0.4375 - precision_m: 0.5681 - recall_m: 0.4938 - val_loss: 1.2891 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 496ms/step - loss: 0.9770 - accuracy: 0.5069 - f1_m: 0.4526 - precision_m: 0.6028 - recall_m: 0.5063 - val_loss: 1.2806 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9655 - accuracy: 0.5486 - f1_m: 0.4932 - precision_m: 0.6229 - recall_m: 0.5500 - val_loss: 1.2540 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.9707 - accuracy: 0.5139 - f1_m: 0.4868 - precision_m: 0.6149 - recall_m: 0.5375 - val_loss: 1.1501 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.9584 - accuracy: 0.5625 - f1_m: 0.5237 - precision_m: 0.6863 - recall_m: 0.5688 - val_loss: 1.2146 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9681 - accuracy: 0.5278 - f1_m: 0.4950 - precision_m: 0.6381 - recall_m: 0.5437 - val_loss: 1.1375 - val_accuracy: 0.4865 - val_f1_m: 0.2215 - val_precision_m: 0.6438 - val_recall_m: 0.3656\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.9719 - accuracy: 0.5069 - f1_m: 0.4535 - precision_m: 0.6012 - recall_m: 0.5063 - val_loss: 1.1295 - val_accuracy: 0.4865 - val_f1_m: 0.3960 - val_precision_m: 0.5688 - val_recall_m: 0.4500\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9783 - accuracy: 0.5208 - f1_m: 0.4589 - precision_m: 0.6007 - recall_m: 0.5063 - val_loss: 1.1240 - val_accuracy: 0.4865 - val_f1_m: 0.3894 - val_precision_m: 0.6845 - val_recall_m: 0.4500\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.9786 - accuracy: 0.4792 - f1_m: 0.4448 - precision_m: 0.5849 - recall_m: 0.4938 - val_loss: 1.1477 - val_accuracy: 0.4595 - val_f1_m: 0.5351 - val_precision_m: 0.7050 - val_recall_m: 0.6031\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.9678 - accuracy: 0.5000 - f1_m: 0.4640 - precision_m: 0.5815 - recall_m: 0.5063 - val_loss: 1.2242 - val_accuracy: 0.3784 - val_f1_m: 0.3502 - val_precision_m: 0.6837 - val_recall_m: 0.4719\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.9722 - accuracy: 0.5486 - f1_m: 0.4944 - precision_m: 0.6177 - recall_m: 0.5562 - val_loss: 1.4283 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.9670 - accuracy: 0.5208 - f1_m: 0.4588 - precision_m: 0.6086 - recall_m: 0.5188 - val_loss: 1.2455 - val_accuracy: 0.4054 - val_f1_m: 0.3590 - val_precision_m: 0.7758 - val_recall_m: 0.4875\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9764 - accuracy: 0.5000 - f1_m: 0.4445 - precision_m: 0.5610 - recall_m: 0.5000 - val_loss: 1.3064 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 3s 740ms/step - loss: 0.9673 - accuracy: 0.5000 - f1_m: 0.4397 - precision_m: 0.5861 - recall_m: 0.4938 - val_loss: 1.6376 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 3s 662ms/step - loss: 0.9729 - accuracy: 0.5069 - f1_m: 0.4474 - precision_m: 0.5308 - recall_m: 0.5000 - val_loss: 1.6998 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9721 - accuracy: 0.5417 - f1_m: 0.4942 - precision_m: 0.6257 - recall_m: 0.5437 - val_loss: 1.7455 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.9761 - accuracy: 0.5000 - f1_m: 0.4343 - precision_m: 0.5528 - recall_m: 0.4812 - val_loss: 1.8514 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.9848 - accuracy: 0.5278 - f1_m: 0.5029 - precision_m: 0.6325 - recall_m: 0.5500 - val_loss: 1.2237 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.9723 - accuracy: 0.5208 - f1_m: 0.4706 - precision_m: 0.6035 - recall_m: 0.5250 - val_loss: 1.2335 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.9749 - accuracy: 0.4931 - f1_m: 0.4428 - precision_m: 0.6122 - recall_m: 0.4938 - val_loss: 1.2362 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.9733 - accuracy: 0.4722 - f1_m: 0.4608 - precision_m: 0.5690 - recall_m: 0.5000 - val_loss: 1.1142 - val_accuracy: 0.5135 - val_f1_m: 0.3743 - val_precision_m: 0.8005 - val_recall_m: 0.4656\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9763 - accuracy: 0.5069 - f1_m: 0.4525 - precision_m: 0.5795 - recall_m: 0.5000 - val_loss: 0.9896 - val_accuracy: 0.5946 - val_f1_m: 0.6133 - val_precision_m: 0.7386 - val_recall_m: 0.6812\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.9757 - accuracy: 0.4861 - f1_m: 0.4325 - precision_m: 0.6013 - recall_m: 0.4812 - val_loss: 1.1303 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.9711 - accuracy: 0.5139 - f1_m: 0.4584 - precision_m: 0.6024 - recall_m: 0.5188 - val_loss: 1.0044 - val_accuracy: 0.5135 - val_f1_m: 0.3543 - val_precision_m: 0.6588 - val_recall_m: 0.4656\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.9714 - accuracy: 0.5139 - f1_m: 0.4511 - precision_m: 0.5981 - recall_m: 0.5125 - val_loss: 1.2411 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.9700 - accuracy: 0.5417 - f1_m: 0.4874 - precision_m: 0.6249 - recall_m: 0.5437 - val_loss: 1.1041 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 0.9688 - accuracy: 0.5000 - f1_m: 0.4402 - precision_m: 0.5020 - recall_m: 0.4938 - val_loss: 1.1261 - val_accuracy: 0.4865 - val_f1_m: 0.2176 - val_precision_m: 0.7955 - val_recall_m: 0.3656\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9847 - accuracy: 0.5000 - f1_m: 0.4388 - precision_m: 0.5260 - recall_m: 0.4875 - val_loss: 0.9997 - val_accuracy: 0.5135 - val_f1_m: 0.3582 - val_precision_m: 0.5071 - val_recall_m: 0.4656\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.9681 - accuracy: 0.5208 - f1_m: 0.4687 - precision_m: 0.6425 - recall_m: 0.5250 - val_loss: 0.9985 - val_accuracy: 0.5135 - val_f1_m: 0.3543 - val_precision_m: 0.6588 - val_recall_m: 0.4656\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PXjVxSG4yt-o"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}