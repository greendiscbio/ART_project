{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjVxSG4yt-o"
      },
      "source": [
        "#Import libraies and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVA_ZA7c5BE0",
        "outputId": "058944a2-66fa-4e86-99c3-fec86f06ae7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.7/dist-packages (from ray) (20.16.7)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.50.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray) (1.15.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (0.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray) (3.10.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n"
          ]
        }
      ],
      "source": [
        "pip install ray torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlaA55u5HNx",
        "outputId": "32a8255d-e3c0-4581-8287-aa7536bb609d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU9kk9xU5K4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvgorDkMN429"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "27b2efb9-c024-4c54-c931-6d0c872ed16c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUYbBj2yxpO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(43893, 1))\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block1_filters'], kernel_size=(8), strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv1D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv1D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "    print(predictions)\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vViFfkzJTH"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "import random\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    recall = recall_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    precision = precision_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    f1 = f1_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oss9TBkZzMYA"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist(config):\n",
        "  path ='/content/drive/MyDrive/ART_Inv/CNN/Ray_Tune/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame.iloc[:,28:43921  ]   \n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      # elif data_frame.PFS[i]<6:\n",
        "      #     Y.append(1)\n",
        "      else:\n",
        "          Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, stratify = Y)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 43893 , 1)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 43893, 1)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # Create model\n",
        "  model = ConvNet(config)\n",
        "  # Compile model with losses and metrics\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =config['lr']),\n",
        "                # tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', f1_m, precision_m, recall_m], run_eagerly=True)\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      epochs=100,\n",
        "                      validation_data=(X_test, yTest))\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0],\n",
        "  \"val_f1_m\": history_m.history[\"val_f1_m\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QP5Zl8izRcd"
      },
      "source": [
        "# Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwt9luxAGLl",
        "outputId": "ecde648e-204f-479c-dfd3-81f1d86e3b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hpbandster in /usr/local/lib/python3.7/dist-packages (0.7.4)\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.7.3)\n",
            "Requirement already satisfied: serpent in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.41)\n",
            "Requirement already satisfied: netifaces in /usr/local/lib/python3.7/dist-packages (from hpbandster) (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.21.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from hpbandster) (0.12.2)\n",
            "Requirement already satisfied: Pyro4 in /usr/local/lib/python3.7/dist-packages (from hpbandster) (4.82)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (0.29.32)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (4.1.1)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (0.5.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels->hpbandster) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install hpbandster ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCRd1vVu-GX5",
        "outputId": "378ddf03-fb1b-462d-e0af-676abb174c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (4.1.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (0.29.32)\n"
          ]
        }
      ],
      "source": [
        "pip install ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoSc_LZj-PrU"
      },
      "outputs": [],
      "source": [
        "import ConfigSpace as CS\n",
        "config_space = CS.ConfigurationSpace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aagkiF3-Syc",
        "outputId": "349434f9-5c35-4bdc-a820-6d124e1644bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fc1_units, Type: Categorical, Choices: {8, 16, 32, 64, 128}, Default: 8"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "config_space = CS.ConfigurationSpace()\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"lr\", choices=[ 0.0001, 0.001, 0.01, 0.1]))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"dropout_rate\", choices=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"conv_block1_filters\", choices=[8, 16, 32, 64, 128]))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"fc_layer_type\", choices= ['dense', 'convolution']))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"pool_type\", choices= ['max', 'average']))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"fc1_units\", choices=[8, 16, 32, 64, 128]))\n",
        "\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"lr\", choices=[0.001]))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"dropout_rate\", choices=[ 0.3])) \n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"conv_block1_filters\", choices=[8]))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"fc_layer_type\", choices= ['dense']))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"pool_type\", choices= [ 'average']))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"fc1_units\", choices=[16]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b5NabPB3_mlz",
        "outputId": "aa0c3199-aed7-461a-d22d-6d099ffbe77f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-21 16:06:02,153\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2022-11-21 17:04:55</td></tr>\n",
              "<tr><td>Running for: </td><td>00:58:53.57        </td></tr>\n",
              "<tr><td>Memory:      </td><td>2.4/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using HyperBand: num_stopped=0 total_brackets=2<br>Round #0:<br>  Bracket(Max Size (n)=2, Milestone (r)=2, completed=50.0%): {RUNNING: 1, TERMINATED: 2} <br>Resources requested: 1.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_02558fec</td><td>RUNNING   </td><td>172.28.0.2:9480</td><td style=\"text-align: right;\">                    8</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_653a4aca</td><td>TERMINATED</td><td>172.28.0.2:6763</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         16</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1267.93 </td><td style=\"text-align: right;\">0.706276</td><td style=\"text-align: right;\">  0.695433</td><td style=\"text-align: right;\">  0.465278</td></tr>\n",
              "<tr><td>train_mnist_5c7f9388</td><td>TERMINATED</td><td>172.28.0.2:8236</td><td style=\"text-align: right;\">                    8</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         273.826</td><td style=\"text-align: right;\">0.749246</td><td style=\"text-align: right;\">  0.693569</td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m 2022-11-21 16:06:25.376199: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/activation_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  conv1d (Conv1D)             (None, 43886, 64)         576       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  batch_normalization (BatchN  (None, 43886, 64)        256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  activation (Activation)     (None, 43886, 64)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  global_average_pooling1d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  dense (Dense)               (None, 16)                1040      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  dropout (Dropout)           (None, 16)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  batch_normalization_1 (Batc  (None, 16)               64        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  activation_1 (Activation)   (None, 16)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  dense_1 (Dense)             (None, 2)                 34        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  batch_normalization_2 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Total params: 1,981\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Trainable params: 1,817\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Non-trainable params: 164\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Total number of layers: 13\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f31942b3050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f31942b3050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f31942b3050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f31942b3050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f31942ba830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f31942ba830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f31942ba830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f31942ba830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f3139bd2710> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f3139bd2710>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f3139bd2710> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f3139bd2710>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 13s - loss: 0.6831 - accuracy: 0.5312 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7112 - accuracy: 0.4688 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.7156 - accuracy: 0.4479 - f1_m: 0.3588 - precision_m: 0.7539 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.7108 - accuracy: 0.4453 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7063 - accuracy: 0.4653 - f1_m: 0.2885 - precision_m: 0.7656 - recall_m: 0.4500\n",
            "5/5 [==============================] - 13s 2s/step - loss: 0.7063 - accuracy: 0.4653 - f1_m: 0.2885 - precision_m: 0.7656 - recall_m: 0.4500 - val_loss: 0.6954 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 2/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7253 - accuracy: 0.5000 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 9s - loss: 0.7017 - accuracy: 0.5781 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 7s - loss: 0.6866 - accuracy: 0.5938 - f1_m: 0.3125 - precision_m: 0.7539 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6907 - accuracy: 0.5703 - f1_m: 0.3010 - precision_m: 0.7539 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5625 - f1_m: 0.3074 - precision_m: 0.7531 - recall_m: 0.4750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6940 - accuracy: 0.5625 - f1_m: 0.3074 - precision_m: 0.7531 - recall_m: 0.4750 - val_loss: 0.6957 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 3/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6619 - accuracy: 0.6875 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6752 - accuracy: 0.5938 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6709 - accuracy: 0.6146 - f1_m: 0.3235 - precision_m: 0.7529 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6622 - accuracy: 0.6406 - f1_m: 0.3013 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.6319 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.6627 - accuracy: 0.6319 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6977 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 4/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6677 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6696 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6663 - accuracy: 0.6042 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6639 - accuracy: 0.6094 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6659 - accuracy: 0.5903 - f1_m: 0.3233 - precision_m: 0.7566 - recall_m: 0.4875\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6659 - accuracy: 0.5903 - f1_m: 0.3233 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.7010 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 5/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6167 - accuracy: 0.8125 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6574 - accuracy: 0.6250 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6660 - accuracy: 0.6250 - f1_m: 0.2693 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6671 - accuracy: 0.6250 - f1_m: 0.2941 - precision_m: 0.7566 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6632 - accuracy: 0.6389 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6632 - accuracy: 0.6389 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.7072 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 6/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6487 - accuracy: 0.5625 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6429 - accuracy: 0.6094 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6438 - accuracy: 0.6250 - f1_m: 0.2703 - precision_m: 0.7598 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6518 - accuracy: 0.6172 - f1_m: 0.2949 - precision_m: 0.7576 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.6250 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6533 - accuracy: 0.6250 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.7218 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7155 - accuracy: 0.5000 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6720 - accuracy: 0.6094 - f1_m: 0.2505 - precision_m: 0.7563 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6590 - accuracy: 0.6146 - f1_m: 0.2452 - precision_m: 0.7572 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6535 - accuracy: 0.6328 - f1_m: 0.2761 - precision_m: 0.7556 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.6250 - f1_m: 0.3329 - precision_m: 0.7615 - recall_m: 0.4938\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6552 - accuracy: 0.6250 - f1_m: 0.3329 - precision_m: 0.7615 - recall_m: 0.4938 - val_loss: 0.7297 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 8/100\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 0.6998 - accuracy: 0.4375 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 10s - loss: 0.7188 - accuracy: 0.4688 - f1_m: 0.3900 - precision_m: 0.7583 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6908 - accuracy: 0.5312 - f1_m: 0.3382 - precision_m: 0.7585 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6602 - accuracy: 0.5938 - f1_m: 0.3124 - precision_m: 0.7585 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.6181 - f1_m: 0.3031 - precision_m: 0.7576 - recall_m: 0.4688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6501 - accuracy: 0.6181 - f1_m: 0.3031 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7396 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 9/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7152 - accuracy: 0.5625 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6919 - accuracy: 0.5625 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6764 - accuracy: 0.5833 - f1_m: 0.2667 - precision_m: 0.7546 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6645 - accuracy: 0.6094 - f1_m: 0.2666 - precision_m: 0.7544 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.6181 - f1_m: 0.3419 - precision_m: 0.7660 - recall_m: 0.5000\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6636 - accuracy: 0.6181 - f1_m: 0.3419 - precision_m: 0.7660 - recall_m: 0.5000 - val_loss: 0.7308 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 10/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7158 - accuracy: 0.4062 - f1_m: 0.5200 - precision_m: 0.7744 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6926 - accuracy: 0.4688 - f1_m: 0.4443 - precision_m: 0.7627 - recall_m: 0.5938\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6837 - accuracy: 0.5208 - f1_m: 0.3850 - precision_m: 0.7598 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6689 - accuracy: 0.5703 - f1_m: 0.3399 - precision_m: 0.7612 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.5694 - f1_m: 0.2919 - precision_m: 0.7715 - recall_m: 0.4500\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6696 - accuracy: 0.5694 - f1_m: 0.2919 - precision_m: 0.7715 - recall_m: 0.4500 - val_loss: 0.7319 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 11/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7020 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6974 - accuracy: 0.5312 - f1_m: 0.4055 - precision_m: 0.7549 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6763 - accuracy: 0.5625 - f1_m: 0.3290 - precision_m: 0.7614 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6629 - accuracy: 0.5859 - f1_m: 0.3054 - precision_m: 0.7607 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.6042 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6539 - accuracy: 0.6042 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750 - val_loss: 0.7527 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 12/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6417 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6529 - accuracy: 0.6406 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6476 - accuracy: 0.6250 - f1_m: 0.3122 - precision_m: 0.7533 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6574 - accuracy: 0.5938 - f1_m: 0.3090 - precision_m: 0.7527 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.6181 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6483 - accuracy: 0.6181 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.8032 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 13/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6323 - accuracy: 0.5938 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6550 - accuracy: 0.6250 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6772 - accuracy: 0.5625 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6757 - accuracy: 0.5703 - f1_m: 0.2847 - precision_m: 0.7554 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.5764 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.6738 - accuracy: 0.5764 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875 - val_loss: 0.7767 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 14/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 0.6720 - accuracy: 0.6250 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6615 - accuracy: 0.6406 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6556 - accuracy: 0.6667 - f1_m: 0.3005 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6568 - accuracy: 0.6406 - f1_m: 0.3087 - precision_m: 0.7522 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.6528 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688\n",
            "5/5 [==============================] - 13s 2s/step - loss: 0.6526 - accuracy: 0.6528 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.7274 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 15/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6664 - accuracy: 0.5625 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6352 - accuracy: 0.6250 - f1_m: 0.3868 - precision_m: 0.7524 - recall_m: 0.5469 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6686 - accuracy: 0.5833 - f1_m: 0.3929 - precision_m: 0.7529 - recall_m: 0.5521\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6652 - accuracy: 0.5938 - f1_m: 0.3319 - precision_m: 0.7610 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.5833 - f1_m: 0.2952 - precision_m: 0.7658 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6639 - accuracy: 0.5833 - f1_m: 0.2952 - precision_m: 0.7658 - recall_m: 0.4563 - val_loss: 0.7002 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 16/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6934 - accuracy: 0.5000 - f1_m: 0.5200 - precision_m: 0.7744 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7085 - accuracy: 0.5312 - f1_m: 0.3932 - precision_m: 0.7642 - recall_m: 0.5469 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6976 - accuracy: 0.5521 - f1_m: 0.4096 - precision_m: 0.7624 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.7121 - accuracy: 0.5156 - f1_m: 0.3381 - precision_m: 0.7712 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.5347 - f1_m: 0.3002 - precision_m: 0.7740 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6959 - accuracy: 0.5347 - f1_m: 0.3002 - precision_m: 0.7740 - recall_m: 0.4563 - val_loss: 0.6876 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 17/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6258 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6563 - accuracy: 0.6094 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6706 - accuracy: 0.5938 - f1_m: 0.3349 - precision_m: 0.7526 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6713 - accuracy: 0.5703 - f1_m: 0.3260 - precision_m: 0.7522 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5764 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6703 - accuracy: 0.5764 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.6863 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 18/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7923 - accuracy: 0.4062 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7036 - accuracy: 0.5000 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6970 - accuracy: 0.5104 - f1_m: 0.3506 - precision_m: 0.7594 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6837 - accuracy: 0.5312 - f1_m: 0.3296 - precision_m: 0.7581 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.5417 - f1_m: 0.2934 - precision_m: 0.7635 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6807 - accuracy: 0.5417 - f1_m: 0.2934 - precision_m: 0.7635 - recall_m: 0.4563 - val_loss: 0.6862 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 19/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7096 - accuracy: 0.5312 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6940 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 0.6759 - accuracy: 0.6146 - f1_m: 0.3110 - precision_m: 0.7513 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6812 - accuracy: 0.6094 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.6250 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688\n",
            "5/5 [==============================] - 15s 3s/step - loss: 0.6681 - accuracy: 0.6250 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.6851 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 20/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7199 - accuracy: 0.4688 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6944 - accuracy: 0.5469 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6618 - accuracy: 0.5833 - f1_m: 0.3008 - precision_m: 0.7536 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6604 - accuracy: 0.6016 - f1_m: 0.2843 - precision_m: 0.7549 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.5903 - f1_m: 0.3236 - precision_m: 0.7570 - recall_m: 0.4875\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6590 - accuracy: 0.5903 - f1_m: 0.3236 - precision_m: 0.7570 - recall_m: 0.4875 - val_loss: 0.6920 - val_accuracy: 0.5946 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 21/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6239 - accuracy: 0.7188 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6502 - accuracy: 0.6250 - f1_m: 0.3774 - precision_m: 0.7666 - recall_m: 0.5312 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6535 - accuracy: 0.6146 - f1_m: 0.2927 - precision_m: 0.7770 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6677 - accuracy: 0.6016 - f1_m: 0.2861 - precision_m: 0.7712 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.6042 - f1_m: 0.3409 - precision_m: 0.7740 - recall_m: 0.4938\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6652 - accuracy: 0.6042 - f1_m: 0.3409 - precision_m: 0.7740 - recall_m: 0.4938 - val_loss: 0.7025 - val_accuracy: 0.5135 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 22/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6988 - accuracy: 0.5312 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6734 - accuracy: 0.6094 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6604 - accuracy: 0.6250 - f1_m: 0.2695 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6713 - accuracy: 0.6016 - f1_m: 0.3034 - precision_m: 0.7573 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6618 - accuracy: 0.6250 - f1_m: 0.3093 - precision_m: 0.7559 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6618 - accuracy: 0.6250 - f1_m: 0.3093 - precision_m: 0.7559 - recall_m: 0.4750 - val_loss: 0.7172 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 23/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6550 - accuracy: 0.6250 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6565 - accuracy: 0.6250 - f1_m: 0.2587 - precision_m: 0.7681 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6657 - accuracy: 0.5833 - f1_m: 0.2954 - precision_m: 0.7624 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6539 - accuracy: 0.6328 - f1_m: 0.3137 - precision_m: 0.7595 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.6181 - f1_m: 0.3042 - precision_m: 0.7584 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6631 - accuracy: 0.6181 - f1_m: 0.3042 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.7177 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 24/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6662 - accuracy: 0.5938 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6724 - accuracy: 0.5469 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6727 - accuracy: 0.5521 - f1_m: 0.3261 - precision_m: 0.7568 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6655 - accuracy: 0.6016 - f1_m: 0.2957 - precision_m: 0.7590 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.6181 - f1_m: 0.3175 - precision_m: 0.7580 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6575 - accuracy: 0.6181 - f1_m: 0.3175 - precision_m: 0.7580 - recall_m: 0.4812 - val_loss: 0.7095 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 25/100\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.6827 - accuracy: 0.5312 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 10s - loss: 0.6714 - accuracy: 0.5781 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6766 - accuracy: 0.5833 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6806 - accuracy: 0.5781 - f1_m: 0.3260 - precision_m: 0.7522 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.5556 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6843 - accuracy: 0.5556 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.7011 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 26/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6905 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6801 - accuracy: 0.6250 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6823 - accuracy: 0.5938 - f1_m: 0.2790 - precision_m: 0.7555 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6707 - accuracy: 0.6250 - f1_m: 0.2758 - precision_m: 0.7551 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.6111 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6756 - accuracy: 0.6111 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.6922 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 27/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6635 - accuracy: 0.5000 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6591 - accuracy: 0.5469 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6571 - accuracy: 0.5521 - f1_m: 0.3044 - precision_m: 0.7588 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6503 - accuracy: 0.6094 - f1_m: 0.2949 - precision_m: 0.7576 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6484 - accuracy: 0.6111 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6484 - accuracy: 0.6111 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.6888 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 28/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6652 - accuracy: 0.5938 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6372 - accuracy: 0.6719 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6468 - accuracy: 0.6771 - f1_m: 0.2695 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6525 - accuracy: 0.6562 - f1_m: 0.2943 - precision_m: 0.7566 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6552 - accuracy: 0.6528 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6552 - accuracy: 0.6528 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6881 - val_accuracy: 0.4324 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 29/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5915 - accuracy: 0.8438 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5856 - accuracy: 0.8281 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6171 - accuracy: 0.7292 - f1_m: 0.3513 - precision_m: 0.7614 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6482 - accuracy: 0.6797 - f1_m: 0.3007 - precision_m: 0.7673 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.6597 - f1_m: 0.3216 - precision_m: 0.7646 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6532 - accuracy: 0.6597 - f1_m: 0.3216 - precision_m: 0.7646 - recall_m: 0.4812 - val_loss: 0.6847 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 30/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6433 - accuracy: 0.6562 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6315 - accuracy: 0.6719 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6350 - accuracy: 0.6562 - f1_m: 0.3466 - precision_m: 0.7529 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6432 - accuracy: 0.6406 - f1_m: 0.2972 - precision_m: 0.7610 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.6319 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6432 - accuracy: 0.6319 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812 - val_loss: 0.6854 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 31/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6671 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6493 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6401 - accuracy: 0.6458 - f1_m: 0.3139 - precision_m: 0.7559 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6488 - accuracy: 0.6328 - f1_m: 0.2941 - precision_m: 0.7566 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.6458 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6430 - accuracy: 0.6458 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6867 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 32/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6395 - accuracy: 0.6875 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6328 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6455 - accuracy: 0.6146 - f1_m: 0.3005 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6354 - accuracy: 0.6250 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.6111 - f1_m: 0.3234 - precision_m: 0.7566 - recall_m: 0.4875\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6405 - accuracy: 0.6111 - f1_m: 0.3234 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.6881 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 33/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5652 - accuracy: 0.8125 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5670 - accuracy: 0.7812 - f1_m: 0.2866 - precision_m: 0.7583 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6004 - accuracy: 0.7292 - f1_m: 0.3513 - precision_m: 0.7607 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6240 - accuracy: 0.6953 - f1_m: 0.3075 - precision_m: 0.7642 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.6736 - f1_m: 0.3126 - precision_m: 0.7613 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6312 - accuracy: 0.6736 - f1_m: 0.3126 - precision_m: 0.7613 - recall_m: 0.4750 - val_loss: 0.6896 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 34/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6388 - accuracy: 0.6875 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6249 - accuracy: 0.7031 - f1_m: 0.3735 - precision_m: 0.7598 - recall_m: 0.5312 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6530 - accuracy: 0.6458 - f1_m: 0.3378 - precision_m: 0.7578 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6549 - accuracy: 0.6328 - f1_m: 0.3199 - precision_m: 0.7568 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.6319 - f1_m: 0.2968 - precision_m: 0.7586 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6568 - accuracy: 0.6319 - f1_m: 0.2968 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.6905 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 35/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6832 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6286 - accuracy: 0.6562 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6384 - accuracy: 0.6354 - f1_m: 0.3130 - precision_m: 0.7546 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6635 - accuracy: 0.6094 - f1_m: 0.3095 - precision_m: 0.7537 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.6111 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6531 - accuracy: 0.6111 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.6887 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 36/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6423 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 11s - loss: 0.6253 - accuracy: 0.6406 - f1_m: 0.2689 - precision_m: 0.7578 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 6s - loss: 0.6524 - accuracy: 0.5938 - f1_m: 0.3022 - precision_m: 0.7555 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6612 - accuracy: 0.5781 - f1_m: 0.3100 - precision_m: 0.7542 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.5972 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6463 - accuracy: 0.5972 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.6884 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 37/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6374 - accuracy: 0.6875 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6659 - accuracy: 0.5781 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6525 - accuracy: 0.5938 - f1_m: 0.2790 - precision_m: 0.7555 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6387 - accuracy: 0.6094 - f1_m: 0.2841 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.6042 - f1_m: 0.3234 - precision_m: 0.7566 - recall_m: 0.4875\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6388 - accuracy: 0.6042 - f1_m: 0.3234 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.6852 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 38/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6123 - accuracy: 0.6562 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6254 - accuracy: 0.6406 - f1_m: 0.4247 - precision_m: 0.7583 - recall_m: 0.5781 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6281 - accuracy: 0.6458 - f1_m: 0.3513 - precision_m: 0.7607 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6290 - accuracy: 0.6562 - f1_m: 0.3075 - precision_m: 0.7642 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6393 - accuracy: 0.6458 - f1_m: 0.3126 - precision_m: 0.7613 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6393 - accuracy: 0.6458 - f1_m: 0.3126 - precision_m: 0.7613 - recall_m: 0.4750 - val_loss: 0.6892 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 39/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6512 - accuracy: 0.5938 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6576 - accuracy: 0.5938 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6327 - accuracy: 0.6250 - f1_m: 0.3345 - precision_m: 0.7520 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6199 - accuracy: 0.6328 - f1_m: 0.3020 - precision_m: 0.7554 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.6111 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6379 - accuracy: 0.6111 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.6946 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 40/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6359 - accuracy: 0.5312 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6295 - accuracy: 0.5625 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6452 - accuracy: 0.5417 - f1_m: 0.3349 - precision_m: 0.7526 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6429 - accuracy: 0.5547 - f1_m: 0.3023 - precision_m: 0.7559 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.5833 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6342 - accuracy: 0.5833 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750 - val_loss: 0.7073 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 41/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5930 - accuracy: 0.6875 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6819 - accuracy: 0.5938 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6809 - accuracy: 0.5833 - f1_m: 0.3361 - precision_m: 0.7546 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6635 - accuracy: 0.5938 - f1_m: 0.3187 - precision_m: 0.7544 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.6181 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625\n",
            "5/5 [==============================] - 13s 3s/step - loss: 0.6536 - accuracy: 0.6181 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7051 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 42/100\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 0.6522 - accuracy: 0.6250 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6265 - accuracy: 0.6562 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6468 - accuracy: 0.5833 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6591 - accuracy: 0.5625 - f1_m: 0.3212 - precision_m: 0.7588 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.5833 - f1_m: 0.2979 - precision_m: 0.7602 - recall_m: 0.4625\n",
            "5/5 [==============================] - 13s 2s/step - loss: 0.6450 - accuracy: 0.5833 - f1_m: 0.2979 - precision_m: 0.7602 - recall_m: 0.4625 - val_loss: 0.7019 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 43/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5833 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6254 - accuracy: 0.6406 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6256 - accuracy: 0.6458 - f1_m: 0.3235 - precision_m: 0.7529 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6549 - accuracy: 0.6328 - f1_m: 0.3013 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.6250 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6608 - accuracy: 0.6250 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6890 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 44/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6777 - accuracy: 0.5938 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7025 - accuracy: 0.5938 - f1_m: 0.2866 - precision_m: 0.7583 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6925 - accuracy: 0.5833 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6900 - accuracy: 0.6172 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.6111 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6825 - accuracy: 0.6111 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6848 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 45/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6432 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6473 - accuracy: 0.6719 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6587 - accuracy: 0.6354 - f1_m: 0.2781 - precision_m: 0.7542 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6578 - accuracy: 0.6172 - f1_m: 0.3007 - precision_m: 0.7534 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.6319 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6460 - accuracy: 0.6319 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7004 - val_accuracy: 0.5135 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 46/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6756 - accuracy: 0.5312 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6664 - accuracy: 0.5625 - f1_m: 0.3868 - precision_m: 0.7524 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6744 - accuracy: 0.5625 - f1_m: 0.3929 - precision_m: 0.7529 - recall_m: 0.5521\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6408 - accuracy: 0.6094 - f1_m: 0.3255 - precision_m: 0.7642 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.6319 - f1_m: 0.3013 - precision_m: 0.7645 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6334 - accuracy: 0.6319 - f1_m: 0.3013 - precision_m: 0.7645 - recall_m: 0.4625 - val_loss: 0.7967 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6825 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6602 - accuracy: 0.6250 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 0.6582 - accuracy: 0.6458 - f1_m: 0.3360 - precision_m: 0.7546 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6458 - accuracy: 0.6484 - f1_m: 0.3107 - precision_m: 0.7556 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.6319 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6519 - accuracy: 0.6319 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.9704 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 48/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7634 - accuracy: 0.4375 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7168 - accuracy: 0.5469 - f1_m: 0.2418 - precision_m: 0.7915 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6746 - accuracy: 0.6146 - f1_m: 0.2840 - precision_m: 0.7780 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6656 - accuracy: 0.6250 - f1_m: 0.3052 - precision_m: 0.7712 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.6250 - f1_m: 0.3252 - precision_m: 0.7678 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6564 - accuracy: 0.6250 - f1_m: 0.3252 - precision_m: 0.7678 - recall_m: 0.4812 - val_loss: 1.1278 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 49/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6864 - accuracy: 0.5000 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6802 - accuracy: 0.5625 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6542 - accuracy: 0.6146 - f1_m: 0.3697 - precision_m: 0.7529 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6394 - accuracy: 0.6406 - f1_m: 0.3212 - precision_m: 0.7583 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.6597 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6287 - accuracy: 0.6597 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 1.3957 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 50/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5985 - accuracy: 0.7812 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5943 - accuracy: 0.7344 - f1_m: 0.2411 - precision_m: 0.7676 - recall_m: 0.4062 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6354 - accuracy: 0.6562 - f1_m: 0.2957 - precision_m: 0.7630 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6490 - accuracy: 0.6484 - f1_m: 0.3139 - precision_m: 0.7600 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.6319 - f1_m: 0.3044 - precision_m: 0.7588 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6518 - accuracy: 0.6319 - f1_m: 0.3044 - precision_m: 0.7588 - recall_m: 0.4688 - val_loss: 1.2133 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 51/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.5957 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6400 - accuracy: 0.6562 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6282 - accuracy: 0.6667 - f1_m: 0.3220 - precision_m: 0.7503 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6253 - accuracy: 0.6719 - f1_m: 0.2926 - precision_m: 0.7542 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6318 - accuracy: 0.6597 - f1_m: 0.3151 - precision_m: 0.7541 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6318 - accuracy: 0.6597 - f1_m: 0.3151 - precision_m: 0.7541 - recall_m: 0.4812 - val_loss: 0.9928 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 52/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6129 - accuracy: 0.6875 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6509 - accuracy: 0.5938 - f1_m: 0.3021 - precision_m: 0.7817 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6358 - accuracy: 0.6146 - f1_m: 0.3125 - precision_m: 0.7712 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6482 - accuracy: 0.6094 - f1_m: 0.3177 - precision_m: 0.7659 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.6181 - f1_m: 0.3074 - precision_m: 0.7635 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6388 - accuracy: 0.6181 - f1_m: 0.3074 - precision_m: 0.7635 - recall_m: 0.4688 - val_loss: 0.7769 - val_accuracy: 0.5135 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 53/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 0.6470 - accuracy: 0.6250 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 11s - loss: 0.6350 - accuracy: 0.6094 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 6s - loss: 0.6542 - accuracy: 0.5938 - f1_m: 0.3337 - precision_m: 0.7507 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6583 - accuracy: 0.6016 - f1_m: 0.3169 - precision_m: 0.7515 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6578 - accuracy: 0.5972 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6578 - accuracy: 0.5972 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7167 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 54/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6285 - accuracy: 0.6250 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6231 - accuracy: 0.6719 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6263 - accuracy: 0.6458 - f1_m: 0.2915 - precision_m: 0.7572 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6332 - accuracy: 0.6484 - f1_m: 0.2852 - precision_m: 0.7563 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6556 - accuracy: 0.6111 - f1_m: 0.3243 - precision_m: 0.7582 - recall_m: 0.4875\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6556 - accuracy: 0.6111 - f1_m: 0.3243 - precision_m: 0.7582 - recall_m: 0.4875 - val_loss: 0.7029 - val_accuracy: 0.5946 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 55/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6601 - accuracy: 0.7188 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6573 - accuracy: 0.6406 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6385 - accuracy: 0.6562 - f1_m: 0.3235 - precision_m: 0.7529 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6394 - accuracy: 0.6406 - f1_m: 0.3092 - precision_m: 0.7532 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.6597 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6304 - accuracy: 0.6597 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688 - val_loss: 0.8468 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 56/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6728 - accuracy: 0.5938 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6327 - accuracy: 0.6406 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6245 - accuracy: 0.6458 - f1_m: 0.3228 - precision_m: 0.7516 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6107 - accuracy: 0.6641 - f1_m: 0.3169 - precision_m: 0.7515 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.6597 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6237 - accuracy: 0.6597 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.9496 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 57/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7520 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6588 - accuracy: 0.6562 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6461 - accuracy: 0.6250 - f1_m: 0.3044 - precision_m: 0.7588 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6612 - accuracy: 0.6016 - f1_m: 0.3031 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.5903 - f1_m: 0.3091 - precision_m: 0.7555 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6650 - accuracy: 0.5903 - f1_m: 0.3091 - precision_m: 0.7555 - recall_m: 0.4750 - val_loss: 0.8811 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 58/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6360 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6571 - accuracy: 0.6406 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6482 - accuracy: 0.6562 - f1_m: 0.3110 - precision_m: 0.7513 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6364 - accuracy: 0.6641 - f1_m: 0.2919 - precision_m: 0.7532 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.6528 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6413 - accuracy: 0.6528 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7351 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 59/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 0.6634 - accuracy: 0.6875 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6379 - accuracy: 0.6562 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6208 - accuracy: 0.6771 - f1_m: 0.2891 - precision_m: 0.7533 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6214 - accuracy: 0.6797 - f1_m: 0.2916 - precision_m: 0.7527 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.6597 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812\n",
            "5/5 [==============================] - 13s 2s/step - loss: 0.6258 - accuracy: 0.6597 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812 - val_loss: 0.6982 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 60/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6334 - accuracy: 0.5312 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6133 - accuracy: 0.6094 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6157 - accuracy: 0.6458 - f1_m: 0.3029 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6248 - accuracy: 0.6328 - f1_m: 0.3105 - precision_m: 0.7551 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.6250 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6386 - accuracy: 0.6250 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 - val_loss: 0.6906 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 61/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6144 - accuracy: 0.7188 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6369 - accuracy: 0.6406 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6451 - accuracy: 0.6250 - f1_m: 0.3732 - precision_m: 0.7594 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6413 - accuracy: 0.6328 - f1_m: 0.3386 - precision_m: 0.7593 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.6042 - f1_m: 0.2909 - precision_m: 0.7699 - recall_m: 0.4500\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6573 - accuracy: 0.6042 - f1_m: 0.2909 - precision_m: 0.7699 - recall_m: 0.4500 - val_loss: 0.6896 - val_accuracy: 0.5946 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 62/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6453 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6632 - accuracy: 0.6250 - f1_m: 0.2689 - precision_m: 0.7578 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6482 - accuracy: 0.6354 - f1_m: 0.3022 - precision_m: 0.7555 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6442 - accuracy: 0.6328 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.6319 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6496 - accuracy: 0.6319 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6909 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 63/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7082 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6848 - accuracy: 0.6406 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6683 - accuracy: 0.6354 - f1_m: 0.3110 - precision_m: 0.7513 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6427 - accuracy: 0.6797 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.6875 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6357 - accuracy: 0.6875 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750 - val_loss: 0.6880 - val_accuracy: 0.6216 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 64/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6379 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 11s - loss: 0.6638 - accuracy: 0.5781 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 7s - loss: 0.6685 - accuracy: 0.6042 - f1_m: 0.3220 - precision_m: 0.7503 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6616 - accuracy: 0.6172 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.6528 - f1_m: 0.2939 - precision_m: 0.7535 - recall_m: 0.4625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6437 - accuracy: 0.6528 - f1_m: 0.2939 - precision_m: 0.7535 - recall_m: 0.4625 - val_loss: 0.6889 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 65/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6034 - accuracy: 0.6875 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6244 - accuracy: 0.6875 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6450 - accuracy: 0.6667 - f1_m: 0.2667 - precision_m: 0.7546 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6284 - accuracy: 0.6719 - f1_m: 0.2834 - precision_m: 0.7534 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.6319 - f1_m: 0.3229 - precision_m: 0.7559 - recall_m: 0.4875\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6446 - accuracy: 0.6319 - f1_m: 0.3229 - precision_m: 0.7559 - recall_m: 0.4875 - val_loss: 0.6913 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 66/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5998 - accuracy: 0.6875 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6069 - accuracy: 0.7031 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6466 - accuracy: 0.6667 - f1_m: 0.2886 - precision_m: 0.7526 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6466 - accuracy: 0.6484 - f1_m: 0.3086 - precision_m: 0.7522 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.6597 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6379 - accuracy: 0.6597 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.6913 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 67/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5725 - accuracy: 0.7812 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5962 - accuracy: 0.7344 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6185 - accuracy: 0.6667 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6367 - accuracy: 0.6641 - f1_m: 0.2929 - precision_m: 0.7546 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.6597 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6463 - accuracy: 0.6597 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.6939 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 68/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6487 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6482 - accuracy: 0.5469 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6541 - accuracy: 0.5729 - f1_m: 0.2899 - precision_m: 0.7546 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6461 - accuracy: 0.5938 - f1_m: 0.3007 - precision_m: 0.7534 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.6181 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6345 - accuracy: 0.6181 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.6945 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 69/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6129 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6269 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.5820 - accuracy: 0.7083 - f1_m: 0.3106 - precision_m: 0.7507 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6090 - accuracy: 0.6797 - f1_m: 0.2769 - precision_m: 0.7566 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.6458 - f1_m: 0.3336 - precision_m: 0.7623 - recall_m: 0.4938\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6229 - accuracy: 0.6458 - f1_m: 0.3336 - precision_m: 0.7623 - recall_m: 0.4938 - val_loss: 0.6962 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 70/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6293 - accuracy: 0.6250 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6501 - accuracy: 0.6250 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6530 - accuracy: 0.6250 - f1_m: 0.2695 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6503 - accuracy: 0.6016 - f1_m: 0.3321 - precision_m: 0.7625 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.5972 - f1_m: 0.2955 - precision_m: 0.7670 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6612 - accuracy: 0.5972 - f1_m: 0.2955 - precision_m: 0.7670 - recall_m: 0.4563 - val_loss: 0.6990 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 71/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6362 - accuracy: 0.5938 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6395 - accuracy: 0.6094 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6136 - accuracy: 0.6562 - f1_m: 0.3337 - precision_m: 0.7507 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6154 - accuracy: 0.6641 - f1_m: 0.3251 - precision_m: 0.7507 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.6389 - f1_m: 0.2898 - precision_m: 0.7576 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6413 - accuracy: 0.6389 - f1_m: 0.2898 - precision_m: 0.7576 - recall_m: 0.4563 - val_loss: 0.6976 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 72/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6740 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6624 - accuracy: 0.5938 - f1_m: 0.3199 - precision_m: 0.7563 - recall_m: 0.4844 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6348 - accuracy: 0.6667 - f1_m: 0.3020 - precision_m: 0.7555 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6199 - accuracy: 0.6641 - f1_m: 0.3098 - precision_m: 0.7542 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.6597 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6249 - accuracy: 0.6597 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7064 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 73/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6612 - accuracy: 0.5938 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6444 - accuracy: 0.6406 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6530 - accuracy: 0.6458 - f1_m: 0.2919 - precision_m: 0.7578 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6671 - accuracy: 0.6094 - f1_m: 0.3023 - precision_m: 0.7559 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.6111 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6666 - accuracy: 0.6111 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750 - val_loss: 0.7275 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 74/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6052 - accuracy: 0.7188 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6251 - accuracy: 0.7031 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6524 - accuracy: 0.6458 - f1_m: 0.3044 - precision_m: 0.7594 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6573 - accuracy: 0.6094 - f1_m: 0.2794 - precision_m: 0.7610 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.6042 - f1_m: 0.3356 - precision_m: 0.7658 - recall_m: 0.4938\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6629 - accuracy: 0.6042 - f1_m: 0.3356 - precision_m: 0.7658 - recall_m: 0.4938 - val_loss: 0.7155 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 75/100\n",
            "1/5 [=====>........................] - ETA: 12s - loss: 0.6606 - accuracy: 0.6562 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6702 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 7s - loss: 0.6708 - accuracy: 0.6146 - f1_m: 0.3240 - precision_m: 0.7536 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6605 - accuracy: 0.6328 - f1_m: 0.3096 - precision_m: 0.7537 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.6458 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688\n",
            "5/5 [==============================] - 15s 3s/step - loss: 0.6526 - accuracy: 0.6458 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.6884 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 76/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6144 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6600 - accuracy: 0.6250 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6602 - accuracy: 0.6250 - f1_m: 0.3455 - precision_m: 0.7510 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6576 - accuracy: 0.6172 - f1_m: 0.3178 - precision_m: 0.7529 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.6389 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6525 - accuracy: 0.6389 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625 - val_loss: 0.7415 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 77/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6289 - accuracy: 0.7188 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6293 - accuracy: 0.6719 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6553 - accuracy: 0.6042 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6421 - accuracy: 0.6562 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.6458 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6497 - accuracy: 0.6458 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.8465 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 78/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6421 - accuracy: 0.6250 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6423 - accuracy: 0.6406 - f1_m: 0.3344 - precision_m: 0.7798 - recall_m: 0.4844 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6409 - accuracy: 0.6250 - f1_m: 0.3458 - precision_m: 0.7702 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6368 - accuracy: 0.6328 - f1_m: 0.3033 - precision_m: 0.7712 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.6389 - f1_m: 0.3237 - precision_m: 0.7678 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6306 - accuracy: 0.6389 - f1_m: 0.3237 - precision_m: 0.7678 - recall_m: 0.4812 - val_loss: 1.1109 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 79/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5617 - accuracy: 0.7188 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5847 - accuracy: 0.6719 - f1_m: 0.2505 - precision_m: 0.7563 - recall_m: 0.4219 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6121 - accuracy: 0.6458 - f1_m: 0.3020 - precision_m: 0.7555 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6072 - accuracy: 0.6641 - f1_m: 0.3098 - precision_m: 0.7542 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.6389 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6215 - accuracy: 0.6389 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 1.4713 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 80/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6850 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6132 - accuracy: 0.7344 - f1_m: 0.2375 - precision_m: 0.7627 - recall_m: 0.4062 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6129 - accuracy: 0.7188 - f1_m: 0.2581 - precision_m: 0.7588 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6161 - accuracy: 0.6953 - f1_m: 0.2857 - precision_m: 0.7568 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.6528 - f1_m: 0.3247 - precision_m: 0.7586 - recall_m: 0.4875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6443 - accuracy: 0.6528 - f1_m: 0.3247 - precision_m: 0.7586 - recall_m: 0.4875 - val_loss: 1.6557 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 81/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 0.5947 - accuracy: 0.7188 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6054 - accuracy: 0.7344 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6334 - accuracy: 0.6979 - f1_m: 0.3125 - precision_m: 0.7539 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6382 - accuracy: 0.6875 - f1_m: 0.3010 - precision_m: 0.7539 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6390 - accuracy: 0.6736 - f1_m: 0.3074 - precision_m: 0.7531 - recall_m: 0.4750\n",
            "5/5 [==============================] - 13s 2s/step - loss: 0.6390 - accuracy: 0.6736 - f1_m: 0.3074 - precision_m: 0.7531 - recall_m: 0.4750 - val_loss: 1.4771 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 82/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5980 - accuracy: 0.7812 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6222 - accuracy: 0.6719 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6142 - accuracy: 0.6979 - f1_m: 0.3008 - precision_m: 0.7536 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6166 - accuracy: 0.6953 - f1_m: 0.3178 - precision_m: 0.7529 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.6667 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6288 - accuracy: 0.6667 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625 - val_loss: 1.3121 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 83/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6686 - accuracy: 0.5000 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6293 - accuracy: 0.5625 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6424 - accuracy: 0.5729 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6614 - accuracy: 0.5703 - f1_m: 0.3169 - precision_m: 0.7515 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6521 - accuracy: 0.5833 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6521 - accuracy: 0.5833 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.9848 - val_accuracy: 0.4595 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 84/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.5867 - accuracy: 0.7500 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5848 - accuracy: 0.7344 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6052 - accuracy: 0.6875 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6250 - accuracy: 0.6562 - f1_m: 0.3083 - precision_m: 0.7517 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6187 - accuracy: 0.6597 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6187 - accuracy: 0.6597 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.7993 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 85/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6969 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6452 - accuracy: 0.6250 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6552 - accuracy: 0.6250 - f1_m: 0.2703 - precision_m: 0.7598 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6567 - accuracy: 0.6250 - f1_m: 0.3133 - precision_m: 0.7595 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.6389 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6472 - accuracy: 0.6389 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.7136 - val_accuracy: 0.4865 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 86/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7366 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 0.6762 - accuracy: 0.6094 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 0.6458 - accuracy: 0.6458 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 0.6373 - accuracy: 0.6562 - f1_m: 0.3083 - precision_m: 0.7517 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.6528 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6410 - accuracy: 0.6528 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.6864 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 87/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6414 - accuracy: 0.5938 - f1_m: 0.5200 - precision_m: 0.7744 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6706 - accuracy: 0.5781 - f1_m: 0.4267 - precision_m: 0.7622 - recall_m: 0.5781 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6717 - accuracy: 0.5938 - f1_m: 0.3732 - precision_m: 0.7594 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6595 - accuracy: 0.6172 - f1_m: 0.3311 - precision_m: 0.7610 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.6250 - f1_m: 0.2946 - precision_m: 0.7658 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6589 - accuracy: 0.6250 - f1_m: 0.2946 - precision_m: 0.7658 - recall_m: 0.4563 - val_loss: 0.6955 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 88/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5984 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6207 - accuracy: 0.5938 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6598 - accuracy: 0.5521 - f1_m: 0.3811 - precision_m: 0.7526 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6347 - accuracy: 0.5781 - f1_m: 0.3370 - precision_m: 0.7559 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.6042 - f1_m: 0.2896 - precision_m: 0.7672 - recall_m: 0.4500\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6240 - accuracy: 0.6042 - f1_m: 0.2896 - precision_m: 0.7672 - recall_m: 0.4500 - val_loss: 0.7163 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 89/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6470 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7019 - accuracy: 0.5312 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6635 - accuracy: 0.5729 - f1_m: 0.3349 - precision_m: 0.7526 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6543 - accuracy: 0.5859 - f1_m: 0.3177 - precision_m: 0.7529 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.5972 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6517 - accuracy: 0.5972 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625 - val_loss: 0.7437 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 90/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6541 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6677 - accuracy: 0.6094 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6318 - accuracy: 0.6458 - f1_m: 0.3261 - precision_m: 0.7568 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6346 - accuracy: 0.6328 - f1_m: 0.3193 - precision_m: 0.7554 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.6389 - f1_m: 0.2964 - precision_m: 0.7574 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6313 - accuracy: 0.6389 - f1_m: 0.2964 - precision_m: 0.7574 - recall_m: 0.4625 - val_loss: 0.7390 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 91/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5630 - accuracy: 0.7812 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6154 - accuracy: 0.6719 - f1_m: 0.3975 - precision_m: 0.7720 - recall_m: 0.5469 \n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6362 - accuracy: 0.6354 - f1_m: 0.4000 - precision_m: 0.7660 - recall_m: 0.5521\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6439 - accuracy: 0.6406 - f1_m: 0.3372 - precision_m: 0.7708 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.6458 - f1_m: 0.2995 - precision_m: 0.7736 - recall_m: 0.4563\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6329 - accuracy: 0.6458 - f1_m: 0.2995 - precision_m: 0.7736 - recall_m: 0.4563 - val_loss: 0.7437 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 92/100\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 0.6803 - accuracy: 0.4688 - f1_m: 0.5200 - precision_m: 0.7744 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 10s - loss: 0.6531 - accuracy: 0.5625 - f1_m: 0.3344 - precision_m: 0.7798 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6245 - accuracy: 0.6042 - f1_m: 0.2911 - precision_m: 0.7751 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6209 - accuracy: 0.6094 - f1_m: 0.2932 - precision_m: 0.7690 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.5833 - f1_m: 0.3307 - precision_m: 0.7684 - recall_m: 0.4875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6355 - accuracy: 0.5833 - f1_m: 0.3307 - precision_m: 0.7684 - recall_m: 0.4875 - val_loss: 0.7451 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 93/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.7232 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7167 - accuracy: 0.5312 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6987 - accuracy: 0.5625 - f1_m: 0.3349 - precision_m: 0.7526 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6680 - accuracy: 0.6094 - f1_m: 0.3098 - precision_m: 0.7542 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.6042 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6674 - accuracy: 0.6042 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7269 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 94/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6065 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.7017 - accuracy: 0.6250 - f1_m: 0.3708 - precision_m: 0.7549 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 4s - loss: 0.6784 - accuracy: 0.6354 - f1_m: 0.3583 - precision_m: 0.7533 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6544 - accuracy: 0.6484 - f1_m: 0.3199 - precision_m: 0.7563 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.6528 - f1_m: 0.2968 - precision_m: 0.7582 - recall_m: 0.4625\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6499 - accuracy: 0.6528 - f1_m: 0.2968 - precision_m: 0.7582 - recall_m: 0.4625 - val_loss: 0.7079 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 95/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6283 - accuracy: 0.6562 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5911 - accuracy: 0.6719 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6010 - accuracy: 0.6771 - f1_m: 0.3005 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6158 - accuracy: 0.6562 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.6319 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6254 - accuracy: 0.6319 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.6999 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 96/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6151 - accuracy: 0.7188 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6470 - accuracy: 0.6250 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6366 - accuracy: 0.6146 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6268 - accuracy: 0.6250 - f1_m: 0.2773 - precision_m: 0.7576 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.6181 - f1_m: 0.3339 - precision_m: 0.7631 - recall_m: 0.4938\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6362 - accuracy: 0.6181 - f1_m: 0.3339 - precision_m: 0.7631 - recall_m: 0.4938 - val_loss: 0.6955 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 97/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.5853 - accuracy: 0.6875 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.5921 - accuracy: 0.7031 - f1_m: 0.2866 - precision_m: 0.7583 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6027 - accuracy: 0.6562 - f1_m: 0.3022 - precision_m: 0.7555 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6212 - accuracy: 0.6406 - f1_m: 0.2932 - precision_m: 0.7551 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.6389 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6340 - accuracy: 0.6389 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.6946 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 98/100\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.6097 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 9s - loss: 0.5836 - accuracy: 0.6875 - f1_m: 0.2375 - precision_m: 0.7627 - recall_m: 0.4062 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6305 - accuracy: 0.6250 - f1_m: 0.2366 - precision_m: 0.7614 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6213 - accuracy: 0.6328 - f1_m: 0.2787 - precision_m: 0.7595 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.6250 - f1_m: 0.3350 - precision_m: 0.7646 - recall_m: 0.4938\n",
            "5/5 [==============================] - 14s 3s/step - loss: 0.6206 - accuracy: 0.6250 - f1_m: 0.3350 - precision_m: 0.7646 - recall_m: 0.4938 - val_loss: 0.6968 - val_accuracy: 0.5676 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 99/100\n",
            "1/5 [=====>........................] - ETA: 9s - loss: 0.6328 - accuracy: 0.6875 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6176 - accuracy: 0.6875 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6470 - accuracy: 0.6250 - f1_m: 0.3378 - precision_m: 0.7578 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6403 - accuracy: 0.6484 - f1_m: 0.3045 - precision_m: 0.7598 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.6458 - f1_m: 0.3103 - precision_m: 0.7578 - recall_m: 0.4750\n",
            "5/5 [==============================] - 12s 2s/step - loss: 0.6452 - accuracy: 0.6458 - f1_m: 0.3103 - precision_m: 0.7578 - recall_m: 0.4750 - val_loss: 0.6954 - val_accuracy: 0.5405 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m Epoch 100/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.6137 - accuracy: 0.6875 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 0.6056 - accuracy: 0.6719 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6268 - accuracy: 0.6667 - f1_m: 0.2773 - precision_m: 0.7529 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6330 - accuracy: 0.6562 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.6597 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                                                                           </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip   </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  val_accuracy</th><th style=\"text-align: right;\">  val_f1_m</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5c7f9388</td><td style=\"text-align: right;\">  0.486111</td><td>2022-11-21_16-31-54</td><td>True  </td><td>                </td><td>672cc7a5dafd4eae8d0760b447e33063</td><td>2_conv_block1_filters=8,dropout_rate=0.1000,fc1_units=64,fc_layer_type=dense,lr=0.0001,pool_type=max     </td><td>aad98450a16b</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">0.749246</td><td>172.28.0.2</td><td style=\"text-align: right;\"> 8236</td><td style=\"text-align: right;\">             273.826</td><td style=\"text-align: right;\">           273.826</td><td style=\"text-align: right;\">       273.826</td><td style=\"text-align: right;\"> 1669048314</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>5c7f9388  </td><td style=\"text-align: right;\">      0.459459</td><td style=\"text-align: right;\">  0.472917</td><td style=\"text-align: right;\">  0.693569</td><td style=\"text-align: right;\">   0.0038662 </td></tr>\n",
              "<tr><td>train_mnist_653a4aca</td><td style=\"text-align: right;\">  0.465278</td><td>2022-11-21_16-27-15</td><td>True  </td><td>                </td><td>efbfef17283e45e9aeb2bf3096d5542b</td><td>1_conv_block1_filters=64,dropout_rate=0.2000,fc1_units=16,fc_layer_type=dense,lr=0.0100,pool_type=average</td><td>aad98450a16b</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">0.706276</td><td>172.28.0.2</td><td style=\"text-align: right;\"> 6763</td><td style=\"text-align: right;\">            1267.93 </td><td style=\"text-align: right;\">          1267.93 </td><td style=\"text-align: right;\">      1267.93 </td><td style=\"text-align: right;\"> 1669048035</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>653a4aca  </td><td style=\"text-align: right;\">      0.459459</td><td style=\"text-align: right;\">  0.184311</td><td style=\"text-align: right;\">  0.695433</td><td style=\"text-align: right;\">   0.00428319</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=6763)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 12s 2s/step - loss: 0.6254 - accuracy: 0.6597 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.6943 - val_accuracy: 0.5946 - val_f1_m: 0.1843 - val_precision_m: 0.8755 - val_recall_m: 0.2656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m 2022-11-21 16:27:31.199459: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/activation_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  conv1d (Conv1D)             (None, 43886, 8)          72        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  batch_normalization (BatchN  (None, 43886, 8)         32        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  activation (Activation)     (None, 43886, 8)          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  global_max_pooling1d (Globa  (None, 8)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  dense (Dense)               (None, 64)                576       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  dropout (Dropout)           (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  batch_normalization_1 (Batc  (None, 64)               256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  activation_1 (Activation)   (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  dense_1 (Dense)             (None, 2)                 130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  batch_normalization_2 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Total params: 1,077\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Trainable params: 929\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Non-trainable params: 148\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Total number of layers: 13\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f4787993050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f4787993050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f4787993050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f4787993050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f478799b830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f478799b830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f478799b830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f478799b830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f472d2ad710> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f472d2ad710>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f472d2ad710> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f472d2ad710>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7444 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7379 - accuracy: 0.4688 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7609 - accuracy: 0.4375 - f1_m: 0.2218 - precision_m: 0.7725 - recall_m: 0.3854\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7552 - accuracy: 0.4688 - f1_m: 0.3064 - precision_m: 0.7756 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7492 - accuracy: 0.4861 - f1_m: 0.3261 - precision_m: 0.7713 - recall_m: 0.4812\n",
            "5/5 [==============================] - 3s 491ms/step - loss: 0.7492 - accuracy: 0.4861 - f1_m: 0.3261 - precision_m: 0.7713 - recall_m: 0.4812 - val_loss: 0.6936 - val_accuracy: 0.4595 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 2/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7066 - accuracy: 0.5312 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7236 - accuracy: 0.5000 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7453 - accuracy: 0.4792 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7453 - accuracy: 0.4922 - f1_m: 0.3023 - precision_m: 0.7559 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7386 - accuracy: 0.4931 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.7386 - accuracy: 0.4931 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750 - val_loss: 0.6937 - val_accuracy: 0.4595 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 3/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7799 - accuracy: 0.4375 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7546 - accuracy: 0.4844 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7483 - accuracy: 0.4688 - f1_m: 0.3029 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7394 - accuracy: 0.4922 - f1_m: 0.3105 - precision_m: 0.7551 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.4792 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.7460 - accuracy: 0.4792 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 - val_loss: 0.6928 - val_accuracy: 0.4595 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 4/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6645 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7206 - accuracy: 0.5469 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7207 - accuracy: 0.5521 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7245 - accuracy: 0.5547 - f1_m: 0.3212 - precision_m: 0.7588 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.5556 - f1_m: 0.2979 - precision_m: 0.7602 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 499ms/step - loss: 0.7232 - accuracy: 0.5556 - f1_m: 0.2979 - precision_m: 0.7602 - recall_m: 0.4625 - val_loss: 0.6923 - val_accuracy: 0.5946 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 5/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6570 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7176 - accuracy: 0.5312 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7168 - accuracy: 0.5625 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7135 - accuracy: 0.5391 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7077 - accuracy: 0.5486 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.7077 - accuracy: 0.5486 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.6926 - val_accuracy: 0.6486 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 6/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7155 - accuracy: 0.5312 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7231 - accuracy: 0.5156 - f1_m: 0.3427 - precision_m: 0.7656 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7141 - accuracy: 0.5104 - f1_m: 0.3172 - precision_m: 0.7617 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7180 - accuracy: 0.5312 - f1_m: 0.3045 - precision_m: 0.7598 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.5278 - f1_m: 0.3103 - precision_m: 0.7578 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.7137 - accuracy: 0.5278 - f1_m: 0.3103 - precision_m: 0.7578 - recall_m: 0.4750 - val_loss: 0.6923 - val_accuracy: 0.6486 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6673 - accuracy: 0.5625 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7237 - accuracy: 0.4844 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7360 - accuracy: 0.4896 - f1_m: 0.3496 - precision_m: 0.7581 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7474 - accuracy: 0.4531 - f1_m: 0.3062 - precision_m: 0.7622 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.4792 - f1_m: 0.3116 - precision_m: 0.7598 - recall_m: 0.4750\n",
            "5/5 [==============================] - 3s 731ms/step - loss: 0.7397 - accuracy: 0.4792 - f1_m: 0.3116 - precision_m: 0.7598 - recall_m: 0.4750 - val_loss: 0.6923 - val_accuracy: 0.6216 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 8/100\n",
            "1/5 [=====>........................] - ETA: 3s - loss: 0.7939 - accuracy: 0.3125 - f1_m: 0.5602 - precision_m: 0.7852 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 2s - loss: 0.7447 - accuracy: 0.4688 - f1_m: 0.3545 - precision_m: 0.7852 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7523 - accuracy: 0.4688 - f1_m: 0.3592 - precision_m: 0.7738 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7499 - accuracy: 0.4688 - f1_m: 0.3205 - precision_m: 0.7717 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7461 - accuracy: 0.4861 - f1_m: 0.3097 - precision_m: 0.7682 - recall_m: 0.4688\n",
            "5/5 [==============================] - 4s 796ms/step - loss: 0.7461 - accuracy: 0.4861 - f1_m: 0.3097 - precision_m: 0.7682 - recall_m: 0.4688 - val_loss: 0.6923 - val_accuracy: 0.6486 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 9/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7688 - accuracy: 0.5000 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7375 - accuracy: 0.4688 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6990 - accuracy: 0.5312 - f1_m: 0.2777 - precision_m: 0.7536 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6803 - accuracy: 0.5547 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.5417 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.6877 - accuracy: 0.5417 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6922 - val_accuracy: 0.5676 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 10/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7686 - accuracy: 0.4375 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7429 - accuracy: 0.5156 - f1_m: 0.1949 - precision_m: 0.7759 - recall_m: 0.3594\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7422 - accuracy: 0.5417 - f1_m: 0.2410 - precision_m: 0.7673 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7550 - accuracy: 0.4844 - f1_m: 0.3010 - precision_m: 0.7668 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.4861 - f1_m: 0.3218 - precision_m: 0.7643 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.7508 - accuracy: 0.4861 - f1_m: 0.3218 - precision_m: 0.7643 - recall_m: 0.4812 - val_loss: 0.6917 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 11/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7393 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7218 - accuracy: 0.5000 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7210 - accuracy: 0.4896 - f1_m: 0.3815 - precision_m: 0.7533 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7342 - accuracy: 0.4922 - f1_m: 0.3301 - precision_m: 0.7585 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7296 - accuracy: 0.5139 - f1_m: 0.2938 - precision_m: 0.7639 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.7296 - accuracy: 0.5139 - f1_m: 0.2938 - precision_m: 0.7639 - recall_m: 0.4563 - val_loss: 0.6913 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 12/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7534 - accuracy: 0.4062 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7345 - accuracy: 0.4688 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7302 - accuracy: 0.4479 - f1_m: 0.3268 - precision_m: 0.7581 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7313 - accuracy: 0.4297 - f1_m: 0.3199 - precision_m: 0.7563 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7402 - accuracy: 0.4167 - f1_m: 0.2968 - precision_m: 0.7582 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.7402 - accuracy: 0.4167 - f1_m: 0.2968 - precision_m: 0.7582 - recall_m: 0.4625 - val_loss: 0.6907 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 13/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6717 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6968 - accuracy: 0.5000 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7079 - accuracy: 0.5104 - f1_m: 0.3172 - precision_m: 0.7611 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7180 - accuracy: 0.5078 - f1_m: 0.3212 - precision_m: 0.7583 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.5139 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.7195 - accuracy: 0.5139 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.6903 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 14/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7273 - accuracy: 0.5938 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7429 - accuracy: 0.5312 - f1_m: 0.2505 - precision_m: 0.7563 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7515 - accuracy: 0.5208 - f1_m: 0.3145 - precision_m: 0.7572 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7464 - accuracy: 0.5000 - f1_m: 0.3280 - precision_m: 0.7556 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.4792 - f1_m: 0.2922 - precision_m: 0.7615 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.7569 - accuracy: 0.4792 - f1_m: 0.2922 - precision_m: 0.7615 - recall_m: 0.4563 - val_loss: 0.6898 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 15/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7839 - accuracy: 0.4375 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7779 - accuracy: 0.4062 - f1_m: 0.3199 - precision_m: 0.7563 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7501 - accuracy: 0.4688 - f1_m: 0.3130 - precision_m: 0.7546 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7474 - accuracy: 0.4688 - f1_m: 0.2934 - precision_m: 0.7556 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.4722 - f1_m: 0.3157 - precision_m: 0.7553 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 473ms/step - loss: 0.7368 - accuracy: 0.4722 - f1_m: 0.3157 - precision_m: 0.7553 - recall_m: 0.4812 - val_loss: 0.6892 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 16/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7774 - accuracy: 0.3750 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7613 - accuracy: 0.4531 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7577 - accuracy: 0.4375 - f1_m: 0.3368 - precision_m: 0.7559 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7652 - accuracy: 0.4375 - f1_m: 0.3038 - precision_m: 0.7583 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.4444 - f1_m: 0.3097 - precision_m: 0.7566 - recall_m: 0.4750\n",
            "5/5 [==============================] - 3s 502ms/step - loss: 0.7584 - accuracy: 0.4444 - f1_m: 0.3097 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 0.6887 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 17/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7612 - accuracy: 0.4688 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7280 - accuracy: 0.5469 - f1_m: 0.2904 - precision_m: 0.7642 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7193 - accuracy: 0.5521 - f1_m: 0.3286 - precision_m: 0.7607 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7063 - accuracy: 0.5859 - f1_m: 0.3051 - precision_m: 0.7603 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.5972 - f1_m: 0.3108 - precision_m: 0.7582 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.7064 - accuracy: 0.5972 - f1_m: 0.3108 - precision_m: 0.7582 - recall_m: 0.4750 - val_loss: 0.6881 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 18/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6927 - accuracy: 0.4688 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7354 - accuracy: 0.4375 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7310 - accuracy: 0.4583 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7093 - accuracy: 0.5000 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7087 - accuracy: 0.4931 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.7087 - accuracy: 0.4931 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.6879 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 19/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7240 - accuracy: 0.4688 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7381 - accuracy: 0.4531 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7234 - accuracy: 0.4688 - f1_m: 0.3228 - precision_m: 0.7516 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7153 - accuracy: 0.4844 - f1_m: 0.3007 - precision_m: 0.7534 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.5069 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.7075 - accuracy: 0.5069 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 20/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6605 - accuracy: 0.5625 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7404 - accuracy: 0.4531 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7358 - accuracy: 0.4688 - f1_m: 0.3228 - precision_m: 0.7516 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7148 - accuracy: 0.4922 - f1_m: 0.3254 - precision_m: 0.7512 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7084 - accuracy: 0.5000 - f1_m: 0.2901 - precision_m: 0.7580 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.7084 - accuracy: 0.5000 - f1_m: 0.2901 - precision_m: 0.7580 - recall_m: 0.4563 - val_loss: 0.6876 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 21/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6840 - accuracy: 0.5625 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7326 - accuracy: 0.5000 - f1_m: 0.2375 - precision_m: 0.7627 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7097 - accuracy: 0.5312 - f1_m: 0.2471 - precision_m: 0.7598 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7373 - accuracy: 0.4766 - f1_m: 0.2866 - precision_m: 0.7583 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7277 - accuracy: 0.4861 - f1_m: 0.3254 - precision_m: 0.7598 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.7277 - accuracy: 0.4861 - f1_m: 0.3254 - precision_m: 0.7598 - recall_m: 0.4875 - val_loss: 0.6875 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 22/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7102 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7063 - accuracy: 0.5625 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7022 - accuracy: 0.5729 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6911 - accuracy: 0.5938 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.5694 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7002 - accuracy: 0.5694 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6875 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 23/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7353 - accuracy: 0.4688 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7288 - accuracy: 0.4531 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7217 - accuracy: 0.5000 - f1_m: 0.3349 - precision_m: 0.7526 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7432 - accuracy: 0.4453 - f1_m: 0.3260 - precision_m: 0.7522 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7526 - accuracy: 0.4306 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.7526 - accuracy: 0.4306 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.6875 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 24/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7301 - accuracy: 0.4375 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7250 - accuracy: 0.5156 - f1_m: 0.2240 - precision_m: 0.7681 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7255 - accuracy: 0.5104 - f1_m: 0.2968 - precision_m: 0.7650 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7089 - accuracy: 0.5312 - f1_m: 0.2813 - precision_m: 0.7634 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7165 - accuracy: 0.5208 - f1_m: 0.3371 - precision_m: 0.7678 - recall_m: 0.4938\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7165 - accuracy: 0.5208 - f1_m: 0.3371 - precision_m: 0.7678 - recall_m: 0.4938 - val_loss: 0.6876 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 25/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7107 - accuracy: 0.6250 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7193 - accuracy: 0.5312 - f1_m: 0.4247 - precision_m: 0.7583 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7195 - accuracy: 0.5312 - f1_m: 0.3418 - precision_m: 0.7637 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7083 - accuracy: 0.5391 - f1_m: 0.3311 - precision_m: 0.7605 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7065 - accuracy: 0.5486 - f1_m: 0.2947 - precision_m: 0.7654 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.7065 - accuracy: 0.5486 - f1_m: 0.2947 - precision_m: 0.7654 - recall_m: 0.4563 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 26/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7340 - accuracy: 0.5000 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7318 - accuracy: 0.5156 - f1_m: 0.2460 - precision_m: 0.7744 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7165 - accuracy: 0.4896 - f1_m: 0.2990 - precision_m: 0.7676 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7145 - accuracy: 0.4922 - f1_m: 0.2830 - precision_m: 0.7654 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7113 - accuracy: 0.5069 - f1_m: 0.3384 - precision_m: 0.7693 - recall_m: 0.4938\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.7113 - accuracy: 0.5069 - f1_m: 0.3384 - precision_m: 0.7693 - recall_m: 0.4938 - val_loss: 0.6878 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 27/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7047 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7379 - accuracy: 0.5469 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6985 - accuracy: 0.5625 - f1_m: 0.3486 - precision_m: 0.7562 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7039 - accuracy: 0.5469 - f1_m: 0.3280 - precision_m: 0.7556 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.5556 - f1_m: 0.2922 - precision_m: 0.7615 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.7004 - accuracy: 0.5556 - f1_m: 0.2922 - precision_m: 0.7615 - recall_m: 0.4563 - val_loss: 0.6878 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 28/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7389 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7157 - accuracy: 0.5938 - f1_m: 0.3544 - precision_m: 0.7563 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7285 - accuracy: 0.5521 - f1_m: 0.3360 - precision_m: 0.7546 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7204 - accuracy: 0.5469 - f1_m: 0.3107 - precision_m: 0.7556 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.5625 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.7185 - accuracy: 0.5625 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.6879 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 29/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7757 - accuracy: 0.4688 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6818 - accuracy: 0.5781 - f1_m: 0.2689 - precision_m: 0.7578 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6976 - accuracy: 0.5625 - f1_m: 0.2790 - precision_m: 0.7555 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7175 - accuracy: 0.5156 - f1_m: 0.2680 - precision_m: 0.7563 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.5069 - f1_m: 0.3429 - precision_m: 0.7676 - recall_m: 0.5000\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.7131 - accuracy: 0.5069 - f1_m: 0.3429 - precision_m: 0.7676 - recall_m: 0.5000 - val_loss: 0.6879 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 30/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6774 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6950 - accuracy: 0.5938 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7066 - accuracy: 0.5729 - f1_m: 0.3337 - precision_m: 0.7507 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7311 - accuracy: 0.5156 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7249 - accuracy: 0.5139 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.7249 - accuracy: 0.5139 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6881 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 31/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6549 - accuracy: 0.6250 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6726 - accuracy: 0.6250 - f1_m: 0.2460 - precision_m: 0.7744 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7123 - accuracy: 0.5833 - f1_m: 0.2751 - precision_m: 0.7663 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6895 - accuracy: 0.6016 - f1_m: 0.2897 - precision_m: 0.7622 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5833 - f1_m: 0.3279 - precision_m: 0.7629 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.6924 - accuracy: 0.5833 - f1_m: 0.3279 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 0.6882 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 32/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6858 - accuracy: 0.5938 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6982 - accuracy: 0.5469 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7103 - accuracy: 0.5521 - f1_m: 0.3097 - precision_m: 0.7686 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7193 - accuracy: 0.5625 - f1_m: 0.2989 - precision_m: 0.7649 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7106 - accuracy: 0.5764 - f1_m: 0.3201 - precision_m: 0.7627 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.7106 - accuracy: 0.5764 - f1_m: 0.3201 - precision_m: 0.7627 - recall_m: 0.4812 - val_loss: 0.6883 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 33/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6711 - accuracy: 0.5625 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6795 - accuracy: 0.5156 - f1_m: 0.2375 - precision_m: 0.7627 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7039 - accuracy: 0.4688 - f1_m: 0.2812 - precision_m: 0.7588 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7131 - accuracy: 0.4922 - f1_m: 0.3122 - precision_m: 0.7576 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.5000 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7118 - accuracy: 0.5000 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 0.6885 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 34/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7661 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7559 - accuracy: 0.4844 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7262 - accuracy: 0.5104 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7242 - accuracy: 0.5312 - f1_m: 0.2995 - precision_m: 0.7515 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.5278 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.7191 - accuracy: 0.5278 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.6886 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 35/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6330 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6682 - accuracy: 0.6406 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6652 - accuracy: 0.6354 - f1_m: 0.3469 - precision_m: 0.7536 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6958 - accuracy: 0.5781 - f1_m: 0.3113 - precision_m: 0.7566 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7132 - accuracy: 0.5486 - f1_m: 0.3023 - precision_m: 0.7561 - recall_m: 0.4688\n",
            "5/5 [==============================] - 3s 678ms/step - loss: 0.7132 - accuracy: 0.5486 - f1_m: 0.3023 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.6888 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 36/100\n",
            "1/5 [=====>........................] - ETA: 3s - loss: 0.7253 - accuracy: 0.5000 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 2s - loss: 0.7114 - accuracy: 0.4844 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7179 - accuracy: 0.4688 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7053 - accuracy: 0.5000 - f1_m: 0.3260 - precision_m: 0.7522 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.5069 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563\n",
            "5/5 [==============================] - 4s 799ms/step - loss: 0.6996 - accuracy: 0.5069 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.6890 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 37/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7353 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7212 - accuracy: 0.5156 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7326 - accuracy: 0.5104 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7085 - accuracy: 0.5312 - f1_m: 0.2758 - precision_m: 0.7551 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7133 - accuracy: 0.5278 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938\n",
            "5/5 [==============================] - 3s 493ms/step - loss: 0.7133 - accuracy: 0.5278 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.6890 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 38/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7421 - accuracy: 0.4688 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6902 - accuracy: 0.5312 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7150 - accuracy: 0.5208 - f1_m: 0.2352 - precision_m: 0.7594 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7163 - accuracy: 0.5156 - f1_m: 0.3064 - precision_m: 0.7632 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.5139 - f1_m: 0.3118 - precision_m: 0.7605 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.7193 - accuracy: 0.5139 - f1_m: 0.3118 - precision_m: 0.7605 - recall_m: 0.4750 - val_loss: 0.6891 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 39/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6964 - accuracy: 0.5625 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6762 - accuracy: 0.6094 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7077 - accuracy: 0.5521 - f1_m: 0.3345 - precision_m: 0.7520 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6976 - accuracy: 0.5469 - f1_m: 0.3257 - precision_m: 0.7517 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.5486 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.6972 - accuracy: 0.5486 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563 - val_loss: 0.6891 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 40/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7538 - accuracy: 0.5938 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7621 - accuracy: 0.5312 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7483 - accuracy: 0.5417 - f1_m: 0.3112 - precision_m: 0.7686 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7435 - accuracy: 0.5391 - f1_m: 0.3255 - precision_m: 0.7642 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.5278 - f1_m: 0.3013 - precision_m: 0.7645 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.7483 - accuracy: 0.5278 - f1_m: 0.3013 - precision_m: 0.7645 - recall_m: 0.4625 - val_loss: 0.6890 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 41/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6160 - accuracy: 0.6562 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6917 - accuracy: 0.5625 - f1_m: 0.3900 - precision_m: 0.7583 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6986 - accuracy: 0.5521 - f1_m: 0.3096 - precision_m: 0.7673 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6800 - accuracy: 0.5547 - f1_m: 0.3155 - precision_m: 0.7629 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.5486 - f1_m: 0.3057 - precision_m: 0.7611 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.6892 - accuracy: 0.5486 - f1_m: 0.3057 - precision_m: 0.7611 - recall_m: 0.4688 - val_loss: 0.6891 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 42/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6754 - accuracy: 0.5625 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6752 - accuracy: 0.5625 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7054 - accuracy: 0.5104 - f1_m: 0.2882 - precision_m: 0.7520 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7121 - accuracy: 0.5234 - f1_m: 0.3083 - precision_m: 0.7517 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7128 - accuracy: 0.5208 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7128 - accuracy: 0.5208 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.6891 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 43/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6833 - accuracy: 0.6250 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6934 - accuracy: 0.5469 - f1_m: 0.2904 - precision_m: 0.7642 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7069 - accuracy: 0.5521 - f1_m: 0.2522 - precision_m: 0.7676 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6930 - accuracy: 0.5859 - f1_m: 0.3094 - precision_m: 0.7671 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7054 - accuracy: 0.5833 - f1_m: 0.3142 - precision_m: 0.7637 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.7054 - accuracy: 0.5833 - f1_m: 0.3142 - precision_m: 0.7637 - recall_m: 0.4750 - val_loss: 0.6892 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 44/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7304 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7441 - accuracy: 0.4688 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7426 - accuracy: 0.4792 - f1_m: 0.2495 - precision_m: 0.7630 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7361 - accuracy: 0.4609 - f1_m: 0.2977 - precision_m: 0.7620 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.4792 - f1_m: 0.3192 - precision_m: 0.7604 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.7291 - accuracy: 0.4792 - f1_m: 0.3192 - precision_m: 0.7604 - recall_m: 0.4812 - val_loss: 0.6891 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 45/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6517 - accuracy: 0.5938 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6512 - accuracy: 0.5938 - f1_m: 0.3386 - precision_m: 0.7588 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6747 - accuracy: 0.5938 - f1_m: 0.2843 - precision_m: 0.7640 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6914 - accuracy: 0.5547 - f1_m: 0.3054 - precision_m: 0.7607 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5764 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.6905 - accuracy: 0.5764 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750 - val_loss: 0.6893 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 46/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6975 - accuracy: 0.6562 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6931 - accuracy: 0.5938 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7062 - accuracy: 0.5521 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7025 - accuracy: 0.5625 - f1_m: 0.3086 - precision_m: 0.7522 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6974 - accuracy: 0.5764 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688\n",
            "5/5 [==============================] - 3s 500ms/step - loss: 0.6974 - accuracy: 0.5764 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.6894 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7835 - accuracy: 0.4375 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7671 - accuracy: 0.4844 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7042 - accuracy: 0.5729 - f1_m: 0.3822 - precision_m: 0.7546 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7094 - accuracy: 0.5547 - f1_m: 0.3306 - precision_m: 0.7595 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7166 - accuracy: 0.5417 - f1_m: 0.2943 - precision_m: 0.7646 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.7166 - accuracy: 0.5417 - f1_m: 0.2943 - precision_m: 0.7646 - recall_m: 0.4563 - val_loss: 0.6898 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 48/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.8222 - accuracy: 0.4375 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7545 - accuracy: 0.5469 - f1_m: 0.2460 - precision_m: 0.7744 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7107 - accuracy: 0.5938 - f1_m: 0.2869 - precision_m: 0.7666 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7249 - accuracy: 0.5625 - f1_m: 0.3354 - precision_m: 0.7664 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.5417 - f1_m: 0.2981 - precision_m: 0.7701 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.7304 - accuracy: 0.5417 - f1_m: 0.2981 - precision_m: 0.7701 - recall_m: 0.4563 - val_loss: 0.6901 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 49/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6895 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6779 - accuracy: 0.5781 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6830 - accuracy: 0.5729 - f1_m: 0.3005 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6856 - accuracy: 0.5703 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5764 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.6912 - accuracy: 0.5764 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 50/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6805 - accuracy: 0.6562 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7278 - accuracy: 0.5469 - f1_m: 0.2866 - precision_m: 0.7583 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7322 - accuracy: 0.5104 - f1_m: 0.3022 - precision_m: 0.7555 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7432 - accuracy: 0.4766 - f1_m: 0.3100 - precision_m: 0.7542 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.5069 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.7288 - accuracy: 0.5069 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 51/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7458 - accuracy: 0.4062 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7294 - accuracy: 0.4688 - f1_m: 0.2689 - precision_m: 0.7578 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7243 - accuracy: 0.4792 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7305 - accuracy: 0.4609 - f1_m: 0.2932 - precision_m: 0.7551 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.4722 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7232 - accuracy: 0.4722 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.6900 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 52/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7263 - accuracy: 0.5625 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6885 - accuracy: 0.6406 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6841 - accuracy: 0.6250 - f1_m: 0.2882 - precision_m: 0.7520 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6962 - accuracy: 0.6016 - f1_m: 0.2673 - precision_m: 0.7554 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5903 - f1_m: 0.3424 - precision_m: 0.7668 - recall_m: 0.5000\n",
            "5/5 [==============================] - 2s 490ms/step - loss: 0.6949 - accuracy: 0.5903 - f1_m: 0.3424 - precision_m: 0.7668 - recall_m: 0.5000 - val_loss: 0.6900 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 53/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7530 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7451 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7180 - accuracy: 0.5104 - f1_m: 0.2777 - precision_m: 0.7536 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7145 - accuracy: 0.5000 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.5069 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.7131 - accuracy: 0.5069 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6901 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 54/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7509 - accuracy: 0.5000 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7193 - accuracy: 0.5312 - f1_m: 0.3708 - precision_m: 0.7549 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7039 - accuracy: 0.5417 - f1_m: 0.3583 - precision_m: 0.7533 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7115 - accuracy: 0.5234 - f1_m: 0.3274 - precision_m: 0.7546 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7094 - accuracy: 0.5208 - f1_m: 0.2917 - precision_m: 0.7607 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.7094 - accuracy: 0.5208 - f1_m: 0.2917 - precision_m: 0.7607 - recall_m: 0.4563 - val_loss: 0.6903 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 55/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6162 - accuracy: 0.6562 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6420 - accuracy: 0.5625 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6610 - accuracy: 0.5625 - f1_m: 0.3125 - precision_m: 0.7539 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6608 - accuracy: 0.5781 - f1_m: 0.2855 - precision_m: 0.7568 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6719 - accuracy: 0.5625 - f1_m: 0.3246 - precision_m: 0.7586 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 496ms/step - loss: 0.6719 - accuracy: 0.5625 - f1_m: 0.3246 - precision_m: 0.7586 - recall_m: 0.4875 - val_loss: 0.6901 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 56/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6647 - accuracy: 0.6250 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7003 - accuracy: 0.5625 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7137 - accuracy: 0.5417 - f1_m: 0.2452 - precision_m: 0.7572 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7139 - accuracy: 0.5156 - f1_m: 0.3041 - precision_m: 0.7593 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.5347 - f1_m: 0.3100 - precision_m: 0.7574 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.7090 - accuracy: 0.5347 - f1_m: 0.3100 - precision_m: 0.7574 - recall_m: 0.4750 - val_loss: 0.6899 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 57/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7173 - accuracy: 0.5000 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6665 - accuracy: 0.5625 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6758 - accuracy: 0.5833 - f1_m: 0.3458 - precision_m: 0.7516 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6709 - accuracy: 0.5781 - f1_m: 0.3342 - precision_m: 0.7515 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.5833 - f1_m: 0.2873 - precision_m: 0.7637 - recall_m: 0.4500\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.6662 - accuracy: 0.5833 - f1_m: 0.2873 - precision_m: 0.7637 - recall_m: 0.4500 - val_loss: 0.6901 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 58/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6513 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6771 - accuracy: 0.6250 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6802 - accuracy: 0.5833 - f1_m: 0.3588 - precision_m: 0.7539 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7053 - accuracy: 0.5625 - f1_m: 0.3130 - precision_m: 0.7590 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.5556 - f1_m: 0.3037 - precision_m: 0.7580 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.7020 - accuracy: 0.5556 - f1_m: 0.3037 - precision_m: 0.7580 - recall_m: 0.4688 - val_loss: 0.6901 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 59/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6769 - accuracy: 0.5312 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7206 - accuracy: 0.5000 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7136 - accuracy: 0.5208 - f1_m: 0.2781 - precision_m: 0.7542 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7115 - accuracy: 0.5234 - f1_m: 0.3007 - precision_m: 0.7534 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7107 - accuracy: 0.5208 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 494ms/step - loss: 0.7107 - accuracy: 0.5208 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.6901 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 60/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6990 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7074 - accuracy: 0.5781 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6893 - accuracy: 0.5729 - f1_m: 0.2695 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7057 - accuracy: 0.5469 - f1_m: 0.2854 - precision_m: 0.7563 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.5694 - f1_m: 0.3245 - precision_m: 0.7582 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.6960 - accuracy: 0.5694 - f1_m: 0.3245 - precision_m: 0.7582 - recall_m: 0.4875 - val_loss: 0.6894 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 61/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7251 - accuracy: 0.4688 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6978 - accuracy: 0.5000 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6977 - accuracy: 0.4792 - f1_m: 0.3345 - precision_m: 0.7520 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6686 - accuracy: 0.5469 - f1_m: 0.3342 - precision_m: 0.7515 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.5625 - f1_m: 0.2873 - precision_m: 0.7637 - recall_m: 0.4500\n",
            "5/5 [==============================] - 2s 493ms/step - loss: 0.6662 - accuracy: 0.5625 - f1_m: 0.2873 - precision_m: 0.7637 - recall_m: 0.4500 - val_loss: 0.6893 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 62/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7539 - accuracy: 0.5000 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7415 - accuracy: 0.5000 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7127 - accuracy: 0.5521 - f1_m: 0.2676 - precision_m: 0.7559 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7022 - accuracy: 0.5547 - f1_m: 0.2929 - precision_m: 0.7546 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7069 - accuracy: 0.5486 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812\n",
            "5/5 [==============================] - 3s 590ms/step - loss: 0.7069 - accuracy: 0.5486 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.6888 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 63/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 0.7000 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 11s - loss: 0.6821 - accuracy: 0.5469 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 5s - loss: 0.6770 - accuracy: 0.5521 - f1_m: 0.2808 - precision_m: 0.7581 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 2s - loss: 0.6752 - accuracy: 0.5625 - f1_m: 0.3028 - precision_m: 0.7563 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5625 - f1_m: 0.3089 - precision_m: 0.7551 - recall_m: 0.4750\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.6794 - accuracy: 0.5625 - f1_m: 0.3089 - precision_m: 0.7551 - recall_m: 0.4750 - val_loss: 0.6883 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 64/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6581 - accuracy: 0.5312 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6807 - accuracy: 0.5469 - f1_m: 0.3544 - precision_m: 0.7563 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6715 - accuracy: 0.5729 - f1_m: 0.2949 - precision_m: 0.7624 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6668 - accuracy: 0.5938 - f1_m: 0.3133 - precision_m: 0.7595 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.6042 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688\n",
            "5/5 [==============================] - 4s 817ms/step - loss: 0.6667 - accuracy: 0.6042 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 65/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7374 - accuracy: 0.5000 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7416 - accuracy: 0.4688 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7139 - accuracy: 0.5417 - f1_m: 0.2798 - precision_m: 0.7568 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7159 - accuracy: 0.5391 - f1_m: 0.2932 - precision_m: 0.7551 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7084 - accuracy: 0.5486 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.7084 - accuracy: 0.5486 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.6876 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 66/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6076 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6777 - accuracy: 0.5312 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6818 - accuracy: 0.5208 - f1_m: 0.3228 - precision_m: 0.7516 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6884 - accuracy: 0.5078 - f1_m: 0.3086 - precision_m: 0.7522 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.5208 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 496ms/step - loss: 0.6843 - accuracy: 0.5208 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 67/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6514 - accuracy: 0.5625 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6649 - accuracy: 0.5781 - f1_m: 0.2642 - precision_m: 0.7759 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6909 - accuracy: 0.5312 - f1_m: 0.3629 - precision_m: 0.7790 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7154 - accuracy: 0.5078 - f1_m: 0.3233 - precision_m: 0.7756 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7180 - accuracy: 0.4931 - f1_m: 0.3119 - precision_m: 0.7713 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.7180 - accuracy: 0.4931 - f1_m: 0.3119 - precision_m: 0.7713 - recall_m: 0.4688 - val_loss: 0.6880 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 68/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6276 - accuracy: 0.6250 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6915 - accuracy: 0.5625 - f1_m: 0.2505 - precision_m: 0.7563 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6828 - accuracy: 0.5729 - f1_m: 0.2352 - precision_m: 0.7594 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6681 - accuracy: 0.5859 - f1_m: 0.2776 - precision_m: 0.7581 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5556 - f1_m: 0.3342 - precision_m: 0.7635 - recall_m: 0.4938\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.6876 - accuracy: 0.5556 - f1_m: 0.3342 - precision_m: 0.7635 - recall_m: 0.4938 - val_loss: 0.6881 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 69/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7666 - accuracy: 0.4375 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6963 - accuracy: 0.5469 - f1_m: 0.2240 - precision_m: 0.7681 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6843 - accuracy: 0.5625 - f1_m: 0.2604 - precision_m: 0.7620 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6970 - accuracy: 0.5391 - f1_m: 0.2875 - precision_m: 0.7593 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7018 - accuracy: 0.5208 - f1_m: 0.3261 - precision_m: 0.7605 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7018 - accuracy: 0.5208 - f1_m: 0.3261 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 70/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7371 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7641 - accuracy: 0.4531 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7373 - accuracy: 0.4896 - f1_m: 0.3223 - precision_m: 0.7510 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7290 - accuracy: 0.5000 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.5278 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7090 - accuracy: 0.5278 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6873 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 71/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6771 - accuracy: 0.5938 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6624 - accuracy: 0.6250 - f1_m: 0.2769 - precision_m: 0.7695 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6882 - accuracy: 0.5729 - f1_m: 0.2843 - precision_m: 0.7633 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7073 - accuracy: 0.5156 - f1_m: 0.3145 - precision_m: 0.7610 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.5208 - f1_m: 0.3049 - precision_m: 0.7596 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.7076 - accuracy: 0.5208 - f1_m: 0.3049 - precision_m: 0.7596 - recall_m: 0.4688 - val_loss: 0.6863 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 72/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6700 - accuracy: 0.5938 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7405 - accuracy: 0.4844 - f1_m: 0.3735 - precision_m: 0.7598 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7148 - accuracy: 0.5104 - f1_m: 0.2902 - precision_m: 0.7725 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7209 - accuracy: 0.5078 - f1_m: 0.2924 - precision_m: 0.7671 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7067 - accuracy: 0.5208 - f1_m: 0.3301 - precision_m: 0.7668 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.7067 - accuracy: 0.5208 - f1_m: 0.3301 - precision_m: 0.7668 - recall_m: 0.4875 - val_loss: 0.6858 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 73/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6876 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7078 - accuracy: 0.5625 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6882 - accuracy: 0.5625 - f1_m: 0.2882 - precision_m: 0.7520 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6825 - accuracy: 0.5938 - f1_m: 0.2995 - precision_m: 0.7515 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.5694 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.6902 - accuracy: 0.5694 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.6847 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 74/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7195 - accuracy: 0.5312 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 2s - loss: 0.7126 - accuracy: 0.5469 - f1_m: 0.3091 - precision_m: 0.7666 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6836 - accuracy: 0.5729 - f1_m: 0.3058 - precision_m: 0.7614 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6950 - accuracy: 0.5391 - f1_m: 0.3127 - precision_m: 0.7585 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5556 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688\n",
            "5/5 [==============================] - 4s 840ms/step - loss: 0.6921 - accuracy: 0.5556 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.6836 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 75/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7014 - accuracy: 0.6250 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7299 - accuracy: 0.5625 - f1_m: 0.2587 - precision_m: 0.7681 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7234 - accuracy: 0.5625 - f1_m: 0.3075 - precision_m: 0.7633 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7016 - accuracy: 0.5938 - f1_m: 0.2972 - precision_m: 0.7610 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5903 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.6922 - accuracy: 0.5903 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812 - val_loss: 0.6831 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 76/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7066 - accuracy: 0.5625 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6716 - accuracy: 0.6094 - f1_m: 0.2904 - precision_m: 0.7642 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6519 - accuracy: 0.5938 - f1_m: 0.2934 - precision_m: 0.7598 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6648 - accuracy: 0.5781 - f1_m: 0.3402 - precision_m: 0.7612 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6820 - accuracy: 0.5694 - f1_m: 0.2922 - precision_m: 0.7715 - recall_m: 0.4500\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.6820 - accuracy: 0.5694 - f1_m: 0.2922 - precision_m: 0.7715 - recall_m: 0.4500 - val_loss: 0.6828 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 77/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6589 - accuracy: 0.6250 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6789 - accuracy: 0.5469 - f1_m: 0.2587 - precision_m: 0.7681 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7100 - accuracy: 0.5104 - f1_m: 0.2722 - precision_m: 0.7624 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6977 - accuracy: 0.5000 - f1_m: 0.2875 - precision_m: 0.7593 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.4931 - f1_m: 0.3261 - precision_m: 0.7605 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.7075 - accuracy: 0.4931 - f1_m: 0.3261 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.6823 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 78/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6756 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7282 - accuracy: 0.5000 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7145 - accuracy: 0.5417 - f1_m: 0.3752 - precision_m: 0.7633 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7187 - accuracy: 0.5156 - f1_m: 0.3186 - precision_m: 0.7688 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.5069 - f1_m: 0.3082 - precision_m: 0.7658 - recall_m: 0.4688\n",
            "5/5 [==============================] - 2s 493ms/step - loss: 0.7203 - accuracy: 0.5069 - f1_m: 0.3082 - precision_m: 0.7658 - recall_m: 0.4688 - val_loss: 0.6810 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 79/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7808 - accuracy: 0.3438 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7405 - accuracy: 0.4688 - f1_m: 0.2375 - precision_m: 0.7627 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7027 - accuracy: 0.5104 - f1_m: 0.2695 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6851 - accuracy: 0.5625 - f1_m: 0.2943 - precision_m: 0.7566 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6851 - accuracy: 0.5694 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.6851 - accuracy: 0.5694 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6798 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 80/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6141 - accuracy: 0.5312 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6908 - accuracy: 0.5312 - f1_m: 0.3735 - precision_m: 0.7598 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6789 - accuracy: 0.5417 - f1_m: 0.3488 - precision_m: 0.7568 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6874 - accuracy: 0.5391 - f1_m: 0.3055 - precision_m: 0.7612 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5208 - f1_m: 0.3111 - precision_m: 0.7590 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.6895 - accuracy: 0.5208 - f1_m: 0.3111 - precision_m: 0.7590 - recall_m: 0.4750 - val_loss: 0.6785 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 81/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6885 - accuracy: 0.5000 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7026 - accuracy: 0.5156 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7134 - accuracy: 0.5104 - f1_m: 0.2824 - precision_m: 0.7607 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7143 - accuracy: 0.5234 - f1_m: 0.3039 - precision_m: 0.7583 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7180 - accuracy: 0.5208 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750\n",
            "5/5 [==============================] - 2s 475ms/step - loss: 0.7180 - accuracy: 0.5208 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 0.6773 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 82/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7033 - accuracy: 0.4062 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6894 - accuracy: 0.4688 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6730 - accuracy: 0.5104 - f1_m: 0.3143 - precision_m: 0.7565 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6876 - accuracy: 0.5078 - f1_m: 0.3191 - precision_m: 0.7549 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5000 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.6939 - accuracy: 0.5000 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.6760 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 83/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7190 - accuracy: 0.4688 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7093 - accuracy: 0.4688 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7255 - accuracy: 0.4688 - f1_m: 0.3811 - precision_m: 0.7526 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7309 - accuracy: 0.4844 - f1_m: 0.3230 - precision_m: 0.7607 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.5000 - f1_m: 0.2993 - precision_m: 0.7617 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.7261 - accuracy: 0.5000 - f1_m: 0.2993 - precision_m: 0.7617 - recall_m: 0.4625 - val_loss: 0.6751 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 84/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6804 - accuracy: 0.5312 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7176 - accuracy: 0.4844 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7193 - accuracy: 0.4896 - f1_m: 0.3473 - precision_m: 0.7542 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7227 - accuracy: 0.4922 - f1_m: 0.3192 - precision_m: 0.7554 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.4861 - f1_m: 0.2963 - precision_m: 0.7574 - recall_m: 0.4625\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.7232 - accuracy: 0.4861 - f1_m: 0.2963 - precision_m: 0.7574 - recall_m: 0.4625 - val_loss: 0.6737 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 85/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7010 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6922 - accuracy: 0.5000 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6927 - accuracy: 0.5208 - f1_m: 0.2882 - precision_m: 0.7520 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6903 - accuracy: 0.5234 - f1_m: 0.3083 - precision_m: 0.7517 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5347 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688\n",
            "5/5 [==============================] - 3s 586ms/step - loss: 0.6920 - accuracy: 0.5347 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.6725 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 86/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6890 - accuracy: 0.5312 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6942 - accuracy: 0.5156 - f1_m: 0.4247 - precision_m: 0.7583 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7085 - accuracy: 0.5312 - f1_m: 0.3614 - precision_m: 0.7585 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7129 - accuracy: 0.5156 - f1_m: 0.3222 - precision_m: 0.7603 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.4861 - f1_m: 0.2986 - precision_m: 0.7613 - recall_m: 0.4625\n",
            "5/5 [==============================] - 3s 493ms/step - loss: 0.7217 - accuracy: 0.4861 - f1_m: 0.2986 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 0.6712 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 87/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7609 - accuracy: 0.4375 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7192 - accuracy: 0.5312 - f1_m: 0.4812 - precision_m: 0.7666 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7109 - accuracy: 0.5521 - f1_m: 0.3620 - precision_m: 0.7770 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7075 - accuracy: 0.5312 - f1_m: 0.3302 - precision_m: 0.7725 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.5347 - f1_m: 0.3050 - precision_m: 0.7711 - recall_m: 0.4625\n",
            "5/5 [==============================] - 3s 718ms/step - loss: 0.6999 - accuracy: 0.5347 - f1_m: 0.3050 - precision_m: 0.7711 - recall_m: 0.4625 - val_loss: 0.6702 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 88/100\n",
            "1/5 [=====>........................] - ETA: 3s - loss: 0.6278 - accuracy: 0.5938 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 2s - loss: 0.6957 - accuracy: 0.5000 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6738 - accuracy: 0.5729 - f1_m: 0.3008 - precision_m: 0.7536 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6796 - accuracy: 0.5703 - f1_m: 0.3178 - precision_m: 0.7529 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.5694 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625\n",
            "5/5 [==============================] - 4s 781ms/step - loss: 0.6807 - accuracy: 0.5694 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625 - val_loss: 0.6690 - val_accuracy: 0.5135 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 89/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.6556 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6560 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6680 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6809 - accuracy: 0.5781 - f1_m: 0.2831 - precision_m: 0.7529 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6849 - accuracy: 0.5625 - f1_m: 0.3226 - precision_m: 0.7555 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 499ms/step - loss: 0.6849 - accuracy: 0.5625 - f1_m: 0.3226 - precision_m: 0.7555 - recall_m: 0.4875 - val_loss: 0.6683 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 90/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.7883 - accuracy: 0.4062 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7709 - accuracy: 0.4531 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7602 - accuracy: 0.4375 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7389 - accuracy: 0.4688 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.4931 - f1_m: 0.3233 - precision_m: 0.7566 - recall_m: 0.4875\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.7294 - accuracy: 0.4931 - f1_m: 0.3233 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.6668 - val_accuracy: 0.5405 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 91/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6767 - accuracy: 0.4375 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6648 - accuracy: 0.5000 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6589 - accuracy: 0.5521 - f1_m: 0.2471 - precision_m: 0.7598 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6721 - accuracy: 0.5469 - f1_m: 0.2687 - precision_m: 0.7573 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6770 - accuracy: 0.5417 - f1_m: 0.3435 - precision_m: 0.7684 - recall_m: 0.5000\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.6770 - accuracy: 0.5417 - f1_m: 0.3435 - precision_m: 0.7684 - recall_m: 0.5000 - val_loss: 0.6661 - val_accuracy: 0.5676 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 92/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7344 - accuracy: 0.4688 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7445 - accuracy: 0.4688 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7325 - accuracy: 0.5000 - f1_m: 0.3458 - precision_m: 0.7516 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7235 - accuracy: 0.5469 - f1_m: 0.3260 - precision_m: 0.7522 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7132 - accuracy: 0.5625 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 483ms/step - loss: 0.7132 - accuracy: 0.5625 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.6655 - val_accuracy: 0.5946 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 93/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7365 - accuracy: 0.4688 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7183 - accuracy: 0.5156 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7002 - accuracy: 0.5625 - f1_m: 0.3473 - precision_m: 0.7542 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6899 - accuracy: 0.5703 - f1_m: 0.3271 - precision_m: 0.7542 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5625 - f1_m: 0.2914 - precision_m: 0.7604 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 491ms/step - loss: 0.6922 - accuracy: 0.5625 - f1_m: 0.2914 - precision_m: 0.7604 - recall_m: 0.4563 - val_loss: 0.6648 - val_accuracy: 0.6216 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 94/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6759 - accuracy: 0.5938 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7150 - accuracy: 0.5625 - f1_m: 0.3932 - precision_m: 0.7642 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6853 - accuracy: 0.6042 - f1_m: 0.3303 - precision_m: 0.7646 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6909 - accuracy: 0.5859 - f1_m: 0.2849 - precision_m: 0.7698 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6793 - accuracy: 0.6042 - f1_m: 0.3400 - precision_m: 0.7729 - recall_m: 0.4938\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.6793 - accuracy: 0.6042 - f1_m: 0.3400 - precision_m: 0.7729 - recall_m: 0.4938 - val_loss: 0.6642 - val_accuracy: 0.5946 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 95/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.5875 - accuracy: 0.6562 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6581 - accuracy: 0.5938 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6789 - accuracy: 0.5417 - f1_m: 0.3122 - precision_m: 0.7533 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6921 - accuracy: 0.5234 - f1_m: 0.3263 - precision_m: 0.7527 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.5139 - f1_m: 0.2908 - precision_m: 0.7592 - recall_m: 0.4563\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.6904 - accuracy: 0.5139 - f1_m: 0.2908 - precision_m: 0.7592 - recall_m: 0.4563 - val_loss: 0.6634 - val_accuracy: 0.5946 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 96/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6999 - accuracy: 0.5625 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7155 - accuracy: 0.5469 - f1_m: 0.2904 - precision_m: 0.7642 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.7217 - accuracy: 0.5208 - f1_m: 0.3411 - precision_m: 0.7624 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7227 - accuracy: 0.5078 - f1_m: 0.3070 - precision_m: 0.7632 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7241 - accuracy: 0.5069 - f1_m: 0.3122 - precision_m: 0.7605 - recall_m: 0.4750\n",
            "5/5 [==============================] - 3s 497ms/step - loss: 0.7241 - accuracy: 0.5069 - f1_m: 0.3122 - precision_m: 0.7605 - recall_m: 0.4750 - val_loss: 0.6624 - val_accuracy: 0.7027 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 97/100\n",
            "1/5 [=====>........................] - ETA: 1s - loss: 0.7041 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6810 - accuracy: 0.6562 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6903 - accuracy: 0.6146 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7152 - accuracy: 0.5703 - f1_m: 0.2919 - precision_m: 0.7532 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.5625 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 492ms/step - loss: 0.7216 - accuracy: 0.5625 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.6614 - val_accuracy: 0.7027 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 98/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6671 - accuracy: 0.5938 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.7031 - accuracy: 0.5312 - f1_m: 0.2769 - precision_m: 0.7695 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6848 - accuracy: 0.5417 - f1_m: 0.2734 - precision_m: 0.7643 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6888 - accuracy: 0.5781 - f1_m: 0.2972 - precision_m: 0.7610 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5625 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.6917 - accuracy: 0.5625 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812 - val_loss: 0.6610 - val_accuracy: 0.7027 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 99/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6276 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6466 - accuracy: 0.6094 - f1_m: 0.2587 - precision_m: 0.7681 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.6983 - accuracy: 0.5417 - f1_m: 0.2722 - precision_m: 0.7624 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6839 - accuracy: 0.5547 - f1_m: 0.3148 - precision_m: 0.7615 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6786 - accuracy: 0.5694 - f1_m: 0.3051 - precision_m: 0.7600 - recall_m: 0.4688\n",
            "5/5 [==============================] - 3s 497ms/step - loss: 0.6786 - accuracy: 0.5694 - f1_m: 0.3051 - precision_m: 0.7600 - recall_m: 0.4688 - val_loss: 0.6609 - val_accuracy: 0.7027 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8236)\u001b[0m Epoch 100/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 0.6793 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 1s - loss: 0.6650 - accuracy: 0.6250 - f1_m: 0.3544 - precision_m: 0.7563 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6782 - accuracy: 0.6146 - f1_m: 0.3145 - precision_m: 0.7572 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6953 - accuracy: 0.5859 - f1_m: 0.2945 - precision_m: 0.7576 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6897 - accuracy: 0.5833 - f1_m: 0.3166 - precision_m: 0.7568 - recall_m: 0.4812\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.6897 - accuracy: 0.5833 - f1_m: 0.3166 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.6608 - val_accuracy: 0.7027 - val_f1_m: 0.4729 - val_precision_m: 0.7994 - val_recall_m: 0.6031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m 2022-11-21 16:32:09.709510: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/activation_2/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  conv1d (Conv1D)             (None, 43886, 8)          72        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  batch_normalization (BatchN  (None, 43886, 8)         32        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  activation (Activation)     (None, 43886, 8)          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  conv1d_1 (Conv1D)           (None, 43886, 64)         576       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  dropout (Dropout)           (None, 43886, 64)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  batch_normalization_1 (Batc  (None, 43886, 64)        256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  activation_1 (Activation)   (None, 43886, 64)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  conv1d_2 (Conv1D)           (None, 43886, 2)          130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  dropout_1 (Dropout)         (None, 43886, 2)          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  batch_normalization_2 (Batc  (None, 43886, 2)         8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Total params: 1,077\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Trainable params: 929\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Non-trainable params: 148\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Total number of layers: 13\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f41c0d32050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f41c0d32050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f41c0d32050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f41c0d32050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f41c0d39830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f41c0d39830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f41c0d39830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f41c0d39830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f416664c710> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f416664c710>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f416664c710> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f416664c710>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 0.6909 - accuracy: 0.5938 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6981 - accuracy: 0.4219 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6988 - accuracy: 0.3958 - f1_m: 0.3244 - precision_m: 0.7542 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6975 - accuracy: 0.4297 - f1_m: 0.2944 - precision_m: 0.7571 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.4583 - f1_m: 0.3165 - precision_m: 0.7564 - recall_m: 0.4812\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6958 - accuracy: 0.4583 - f1_m: 0.3165 - precision_m: 0.7564 - recall_m: 0.4812 - val_loss: 0.6952 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 2/100\n",
            "1/5 [=====>........................] - ETA: 18s - loss: 0.6928 - accuracy: 0.5625 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6901 - accuracy: 0.5625 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6937 - accuracy: 0.5208 - f1_m: 0.2410 - precision_m: 0.7673 - recall_m: 0.4062 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6920 - accuracy: 0.5391 - f1_m: 0.2729 - precision_m: 0.7632 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.5486 - f1_m: 0.3469 - precision_m: 0.7730 - recall_m: 0.5000\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6899 - accuracy: 0.5486 - f1_m: 0.3469 - precision_m: 0.7730 - recall_m: 0.5000 - val_loss: 0.6947 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 3/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6818 - accuracy: 0.5312 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6835 - accuracy: 0.5469 - f1_m: 0.2689 - precision_m: 0.7578 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6877 - accuracy: 0.5417 - f1_m: 0.2904 - precision_m: 0.7552 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6854 - accuracy: 0.5547 - f1_m: 0.3191 - precision_m: 0.7549 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.5556 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6840 - accuracy: 0.5556 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.6940 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 4/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6854 - accuracy: 0.5625 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6829 - accuracy: 0.5938 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6848 - accuracy: 0.5833 - f1_m: 0.2781 - precision_m: 0.7542 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6812 - accuracy: 0.6172 - f1_m: 0.2919 - precision_m: 0.7532 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.6250 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6798 - accuracy: 0.6250 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.6932 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 5/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6736 - accuracy: 0.6562 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.6802 - accuracy: 0.6719 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6902 - accuracy: 0.5729 - f1_m: 0.3172 - precision_m: 0.7617 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6766 - accuracy: 0.6172 - f1_m: 0.2966 - precision_m: 0.7610 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.6250 - f1_m: 0.3183 - precision_m: 0.7596 - recall_m: 0.4812\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6767 - accuracy: 0.6250 - f1_m: 0.3183 - precision_m: 0.7596 - recall_m: 0.4812 - val_loss: 0.6923 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 6/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.7009 - accuracy: 0.5312 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6831 - accuracy: 0.5625 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6767 - accuracy: 0.6146 - f1_m: 0.3130 - precision_m: 0.7546 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6756 - accuracy: 0.6250 - f1_m: 0.3095 - precision_m: 0.7537 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6751 - accuracy: 0.6181 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6751 - accuracy: 0.6181 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.6913 - val_accuracy: 0.6216 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6685 - accuracy: 0.7188 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6628 - accuracy: 0.7188 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6707 - accuracy: 0.6771 - f1_m: 0.2781 - precision_m: 0.7542 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6744 - accuracy: 0.6484 - f1_m: 0.2673 - precision_m: 0.7554 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.6458 - f1_m: 0.3424 - precision_m: 0.7668 - recall_m: 0.5000\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6739 - accuracy: 0.6458 - f1_m: 0.3424 - precision_m: 0.7668 - recall_m: 0.5000 - val_loss: 0.6905 - val_accuracy: 0.6216 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 8/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6798 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6784 - accuracy: 0.5781 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6714 - accuracy: 0.6146 - f1_m: 0.3223 - precision_m: 0.7510 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 0.6710 - accuracy: 0.6406 - f1_m: 0.3251 - precision_m: 0.7507 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6722 - accuracy: 0.6319 - f1_m: 0.2898 - precision_m: 0.7576 - recall_m: 0.4563\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6722 - accuracy: 0.6319 - f1_m: 0.2898 - precision_m: 0.7576 - recall_m: 0.4563 - val_loss: 0.6899 - val_accuracy: 0.5946 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 9/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6632 - accuracy: 0.6562 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6687 - accuracy: 0.6562 - f1_m: 0.2375 - precision_m: 0.7627 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6768 - accuracy: 0.6042 - f1_m: 0.3058 - precision_m: 0.7614 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6682 - accuracy: 0.6562 - f1_m: 0.3215 - precision_m: 0.7588 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.6319 - f1_m: 0.2981 - precision_m: 0.7602 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6712 - accuracy: 0.6319 - f1_m: 0.2981 - precision_m: 0.7602 - recall_m: 0.4625 - val_loss: 0.6892 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 10/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6660 - accuracy: 0.6875 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6664 - accuracy: 0.7031 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6688 - accuracy: 0.6458 - f1_m: 0.3005 - precision_m: 0.7529 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6699 - accuracy: 0.6328 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.6319 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6710 - accuracy: 0.6319 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.6887 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 11/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6727 - accuracy: 0.6875 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6633 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6665 - accuracy: 0.6875 - f1_m: 0.2581 - precision_m: 0.7588 - recall_m: 0.4271 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6674 - accuracy: 0.6641 - f1_m: 0.3042 - precision_m: 0.7588 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.6597 - f1_m: 0.3100 - precision_m: 0.7570 - recall_m: 0.4750\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6688 - accuracy: 0.6597 - f1_m: 0.3100 - precision_m: 0.7570 - recall_m: 0.4750 - val_loss: 0.6882 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 12/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6927 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6818 - accuracy: 0.6094 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6675 - accuracy: 0.6771 - f1_m: 0.2812 - precision_m: 0.7588 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6643 - accuracy: 0.6797 - f1_m: 0.2696 - precision_m: 0.7588 - recall_m: 0.4375\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.6597 - f1_m: 0.3443 - precision_m: 0.7695 - recall_m: 0.5000\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6696 - accuracy: 0.6597 - f1_m: 0.3443 - precision_m: 0.7695 - recall_m: 0.5000 - val_loss: 0.6879 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 13/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6607 - accuracy: 0.7188 - f1_m: 0.5602 - precision_m: 0.7852 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6609 - accuracy: 0.7031 - f1_m: 0.4132 - precision_m: 0.7695 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6663 - accuracy: 0.6667 - f1_m: 0.3752 - precision_m: 0.7633 - recall_m: 0.5312 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6695 - accuracy: 0.6406 - f1_m: 0.3254 - precision_m: 0.7661 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.6319 - f1_m: 0.3012 - precision_m: 0.7660 - recall_m: 0.4625\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.6694 - accuracy: 0.6319 - f1_m: 0.3012 - precision_m: 0.7660 - recall_m: 0.4625 - val_loss: 0.6878 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 14/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6715 - accuracy: 0.5938 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6683 - accuracy: 0.5938 - f1_m: 0.2904 - precision_m: 0.7642 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6638 - accuracy: 0.6354 - f1_m: 0.2934 - precision_m: 0.7598 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6670 - accuracy: 0.6484 - f1_m: 0.3122 - precision_m: 0.7576 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.6250 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "5/5 [==============================] - 21s 4s/step - loss: 0.6674 - accuracy: 0.6250 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 15/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 0.6622 - accuracy: 0.6875 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6703 - accuracy: 0.6562 - f1_m: 0.2689 - precision_m: 0.7578 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6734 - accuracy: 0.6250 - f1_m: 0.2904 - precision_m: 0.7552 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6659 - accuracy: 0.6484 - f1_m: 0.3011 - precision_m: 0.7539 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.6528 - f1_m: 0.3076 - precision_m: 0.7531 - recall_m: 0.4750\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6666 - accuracy: 0.6528 - f1_m: 0.3076 - precision_m: 0.7531 - recall_m: 0.4750 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 16/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6438 - accuracy: 0.7188 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6640 - accuracy: 0.5938 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6635 - accuracy: 0.6562 - f1_m: 0.3223 - precision_m: 0.7510 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6690 - accuracy: 0.6641 - f1_m: 0.3166 - precision_m: 0.7510 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.6875 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6654 - accuracy: 0.6875 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625 - val_loss: 0.6877 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 17/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6787 - accuracy: 0.6250 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6835 - accuracy: 0.5938 - f1_m: 0.3091 - precision_m: 0.7666 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6727 - accuracy: 0.6042 - f1_m: 0.2743 - precision_m: 0.7663 - recall_m: 0.4375 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6676 - accuracy: 0.6328 - f1_m: 0.3163 - precision_m: 0.7644 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.6389 - f1_m: 0.3063 - precision_m: 0.7623 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6671 - accuracy: 0.6389 - f1_m: 0.3063 - precision_m: 0.7623 - recall_m: 0.4688 - val_loss: 0.6878 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 18/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6592 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.6488 - accuracy: 0.7344 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 11s - loss: 0.6604 - accuracy: 0.7083 - f1_m: 0.2891 - precision_m: 0.7533 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 0.6672 - accuracy: 0.6719 - f1_m: 0.2916 - precision_m: 0.7527 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6649 - accuracy: 0.6667 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.6649 - accuracy: 0.6667 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812 - val_loss: 0.6880 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 19/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6761 - accuracy: 0.5312 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6674 - accuracy: 0.6094 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6708 - accuracy: 0.5833 - f1_m: 0.3110 - precision_m: 0.7513 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6651 - accuracy: 0.6172 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.6181 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6648 - accuracy: 0.6181 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.6882 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 20/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6604 - accuracy: 0.5625 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6469 - accuracy: 0.6719 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6522 - accuracy: 0.6562 - f1_m: 0.3290 - precision_m: 0.7614 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6569 - accuracy: 0.6641 - f1_m: 0.3054 - precision_m: 0.7607 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.6389 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6645 - accuracy: 0.6389 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750 - val_loss: 0.6885 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 21/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.7129 - accuracy: 0.4375 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6791 - accuracy: 0.5625 - f1_m: 0.4247 - precision_m: 0.7583 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6711 - accuracy: 0.5938 - f1_m: 0.3243 - precision_m: 0.7715 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 0.6674 - accuracy: 0.6016 - f1_m: 0.3098 - precision_m: 0.7671 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.6250 - f1_m: 0.3145 - precision_m: 0.7637 - recall_m: 0.4750\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6645 - accuracy: 0.6250 - f1_m: 0.3145 - precision_m: 0.7637 - recall_m: 0.4750 - val_loss: 0.6889 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 22/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6607 - accuracy: 0.6562 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6653 - accuracy: 0.6562 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6685 - accuracy: 0.6458 - f1_m: 0.2480 - precision_m: 0.7611 - recall_m: 0.4167 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6629 - accuracy: 0.6641 - f1_m: 0.3160 - precision_m: 0.7644 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.6528 - f1_m: 0.3061 - precision_m: 0.7623 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6620 - accuracy: 0.6528 - f1_m: 0.3061 - precision_m: 0.7623 - recall_m: 0.4688 - val_loss: 0.6892 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 23/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6676 - accuracy: 0.5938 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6760 - accuracy: 0.5938 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6712 - accuracy: 0.6250 - f1_m: 0.2824 - precision_m: 0.7607 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6628 - accuracy: 0.6484 - f1_m: 0.3039 - precision_m: 0.7583 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6655 - accuracy: 0.6458 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6655 - accuracy: 0.6458 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 0.6895 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 24/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6670 - accuracy: 0.5625 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6640 - accuracy: 0.5938 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6585 - accuracy: 0.6354 - f1_m: 0.2798 - precision_m: 0.7568 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6585 - accuracy: 0.6328 - f1_m: 0.2847 - precision_m: 0.7554 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.6319 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6629 - accuracy: 0.6319 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875 - val_loss: 0.6897 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 25/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6654 - accuracy: 0.6562 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6659 - accuracy: 0.6406 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6648 - accuracy: 0.6146 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6592 - accuracy: 0.6562 - f1_m: 0.3102 - precision_m: 0.7546 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.6528 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6617 - accuracy: 0.6528 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688 - val_loss: 0.6899 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 26/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6659 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6531 - accuracy: 0.6562 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6598 - accuracy: 0.6458 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6627 - accuracy: 0.6562 - f1_m: 0.2844 - precision_m: 0.7549 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.6458 - f1_m: 0.3237 - precision_m: 0.7570 - recall_m: 0.4875\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6619 - accuracy: 0.6458 - f1_m: 0.3237 - precision_m: 0.7570 - recall_m: 0.4875 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 27/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.7073 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6834 - accuracy: 0.5781 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6745 - accuracy: 0.5938 - f1_m: 0.3345 - precision_m: 0.7520 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6658 - accuracy: 0.6094 - f1_m: 0.3020 - precision_m: 0.7554 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.6319 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6611 - accuracy: 0.6319 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.6903 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 28/100\n",
            "1/5 [=====>........................] - ETA: 21s - loss: 0.6862 - accuracy: 0.5000 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 16s - loss: 0.6795 - accuracy: 0.5781 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 9s - loss: 0.6701 - accuracy: 0.6146 - f1_m: 0.3008 - precision_m: 0.7536 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6677 - accuracy: 0.6250 - f1_m: 0.3269 - precision_m: 0.7537 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.6528 - f1_m: 0.2913 - precision_m: 0.7600 - recall_m: 0.4563\n",
            "5/5 [==============================] - 23s 4s/step - loss: 0.6620 - accuracy: 0.6528 - f1_m: 0.2913 - precision_m: 0.7600 - recall_m: 0.4563 - val_loss: 0.6903 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 29/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6544 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6602 - accuracy: 0.6719 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6595 - accuracy: 0.6667 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6633 - accuracy: 0.6641 - f1_m: 0.2929 - precision_m: 0.7546 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6618 - accuracy: 0.6528 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6618 - accuracy: 0.6528 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 30/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6158 - accuracy: 0.7812 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6465 - accuracy: 0.6875 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6641 - accuracy: 0.6458 - f1_m: 0.2597 - precision_m: 0.7614 - recall_m: 0.4271 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6663 - accuracy: 0.6328 - f1_m: 0.3248 - precision_m: 0.7646 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6630 - accuracy: 0.6250 - f1_m: 0.3008 - precision_m: 0.7648 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6630 - accuracy: 0.6250 - f1_m: 0.3008 - precision_m: 0.7648 - recall_m: 0.4625 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 31/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6559 - accuracy: 0.6562 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6524 - accuracy: 0.7031 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 9s - loss: 0.6571 - accuracy: 0.6667 - f1_m: 0.3244 - precision_m: 0.7542 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6573 - accuracy: 0.6641 - f1_m: 0.3181 - precision_m: 0.7534 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.6597 - f1_m: 0.2954 - precision_m: 0.7559 - recall_m: 0.4625\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6583 - accuracy: 0.6597 - f1_m: 0.2954 - precision_m: 0.7559 - recall_m: 0.4625 - val_loss: 0.6903 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 32/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6367 - accuracy: 0.7500 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6592 - accuracy: 0.6719 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6583 - accuracy: 0.6771 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6552 - accuracy: 0.6641 - f1_m: 0.2932 - precision_m: 0.7551 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6579 - accuracy: 0.6528 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6579 - accuracy: 0.6528 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.6905 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 33/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6860 - accuracy: 0.5312 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6622 - accuracy: 0.6562 - f1_m: 0.2053 - precision_m: 0.7666 - recall_m: 0.3750\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6771 - accuracy: 0.6146 - f1_m: 0.2843 - precision_m: 0.7640 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6636 - accuracy: 0.6406 - f1_m: 0.2798 - precision_m: 0.7615 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6638 - accuracy: 0.6389 - f1_m: 0.3359 - precision_m: 0.7662 - recall_m: 0.4938\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6638 - accuracy: 0.6389 - f1_m: 0.3359 - precision_m: 0.7662 - recall_m: 0.4938 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 34/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.7110 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6836 - accuracy: 0.6250 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6742 - accuracy: 0.6250 - f1_m: 0.2957 - precision_m: 0.7630 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6654 - accuracy: 0.6406 - f1_m: 0.3139 - precision_m: 0.7600 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.6458 - f1_m: 0.3044 - precision_m: 0.7588 - recall_m: 0.4688\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6610 - accuracy: 0.6458 - f1_m: 0.3044 - precision_m: 0.7588 - recall_m: 0.4688 - val_loss: 0.6911 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 35/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6505 - accuracy: 0.6875 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6694 - accuracy: 0.6250 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6616 - accuracy: 0.6458 - f1_m: 0.3106 - precision_m: 0.7507 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6571 - accuracy: 0.6719 - f1_m: 0.3077 - precision_m: 0.7507 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.6736 - f1_m: 0.2994 - precision_m: 0.7514 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6571 - accuracy: 0.6736 - f1_m: 0.2994 - precision_m: 0.7514 - recall_m: 0.4688 - val_loss: 0.6914 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 36/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6524 - accuracy: 0.6562 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6589 - accuracy: 0.6406 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6613 - accuracy: 0.6354 - f1_m: 0.3143 - precision_m: 0.7565 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6540 - accuracy: 0.6484 - f1_m: 0.3279 - precision_m: 0.7551 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.6458 - f1_m: 0.2921 - precision_m: 0.7611 - recall_m: 0.4563\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6576 - accuracy: 0.6458 - f1_m: 0.2921 - precision_m: 0.7611 - recall_m: 0.4563 - val_loss: 0.6917 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 37/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6354 - accuracy: 0.7500 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6694 - accuracy: 0.6406 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6680 - accuracy: 0.6354 - f1_m: 0.3583 - precision_m: 0.7533 - recall_m: 0.5208 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6588 - accuracy: 0.6406 - f1_m: 0.3059 - precision_m: 0.7612 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.6528 - f1_m: 0.3114 - precision_m: 0.7590 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6575 - accuracy: 0.6528 - f1_m: 0.3114 - precision_m: 0.7590 - recall_m: 0.4750 - val_loss: 0.6924 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 38/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.6949 - accuracy: 0.5938 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 13s - loss: 0.6801 - accuracy: 0.6094 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6677 - accuracy: 0.6250 - f1_m: 0.2926 - precision_m: 0.7585 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6670 - accuracy: 0.6172 - f1_m: 0.3301 - precision_m: 0.7585 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.6389 - f1_m: 0.2938 - precision_m: 0.7639 - recall_m: 0.4563\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6604 - accuracy: 0.6389 - f1_m: 0.2938 - precision_m: 0.7639 - recall_m: 0.4563 - val_loss: 0.6932 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 39/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6467 - accuracy: 0.5938 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6467 - accuracy: 0.6250 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6480 - accuracy: 0.6354 - f1_m: 0.3345 - precision_m: 0.7520 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6580 - accuracy: 0.6016 - f1_m: 0.3257 - precision_m: 0.7517 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.6181 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6561 - accuracy: 0.6181 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563 - val_loss: 0.6948 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 40/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6691 - accuracy: 0.5625 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6513 - accuracy: 0.6562 - f1_m: 0.2840 - precision_m: 0.7544 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6592 - accuracy: 0.6458 - f1_m: 0.3244 - precision_m: 0.7542 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6540 - accuracy: 0.6484 - f1_m: 0.3181 - precision_m: 0.7534 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.6458 - f1_m: 0.2954 - precision_m: 0.7559 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6553 - accuracy: 0.6458 - f1_m: 0.2954 - precision_m: 0.7559 - recall_m: 0.4625 - val_loss: 0.6966 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 41/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6526 - accuracy: 0.6250 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 14s - loss: 0.6651 - accuracy: 0.5781 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6496 - accuracy: 0.6458 - f1_m: 0.2597 - precision_m: 0.7614 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6579 - accuracy: 0.6406 - f1_m: 0.3451 - precision_m: 0.7705 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.6528 - f1_m: 0.2961 - precision_m: 0.7789 - recall_m: 0.4500\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6557 - accuracy: 0.6528 - f1_m: 0.2961 - precision_m: 0.7789 - recall_m: 0.4500 - val_loss: 0.6992 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 42/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6495 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6493 - accuracy: 0.6562 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6638 - accuracy: 0.6354 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6570 - accuracy: 0.6484 - f1_m: 0.3169 - precision_m: 0.7515 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.6389 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6557 - accuracy: 0.6389 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7024 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 43/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6524 - accuracy: 0.6250 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6497 - accuracy: 0.6562 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6532 - accuracy: 0.6562 - f1_m: 0.2462 - precision_m: 0.7585 - recall_m: 0.4167 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6489 - accuracy: 0.6641 - f1_m: 0.2859 - precision_m: 0.7573 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.6597 - f1_m: 0.3248 - precision_m: 0.7590 - recall_m: 0.4875\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6520 - accuracy: 0.6597 - f1_m: 0.3248 - precision_m: 0.7590 - recall_m: 0.4875 - val_loss: 0.7061 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 44/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6476 - accuracy: 0.6875 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6523 - accuracy: 0.6406 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6569 - accuracy: 0.6146 - f1_m: 0.2361 - precision_m: 0.7607 - recall_m: 0.4062 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6609 - accuracy: 0.6016 - f1_m: 0.2973 - precision_m: 0.7620 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.6111 - f1_m: 0.3188 - precision_m: 0.7604 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6600 - accuracy: 0.6111 - f1_m: 0.3188 - precision_m: 0.7604 - recall_m: 0.4812 - val_loss: 0.7087 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 45/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6594 - accuracy: 0.5938 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 0.6570 - accuracy: 0.6562 - f1_m: 0.3577 - precision_m: 0.7622 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6538 - accuracy: 0.6562 - f1_m: 0.2971 - precision_m: 0.7663 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6555 - accuracy: 0.6562 - f1_m: 0.2976 - precision_m: 0.7625 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.6597 - f1_m: 0.3191 - precision_m: 0.7607 - recall_m: 0.4812\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6549 - accuracy: 0.6597 - f1_m: 0.3191 - precision_m: 0.7607 - recall_m: 0.4812 - val_loss: 0.7150 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 46/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6393 - accuracy: 0.6875 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6561 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6541 - accuracy: 0.6562 - f1_m: 0.2773 - precision_m: 0.7529 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6515 - accuracy: 0.6484 - f1_m: 0.3186 - precision_m: 0.7544 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6521 - accuracy: 0.6528 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6521 - accuracy: 0.6528 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7219 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6805 - accuracy: 0.5625 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6570 - accuracy: 0.6406 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6422 - accuracy: 0.6875 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6535 - accuracy: 0.6484 - f1_m: 0.3166 - precision_m: 0.7510 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.6458 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6536 - accuracy: 0.6458 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625 - val_loss: 0.7299 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 48/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6768 - accuracy: 0.5312 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6548 - accuracy: 0.5938 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 9s - loss: 0.6540 - accuracy: 0.6042 - f1_m: 0.3122 - precision_m: 0.7533 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 5s - loss: 0.6483 - accuracy: 0.6406 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.6319 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6532 - accuracy: 0.6319 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.7354 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 49/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6300 - accuracy: 0.7812 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6492 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6449 - accuracy: 0.6667 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6516 - accuracy: 0.6328 - f1_m: 0.2910 - precision_m: 0.7517 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.6389 - f1_m: 0.3138 - precision_m: 0.7521 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6512 - accuracy: 0.6389 - f1_m: 0.3138 - precision_m: 0.7521 - recall_m: 0.4812 - val_loss: 0.7369 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 50/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6403 - accuracy: 0.6875 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6430 - accuracy: 0.6719 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6525 - accuracy: 0.6667 - f1_m: 0.3572 - precision_m: 0.7513 - recall_m: 0.5208 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6505 - accuracy: 0.6641 - f1_m: 0.3427 - precision_m: 0.7512 - recall_m: 0.5078\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.6528 - f1_m: 0.2860 - precision_m: 0.7705 - recall_m: 0.4437\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6516 - accuracy: 0.6528 - f1_m: 0.2860 - precision_m: 0.7705 - recall_m: 0.4437 - val_loss: 0.7379 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 51/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6495 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6481 - accuracy: 0.6094 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6440 - accuracy: 0.6458 - f1_m: 0.3451 - precision_m: 0.7503 - recall_m: 0.5104 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6524 - accuracy: 0.6484 - f1_m: 0.3254 - precision_m: 0.7512 - recall_m: 0.4922\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.6458 - f1_m: 0.2901 - precision_m: 0.7580 - recall_m: 0.4563\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6539 - accuracy: 0.6458 - f1_m: 0.2901 - precision_m: 0.7580 - recall_m: 0.4563 - val_loss: 0.7409 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 52/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6587 - accuracy: 0.6250 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6491 - accuracy: 0.6406 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6438 - accuracy: 0.6667 - f1_m: 0.3228 - precision_m: 0.7516 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6482 - accuracy: 0.6562 - f1_m: 0.3007 - precision_m: 0.7534 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.6389 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6520 - accuracy: 0.6389 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7457 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 53/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6360 - accuracy: 0.7188 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6427 - accuracy: 0.6719 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6517 - accuracy: 0.6562 - f1_m: 0.3223 - precision_m: 0.7510 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6519 - accuracy: 0.6328 - f1_m: 0.3166 - precision_m: 0.7510 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6506 - accuracy: 0.6389 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6506 - accuracy: 0.6389 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625 - val_loss: 0.7466 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 54/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6675 - accuracy: 0.5938 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6470 - accuracy: 0.6562 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6479 - accuracy: 0.6562 - f1_m: 0.2882 - precision_m: 0.7520 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6483 - accuracy: 0.6484 - f1_m: 0.3083 - precision_m: 0.7517 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.6458 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6497 - accuracy: 0.6458 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.7469 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 55/100\n",
            "1/5 [=====>........................] - ETA: 22s - loss: 0.7472 - accuracy: 0.3750 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 15s - loss: 0.6800 - accuracy: 0.5625 - f1_m: 0.3708 - precision_m: 0.7549 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 9s - loss: 0.6557 - accuracy: 0.6146 - f1_m: 0.3254 - precision_m: 0.7562 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6507 - accuracy: 0.6328 - f1_m: 0.2952 - precision_m: 0.7585 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.6250 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6526 - accuracy: 0.6250 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812 - val_loss: 0.7490 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 56/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6500 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6518 - accuracy: 0.6250 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6480 - accuracy: 0.6250 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6447 - accuracy: 0.6484 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.6458 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6479 - accuracy: 0.6458 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.7555 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 57/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6560 - accuracy: 0.5938 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6473 - accuracy: 0.6406 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6490 - accuracy: 0.6146 - f1_m: 0.2808 - precision_m: 0.7581 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6464 - accuracy: 0.6250 - f1_m: 0.3212 - precision_m: 0.7583 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.6389 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6455 - accuracy: 0.6389 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.7572 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 58/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6414 - accuracy: 0.6562 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 15s - loss: 0.6526 - accuracy: 0.6406 - f1_m: 0.3735 - precision_m: 0.7598 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6478 - accuracy: 0.6458 - f1_m: 0.3378 - precision_m: 0.7578 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6486 - accuracy: 0.6484 - f1_m: 0.2905 - precision_m: 0.7646 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.6389 - f1_m: 0.3286 - precision_m: 0.7648 - recall_m: 0.4875\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6529 - accuracy: 0.6389 - f1_m: 0.3286 - precision_m: 0.7648 - recall_m: 0.4875 - val_loss: 0.7577 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 59/100\n",
            "1/5 [=====>........................] - ETA: 21s - loss: 0.6973 - accuracy: 0.5000 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6734 - accuracy: 0.5938 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6565 - accuracy: 0.6354 - f1_m: 0.2667 - precision_m: 0.7546 - recall_m: 0.4375 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6568 - accuracy: 0.6328 - f1_m: 0.3013 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.6528 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 21s 4s/step - loss: 0.6487 - accuracy: 0.6528 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7594 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 60/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6466 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6548 - accuracy: 0.6250 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6506 - accuracy: 0.6354 - f1_m: 0.2773 - precision_m: 0.7529 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6495 - accuracy: 0.6484 - f1_m: 0.3092 - precision_m: 0.7532 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6476 - accuracy: 0.6458 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6476 - accuracy: 0.6458 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688 - val_loss: 0.7693 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 61/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6286 - accuracy: 0.6875 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 15s - loss: 0.6491 - accuracy: 0.6406 - f1_m: 0.3577 - precision_m: 0.7622 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6387 - accuracy: 0.6562 - f1_m: 0.3273 - precision_m: 0.7594 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 0.6505 - accuracy: 0.6328 - f1_m: 0.3041 - precision_m: 0.7593 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.6319 - f1_m: 0.3100 - precision_m: 0.7574 - recall_m: 0.4750\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.6519 - accuracy: 0.6319 - f1_m: 0.3100 - precision_m: 0.7574 - recall_m: 0.4750 - val_loss: 0.7767 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 62/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6440 - accuracy: 0.6250 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6434 - accuracy: 0.6094 - f1_m: 0.2519 - precision_m: 0.7583 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6465 - accuracy: 0.6146 - f1_m: 0.2567 - precision_m: 0.7568 - recall_m: 0.4271 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6519 - accuracy: 0.6016 - f1_m: 0.3127 - precision_m: 0.7590 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.6319 - f1_m: 0.3034 - precision_m: 0.7580 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6429 - accuracy: 0.6319 - f1_m: 0.3034 - precision_m: 0.7580 - recall_m: 0.4688 - val_loss: 0.7896 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 63/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6418 - accuracy: 0.6875 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6568 - accuracy: 0.6250 - f1_m: 0.3386 - precision_m: 0.7588 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6450 - accuracy: 0.6562 - f1_m: 0.3039 - precision_m: 0.7588 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6477 - accuracy: 0.6484 - f1_m: 0.2945 - precision_m: 0.7576 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.6597 - f1_m: 0.3166 - precision_m: 0.7568 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6439 - accuracy: 0.6597 - f1_m: 0.3166 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.8006 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 64/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6586 - accuracy: 0.5938 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6357 - accuracy: 0.6562 - f1_m: 0.3235 - precision_m: 0.7622 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6399 - accuracy: 0.6354 - f1_m: 0.3044 - precision_m: 0.7594 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6397 - accuracy: 0.6406 - f1_m: 0.2949 - precision_m: 0.7581 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.6319 - f1_m: 0.3169 - precision_m: 0.7572 - recall_m: 0.4812\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6471 - accuracy: 0.6319 - f1_m: 0.3169 - precision_m: 0.7572 - recall_m: 0.4812 - val_loss: 0.8055 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 65/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6960 - accuracy: 0.5312 - f1_m: 0.4808 - precision_m: 0.7656 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6497 - accuracy: 0.6562 - f1_m: 0.3283 - precision_m: 0.7700 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6442 - accuracy: 0.6771 - f1_m: 0.3076 - precision_m: 0.7646 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6474 - accuracy: 0.6484 - f1_m: 0.3229 - precision_m: 0.7612 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.6528 - f1_m: 0.2992 - precision_m: 0.7621 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6450 - accuracy: 0.6528 - f1_m: 0.2992 - precision_m: 0.7621 - recall_m: 0.4625 - val_loss: 0.8005 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 66/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6868 - accuracy: 0.5625 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6680 - accuracy: 0.6094 - f1_m: 0.2722 - precision_m: 0.7627 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6520 - accuracy: 0.6458 - f1_m: 0.2703 - precision_m: 0.7598 - recall_m: 0.4375 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6457 - accuracy: 0.6641 - f1_m: 0.2949 - precision_m: 0.7576 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.6528 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6470 - accuracy: 0.6528 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.7984 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 67/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6904 - accuracy: 0.5625 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6504 - accuracy: 0.6719 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6511 - accuracy: 0.6562 - f1_m: 0.2891 - precision_m: 0.7533 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6474 - accuracy: 0.6562 - f1_m: 0.3370 - precision_m: 0.7563 - recall_m: 0.5000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.6597 - f1_m: 0.2896 - precision_m: 0.7676 - recall_m: 0.4500\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6461 - accuracy: 0.6597 - f1_m: 0.2896 - precision_m: 0.7676 - recall_m: 0.4500 - val_loss: 0.7847 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 68/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.6718 - accuracy: 0.5000 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6638 - accuracy: 0.5469 - f1_m: 0.3357 - precision_m: 0.7539 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6709 - accuracy: 0.5625 - f1_m: 0.3588 - precision_m: 0.7539 - recall_m: 0.5208 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6541 - accuracy: 0.6094 - f1_m: 0.3202 - precision_m: 0.7568 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.6319 - f1_m: 0.2971 - precision_m: 0.7586 - recall_m: 0.4625\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6505 - accuracy: 0.6319 - f1_m: 0.2971 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.7858 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 69/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6064 - accuracy: 0.7500 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6478 - accuracy: 0.5938 - f1_m: 0.3879 - precision_m: 0.7544 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6396 - accuracy: 0.6458 - f1_m: 0.3368 - precision_m: 0.7559 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6421 - accuracy: 0.6484 - f1_m: 0.2835 - precision_m: 0.7664 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.6458 - f1_m: 0.3388 - precision_m: 0.7701 - recall_m: 0.4938\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6449 - accuracy: 0.6458 - f1_m: 0.3388 - precision_m: 0.7701 - recall_m: 0.4938 - val_loss: 0.7917 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 70/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6109 - accuracy: 0.7188 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6288 - accuracy: 0.7031 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6509 - accuracy: 0.6667 - f1_m: 0.3228 - precision_m: 0.7516 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6420 - accuracy: 0.6797 - f1_m: 0.2932 - precision_m: 0.7551 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.6528 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6482 - accuracy: 0.6528 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.8001 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 71/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.6551 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 0.6431 - accuracy: 0.6562 - f1_m: 0.2284 - precision_m: 0.7739 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6391 - accuracy: 0.6562 - f1_m: 0.2751 - precision_m: 0.7663 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6477 - accuracy: 0.6406 - f1_m: 0.3076 - precision_m: 0.7632 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.6458 - f1_m: 0.3128 - precision_m: 0.7605 - recall_m: 0.4750\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6453 - accuracy: 0.6458 - f1_m: 0.3128 - precision_m: 0.7605 - recall_m: 0.4750 - val_loss: 0.8080 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 72/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6348 - accuracy: 0.7188 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6590 - accuracy: 0.6250 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6560 - accuracy: 0.6250 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6475 - accuracy: 0.6328 - f1_m: 0.3169 - precision_m: 0.7515 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.6458 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6440 - accuracy: 0.6458 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.8148 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 73/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6323 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6344 - accuracy: 0.6562 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6494 - accuracy: 0.6250 - f1_m: 0.2790 - precision_m: 0.7555 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6434 - accuracy: 0.6406 - f1_m: 0.2926 - precision_m: 0.7542 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.6319 - f1_m: 0.3151 - precision_m: 0.7541 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6459 - accuracy: 0.6319 - f1_m: 0.3151 - precision_m: 0.7541 - recall_m: 0.4812 - val_loss: 0.8412 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 74/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6556 - accuracy: 0.5625 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6617 - accuracy: 0.5469 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6450 - accuracy: 0.6042 - f1_m: 0.3576 - precision_m: 0.7520 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6503 - accuracy: 0.6172 - f1_m: 0.3122 - precision_m: 0.7576 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.6389 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6431 - accuracy: 0.6389 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 0.8699 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 75/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6818 - accuracy: 0.4688 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6702 - accuracy: 0.5312 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6391 - accuracy: 0.6042 - f1_m: 0.2836 - precision_m: 0.7620 - recall_m: 0.4479 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6431 - accuracy: 0.6172 - f1_m: 0.3233 - precision_m: 0.7612 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.6111 - f1_m: 0.2995 - precision_m: 0.7621 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6461 - accuracy: 0.6111 - f1_m: 0.2995 - precision_m: 0.7621 - recall_m: 0.4625 - val_loss: 0.8655 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 76/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6525 - accuracy: 0.6562 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6359 - accuracy: 0.7344 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6355 - accuracy: 0.6875 - f1_m: 0.2634 - precision_m: 0.7660 - recall_m: 0.4271 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6420 - accuracy: 0.6562 - f1_m: 0.2897 - precision_m: 0.7622 - recall_m: 0.4531\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.6528 - f1_m: 0.3279 - precision_m: 0.7629 - recall_m: 0.4875\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6411 - accuracy: 0.6528 - f1_m: 0.3279 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 0.8629 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 77/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6546 - accuracy: 0.6250 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6265 - accuracy: 0.6719 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6347 - accuracy: 0.6667 - f1_m: 0.3361 - precision_m: 0.7546 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6342 - accuracy: 0.6797 - f1_m: 0.3187 - precision_m: 0.7544 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6399 - accuracy: 0.6667 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6399 - accuracy: 0.6667 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.8380 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 78/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6556 - accuracy: 0.6250 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 15s - loss: 0.6841 - accuracy: 0.5312 - f1_m: 0.2904 - precision_m: 0.7642 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6579 - accuracy: 0.6042 - f1_m: 0.2824 - precision_m: 0.7607 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6402 - accuracy: 0.6484 - f1_m: 0.2951 - precision_m: 0.7581 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.6458 - f1_m: 0.3171 - precision_m: 0.7572 - recall_m: 0.4812\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6414 - accuracy: 0.6458 - f1_m: 0.3171 - precision_m: 0.7572 - recall_m: 0.4812 - val_loss: 0.8110 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 79/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6600 - accuracy: 0.5938 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6277 - accuracy: 0.6719 - f1_m: 0.3692 - precision_m: 0.7520 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6405 - accuracy: 0.6562 - f1_m: 0.3572 - precision_m: 0.7513 - recall_m: 0.5208 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6460 - accuracy: 0.6328 - f1_m: 0.3191 - precision_m: 0.7549 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.6528 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6426 - accuracy: 0.6528 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.8033 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 80/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6724 - accuracy: 0.5625 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6455 - accuracy: 0.6406 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6510 - accuracy: 0.6354 - f1_m: 0.2908 - precision_m: 0.7559 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6514 - accuracy: 0.6328 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.6458 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6430 - accuracy: 0.6458 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.8069 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 81/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6228 - accuracy: 0.6562 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6045 - accuracy: 0.7500 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 9s - loss: 0.6388 - accuracy: 0.6771 - f1_m: 0.3513 - precision_m: 0.7614 - recall_m: 0.5104 \n",
            "4/5 [=======================>......] - ETA: 5s - loss: 0.6345 - accuracy: 0.6797 - f1_m: 0.3222 - precision_m: 0.7607 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.6597 - f1_m: 0.2986 - precision_m: 0.7617 - recall_m: 0.4625\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6414 - accuracy: 0.6597 - f1_m: 0.2986 - precision_m: 0.7617 - recall_m: 0.4625 - val_loss: 0.8087 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 82/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6816 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6427 - accuracy: 0.6250 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6497 - accuracy: 0.6354 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6460 - accuracy: 0.6328 - f1_m: 0.3086 - precision_m: 0.7522 - recall_m: 0.4766\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.6528 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6416 - accuracy: 0.6528 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.8204 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 83/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6415 - accuracy: 0.7500 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6468 - accuracy: 0.7188 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6496 - accuracy: 0.6667 - f1_m: 0.3220 - precision_m: 0.7503 - recall_m: 0.4896 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6424 - accuracy: 0.6797 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.6736 - f1_m: 0.2939 - precision_m: 0.7535 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6416 - accuracy: 0.6736 - f1_m: 0.2939 - precision_m: 0.7535 - recall_m: 0.4625 - val_loss: 0.8532 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 84/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6373 - accuracy: 0.6875 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6183 - accuracy: 0.7188 - f1_m: 0.3521 - precision_m: 0.7524 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6222 - accuracy: 0.6875 - f1_m: 0.3029 - precision_m: 0.7568 - recall_m: 0.4688 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6350 - accuracy: 0.6484 - f1_m: 0.3020 - precision_m: 0.7554 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.6458 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6376 - accuracy: 0.6458 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.9047 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 85/100\n",
            "1/5 [=====>........................] - ETA: 18s - loss: 0.6335 - accuracy: 0.6562 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6146 - accuracy: 0.6875 - f1_m: 0.3708 - precision_m: 0.7549 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6274 - accuracy: 0.6771 - f1_m: 0.3154 - precision_m: 0.7585 - recall_m: 0.4792 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6468 - accuracy: 0.6250 - f1_m: 0.2952 - precision_m: 0.7585 - recall_m: 0.4609\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.6389 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6434 - accuracy: 0.6389 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812 - val_loss: 0.9457 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 86/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6033 - accuracy: 0.7500 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.5975 - accuracy: 0.7812 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6213 - accuracy: 0.7188 - f1_m: 0.2714 - precision_m: 0.7617 - recall_m: 0.4375 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6302 - accuracy: 0.6953 - f1_m: 0.2783 - precision_m: 0.7590 - recall_m: 0.4453\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.6736 - f1_m: 0.3347 - precision_m: 0.7643 - recall_m: 0.4938\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6420 - accuracy: 0.6736 - f1_m: 0.3347 - precision_m: 0.7643 - recall_m: 0.4938 - val_loss: 0.9659 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 87/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6097 - accuracy: 0.7188 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6316 - accuracy: 0.7031 - f1_m: 0.4247 - precision_m: 0.7583 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6424 - accuracy: 0.6875 - f1_m: 0.3614 - precision_m: 0.7585 - recall_m: 0.5208 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6425 - accuracy: 0.6719 - f1_m: 0.3222 - precision_m: 0.7603 - recall_m: 0.4844\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.6667 - f1_m: 0.2986 - precision_m: 0.7613 - recall_m: 0.4625\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6419 - accuracy: 0.6667 - f1_m: 0.2986 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 0.9707 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 88/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.6672 - accuracy: 0.6250 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 13s - loss: 0.6509 - accuracy: 0.6562 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6560 - accuracy: 0.6250 - f1_m: 0.3337 - precision_m: 0.7507 - recall_m: 0.5000 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6405 - accuracy: 0.6484 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.6458 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6411 - accuracy: 0.6458 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.9274 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 89/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6342 - accuracy: 0.6875 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6178 - accuracy: 0.7344 - f1_m: 0.2505 - precision_m: 0.7563 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6177 - accuracy: 0.7292 - f1_m: 0.2899 - precision_m: 0.7546 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6338 - accuracy: 0.6953 - f1_m: 0.3007 - precision_m: 0.7534 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.6806 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6381 - accuracy: 0.6806 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.9031 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 90/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6872 - accuracy: 0.4688 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6692 - accuracy: 0.5625 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6510 - accuracy: 0.6042 - f1_m: 0.2585 - precision_m: 0.7594 - recall_m: 0.4271 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6412 - accuracy: 0.6406 - f1_m: 0.2605 - precision_m: 0.7581 - recall_m: 0.4297\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6465 - accuracy: 0.6250 - f1_m: 0.3541 - precision_m: 0.7760 - recall_m: 0.5063\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6465 - accuracy: 0.6250 - f1_m: 0.3541 - precision_m: 0.7760 - recall_m: 0.5063 - val_loss: 0.8975 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 91/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6435 - accuracy: 0.5938 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.6153 - accuracy: 0.7031 - f1_m: 0.3235 - precision_m: 0.7622 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6295 - accuracy: 0.6875 - f1_m: 0.3044 - precision_m: 0.7594 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6387 - accuracy: 0.6484 - f1_m: 0.3031 - precision_m: 0.7573 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.6597 - f1_m: 0.3092 - precision_m: 0.7559 - recall_m: 0.4750\n",
            "5/5 [==============================] - 22s 4s/step - loss: 0.6384 - accuracy: 0.6597 - f1_m: 0.3092 - precision_m: 0.7559 - recall_m: 0.4750 - val_loss: 0.9062 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 92/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6725 - accuracy: 0.5625 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6313 - accuracy: 0.6719 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6312 - accuracy: 0.6875 - f1_m: 0.2891 - precision_m: 0.7533 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6392 - accuracy: 0.6797 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.6875 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6373 - accuracy: 0.6875 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.8767 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 93/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6448 - accuracy: 0.6250 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6141 - accuracy: 0.7188 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 8s - loss: 0.6339 - accuracy: 0.6771 - f1_m: 0.2886 - precision_m: 0.7526 - recall_m: 0.4583 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6427 - accuracy: 0.6484 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.6597 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.6365 - accuracy: 0.6597 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750 - val_loss: 0.8835 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 94/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6722 - accuracy: 0.5938 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 13s - loss: 0.6482 - accuracy: 0.6250 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 10s - loss: 0.6473 - accuracy: 0.6250 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 0.6428 - accuracy: 0.6328 - f1_m: 0.3169 - precision_m: 0.7515 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.6389 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 22s 5s/step - loss: 0.6363 - accuracy: 0.6389 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.8646 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9480)\u001b[0m Epoch 95/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.6348 - accuracy: 0.6875 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 0.6530 - accuracy: 0.6406 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n"
          ]
        }
      ],
      "source": [
        "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
        "from ray.tune.suggest.bohb import TuneBOHB\n",
        "algo = TuneBOHB(\n",
        "    config_space, metric=\"val_f1_m\", mode=\"max\", max_concurrent=1)\n",
        "bohb = HyperBandForBOHB(\n",
        "    time_attr=\"training_iteration\",\n",
        "    metric=\"val_f1_m\",\n",
        "      mode=\"max\",\n",
        "      max_t=2)\n",
        "for i in range(1):\n",
        "  tune.run(train_mnist, scheduler=bohb, num_samples=3, search_alg=algo)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}