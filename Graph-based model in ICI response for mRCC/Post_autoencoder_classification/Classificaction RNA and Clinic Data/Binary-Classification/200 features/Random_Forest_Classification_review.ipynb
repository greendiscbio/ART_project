{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload Clinic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.442789</td>\n",
       "      <td>0.226327</td>\n",
       "      <td>-3.395011</td>\n",
       "      <td>0.761912</td>\n",
       "      <td>-1.181912</td>\n",
       "      <td>-2.057796</td>\n",
       "      <td>1.901030</td>\n",
       "      <td>1.522585</td>\n",
       "      <td>1.423520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.868301</td>\n",
       "      <td>-0.086499</td>\n",
       "      <td>-1.845631</td>\n",
       "      <td>0.055275</td>\n",
       "      <td>-0.643941</td>\n",
       "      <td>1.154629</td>\n",
       "      <td>0.672262</td>\n",
       "      <td>-1.960425</td>\n",
       "      <td>0.978955</td>\n",
       "      <td>1.969951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.028265</td>\n",
       "      <td>1.410163</td>\n",
       "      <td>-2.657692</td>\n",
       "      <td>0.825858</td>\n",
       "      <td>0.435628</td>\n",
       "      <td>-0.972779</td>\n",
       "      <td>1.769565</td>\n",
       "      <td>1.036833</td>\n",
       "      <td>1.384876</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.698915</td>\n",
       "      <td>-1.105859</td>\n",
       "      <td>-0.437742</td>\n",
       "      <td>0.587427</td>\n",
       "      <td>0.048230</td>\n",
       "      <td>-0.216112</td>\n",
       "      <td>1.084762</td>\n",
       "      <td>-2.144046</td>\n",
       "      <td>1.397851</td>\n",
       "      <td>0.873189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.269204</td>\n",
       "      <td>0.884609</td>\n",
       "      <td>-1.665391</td>\n",
       "      <td>1.609233</td>\n",
       "      <td>-0.564921</td>\n",
       "      <td>0.837579</td>\n",
       "      <td>1.007009</td>\n",
       "      <td>-0.886500</td>\n",
       "      <td>0.638139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221767</td>\n",
       "      <td>-2.244491</td>\n",
       "      <td>-1.593955</td>\n",
       "      <td>-0.136215</td>\n",
       "      <td>-0.294638</td>\n",
       "      <td>-0.849120</td>\n",
       "      <td>-0.267188</td>\n",
       "      <td>-1.294744</td>\n",
       "      <td>0.276453</td>\n",
       "      <td>-0.562008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.239312</td>\n",
       "      <td>0.799451</td>\n",
       "      <td>-2.839295</td>\n",
       "      <td>0.810844</td>\n",
       "      <td>0.533907</td>\n",
       "      <td>-0.948322</td>\n",
       "      <td>1.995090</td>\n",
       "      <td>0.853652</td>\n",
       "      <td>1.670330</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.495095</td>\n",
       "      <td>-1.396998</td>\n",
       "      <td>-0.734805</td>\n",
       "      <td>0.479203</td>\n",
       "      <td>-0.163358</td>\n",
       "      <td>-0.100398</td>\n",
       "      <td>0.647680</td>\n",
       "      <td>-2.374888</td>\n",
       "      <td>1.707838</td>\n",
       "      <td>0.507836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.351865</td>\n",
       "      <td>-1.245096</td>\n",
       "      <td>-0.744767</td>\n",
       "      <td>-1.102401</td>\n",
       "      <td>0.138185</td>\n",
       "      <td>1.691464</td>\n",
       "      <td>0.830067</td>\n",
       "      <td>0.261012</td>\n",
       "      <td>0.593560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.819882</td>\n",
       "      <td>-0.315093</td>\n",
       "      <td>-2.720363</td>\n",
       "      <td>-1.119180</td>\n",
       "      <td>0.080892</td>\n",
       "      <td>-1.040733</td>\n",
       "      <td>0.136569</td>\n",
       "      <td>-1.674414</td>\n",
       "      <td>0.958555</td>\n",
       "      <td>-1.271945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target         0         1         2         3         4         5  \\\n",
       "0       1  0.442789  0.226327 -3.395011  0.761912 -1.181912 -2.057796   \n",
       "1       1 -0.028265  1.410163 -2.657692  0.825858  0.435628 -0.972779   \n",
       "2       1  0.269204  0.884609 -1.665391  1.609233 -0.564921  0.837579   \n",
       "3       0  0.239312  0.799451 -2.839295  0.810844  0.533907 -0.948322   \n",
       "4       1 -0.351865 -1.245096 -0.744767 -1.102401  0.138185  1.691464   \n",
       "\n",
       "          6         7         8  ...       190       191       192       193  \\\n",
       "0  1.901030  1.522585  1.423520  ... -0.868301 -0.086499 -1.845631  0.055275   \n",
       "1  1.769565  1.036833  1.384876  ... -1.698915 -1.105859 -0.437742  0.587427   \n",
       "2  1.007009 -0.886500  0.638139  ... -0.221767 -2.244491 -1.593955 -0.136215   \n",
       "3  1.995090  0.853652  1.670330  ... -1.495095 -1.396998 -0.734805  0.479203   \n",
       "4  0.830067  0.261012  0.593560  ...  1.819882 -0.315093 -2.720363 -1.119180   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.643941  1.154629  0.672262 -1.960425  0.978955  1.969951  \n",
       "1  0.048230 -0.216112  1.084762 -2.144046  1.397851  0.873189  \n",
       "2 -0.294638 -0.849120 -0.267188 -1.294744  0.276453 -0.562008  \n",
       "3 -0.163358 -0.100398  0.647680 -2.374888  1.707838  0.507836  \n",
       "4  0.080892 -1.040733  0.136569 -1.674414  0.958555 -1.271945  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =\"../../../../Data_preprocessing/RNA_post_autoencoder/encoded_data_binary_200_review.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.reset_index\n",
    "data.round(4)\n",
    "data=data.iloc[:,1:202 ] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.442789  0.226327 -3.395011  0.761912 -1.181912 -2.057796  1.901030   \n",
      "1   -0.028265  1.410163 -2.657692  0.825858  0.435628 -0.972779  1.769565   \n",
      "2    0.269204  0.884609 -1.665391  1.609233 -0.564921  0.837579  1.007009   \n",
      "3    0.239312  0.799451 -2.839295  0.810844  0.533907 -0.948322  1.995090   \n",
      "4   -0.351865 -1.245096 -0.744767 -1.102401  0.138185  1.691464  0.830067   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "176  0.121525  0.789393 -1.679044 -0.338311 -0.033060  0.143954  0.686666   \n",
      "177 -0.217280  0.614284 -3.202434  1.415873 -0.034867 -1.669631  1.756469   \n",
      "178 -0.015025  0.468370 -1.550519 -0.117665 -0.567333 -0.207721  0.605682   \n",
      "179 -0.244144  1.576056 -1.483863  0.089200 -0.107631 -0.831589  0.260183   \n",
      "180 -0.161056  0.517091 -1.964447  0.106236 -0.606570 -0.446199  0.921929   \n",
      "\n",
      "            7         8         9  ...       190       191       192  \\\n",
      "0    1.522585  1.423520 -1.133097  ... -0.868301 -0.086499 -1.845631   \n",
      "1    1.036833  1.384876 -0.905239  ... -1.698915 -1.105859 -0.437742   \n",
      "2   -0.886500  0.638139 -1.383349  ... -0.221767 -2.244491 -1.593955   \n",
      "3    0.853652  1.670330 -0.798142  ... -1.495095 -1.396998 -0.734805   \n",
      "4    0.261012  0.593560 -1.265134  ...  1.819882 -0.315093 -2.720363   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "176  1.352235  1.231143 -0.639037  ... -0.502338 -0.878246 -0.937684   \n",
      "177  0.895597  1.353813 -1.647205  ... -2.315726 -1.170154 -0.700554   \n",
      "178  1.060858  1.207397 -1.092568  ... -0.698835 -0.730946 -1.062844   \n",
      "179  2.085388  0.600841 -0.547670  ... -0.273632 -0.892104 -0.405529   \n",
      "180  0.930891  1.126651 -1.270567  ... -1.209615 -0.611399 -1.004538   \n",
      "\n",
      "          193       194       195       196       197       198       199  \n",
      "0    0.055275 -0.643941  1.154629  0.672262 -1.960425  0.978955  1.969951  \n",
      "1    0.587427  0.048230 -0.216112  1.084762 -2.144046  1.397851  0.873189  \n",
      "2   -0.136215 -0.294638 -0.849120 -0.267188 -1.294744  0.276453 -0.562008  \n",
      "3    0.479203 -0.163358 -0.100398  0.647680 -2.374888  1.707838  0.507836  \n",
      "4   -1.119180  0.080892 -1.040733  0.136569 -1.674414  0.958555 -1.271945  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "176 -0.365146 -0.266997 -0.380955  0.623903 -1.798886  1.023760  0.489026  \n",
      "177  0.697908 -0.029973  0.495671  1.142163 -2.011623  1.012784  1.365545  \n",
      "178  0.000504 -0.282695 -0.163101  0.642795 -1.728818  0.643054  0.523558  \n",
      "179 -0.367688 -0.037767 -0.513179  1.949885 -1.906372  1.478283  0.894822  \n",
      "180  0.271342 -0.129115  0.178572  0.809353 -1.441472  0.458278  1.025028  \n",
      "\n",
      "[181 rows x 200 columns]\n",
      "Numero de pacientes:  181\n"
     ]
    }
   ],
   "source": [
    "Y = data.Target # Target column\n",
    "\n",
    "X = data.iloc[:,1:202] # I selected all the columns by removing the Unnamed column (row id) and the Target column.\n",
    "\n",
    "print(X)\n",
    "print('Numero de pacientes: ',len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 144\n",
      "Target column size of the training set: 144\n",
      "Test set size: 37\n",
      "Target column size of the test set: 37\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125, stratify=Y)\n",
    "\n",
    "print('Training set size:', len(XTrain))\n",
    "print('Target column size of the training set:', len(yTrain))\n",
    "print('Test set size:', len(XTest))\n",
    "print('Target column size of the test set:', len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select the parameters of the model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 5, 10, 50],\n",
       "                         'min_samples_leaf': [1, 3],\n",
       "                         'min_samples_split': [2, 3, 4, 5],\n",
       "                         'n_estimators': [10, 15], 'random_state': [125]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'min_samples_leaf': [1, 3],\n",
    "              'min_samples_split': [2, 3, 4, 5],\n",
    "              'random_state':[125],\n",
    "              'n_estimators': [10, 15],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth':[None, 2, 5, 10,50]\n",
    "              }\n",
    "\n",
    "# I created a GridSearchCV which allows us to systematically evaluate and select the parameters of our model.\n",
    "# By indicating a model and the parameters to test, you can evaluate the performance of the first one based on the\n",
    "# seconds through cross validation.\n",
    "clf = GridSearchCV(\n",
    "        estimator  = RandomForestClassifier(),\n",
    "        param_grid = param_grid,\n",
    "        cv=5\n",
    "       )\n",
    "\n",
    "clf.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor estimación de parámetros según GridSearchCV:\n",
      "RandomForestClassifier(criterion='entropy', max_depth=2, min_samples_leaf=3,\n",
      "                       n_estimators=15, random_state=125)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor estimación de parámetros según GridSearchCV:\")\n",
    "print(clf.best_estimator_)\n",
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result of the cross validation of the model with the best paramters:0.6386699507389163\n"
     ]
    }
   ],
   "source": [
    "print(\"Best result of the cross validation of the model with the best paramters:\" +str(clf.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the training dataset\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "yTrain=yTrain.to_numpy()\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTrain),1) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "yTest=yTest.to_numpy()\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training dataset:0.7361111111111112\n",
      "Final accuracy on the testing dataset: 0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy on the training dataset:' + str(contTrain/len(yTrain)))\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Training)------------------\n",
      "[[43 25]\n",
      " [13 63]]\n",
      "Input data:  [1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1]\n",
      "Prediction:        [1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Confusion Matrix (Training)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Input data:  ' + str(np.array(yTrain)))\n",
    "print('Prediction:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69        68\n",
      "           1       0.72      0.83      0.77        76\n",
      "\n",
      "    accuracy                           0.74       144\n",
      "   macro avg       0.74      0.73      0.73       144\n",
      "weighted avg       0.74      0.74      0.73       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[ 4 13]\n",
      " [ 4 16]]\n",
      "Input data:  [0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0]\n",
      "Prediction:        [1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Input data:  ' + str(np.array(yTest)))\n",
    "print('Prediction:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.24      0.32        17\n",
      "           1       0.55      0.80      0.65        20\n",
      "\n",
      "    accuracy                           0.54        37\n",
      "   macro avg       0.53      0.52      0.49        37\n",
      "weighted avg       0.53      0.54      0.50        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with relevance over 0:  36\n",
      "Features with relevance over 0.05:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEWCAYAAABPON1ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUgElEQVR4nO3de5RlZX3m8e8jzR0EFEJoUBsNYghGlIuZjEaCGsWE4KzRUTFGyBg1s4zR8RI1xsEko8SQRMVkDDqKo0ZQTAyjGECNSoQRqrnItSM0IDelucnFCwK/+WO/JYfKKbq6q07V293fz1pn9T778u7ffvuc57y1d51dqSokSf162FIXIEl6aAa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDOpNRJKvJnnFUtcxTpKnJ1m1QG0dnOS69dz2hCR/thB1LKQkb0vy4Ta9IkklWbbUdWnxGNQbkCRXJ/lhkruSfLcFy3ZLXdd8VdWZVbX3Utex2Ob6oVJV76qqBfmQba+hZy1EW1o8BvWG57Cq2g7YD3gy8NalLUeT5MhZYFBvsKrqu8BpDIENQJJfSnJWktuTXJjk4Nm2T/I7SS5LcluS05I8ps3/X0mOnbHuPyX57236LUmuTHJnkkuT/KeR9Y5M8q9Jjm3tXpXk0JHlj0jy0SQ3tOWfa/MfNLJ8qH2MOY6t208WtyW5FDhwxvLlST6bZE2r57UP2bEP3vZ3k1yR5NYkpyRZ3uYnyV8nuSnJHUkuSrLvLG0c1fr5ziSrk7yqzd8W+CKwvP2EdFer9egkJyf5RJI7gCPbvE/MaPp3Wj/emOSNI/t70Omb0b5N8nHg0cD/bft7c5v/m0kuaa+bryb5+ZHt/zDJ9a3+VUmeOdf+0wKqKh8byAO4GnhWm94DuAh4X3u+O3AL8DyGD+Bnt+e7tOVfBV7Rpg8HrgB+HlgGvB04qy37FeBaIO35TsAPgeXt+QuB5W0fLwLuBnZry44EfgL8LrAZ8HvADSNtfQE4qbW5OfCMNv9g4LqR45x1H2P65BjgTOARwKOAi6fbatuvBN4BbAE8FlgNPGeWtk4A/qxNHwLcDDwF2BI4Dvh6W/ac1u6OQFo/zlbfrwOPa+s9A/gB8JRxx93mHd368Pmt/q3bvE+05SuAAj4FbAs8EVjDA6+Lnx7DLH179fS67fnjW/8+u/2fvJnhtbEFsHd7LSwf2ffjlvp9sCk+HFFveD6X5E6GN9BNwP9o838LOLWqTq2q+6vqDGCKIbhnejXw7qq6rKruBd4F7NdG1WcyBMHT27ovAM6uqhsAquozVXVD28dJwLeBg0bavqaqPlRV9wEfA3YDdk2yG3Ao8Oqquq2qflJVXxt3gHPYx6j/AvzPqrq1qq4F3j+y7ECGD6o/qap7qmo18CHgxbO0NeqlwEeq6ryq+jHDKab/kGQFQ5BuDzyB4UPosqq6cZZj+UJVXVmDrwGn80DfzubsqvpcO/4fzrLOO6vq7qq6CPgo8JI5HNM4LwK+UFVnVNVPgGMZPhx+GbiP4UNqnySbV9XVVXXleu5H82BQb3ieX1XbM4yUngDs3OY/Bnhh+/H19iS3A09jCMqZHgO8b2S9WxlGfLtXVQEn8sAb/wjgk9MbJvntJBeMbLvvSA0A352eqKoftMntGEa7t1bVbWs7wDnsY9Ryhg+tadfMOM7lM/rkbcCua6uhtfvTtqrqLoafUHavqq8AHwD+BrgpyfFJHj7LsRya5P+10ye3M3xwznYs065dy/KZ61zT6l0fM4/z/tb27lV1BfA6hhH9TUlOnD79o8VlUG+g2ujsBIYREAxvro9X1Y4jj22r6pgxm18LvGrGultX1Vlt+aeAF7QR9lOBzwK05x8CXgM8sqp2ZDjVkDmUfC3wiCQ7PtRK67GPGxk+BKY9esY+r5pxnNtX1bifMma6gSHop+vaFngkcD1AVb2/qvYH9mE4ffCmMceyJUPfHQvs2o7l1JFjme3WlXO5peXMY76hTd8NbDOy7GfX0vbM40xre/o4/76qntbWKeDP51CbFphBvWF7L/DsJE8CPgEcluQ5STZLslW7kLTHmO0+CLw1yS8AJNkhyQunF1bV+QznZz8MnFZVt7dF2zK8Wde07Y5iGO2uVTs18EXgb5PslGTzJL8yZtV13cen27Hs1I7190eWnQPc2S6Ibd36Zd8kB45v6kE+BRyVZL8WuO8CvllVVyc5MMlTk2zOEIw/Au4f08YWDKcO1gD3Zriw+msjy78HPDLJDnOoZ6Y/TrJN+z88iuHcP8AFwPMyXLj9WYYR8ajvMZyrn/Zp4NeTPLMdzxuAHwNnJdk7ySHt+H/EcK1i3HFqwgzqDVhVrQH+D/COdn72cIYf7dcwjCbfxJj/46r6R4aR0YntNwsuZjh/POrvgWe1f6e3uxT4S+Bshjf8E4FvrEPJL2M4v3s5w/n1142pbV338U6GH92vYjj/+/GRtu4DfoPhN2Ou4oEPn7UGY1V9CfhjhhHxjQwXBKfPbT+cYdR/W9v3LcBfjGnjTuC1DGF4G8NppFNGll/O8IGwup2aWZfTCl9juOj3ZeDYqjq9zf84cCHDRcPTeSDAp70beHvb3xurahXD9Y3jGPrnMIZfAb2H4UPmmDb/u8DP4K+DLonpq/GSpE45opakzhnUktQ5g1qSOmdQS1LnJnLDl5133rlWrFgxiaYlaaO0cuXKm6tql3HLJhLUK1asYGpqahJNS9JGKck1sy3z1Ickdc6glqTOGdSS1DmDWpI6Z1BLUucMaknqnEEtSZ0zqCWpcxP5wsvKlZC5/M0PSdpITPKO0Y6oJalzBrUkdc6glqTOGdSS1DmDWpI6Z1BLUucMaknqnEEtSZ0zqCWpcwa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSeqcQS1JnZtTUCd5bpJVSa5I8pZJFyVJesBagzrJZsDfAIcC+wAvSbLPpAuTJA3mMqI+CLiiqlZX1T3AicDhky1LkjRtLkG9O3DtyPPr2rwHSfLKJFNJpmDNQtUnSZu8BbuYWFXHV9UBVXUA7LJQzUrSJm8uQX098KiR53u0eZKkRTCXoD4X2CvJnkm2AF4MnDLZsiRJ05atbYWqujfJa4DTgM2Aj1TVJROvTJIEzCGoAarqVODUCdciSRrDbyZKUucMaknqnEEtSZ0zqCWpcwa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSeqcQS1JnTOoJalzBrUkdc6glqTOGdSS1Lllk2h0//1hamoSLUvSpscRtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSeqcQS1JnTOoJalzBrUkdc6glqTOGdSS1DmDWpI6Z1BLUucmcve8lSshmUTLktZV1VJXoPlyRC1JnTOoJalzBrUkdc6glqTOGdSS1DmDWpI6Z1BLUucMaknqnEEtSZ0zqCWpcwa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSercWoM6yUeS3JTk4sUoSJL0YHMZUZ8APHfCdUiSZrHWoK6qrwO3LkItkqQxFuwcdZJXJplKMgVrFqpZSdrkLVhQV9XxVXVAVR0AuyxUs5K0yfO3PiSpcwa1JHVuLr+e9yngbGDvJNcl+a+TL0uSNG3Z2laoqpcsRiGSpPE89SFJnTOoJalzBrUkdc6glqTOGdSS1DmDWpI6Z1BLUucMaknqnEEtSZ0zqCWpcwa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjq3bBKN7r8/TE1NomVJ2vQ4opakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSercRO6et3IlJJNoWdowVS11BdqQOaKWpM4Z1JLUOYNakjpnUEtS5wxqSeqcQS1JnTOoJalzBrUkdc6glqTOGdSS1DmDWpI6Z1BLUucMaknqnEEtSZ0zqCWpcwa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM6tNaiTPCrJvyS5NMklSf5gMQqTJA2WzWGde4E3VNV5SbYHViY5o6ounXBtkiTmMKKuqhur6rw2fSdwGbD7pAuTJA3W6Rx1khXAk4Fvjln2yiRTSaZgzQKVJ0mac1An2Q74LPC6qrpj5vKqOr6qDqiqA2CXhaxRkjZpcwrqJJszhPQnq+ofJluSJGnUXH7rI8D/Bi6rqr+afEmSpFFzGVH/R+BlwCFJLmiP5024LklSs9Zfz6uqfwWyCLVIksbwm4mS1DmDWpI6Z1BLUucMaknqnEEtSZ0zqCWpcwa1JHXOoJakzhnUktQ5g1qSOmdQS1LnDGpJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSeqcQS1JnTOoJalzyybR6P77w9TUJFqWpE2PI2pJ6pxBLUmdM6glqXMGtSR1zqCWpM4Z1JLUOYNakjpnUEtS5wxqSepcqmrhG03uBFYteMMbtp2Bm5e6iA7ZL+PZL+NtzP3ymKraZdyCiXyFHFhVVQdMqO0NUpIp++Tfs1/Gs1/G21T7xVMfktQ5g1qSOjepoD5+Qu1uyOyT8eyX8eyX8TbJfpnIxURJ0sLx1Ickdc6glqTOrVNQJ3luklVJrkjyljHLt0xyUlv+zSQrRpa9tc1fleQ5C1B7N9a3X5I8O8nKJBe1fw9Z9OInaD6vl7b80UnuSvLGRSt6EczzffSLSc5Ockl73Wy1qMVPyDzeQ5sn+Vjri8uSvHXRi18MVTWnB7AZcCXwWGAL4EJgnxnr/Dfgg236xcBJbXqftv6WwJ6tnc3muu+eH/PslycDy9v0vsD1S308PfTLyPKTgc8Ab1zq4+mhXxi+9/At4Ent+SM3hvfRPPvkCODENr0NcDWwYqmPaaEf6zKiPgi4oqpWV9U9wInA4TPWORz4WJs+GXhmkrT5J1bVj6vqKuCK1t7GYL37parOr6ob2vxLgK2TbLkoVU/efF4vJHk+cBVDv2xM5tMvvwZ8q6ouBKiqW6rqvkWqe5Lm0ycFbJtkGbA1cA9wx+KUvXjWJah3B64deX5dmzd2naq6F/g+w6f+XLbdUM2nX0b9Z+C8qvrxhOpcbOvdL0m2A/4QeOci1LnY5vN6eTxQSU5Lcl6SNy9CvYthPn1yMnA3cCPwHeDYqrp10gUvtkl9hVzrIMkvAH/OMGISHA38dVXd1QbYGiwDngYcCPwA+HKSlVX15aUta0kdBNwHLAd2As5M8qWqWr20ZS2sdRlRXw88auT5Hm3e2HXajyI7ALfMcdsN1Xz6hSR7AP8I/HZVXTnxahfPfPrlqcB7klwNvA54W5LXTLjexTKffrkO+HpV3VxVPwBOBZ4y8Yonbz59cgTwz1X1k6q6CfgGsNHdC2RdgvpcYK8keybZguGE/ikz1jkFeHmbfgHwlRrO8p8CvLhdud0T2As4Z36ld2O9+yXJjsAXgLdU1TcWq+BFst79UlVPr6oVVbUCeC/wrqr6wCLVPWnzeR+dBjwxyTYtrJ4BXLpIdU/SfPrkO8AhAEm2BX4JuHxRql5M63h19nnAvzFcof2jNu9PgN9s01sxXKW/giGIHzuy7R+17VYBhy71VdSFfKxvvwBvZzi/dsHI42eW+niWul9mtHE0G9Fvfcy3X4DfYrjAejHwnqU+lqXuE2C7Nv8Shg+tNy31sUzi4VfIJalzfjNRkjpnUEtS5wxqSeqcQS1JnTOoJalzBrXmLMldi7y/FUmOmEC7ByR5/wTaXZHk4jmsc8TI84nUoo2LQa0utS90rGD45tmCqqqpqnrt+mzb6pqPFYwc03xq0abDoNY6S3Jwkq8l+ackq5Mck+SlSc5p9wV+XFvvhCQfTDKV5N+S/Eabv1WSj7Z1z0/yq23+kUlOSfIV4MvAMcDTk1yQ5PVtNHpmuyHReUl+eaSeryY5OcnlST45che+A5OcleTCVt/2bf3Pt+UHZbi/8/ltvb1nOd4zk5wCXJpksyR/keTcJN9K8qox24ytdcwxHZzk80keluTq9m3V6Ta+nWTXJIdluAfz+Um+lGTXBfvP1IZhqb9x42PDeQB3tX8PBm4HdmO4x/j1wDvbsj8A3tumTwD+mWFAsBfDvSq2At4AfKSt8wSGrwFvBRzZ1nnEyH4+P7L/bYCt2vRewNTIet9nuEfEw4CzGW5etAWwGjiwrfdwhhsb/bTd6Xlt+lnAZ8cc98EM3yDdsz1/JfD2Nr0lMMVwn/UVwMVzqPXzM9qeruV9wFFt+qnAl9r0Tjzw901fAfzlUr8WfCzuw7vnaX2dW1U3AiS5Eji9zb8I+NWR9T5dVfcD306ymiGYnwYcB1BVlye5huEWngBn1Oy3qdwc+ECS/RjumPb4kWXnVNV1rZ4LGELz+8CNVXVu29cdbflomzsAH0uyF8O9jTefZd/n1HAvdRjucviLSV4w0sZeDF+BnkutszkJeAfwUdrN8dv8PYCTkuzG8OFz1fjNtbHy1IfW1+h9s+8feX4/D7597sx7FKztngV3P8Sy1wPfA57EcIe0LWap5z7mfgvfPwX+par2BQ5jGNmvra4Av19V+7XHnlV1+oz1H6rW2ZwN/FySXYDnA//Q5h8HfKCqngi86iFq1EbKoNakvbCdf30cw59aWgWcCbwUIMnjgUe3+TPdCWw/8nwHhhHy/cDLGP6E00NZBeyW5MC2r+3HXAzcgQduqXnkHI/pNOD3kmw+fQztzm0z2x1X68xj+qmqKoZb3v4VcFlV3TKmxpeP21YbN4Nak/YdhrudfRF4dVX9CPhb4GFJLmL48f7IGv+Xbb4F3NcuBL6+bffyJBcynEJ5qNE3NfxZpxcBx7VtzuDfj0bfA7w7yfnMfRT+YYY7tZ3Xfh3v78ZsO1utM49pppMY7pB30si8o4HPJFkJ3DzHGrUR8e55mpgkJzBcKDt5qWuRNmSOqCWpc46oJalzjqglqXMGtSR1zqCWpM4Z1JLUOYNakjr3/wFNR/KRDGOepAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 0.02250415890288088\n",
      "1 = 0.009804537193579706\n",
      "2 = 0.0\n",
      "3 = 0.009157324018736295\n",
      "4 = 0.0\n",
      "5 = 0.0\n",
      "6 = 0.0\n",
      "7 = 0.0\n",
      "8 = 0.018809432358090846\n",
      "9 = 0.0\n",
      "10 = 0.0\n",
      "11 = 0.0\n",
      "12 = 0.0\n",
      "13 = 0.0\n",
      "14 = 0.0\n",
      "15 = 0.0\n",
      "16 = 0.0\n",
      "17 = 0.0\n",
      "18 = 0.0\n",
      "19 = 0.01930321713967377\n",
      "20 = 0.0\n",
      "21 = 0.0\n",
      "22 = 0.0\n",
      "23 = 0.0\n",
      "24 = 0.03710377385905983\n",
      "25 = 0.09136780469019898\n",
      "26 = 0.0\n",
      "27 = 0.0\n",
      "28 = 0.0\n",
      "29 = 0.0\n",
      "30 = 0.06550549588459634\n",
      "31 = 0.0\n",
      "32 = 0.0\n",
      "33 = 0.0269603501540779\n",
      "34 = 0.0\n",
      "35 = 0.0\n",
      "36 = 0.02357025308024131\n",
      "37 = 0.0\n",
      "38 = 0.0\n",
      "39 = 0.0\n",
      "40 = 0.0\n",
      "41 = 0.0\n",
      "42 = 0.0\n",
      "43 = 0.0\n",
      "44 = 0.0\n",
      "45 = 0.0\n",
      "46 = 0.0\n",
      "47 = 0.0\n",
      "48 = 0.0\n",
      "49 = 0.0\n",
      "50 = 0.0\n",
      "51 = 0.0\n",
      "52 = 0.0\n",
      "53 = 0.0\n",
      "54 = 0.0\n",
      "55 = 0.032141980969021024\n",
      "56 = 0.0\n",
      "57 = 0.0\n",
      "58 = 0.0\n",
      "59 = 0.0\n",
      "60 = 0.0\n",
      "61 = 0.0\n",
      "62 = 0.0\n",
      "63 = 0.0\n",
      "64 = 0.0\n",
      "65 = 0.0\n",
      "66 = 0.0\n",
      "67 = 0.0\n",
      "68 = 0.0\n",
      "69 = 0.0\n",
      "70 = 0.0\n",
      "71 = 0.0\n",
      "72 = 0.0\n",
      "73 = 0.0\n",
      "74 = 0.0\n",
      "75 = 0.024086278364759208\n",
      "76 = 0.0\n",
      "77 = 0.0\n",
      "78 = 0.03235028286786938\n",
      "79 = 0.027287269837459178\n",
      "80 = 0.015908250334631134\n",
      "81 = 0.030144451888633638\n",
      "82 = 0.0\n",
      "83 = 0.01852749281481274\n",
      "84 = 0.0\n",
      "85 = 0.0\n",
      "86 = 0.0\n",
      "87 = 0.0\n",
      "88 = 0.0\n",
      "89 = 0.0\n",
      "90 = 0.0\n",
      "91 = 0.0\n",
      "92 = 0.0\n",
      "93 = 0.0\n",
      "94 = 0.0\n",
      "95 = 0.0\n",
      "96 = 0.0\n",
      "97 = 0.0\n",
      "98 = 0.0\n",
      "99 = 0.0\n",
      "100 = 0.023207019526322554\n",
      "101 = 0.0\n",
      "102 = 0.0\n",
      "103 = 0.0\n",
      "104 = 0.029784505758533714\n",
      "105 = 0.0\n",
      "106 = 0.0\n",
      "107 = 0.0\n",
      "108 = 0.0\n",
      "109 = 0.0\n",
      "110 = 0.0\n",
      "111 = 0.02023734258121369\n",
      "112 = 0.0\n",
      "113 = 0.0\n",
      "114 = 0.0\n",
      "115 = 0.0\n",
      "116 = 0.0\n",
      "117 = 0.0\n",
      "118 = 0.0\n",
      "119 = 0.0\n",
      "120 = 0.0\n",
      "121 = 0.0\n",
      "122 = 0.02709826798687505\n",
      "123 = 0.0\n",
      "124 = 0.0\n",
      "125 = 0.0\n",
      "126 = 0.0\n",
      "127 = 0.0\n",
      "128 = 0.0\n",
      "129 = 0.0\n",
      "130 = 0.02849312872733957\n",
      "131 = 0.0\n",
      "132 = 0.0\n",
      "133 = 0.0\n",
      "134 = 0.0\n",
      "135 = 0.024818117892252873\n",
      "136 = 0.0\n",
      "137 = 0.0\n",
      "138 = 0.0\n",
      "139 = 0.0\n",
      "140 = 0.0\n",
      "141 = 0.007565603984594314\n",
      "142 = 0.0\n",
      "143 = 0.0\n",
      "144 = 0.0\n",
      "145 = 0.0\n",
      "146 = 0.0\n",
      "147 = 0.0\n",
      "148 = 0.0\n",
      "149 = 0.0\n",
      "150 = 0.0163521295534143\n",
      "151 = 0.0\n",
      "152 = 0.0\n",
      "153 = 0.0\n",
      "154 = 0.0\n",
      "155 = 0.0\n",
      "156 = 0.0\n",
      "157 = 0.019742028279902686\n",
      "158 = 0.0\n",
      "159 = 0.020569964471116642\n",
      "160 = 0.0\n",
      "161 = 0.0\n",
      "162 = 0.0\n",
      "163 = 0.0\n",
      "164 = 0.0\n",
      "165 = 0.04626315847247811\n",
      "166 = 0.0\n",
      "167 = 0.0\n",
      "168 = 0.0\n",
      "169 = 0.0\n",
      "170 = 0.0\n",
      "171 = 0.0\n",
      "172 = 0.05661273697826898\n",
      "173 = 0.0\n",
      "174 = 0.0\n",
      "175 = 0.0\n",
      "176 = 0.0\n",
      "177 = 0.009461144527872271\n",
      "178 = 0.01781178279888467\n",
      "179 = 0.0\n",
      "180 = 0.0\n",
      "181 = 0.0\n",
      "182 = 0.0\n",
      "183 = 0.0\n",
      "184 = 0.0\n",
      "185 = 0.0\n",
      "186 = 0.019566675565592145\n",
      "187 = 0.0\n",
      "188 = 0.022016126944428196\n",
      "189 = 0.03428294478981948\n",
      "190 = 0.0\n",
      "191 = 0.0\n",
      "192 = 0.0\n",
      "193 = 0.03440532634699904\n",
      "194 = 0.0\n",
      "195 = 0.03717964045576951\n",
      "196 = 0.0\n",
      "197 = 0.0\n",
      "198 = 0.0\n",
      "199 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Through the created model we can see which attributes are the most significant to make a decision.\n",
    "# The most relevant attributes will be the ones placed at the top of the tree.\n",
    "features = list(X)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "elems_over_0 = np.fromiter((element for element in importances if element > 0), dtype = importances.dtype)\n",
    "print('Features with relevance over 0: ', len(elems_over_0))\n",
    "\n",
    "newArray = np.fromiter((element for element in importances if element > 0.05), dtype = importances.dtype)\n",
    "importances=newArray\n",
    "indices = np.argsort(importances)\n",
    "print('Features with relevance over 0.05: ', len(newArray))\n",
    "\n",
    "plt.title('Relevancia de los atributos')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Importancia relativa')\n",
    "plt.show()\n",
    "\n",
    "for name, importance in zip(X, model.feature_importances_):\n",
    "    print(name, \"=\", importance)\n",
    "\n",
    "# Attributes whose relevance is 0, will not be necessary to make the prediction of the target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
