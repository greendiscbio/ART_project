{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload Clinic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.832239</td>\n",
       "      <td>1.233726</td>\n",
       "      <td>1.140988</td>\n",
       "      <td>2.165680</td>\n",
       "      <td>-1.597017</td>\n",
       "      <td>-0.743907</td>\n",
       "      <td>-0.071826</td>\n",
       "      <td>0.116781</td>\n",
       "      <td>-0.635038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077455</td>\n",
       "      <td>0.066486</td>\n",
       "      <td>2.200836</td>\n",
       "      <td>2.124988</td>\n",
       "      <td>-0.882250</td>\n",
       "      <td>0.367745</td>\n",
       "      <td>1.330217</td>\n",
       "      <td>0.660291</td>\n",
       "      <td>-0.899856</td>\n",
       "      <td>1.536773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.137469</td>\n",
       "      <td>-0.010969</td>\n",
       "      <td>0.843637</td>\n",
       "      <td>0.966030</td>\n",
       "      <td>0.409513</td>\n",
       "      <td>-0.847683</td>\n",
       "      <td>-1.006673</td>\n",
       "      <td>0.749325</td>\n",
       "      <td>-1.147702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.583738</td>\n",
       "      <td>-1.836914</td>\n",
       "      <td>1.908090</td>\n",
       "      <td>1.263731</td>\n",
       "      <td>-1.759173</td>\n",
       "      <td>-0.579072</td>\n",
       "      <td>1.043836</td>\n",
       "      <td>0.452179</td>\n",
       "      <td>0.771279</td>\n",
       "      <td>1.454416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.405876</td>\n",
       "      <td>0.109203</td>\n",
       "      <td>1.359791</td>\n",
       "      <td>1.225490</td>\n",
       "      <td>-0.138266</td>\n",
       "      <td>-1.679678</td>\n",
       "      <td>0.182724</td>\n",
       "      <td>-0.188638</td>\n",
       "      <td>-1.128553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342459</td>\n",
       "      <td>-0.801281</td>\n",
       "      <td>2.540216</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>-1.590028</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>1.889005</td>\n",
       "      <td>1.706726</td>\n",
       "      <td>0.912262</td>\n",
       "      <td>1.206671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.376180</td>\n",
       "      <td>0.196114</td>\n",
       "      <td>0.779141</td>\n",
       "      <td>1.123773</td>\n",
       "      <td>0.374653</td>\n",
       "      <td>-0.947631</td>\n",
       "      <td>-0.892223</td>\n",
       "      <td>0.621932</td>\n",
       "      <td>-0.999321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272015</td>\n",
       "      <td>-2.344969</td>\n",
       "      <td>2.089854</td>\n",
       "      <td>1.595235</td>\n",
       "      <td>-1.722826</td>\n",
       "      <td>-0.317329</td>\n",
       "      <td>1.074202</td>\n",
       "      <td>0.198977</td>\n",
       "      <td>0.917910</td>\n",
       "      <td>1.435312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.964517</td>\n",
       "      <td>1.128601</td>\n",
       "      <td>-0.194799</td>\n",
       "      <td>-1.433777</td>\n",
       "      <td>-0.143446</td>\n",
       "      <td>-1.161713</td>\n",
       "      <td>-2.380596</td>\n",
       "      <td>0.026122</td>\n",
       "      <td>-1.105232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160001</td>\n",
       "      <td>-1.498763</td>\n",
       "      <td>2.403551</td>\n",
       "      <td>1.303866</td>\n",
       "      <td>-1.757287</td>\n",
       "      <td>0.949241</td>\n",
       "      <td>0.272723</td>\n",
       "      <td>2.771020</td>\n",
       "      <td>1.826682</td>\n",
       "      <td>1.859360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target         0         1         2         3         4         5  \\\n",
       "0       1  0.832239  1.233726  1.140988  2.165680 -1.597017 -0.743907   \n",
       "1       1 -0.137469 -0.010969  0.843637  0.966030  0.409513 -0.847683   \n",
       "2       1 -0.405876  0.109203  1.359791  1.225490 -0.138266 -1.679678   \n",
       "3       0 -0.376180  0.196114  0.779141  1.123773  0.374653 -0.947631   \n",
       "4       1 -1.964517  1.128601 -0.194799 -1.433777 -0.143446 -1.161713   \n",
       "\n",
       "          6         7         8  ...       190       191       192       193  \\\n",
       "0 -0.071826  0.116781 -0.635038  ...  0.077455  0.066486  2.200836  2.124988   \n",
       "1 -1.006673  0.749325 -1.147702  ... -0.583738 -1.836914  1.908090  1.263731   \n",
       "2  0.182724 -0.188638 -1.128553  ...  0.342459 -0.801281  2.540216  0.933610   \n",
       "3 -0.892223  0.621932 -0.999321  ... -0.272015 -2.344969  2.089854  1.595235   \n",
       "4 -2.380596  0.026122 -1.105232  ...  0.160001 -1.498763  2.403551  1.303866   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.882250  0.367745  1.330217  0.660291 -0.899856  1.536773  \n",
       "1 -1.759173 -0.579072  1.043836  0.452179  0.771279  1.454416  \n",
       "2 -1.590028  0.056035  1.889005  1.706726  0.912262  1.206671  \n",
       "3 -1.722826 -0.317329  1.074202  0.198977  0.917910  1.435312  \n",
       "4 -1.757287  0.949241  0.272723  2.771020  1.826682  1.859360  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =\"../../../../Data_preprocessing/RNA_post_autoencoder/encoded_data_binary_200.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.reset_index\n",
    "data.round(4)\n",
    "data=data.iloc[:,1:202 ] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.832239  1.233726  1.140988  2.165680 -1.597017 -0.743907 -0.071826   \n",
      "1   -0.137469 -0.010969  0.843637  0.966030  0.409513 -0.847683 -1.006673   \n",
      "2   -0.405876  0.109203  1.359791  1.225490 -0.138266 -1.679678  0.182724   \n",
      "3   -0.376180  0.196114  0.779141  1.123773  0.374653 -0.947631 -0.892223   \n",
      "4   -1.964517  1.128601 -0.194799 -1.433777 -0.143446 -1.161713 -2.380596   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "176 -0.442013  0.276400  0.702629  0.145038  0.253912 -1.027387 -0.954011   \n",
      "177  0.122423  0.435671  1.195094  1.099650 -0.651924 -1.125421 -0.957930   \n",
      "178 -0.338142  0.528099  0.594873  0.742365 -0.105854 -1.069006 -0.974031   \n",
      "179  0.151963  0.431527  0.093600  0.226152 -0.943175 -1.319361 -1.243683   \n",
      "180 -0.074435  0.889761  1.095850  0.759461 -0.669753 -0.916490 -0.742355   \n",
      "\n",
      "            7         8         9  ...       190       191       192  \\\n",
      "0    0.116781 -0.635038  0.548923  ...  0.077455  0.066486  2.200836   \n",
      "1    0.749325 -1.147702  0.098439  ... -0.583738 -1.836914  1.908090   \n",
      "2   -0.188638 -1.128553 -0.158276  ...  0.342459 -0.801281  2.540216   \n",
      "3    0.621932 -0.999321 -0.351488  ... -0.272015 -2.344969  2.089854   \n",
      "4    0.026122 -1.105232 -1.895611  ...  0.160001 -1.498763  2.403551   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "176  0.681825 -1.122671 -0.146015  ... -0.622276 -0.996579  2.183693   \n",
      "177  0.071794 -0.907884 -0.915887  ...  0.713566 -1.783126  2.620683   \n",
      "178  0.033968 -1.049163 -0.139647  ... -0.064509 -0.176194  2.319744   \n",
      "179  0.791549 -1.067336  0.581175  ... -1.036042 -0.832720  2.438087   \n",
      "180 -0.091989 -1.180757 -0.684140  ...  0.510227 -0.909601  2.493090   \n",
      "\n",
      "          193       194       195       196       197       198       199  \n",
      "0    2.124988 -0.882250  0.367745  1.330217  0.660291 -0.899856  1.536773  \n",
      "1    1.263731 -1.759173 -0.579072  1.043836  0.452179  0.771279  1.454416  \n",
      "2    0.933610 -1.590028  0.056035  1.889005  1.706726  0.912262  1.206671  \n",
      "3    1.595235 -1.722826 -0.317329  1.074202  0.198977  0.917910  1.435312  \n",
      "4    1.303866 -1.757287  0.949241  0.272723  2.771020  1.826682  1.859360  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "176  1.407046 -1.835858  0.038548  0.944488  1.428036  0.897753  1.317829  \n",
      "177  1.726230 -1.587190  0.388223  0.827569  0.461413  0.959736  1.543489  \n",
      "178  1.450573 -1.922804  0.924834  1.011755  1.676499  0.528183  1.373469  \n",
      "179  0.863552 -1.618766  0.002527  0.192175  1.809151  0.257342  1.017938  \n",
      "180  1.693442 -1.744715  0.995943  0.847521  1.176593  0.333622  1.856898  \n",
      "\n",
      "[181 rows x 200 columns]\n",
      "Numero de pacientes:  181\n"
     ]
    }
   ],
   "source": [
    "Y = data.Target # Target column\n",
    "\n",
    "X = data.iloc[:,1:202] # I selected all the columns by removing the Unnamed column (row id) and the Target column.\n",
    "\n",
    "print(X)\n",
    "print('Numero de pacientes: ',len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 144\n",
      "Target column size of the training set: 144\n",
      "Test set size: 37\n",
      "Target column size of the test set: 37\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125, stratify=Y)\n",
    "\n",
    "print('Training set size:', len(XTrain))\n",
    "print('Target column size of the training set:', len(yTrain))\n",
    "print('Test set size:', len(XTest))\n",
    "print('Target column size of the test set:', len(yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select the parameters of the model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 5, 10, 50],\n",
       "                         'min_samples_leaf': [1, 3],\n",
       "                         'min_samples_split': [2, 3, 4, 5],\n",
       "                         'n_estimators': [10, 15], 'random_state': [125]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'min_samples_leaf': [1, 3],\n",
    "              'min_samples_split': [2, 3, 4, 5],\n",
    "              'random_state':[125],\n",
    "              'n_estimators': [10, 15],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth':[None, 2, 5, 10,50]\n",
    "              }\n",
    "\n",
    "# I created a GridSearchCV which allows us to systematically evaluate and select the parameters of our model.\n",
    "# By indicating a model and the parameters to test, you can evaluate the performance of the first one based on the\n",
    "# seconds through cross validation.\n",
    "clf = GridSearchCV(\n",
    "        estimator  = RandomForestClassifier(),\n",
    "        param_grid = param_grid,\n",
    "        cv=5\n",
    "       )\n",
    "\n",
    "clf.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor estimación de parámetros según GridSearchCV:\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, min_samples_split=5,\n",
      "                       n_estimators=15, random_state=125)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejor estimación de parámetros según GridSearchCV:\")\n",
    "print(clf.best_estimator_)\n",
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result of the cross validation of the model with the best paramters:0.6187192118226601\n"
     ]
    }
   ],
   "source": [
    "print(\"Best result of the cross validation of the model with the best paramters:\" +str(clf.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the training dataset\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "yTrain=yTrain.to_numpy()\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTrain),1) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "yTest=yTest.to_numpy()\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training dataset:0.9652777777777778\n",
      "Final accuracy on the testing dataset: 0.5675675675675675\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy on the training dataset:' + str(contTrain/len(yTrain)))\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Training)------------------\n",
      "[[66  2]\n",
      " [ 3 73]]\n",
      "Input data:  [1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1]\n",
      "Prediction:        [1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
      " 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Confusion Matrix (Training)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Input data:  ' + str(np.array(yTrain)))\n",
    "print('Prediction:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        68\n",
      "           1       0.97      0.96      0.97        76\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.96      0.97      0.97       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[ 6 11]\n",
      " [ 5 15]]\n",
      "Input data:  [0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0]\n",
      "Prediction:        [0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Input data:  ' + str(np.array(yTest)))\n",
    "print('Prediction:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.35      0.43        17\n",
      "           1       0.58      0.75      0.65        20\n",
      "\n",
      "    accuracy                           0.57        37\n",
      "   macro avg       0.56      0.55      0.54        37\n",
      "weighted avg       0.56      0.57      0.55        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with relevance over 0:  104\n",
      "Features with relevance over 0.05:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 0.0\n",
      "1 = 0.0197539339449422\n",
      "2 = 0.0164592135126347\n",
      "3 = 0.013857126868887073\n",
      "4 = 0.004878682968522797\n",
      "5 = 0.0\n",
      "6 = 0.002775970385969977\n",
      "7 = 0.006278386422264703\n",
      "8 = 0.007699014421227391\n",
      "9 = 0.0\n",
      "10 = 0.0\n",
      "11 = 0.0029907387573202956\n",
      "12 = 0.006211699996422296\n",
      "13 = 0.0\n",
      "14 = 0.0\n",
      "15 = 0.005712904344584233\n",
      "16 = 0.011538264353843834\n",
      "17 = 0.006119341069769497\n",
      "18 = 0.0\n",
      "19 = 0.003775224942666266\n",
      "20 = 0.004470762696736658\n",
      "21 = 0.0\n",
      "22 = 0.014494109473532775\n",
      "23 = 0.010980504388129687\n",
      "24 = 0.0\n",
      "25 = 0.012318033535853154\n",
      "26 = 0.0\n",
      "27 = 0.007578899791468885\n",
      "28 = 0.009383768223360829\n",
      "29 = 0.0\n",
      "30 = 0.0\n",
      "31 = 0.0245916946772084\n",
      "32 = 0.0\n",
      "33 = 0.0\n",
      "34 = 0.007645190744664201\n",
      "35 = 0.0\n",
      "36 = 0.0\n",
      "37 = 0.01321042293867591\n",
      "38 = 0.0\n",
      "39 = 0.0\n",
      "40 = 0.0\n",
      "41 = 0.010600168990675446\n",
      "42 = 0.006410395231425949\n",
      "43 = 0.008557094234912957\n",
      "44 = 0.0\n",
      "45 = 0.007253848885054228\n",
      "46 = 0.0\n",
      "47 = 0.0\n",
      "48 = 0.007634301467953051\n",
      "49 = 0.007880440496852699\n",
      "50 = 0.0\n",
      "51 = 0.004509929438118313\n",
      "52 = 0.0\n",
      "53 = 0.0\n",
      "54 = 0.007977314672386951\n",
      "55 = 0.0\n",
      "56 = 0.002890747566917769\n",
      "57 = 0.024309165052277166\n",
      "58 = 0.015302801745409841\n",
      "59 = 0.0\n",
      "60 = 0.009985244644402166\n",
      "61 = 0.008643141495248882\n",
      "62 = 0.0033698463339152016\n",
      "63 = 0.0\n",
      "64 = 0.007539143724426415\n",
      "65 = 0.0036244399939911027\n",
      "66 = 0.0\n",
      "67 = 0.007893595933180187\n",
      "68 = 0.003268571512276534\n",
      "69 = 0.0\n",
      "70 = 0.00837806867319567\n",
      "71 = 0.0\n",
      "72 = 0.01563965504734052\n",
      "73 = 0.0\n",
      "74 = 0.003924751309879825\n",
      "75 = 0.0096715322091357\n",
      "76 = 0.004686285518088583\n",
      "77 = 0.0060860288513812895\n",
      "78 = 0.057373952937909055\n",
      "79 = 0.0060998643794570265\n",
      "80 = 0.0\n",
      "81 = 0.0\n",
      "82 = 0.005804154087430006\n",
      "83 = 0.0\n",
      "84 = 0.0\n",
      "85 = 0.0\n",
      "86 = 0.004972577510552142\n",
      "87 = 0.0\n",
      "88 = 0.011756622811133778\n",
      "89 = 0.0\n",
      "90 = 0.013611013611166536\n",
      "91 = 0.003927599401394345\n",
      "92 = 0.0\n",
      "93 = 0.0\n",
      "94 = 0.0\n",
      "95 = 0.011584748003872927\n",
      "96 = 0.0\n",
      "97 = 0.0\n",
      "98 = 0.014879110647009981\n",
      "99 = 0.008520636517426279\n",
      "100 = 0.0\n",
      "101 = 0.0133405956504232\n",
      "102 = 0.01272445923179838\n",
      "103 = 0.006009230938244311\n",
      "104 = 0.0\n",
      "105 = 0.02947687248588598\n",
      "106 = 0.005170797530058415\n",
      "107 = 0.0\n",
      "108 = 0.0\n",
      "109 = 0.01773009168361652\n",
      "110 = 0.0\n",
      "111 = 0.0\n",
      "112 = 0.0\n",
      "113 = 0.0\n",
      "114 = 0.004820292743403023\n",
      "115 = 0.0\n",
      "116 = 0.0\n",
      "117 = 0.005821789735218103\n",
      "118 = 0.0\n",
      "119 = 0.010117607716338201\n",
      "120 = 0.0\n",
      "121 = 0.0115061040608261\n",
      "122 = 0.0084739974406099\n",
      "123 = 0.0\n",
      "124 = 0.004763864580808282\n",
      "125 = 0.013030124971281446\n",
      "126 = 0.0\n",
      "127 = 0.0\n",
      "128 = 0.015688449953426067\n",
      "129 = 0.0028619798916047017\n",
      "130 = 0.010744969685082402\n",
      "131 = 0.0\n",
      "132 = 0.0\n",
      "133 = 0.0\n",
      "134 = 0.0\n",
      "135 = 0.0046424263508140105\n",
      "136 = 0.009400528230094539\n",
      "137 = 0.0\n",
      "138 = 0.0\n",
      "139 = 0.0019112561105184417\n",
      "140 = 0.007856048442724375\n",
      "141 = 0.0\n",
      "142 = 0.005414847543147536\n",
      "143 = 0.0\n",
      "144 = 0.020143051116875185\n",
      "145 = 0.035822494829332335\n",
      "146 = 0.009637004549225175\n",
      "147 = 0.0\n",
      "148 = 0.0\n",
      "149 = 0.0030377780948991286\n",
      "150 = 0.003787623629475134\n",
      "151 = 0.0\n",
      "152 = 0.0\n",
      "153 = 0.0\n",
      "154 = 0.003298840811619406\n",
      "155 = 0.0\n",
      "156 = 0.0\n",
      "157 = 0.008889091875506008\n",
      "158 = 0.0\n",
      "159 = 0.0\n",
      "160 = 0.001805359555285631\n",
      "161 = 0.0\n",
      "162 = 0.014491995800572808\n",
      "163 = 0.0\n",
      "164 = 0.014628855352984815\n",
      "165 = 0.010601775486972985\n",
      "166 = 0.005934995576047779\n",
      "167 = 0.0\n",
      "168 = 0.010281250237202142\n",
      "169 = 0.0\n",
      "170 = 0.0\n",
      "171 = 0.0\n",
      "172 = 0.005881235486062913\n",
      "173 = 0.0033867526001299356\n",
      "174 = 0.0\n",
      "175 = 0.0\n",
      "176 = 0.0\n",
      "177 = 0.015505314741354486\n",
      "178 = 0.0\n",
      "179 = 0.018615280018337763\n",
      "180 = 0.0\n",
      "181 = 0.003707702047727231\n",
      "182 = 0.0\n",
      "183 = 0.0\n",
      "184 = 0.0022034224605569997\n",
      "185 = 0.005471286277532119\n",
      "186 = 0.0\n",
      "187 = 0.0\n",
      "188 = 0.009355686260813992\n",
      "189 = 0.0\n",
      "190 = 0.0024558606532655174\n",
      "191 = 0.0\n",
      "192 = 0.0\n",
      "193 = 0.007678977467651554\n",
      "194 = 0.0053594719165662025\n",
      "195 = 0.02293470333605918\n",
      "196 = 0.001820084665018091\n",
      "197 = 0.0044670887825172655\n",
      "198 = 0.0\n",
      "199 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Through the created model we can see which attributes are the most significant to make a decision.\n",
    "# The most relevant attributes will be the ones placed at the top of the tree.\n",
    "features = list(X)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "elems_over_0 = np.fromiter((element for element in importances if element > 0), dtype = importances.dtype)\n",
    "print('Features with relevance over 0: ', len(elems_over_0))\n",
    "\n",
    "newArray = np.fromiter((element for element in importances if element > 0.05), dtype = importances.dtype)\n",
    "importances=newArray\n",
    "indices = np.argsort(importances)\n",
    "print('Features with relevance over 0.05: ', len(newArray))\n",
    "\n",
    "plt.title('Relevancia de los atributos')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Importancia relativa')\n",
    "plt.show()\n",
    "\n",
    "for name, importance in zip(X, model.feature_importances_):\n",
    "    print(name, \"=\", importance)\n",
    "\n",
    "# Attributes whose relevance is 0, will not be necessary to make the prediction of the target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
