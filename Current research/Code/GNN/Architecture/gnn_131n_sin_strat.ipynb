{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC1yqJaZPINt"
      },
      "source": [
        "# 1. Instalar librerias\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCvXPU7Wtwln",
        "outputId": "5cd14c97-71ec-469e-9c2d-387a94d06a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=274491 sha256=1c677246736404319a9cdabee151766ff6b006243b1f2a5324866141414011f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n"
          ]
        }
      ],
      "source": [
        "pip install torch-scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LME1Y91tzVE",
        "outputId": "51ca16c5-7b91-4f56-9c01-2e98ffefd64c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=516860 sha256=bdbb8fbdae5b81f163292af421baa38a7b7465aeed0105e3c78a34f91ab2f1c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n"
          ]
        }
      ],
      "source": [
        "pip install torch-sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt157k-3t1VD"
      },
      "outputs": [],
      "source": [
        "pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq4sGAzVPUJY"
      },
      "source": [
        "# 2. Crear dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r7QHvCssx_mH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai0AKF5OG0oR",
        "outputId": "6a122753-bbc9-4b2a-c8ed-7e2cc5e37a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oHbPJYt4G8xD"
      },
      "outputs": [],
      "source": [
        "genes = pd.read_csv('/content/drive/MyDrive/ART_Inv/Kinase_gene_matrix_X3_131_nodes.csv')\n",
        "Y = pd.read_csv('/content/drive/MyDrive/ART_Inv/Kinase_gene_matrix_classification.csv')\n",
        "\n",
        "genes = genes.iloc[:,1:132] \n",
        "Y = Y.iloc[:,1:2] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oVJyqnGwmFNd",
        "outputId": "b3e34bca-0ad2-4382-80c8-946e7cca0d6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57409fc7-2439-4be7-92e0-b47777fa92b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AKAP1</th>\n",
              "      <th>AKAP10</th>\n",
              "      <th>AKAP12</th>\n",
              "      <th>AKAP13</th>\n",
              "      <th>AKAP14</th>\n",
              "      <th>AKAP4</th>\n",
              "      <th>AKAP5</th>\n",
              "      <th>AKAP7</th>\n",
              "      <th>AKAP8</th>\n",
              "      <th>AKAP9</th>\n",
              "      <th>...</th>\n",
              "      <th>SKP2</th>\n",
              "      <th>TAB1</th>\n",
              "      <th>TAB2</th>\n",
              "      <th>TAB3</th>\n",
              "      <th>TCEB2</th>\n",
              "      <th>TEC</th>\n",
              "      <th>UBE2M</th>\n",
              "      <th>VCL</th>\n",
              "      <th>XRCC6</th>\n",
              "      <th>ZAP70</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34.608085</td>\n",
              "      <td>33.496161</td>\n",
              "      <td>33.708977</td>\n",
              "      <td>35.071896</td>\n",
              "      <td>22.030411</td>\n",
              "      <td>21.292506</td>\n",
              "      <td>25.036127</td>\n",
              "      <td>32.352171</td>\n",
              "      <td>32.364362</td>\n",
              "      <td>34.799151</td>\n",
              "      <td>...</td>\n",
              "      <td>32.63417</td>\n",
              "      <td>31.95379</td>\n",
              "      <td>34.91153</td>\n",
              "      <td>31.28668</td>\n",
              "      <td>34.75814</td>\n",
              "      <td>29.68056</td>\n",
              "      <td>33.82521</td>\n",
              "      <td>34.12352</td>\n",
              "      <td>35.24634</td>\n",
              "      <td>31.17945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.991203</td>\n",
              "      <td>33.321684</td>\n",
              "      <td>34.364882</td>\n",
              "      <td>35.360390</td>\n",
              "      <td>22.030411</td>\n",
              "      <td>22.762193</td>\n",
              "      <td>28.279929</td>\n",
              "      <td>32.332165</td>\n",
              "      <td>32.865812</td>\n",
              "      <td>35.333528</td>\n",
              "      <td>...</td>\n",
              "      <td>31.80604</td>\n",
              "      <td>31.26559</td>\n",
              "      <td>35.52924</td>\n",
              "      <td>31.96868</td>\n",
              "      <td>34.38246</td>\n",
              "      <td>30.78769</td>\n",
              "      <td>32.57963</td>\n",
              "      <td>35.34613</td>\n",
              "      <td>35.91455</td>\n",
              "      <td>29.38780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.383751</td>\n",
              "      <td>33.224008</td>\n",
              "      <td>31.941494</td>\n",
              "      <td>35.090412</td>\n",
              "      <td>22.030411</td>\n",
              "      <td>21.292506</td>\n",
              "      <td>29.082875</td>\n",
              "      <td>32.506326</td>\n",
              "      <td>33.310765</td>\n",
              "      <td>34.894155</td>\n",
              "      <td>...</td>\n",
              "      <td>32.78642</td>\n",
              "      <td>31.28554</td>\n",
              "      <td>36.91118</td>\n",
              "      <td>31.50909</td>\n",
              "      <td>34.43952</td>\n",
              "      <td>31.05624</td>\n",
              "      <td>33.20477</td>\n",
              "      <td>34.60666</td>\n",
              "      <td>36.05801</td>\n",
              "      <td>29.53435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.504572</td>\n",
              "      <td>34.388289</td>\n",
              "      <td>33.921804</td>\n",
              "      <td>35.522805</td>\n",
              "      <td>22.030411</td>\n",
              "      <td>24.479975</td>\n",
              "      <td>28.863519</td>\n",
              "      <td>32.080430</td>\n",
              "      <td>32.663189</td>\n",
              "      <td>35.605425</td>\n",
              "      <td>...</td>\n",
              "      <td>31.60685</td>\n",
              "      <td>30.86918</td>\n",
              "      <td>35.41662</td>\n",
              "      <td>32.18003</td>\n",
              "      <td>34.36787</td>\n",
              "      <td>30.20403</td>\n",
              "      <td>33.48316</td>\n",
              "      <td>36.13525</td>\n",
              "      <td>35.75676</td>\n",
              "      <td>29.32770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33.960169</td>\n",
              "      <td>32.784996</td>\n",
              "      <td>34.566394</td>\n",
              "      <td>36.050989</td>\n",
              "      <td>22.030411</td>\n",
              "      <td>21.292506</td>\n",
              "      <td>25.036127</td>\n",
              "      <td>25.443711</td>\n",
              "      <td>33.156714</td>\n",
              "      <td>35.929770</td>\n",
              "      <td>...</td>\n",
              "      <td>32.31155</td>\n",
              "      <td>28.88966</td>\n",
              "      <td>36.12132</td>\n",
              "      <td>32.74898</td>\n",
              "      <td>32.50010</td>\n",
              "      <td>27.76103</td>\n",
              "      <td>33.09984</td>\n",
              "      <td>35.03527</td>\n",
              "      <td>36.33015</td>\n",
              "      <td>30.59498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>34.044939</td>\n",
              "      <td>33.310459</td>\n",
              "      <td>34.008777</td>\n",
              "      <td>35.508424</td>\n",
              "      <td>22.537241</td>\n",
              "      <td>21.811701</td>\n",
              "      <td>26.714716</td>\n",
              "      <td>30.997207</td>\n",
              "      <td>33.140357</td>\n",
              "      <td>34.738921</td>\n",
              "      <td>...</td>\n",
              "      <td>31.66193</td>\n",
              "      <td>31.97549</td>\n",
              "      <td>36.17351</td>\n",
              "      <td>31.01873</td>\n",
              "      <td>33.79607</td>\n",
              "      <td>29.74909</td>\n",
              "      <td>33.49762</td>\n",
              "      <td>35.38283</td>\n",
              "      <td>35.53767</td>\n",
              "      <td>29.29301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>32.418678</td>\n",
              "      <td>34.110995</td>\n",
              "      <td>33.243186</td>\n",
              "      <td>33.134963</td>\n",
              "      <td>22.537241</td>\n",
              "      <td>21.811701</td>\n",
              "      <td>28.895484</td>\n",
              "      <td>33.607378</td>\n",
              "      <td>33.533021</td>\n",
              "      <td>35.944165</td>\n",
              "      <td>...</td>\n",
              "      <td>32.99457</td>\n",
              "      <td>28.61897</td>\n",
              "      <td>36.27230</td>\n",
              "      <td>31.53447</td>\n",
              "      <td>36.19576</td>\n",
              "      <td>31.71446</td>\n",
              "      <td>34.16600</td>\n",
              "      <td>32.78765</td>\n",
              "      <td>35.50224</td>\n",
              "      <td>29.65655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>33.336106</td>\n",
              "      <td>33.381949</td>\n",
              "      <td>31.526169</td>\n",
              "      <td>35.679063</td>\n",
              "      <td>22.537241</td>\n",
              "      <td>21.811701</td>\n",
              "      <td>28.132297</td>\n",
              "      <td>32.065304</td>\n",
              "      <td>32.283709</td>\n",
              "      <td>35.312405</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86507</td>\n",
              "      <td>30.50706</td>\n",
              "      <td>36.31789</td>\n",
              "      <td>32.47015</td>\n",
              "      <td>33.71158</td>\n",
              "      <td>31.08636</td>\n",
              "      <td>32.68856</td>\n",
              "      <td>35.17108</td>\n",
              "      <td>35.22805</td>\n",
              "      <td>30.95118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>34.026063</td>\n",
              "      <td>33.764835</td>\n",
              "      <td>33.884949</td>\n",
              "      <td>35.482404</td>\n",
              "      <td>22.537241</td>\n",
              "      <td>21.811701</td>\n",
              "      <td>29.201802</td>\n",
              "      <td>30.616063</td>\n",
              "      <td>34.317215</td>\n",
              "      <td>35.289050</td>\n",
              "      <td>...</td>\n",
              "      <td>32.84061</td>\n",
              "      <td>32.27365</td>\n",
              "      <td>34.55019</td>\n",
              "      <td>32.38527</td>\n",
              "      <td>33.07973</td>\n",
              "      <td>30.64727</td>\n",
              "      <td>32.10466</td>\n",
              "      <td>35.00358</td>\n",
              "      <td>34.81409</td>\n",
              "      <td>30.96574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>34.793381</td>\n",
              "      <td>34.236983</td>\n",
              "      <td>36.290154</td>\n",
              "      <td>35.137711</td>\n",
              "      <td>22.537241</td>\n",
              "      <td>21.811701</td>\n",
              "      <td>29.452123</td>\n",
              "      <td>30.911974</td>\n",
              "      <td>33.108600</td>\n",
              "      <td>34.671708</td>\n",
              "      <td>...</td>\n",
              "      <td>32.83655</td>\n",
              "      <td>30.88783</td>\n",
              "      <td>34.66564</td>\n",
              "      <td>31.35899</td>\n",
              "      <td>34.27163</td>\n",
              "      <td>31.48586</td>\n",
              "      <td>33.27269</td>\n",
              "      <td>34.78994</td>\n",
              "      <td>37.01634</td>\n",
              "      <td>30.50824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>181 rows × 131 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57409fc7-2439-4be7-92e0-b47777fa92b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57409fc7-2439-4be7-92e0-b47777fa92b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57409fc7-2439-4be7-92e0-b47777fa92b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         AKAP1     AKAP10     AKAP12     AKAP13     AKAP14      AKAP4  \\\n",
              "0    34.608085  33.496161  33.708977  35.071896  22.030411  21.292506   \n",
              "1    33.991203  33.321684  34.364882  35.360390  22.030411  22.762193   \n",
              "2    33.383751  33.224008  31.941494  35.090412  22.030411  21.292506   \n",
              "3    33.504572  34.388289  33.921804  35.522805  22.030411  24.479975   \n",
              "4    33.960169  32.784996  34.566394  36.050989  22.030411  21.292506   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "176  34.044939  33.310459  34.008777  35.508424  22.537241  21.811701   \n",
              "177  32.418678  34.110995  33.243186  33.134963  22.537241  21.811701   \n",
              "178  33.336106  33.381949  31.526169  35.679063  22.537241  21.811701   \n",
              "179  34.026063  33.764835  33.884949  35.482404  22.537241  21.811701   \n",
              "180  34.793381  34.236983  36.290154  35.137711  22.537241  21.811701   \n",
              "\n",
              "         AKAP5      AKAP7      AKAP8      AKAP9  ...      SKP2      TAB1  \\\n",
              "0    25.036127  32.352171  32.364362  34.799151  ...  32.63417  31.95379   \n",
              "1    28.279929  32.332165  32.865812  35.333528  ...  31.80604  31.26559   \n",
              "2    29.082875  32.506326  33.310765  34.894155  ...  32.78642  31.28554   \n",
              "3    28.863519  32.080430  32.663189  35.605425  ...  31.60685  30.86918   \n",
              "4    25.036127  25.443711  33.156714  35.929770  ...  32.31155  28.88966   \n",
              "..         ...        ...        ...        ...  ...       ...       ...   \n",
              "176  26.714716  30.997207  33.140357  34.738921  ...  31.66193  31.97549   \n",
              "177  28.895484  33.607378  33.533021  35.944165  ...  32.99457  28.61897   \n",
              "178  28.132297  32.065304  32.283709  35.312405  ...  32.86507  30.50706   \n",
              "179  29.201802  30.616063  34.317215  35.289050  ...  32.84061  32.27365   \n",
              "180  29.452123  30.911974  33.108600  34.671708  ...  32.83655  30.88783   \n",
              "\n",
              "         TAB2      TAB3     TCEB2       TEC     UBE2M       VCL     XRCC6  \\\n",
              "0    34.91153  31.28668  34.75814  29.68056  33.82521  34.12352  35.24634   \n",
              "1    35.52924  31.96868  34.38246  30.78769  32.57963  35.34613  35.91455   \n",
              "2    36.91118  31.50909  34.43952  31.05624  33.20477  34.60666  36.05801   \n",
              "3    35.41662  32.18003  34.36787  30.20403  33.48316  36.13525  35.75676   \n",
              "4    36.12132  32.74898  32.50010  27.76103  33.09984  35.03527  36.33015   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "176  36.17351  31.01873  33.79607  29.74909  33.49762  35.38283  35.53767   \n",
              "177  36.27230  31.53447  36.19576  31.71446  34.16600  32.78765  35.50224   \n",
              "178  36.31789  32.47015  33.71158  31.08636  32.68856  35.17108  35.22805   \n",
              "179  34.55019  32.38527  33.07973  30.64727  32.10466  35.00358  34.81409   \n",
              "180  34.66564  31.35899  34.27163  31.48586  33.27269  34.78994  37.01634   \n",
              "\n",
              "        ZAP70  \n",
              "0    31.17945  \n",
              "1    29.38780  \n",
              "2    29.53435  \n",
              "3    29.32770  \n",
              "4    30.59498  \n",
              "..        ...  \n",
              "176  29.29301  \n",
              "177  29.65655  \n",
              "178  30.95118  \n",
              "179  30.96574  \n",
              "180  30.50824  \n",
              "\n",
              "[181 rows x 131 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-ZxQF6wFKflj"
      },
      "outputs": [],
      "source": [
        "edge_index = torch.tensor([[ 31,  78, 107,  78, 107, 106,  79, 106,  79, 106,  76, 106,  76,\n",
        "        33,  30,  55,  30,  33, 107,  55,  79,  55,  79,  55,  49,  55,\n",
        "        76,  55,  34,  55,  34, 101,  34,  55,  82, 101,  82,  55,  82,\n",
        "       101,  30,   9,   5,  99,  72,  23,   5,  18,  46,  18,  51,  18,\n",
        "        51,  18,   5,  23,  46,  18,  46,  18,  46,  23,  46, 130,  72,\n",
        "       130,   3,  94,  87,  94,   3,  94,  44,  94,  44,  94, 123,  94,\n",
        "       123,  94,  48,  94,  87,  94,  87,  94,  87,  94,  87,  94,  87,\n",
        "        94,  87,  94, 115,  94,  83,  94,   4,  94,  88,  94,  88,  94,\n",
        "        88,  95,  88,  95,  92,  95,  45,  95,  45,  64,  12,  16,  64,\n",
        "        92,  95,   6,  95,  92,  36,  95,  92,  16,  95,  59,  95,  59,\n",
        "        16,  95,   2,  53,  95,  39,  53,  95,  56,  36,  95,  38,  36,\n",
        "        64,  38, 128,  95,  93, 128, 110,  63, 128,  64, 114, 128, 110,\n",
        "        50, 110,  74,  50, 110,  50, 110,  50, 110,  50, 110,  50, 110,\n",
        "        50, 110,  50, 110, 122,   8, 122,   8, 122, 110, 122, 121, 111,\n",
        "        70, 122,   8, 122, 121, 122, 121, 111,  70, 111,  70, 111,  70,\n",
        "       111,  70, 111,  70, 111,  70, 111,  28, 111,  90, 111,  15, 116,\n",
        "        90, 111,  28, 111,  90, 116,  90,   1,  90,   1,  81, 116, 100,\n",
        "       116,  26,   1,  54, 112,   1, 112,  84, 112,  84,  26,  84,  32,\n",
        "        84,  32,  84,  98,  84,  98,  54,  98,  54,  98,  54,  98,  54,\n",
        "        98,  54,  98,  54,  20, 120, 118, 120,  86, 120,  86, 120,  86,\n",
        "       120,  86, 120,  86,  27,  86, 120,  86, 120,  86, 120,  58,  27,\n",
        "        17,  69,  17,  60, 118,  60,  86,  60,  86,  60,  86,  60,  40,\n",
        "        60,  40,  60,  20,  60,  71,  60,  71,  69, 104,  69,  71,  69,\n",
        "        71,  69,  71,  69,  31,  57,  14,  62,  14,  62,  14, 127,  89,\n",
        "        85,  89,  85,  89,  69,  89,  69,  89,  69,  61,  62, 103,  62,\n",
        "        89,  62,  89,  62,  89,  62,  22, 127,  52, 127,  52, 127,  52,\n",
        "        85,  31,  85,  13,  85,  31,  85,  13,  85, 107,  85,   9,  19,\n",
        "        20,  72,  21,  73,  93,  87,  94,  76,  92, 102,  95,  80,  55,\n",
        "        29,  31,  73,  32,  29, 114,   9,  32,  88,  97,  39,  25,  48,\n",
        "       115,  44,  39,  45,  31,  46,  58,  91,  48,  92, 113,  83,  76,\n",
        "        72,  87,   4,  96,  29,  22,  87, 110,  37, 119,  38, 130,  35,\n",
        "       108,  92,  10,  38,  31,  35,  19,  12,  26,  47,  31,  73,  19,\n",
        "        87,   6,  93,   9,  88,  92,  48,   7, 123,  82,  48,   0, 124,\n",
        "        88, 124,  95,   4,  90,  77,   8,   6,   4,  88,  79,   0,  89,\n",
        "        92,  98, 113,  87,  91,  93,  88,  86,   6,   5,  93,   3,  92,\n",
        "        86,   0,  92,   6,  79,  37,  93, 119, 118,  11,  82,  68,  93,\n",
        "         4,  96,  89,   7,  58,  87,   0,  12,   8,  38,   6,  35,  17,\n",
        "         3,  96,  45,  88,  35,  66,   0,  67,  44,   9,  63,  43, 104,\n",
        "        39, 107,  98,   0,  50,  70,  35,  31, 112, 113, 110, 108,  55,\n",
        "        31,  73,  32, 109, 114,  72,  33,  30,  31,  75, 113,  71, 107,\n",
        "        73, 115,  29,  48,  87, 123,  89, 124, 107, 105,  22,  22,  29,\n",
        "        54,  88,  44,  20,  52,  26,  26,  73, 125,  71,  69,  30,  24,\n",
        "        31, 127, 107,  23,  72,  20,  22,  28,  86,  10,  12,  68,  82,\n",
        "       120,  10, 121,  83, 118,  92,  93,  89,  94,  76, 112, 102,  76,\n",
        "        24,  95,  34, 118,  92,  22,  83,  68,  89,  22,  91,  39,  90,\n",
        "        29,  85,  96,  82,  87,  52, 117,  65,  89, 105,  88,  67,   9,\n",
        "        37,  79,  66,  21,  22, 117,  69,   6, 127,  77,  23,  89,  28,\n",
        "        87,  10,   5, 126,  82, 121,   0,  20,  88,  24, 102, 109,  83,\n",
        "        20,  12,  41,  68,  59,   4,  42,  93,  51,  92,  61,  38,  63,\n",
        "        59,  62,  22,  38,  29,  40,  72, 127, 129, 125,  73,  26, 107,\n",
        "        24,  30,  22, 107,  67,  12, 107,  11,  31,  13,  20,   3,  89,\n",
        "         9,  91,  87, 121,  83,  23,  92,  10,  34,  46,   3,  35,  79,\n",
        "        51,  82,  59,  88,  61,  10, 121,  66,  24,  65,  22,  67,  94,\n",
        "        30,  86,  12,  82, 108,  90,  11,  83,  30,  92,  88],\n",
        "                          [ 19,  20,  72,  21,  73,  93,  87,  94,  76,  92, 102,  95,  80,\n",
        "        55,  29,  31,  73,  32,  29, 114,   9,  32,  88,  97,  39,  25,\n",
        "        48, 115,  44,  39,  45,  31,  46,  58,  91,  48,  92, 113,  83,\n",
        "        76,  72,  87,   4,  96,  29,  22,  87, 110,  37, 119,  38, 130,\n",
        "        35, 108,  92,  10,  38,  31,  35,  19,  12,  26,  47,  31,  73,\n",
        "        19,  87,   6,  93,   9,  88,  92,  48,   7, 123,  82,  48,   0,\n",
        "       124,  88, 124,  95,   4,  90,  77,   8,   6,   4,  88,  79,   0,\n",
        "        89,  92,  98, 113,  87,  91,  93,  88,  86,   6,   5,  93,   3,\n",
        "        92,  86,   0,  92,   6,  79,  37,  93, 119, 118,  11,  82,  68,\n",
        "        93,   4,  96,  89,   7,  58,  87,   0,  12,   8,  38,   6,  35,\n",
        "        17,   3,  96,  45,  88,  35,  66,   0,  67,  44,   9,  63,  43,\n",
        "       104,  39, 107,  98,   0,  50,  70,  35,  31, 112, 113, 110, 108,\n",
        "        55,  31,  73,  32, 109, 114,  72,  33,  30,  31,  75, 113,  71,\n",
        "       107,  73, 115,  29,  48,  87, 123,  89, 124, 107, 105,  22,  22,\n",
        "        29,  54,  88,  44,  20,  52,  26,  26,  73, 125,  71,  69,  30,\n",
        "        24,  31, 127, 107,  23,  72,  20,  22,  28,  86,  10,  12,  68,\n",
        "        82, 120,  10, 121,  83, 118,  92,  93,  89,  94,  76, 112, 102,\n",
        "        76,  24,  95,  34, 118,  92,  22,  83,  68,  89,  22,  91,  39,\n",
        "        90,  29,  85,  96,  82,  87,  52, 117,  65,  89, 105,  88,  67,\n",
        "         9,  37,  79,  66,  21,  22, 117,  69,   6, 127,  77,  23,  89,\n",
        "        28,  87,  10,   5, 126,  82, 121,   0,  20,  88,  24, 102, 109,\n",
        "        83,  20,  12,  41,  68,  59,   4,  42,  93,  51,  92,  61,  38,\n",
        "        63,  59,  62,  22,  38,  29,  40,  72, 127, 129, 125,  73,  26,\n",
        "       107,  24,  30,  22, 107,  67,  12, 107,  11,  31,  13,  20,   3,\n",
        "        89,   9,  91,  87, 121,  83,  23,  92,  10,  34,  46,   3,  35,\n",
        "        79,  51,  82,  59,  88,  61,  10, 121,  66,  24,  65,  22,  67,\n",
        "        94,  30,  86,  12,  82, 108,  90,  11,  83,  30,  92,  88,  31,\n",
        "        78, 107,  78, 107, 106,  79, 106,  79, 106,  76, 106,  76,  33,\n",
        "        30,  55,  30,  33, 107,  55,  79,  55,  79,  55,  49,  55,  76,\n",
        "        55,  34,  55,  34, 101,  34,  55,  82, 101,  82,  55,  82, 101,\n",
        "        30,   9,   5,  99,  72,  23,   5,  18,  46,  18,  51,  18,  51,\n",
        "        18,   5,  23,  46,  18,  46,  18,  46,  23,  46, 130,  72, 130,\n",
        "         3,  94,  87,  94,   3,  94,  44,  94,  44,  94, 123,  94, 123,\n",
        "        94,  48,  94,  87,  94,  87,  94,  87,  94,  87,  94,  87,  94,\n",
        "        87,  94, 115,  94,  83,  94,   4,  94,  88,  94,  88,  94,  88,\n",
        "        95,  88,  95,  92,  95,  45,  95,  45,  64,  12,  16,  64,  92,\n",
        "        95,   6,  95,  92,  36,  95,  92,  16,  95,  59,  95,  59,  16,\n",
        "        95,   2,  53,  95,  39,  53,  95,  56,  36,  95,  38,  36,  64,\n",
        "        38, 128,  95,  93, 128, 110,  63, 128,  64, 114, 128, 110,  50,\n",
        "       110,  74,  50, 110,  50, 110,  50, 110,  50, 110,  50, 110,  50,\n",
        "       110,  50, 110, 122,   8, 122,   8, 122, 110, 122, 121, 111,  70,\n",
        "       122,   8, 122, 121, 122, 121, 111,  70, 111,  70, 111,  70, 111,\n",
        "        70, 111,  70, 111,  70, 111,  28, 111,  90, 111,  15, 116,  90,\n",
        "       111,  28, 111,  90, 116,  90,   1,  90,   1,  81, 116, 100, 116,\n",
        "        26,   1,  54, 112,   1, 112,  84, 112,  84,  26,  84,  32,  84,\n",
        "        32,  84,  98,  84,  98,  54,  98,  54,  98,  54,  98,  54,  98,\n",
        "        54,  98,  54,  20, 120, 118, 120,  86, 120,  86, 120,  86, 120,\n",
        "        86, 120,  86,  27,  86, 120,  86, 120,  86, 120,  58,  27,  17,\n",
        "        69,  17,  60, 118,  60,  86,  60,  86,  60,  86,  60,  40,  60,\n",
        "        40,  60,  20,  60,  71,  60,  71,  69, 104,  69,  71,  69,  71,\n",
        "        69,  71,  69,  31,  57,  14,  62,  14,  62,  14, 127,  89,  85,\n",
        "        89,  85,  89,  69,  89,  69,  89,  69,  61,  62, 103,  62,  89,\n",
        "        62,  89,  62,  89,  62,  22, 127,  52, 127,  52, 127,  52,  85,\n",
        "        31,  85,  13,  85,  31,  85,  13,  85, 107,  85,   9]], dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7amtjIdoIsy6",
        "outputId": "d40c1315-fc8c-4017-d284-4b60c4ddc648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1]), Data(x=[131], edge_index=[2, 700], y=[1, 1])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "list_data=[]\n",
        "\n",
        "for g in range(181):\n",
        "  b=[]\n",
        "  for i in genes.iloc[g].to_numpy():\n",
        "    a=[]\n",
        "    a.append(i*10)\n",
        "    b.append(a)\n",
        "  x = torch.tensor([b], dtype=torch.float)\n",
        "  x = torch.reshape(x, (-1,))\n",
        "  edge_index = edge_index\n",
        "  y = torch.tensor([Y.iloc[g].to_numpy()], dtype=torch.float)\n",
        "  data = Data(x=x, edge_index=edge_index, y=y)\n",
        "  list_data.append(data)\n",
        "\n",
        "print(list_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3k2zK2IPbHq"
      },
      "source": [
        "# 3. Dibujar grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qfYKryD5yBys"
      },
      "outputs": [],
      "source": [
        "def plot_graph(data,description=True):\n",
        "    edges_raw = data.edge_index.numpy()\n",
        "    edges = [(x, y) for x, y in zip(edges_raw[0, :], edges_raw[1, :])]\n",
        "    labels = data.x.numpy()\n",
        "    G = nx.Graph()\n",
        "    print(G)\n",
        "    G.add_nodes_from(list(range(np.max(edges_raw))))\n",
        "    G.add_edges_from(edges)\n",
        "    plt.subplot(111)\n",
        "    options = {\n",
        "       'node_size': 100,\n",
        "       'width': 1,\n",
        "    }\n",
        "    nx.draw(G, with_labels=description, node_color=labels.tolist(), cmap=plt.cm.tab10, font_weight='bold', **options)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD0bzuX7yNsr",
        "outputId": "8376fb9c-2b30-4aee-9def-f7c0edd7e6ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Algunas estadísticas del grafo:\n",
            "Número de Características: 1\n",
            "Número de Nodos: 131\n",
            "Número de bordes: 700\n",
            "Grado promedio de nodos: 5.34\n",
            "¿Contiene nodos aislados?: False\n",
            "¿Contiene autoloops?: False\n",
            "¿Es no dirigido?: True\n"
          ]
        }
      ],
      "source": [
        "print(\"Algunas estadísticas del grafo:\")\n",
        "print(f'Número de Características: {data.num_features}')\n",
        "print(f'Número de Nodos: {data.num_nodes}')\n",
        "print(f'Número de bordes: {data.num_edges}')\n",
        "print(f'Grado promedio de nodos: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'¿Contiene nodos aislados?: {data.contains_isolated_nodes()}')\n",
        "print(f'¿Contiene autoloops?: {data.contains_self_loops()}')\n",
        "print(f'¿Es no dirigido?: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "V6QJGNgNyTYz",
        "outputId": "a1c18b31-f6bc-4dc1-d968-e68ea3eb0089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph with 0 nodes and 0 edges\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_graph(data,True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDKdoDbFPgt_"
      },
      "source": [
        "# 4. Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eZ-3eb2f2QLa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
        "\n",
        "\n",
        "class SAGEConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(SAGEConv, self).__init__(aggr='max')\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "        self.act = torch.nn.ReLU()\n",
        "        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
        "        self.update_act = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        edge_index, _ = remove_self_loops(edge_index)\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        x_j = self.lin(x_j)\n",
        "        x_j = self.act(x_j)\n",
        "\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
        "        new_embedding = self.update_lin(new_embedding)\n",
        "        new_embedding = self.update_act(new_embedding)\n",
        "        return new_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F-x76x9G2J79"
      },
      "outputs": [],
      "source": [
        "embed_dim = 131\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import TopKPooling\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = SAGEConv(embed_dim,131)\n",
        "        self.pool1 = TopKPooling(131, ratio=0.8)\n",
        "        self.conv2 = SAGEConv(131, 131)\n",
        "        self.pool2 = TopKPooling(131, ratio=0.8)\n",
        "        self.item_embedding = torch.nn.Embedding(num_embeddings=393, embedding_dim=embed_dim)\n",
        "        self.lin1 = torch.nn.Linear(262, 65)\n",
        "        self.lin3 = torch.nn.Linear(65, 1)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        print(self)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = torch.tensor(x).to(torch.int)\n",
        "        x = self.item_embedding(x)\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
        "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
        "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9bYFlDSQmp8"
      },
      "source": [
        "# 5. New attempt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yU3-sfNc1du6"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Keeps track of most recent, average, sum, and count of a metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YrOOBkThcGRZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def evaluate(loader, model):\n",
        "    model.eval()  \n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    # Batches\n",
        "    for data in loader:\n",
        "        data = data\n",
        "        pred = model(data).detach().numpy()\n",
        "        label = data.y.detach().numpy()\n",
        "        label = label.squeeze(1)\n",
        "        predictions.append(pred)\n",
        "        labels.append(label)\n",
        "\n",
        "    return roc_auc_score(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OdHY5W4tQoKE"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "def train_net():\n",
        "    torch.manual_seed(7)\n",
        "    np.random.seed(7)\n",
        "    best_acc = 0\n",
        "\n",
        "    model = Net()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    model = model\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    train_loader = list_data[0:144]\n",
        "    test_loader = list_data[145:182]\n",
        "    # val_loader = list_data[172:182]\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(0,35):\n",
        "        train_loss = train(train_loader=train_loader,\n",
        "                           model=model,\n",
        "                           criterion=criterion,\n",
        "                           optimizer=optimizer,\n",
        "                           epoch=epoch)\n",
        "\n",
        "\n",
        "        train_acc = evaluate(train_loader, model)\n",
        "        # val_acc = evaluate(val_loader, model)\n",
        "        test_acc = evaluate(test_loader, model)\n",
        "        print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f},  Test Auc: {:.5f}'.\n",
        "              format(epoch, train_loss, train_acc,  test_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xmfMqeBuSLpE"
      },
      "outputs": [],
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "    \"\"\"\n",
        "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
        "    :param optimizer: optimizer with the gradients to be clipped\n",
        "    :param grad_clip: clip value\n",
        "    \"\"\"\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aH237AjFQw0n"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()  \n",
        "\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    # Batches\n",
        "    for i, data in enumerate(train_loader):\n",
        "        data = data\n",
        "        label = data.y\n",
        "        label = label.squeeze(1)\n",
        "\n",
        "        # Forward prop.\n",
        "        out = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(out, label)\n",
        "\n",
        "        # Back prop.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        clip_gradient(optimizer, 5)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Keep track of metrics\n",
        "        losses.update(loss.item())\n",
        "\n",
        "        # Print status\n",
        "        step = 20\n",
        "        if i % step == 0:\n",
        "            status = 'Epoch: [{0}][{1}/{2}]\\t' \\\n",
        "                     'Loss {loss.val:.5f} ({loss.avg:.5f})\\t'.format(epoch, i,\n",
        "                                                                     len(train_loader),\n",
        "                                                                     loss=losses)\n",
        "            # print(status)\n",
        "\n",
        "    return losses.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoZUTpRtdqbM",
        "outputId": "28221965-89a8-42c1-d9fe-af961dc689da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): SAGEConv()\n",
            "  (pool1): TopKPooling(131, ratio=0.8, multiplier=1.0)\n",
            "  (conv2): SAGEConv()\n",
            "  (pool2): TopKPooling(131, ratio=0.8, multiplier=1.0)\n",
            "  (item_embedding): Embedding(393, 131)\n",
            "  (lin1): Linear(in_features=262, out_features=65, bias=True)\n",
            "  (lin3): Linear(in_features=65, out_features=1, bias=True)\n",
            "  (act1): ReLU()\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 0.71225, Train Auc: 0.56105,  Test Auc: 0.61250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 0.71935, Train Auc: 0.69387,  Test Auc: 0.41875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 002, Loss: 0.69179, Train Auc: 0.72678,  Test Auc: 0.49062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 003, Loss: 0.69351, Train Auc: 0.75346,  Test Auc: 0.53437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004, Loss: 0.68952, Train Auc: 0.78033,  Test Auc: 0.50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 005, Loss: 0.69036, Train Auc: 0.81772,  Test Auc: 0.49063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 006, Loss: 0.68932, Train Auc: 0.80818,  Test Auc: 0.54688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 007, Loss: 0.69128, Train Auc: 0.80156,  Test Auc: 0.50313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 008, Loss: 0.68847, Train Auc: 0.78364,  Test Auc: 0.38750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 009, Loss: 0.68772, Train Auc: 0.82103,  Test Auc: 0.45937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.69132, Train Auc: 0.72191,  Test Auc: 0.48750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 011, Loss: 0.69306, Train Auc: 0.82181,  Test Auc: 0.50313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 012, Loss: 0.68224, Train Auc: 0.83096,  Test Auc: 0.47187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 013, Loss: 0.67569, Train Auc: 0.85258,  Test Auc: 0.47500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 014, Loss: 0.64156, Train Auc: 0.87439,  Test Auc: 0.41875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 015, Loss: 0.60524, Train Auc: 0.90964,  Test Auc: 0.46875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 016, Loss: 0.55774, Train Auc: 0.93223,  Test Auc: 0.50313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 017, Loss: 0.45264, Train Auc: 0.94684,  Test Auc: 0.49375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 018, Loss: 0.43308, Train Auc: 0.94917,  Test Auc: 0.45312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 019, Loss: 0.42032, Train Auc: 0.95755,  Test Auc: 0.45938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 020, Loss: 0.39477, Train Auc: 0.94567,  Test Auc: 0.43125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 021, Loss: 0.39941, Train Auc: 0.96767,  Test Auc: 0.40625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 022, Loss: 0.33776, Train Auc: 0.97527,  Test Auc: 0.46250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 023, Loss: 0.25840, Train Auc: 0.98286,  Test Auc: 0.42188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 024, Loss: 0.29959, Train Auc: 0.98247,  Test Auc: 0.50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 025, Loss: 0.23223, Train Auc: 0.98793,  Test Auc: 0.46563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 026, Loss: 0.22917, Train Auc: 0.98520,  Test Auc: 0.60938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 027, Loss: 0.21444, Train Auc: 0.99124,  Test Auc: 0.50313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 028, Loss: 0.19199, Train Auc: 0.99182,  Test Auc: 0.51562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 029, Loss: 0.25520, Train Auc: 0.99163,  Test Auc: 0.53438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 030, Loss: 0.14518, Train Auc: 0.99825,  Test Auc: 0.57812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 031, Loss: 0.22635, Train Auc: 0.99883,  Test Auc: 0.58437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 032, Loss: 0.11506, Train Auc: 0.99864,  Test Auc: 0.55312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 033, Loss: 0.15187, Train Auc: 0.99864,  Test Auc: 0.52812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 034, Loss: 0.10658, Train Auc: 0.99961,  Test Auc: 0.54375\n"
          ]
        }
      ],
      "source": [
        "loss = train_net() #80-20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_QUGpIfDjOVb"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "def train_net():\n",
        "    torch.manual_seed(7)\n",
        "    np.random.seed(7)\n",
        "    best_acc = 0\n",
        "\n",
        "    model = Net()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    model = model\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    train_loader = list_data[0:154]\n",
        "    test_loader = list_data[155:182]\n",
        "    # val_loader = list_data[172:182]\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(0, 35):\n",
        "        train_loss = train(train_loader=train_loader,\n",
        "                           model=model,\n",
        "                           criterion=criterion,\n",
        "                           optimizer=optimizer,\n",
        "                           epoch=epoch)\n",
        "\n",
        "\n",
        "        train_acc = evaluate(train_loader, model)\n",
        "        # val_acc = evaluate(val_loader, model)\n",
        "        test_acc = evaluate(test_loader, model)\n",
        "        print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f},  Test Auc: {:.5f}'.\n",
        "              format(epoch, train_loss, train_acc,  test_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QqDSrZnTSLN",
        "outputId": "ad1dcc54-8c40-4c62-8c91-4e923a93243c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): SAGEConv()\n",
            "  (pool1): TopKPooling(131, ratio=0.8, multiplier=1.0)\n",
            "  (conv2): SAGEConv()\n",
            "  (pool2): TopKPooling(131, ratio=0.8, multiplier=1.0)\n",
            "  (item_embedding): Embedding(393, 131)\n",
            "  (lin1): Linear(in_features=262, out_features=65, bias=True)\n",
            "  (lin3): Linear(in_features=65, out_features=1, bias=True)\n",
            "  (act1): ReLU()\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 0.70902, Train Auc: 0.59255,  Test Auc: 0.50694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 0.71672, Train Auc: 0.61571,  Test Auc: 0.46528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 002, Loss: 0.68781, Train Auc: 0.69103,  Test Auc: 0.53472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 003, Loss: 0.68682, Train Auc: 0.75879,  Test Auc: 0.45833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004, Loss: 0.68651, Train Auc: 0.76334,  Test Auc: 0.44444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 005, Loss: 0.68765, Train Auc: 0.73803,  Test Auc: 0.40278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 006, Loss: 0.68568, Train Auc: 0.79207,  Test Auc: 0.49306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 007, Loss: 0.68728, Train Auc: 0.79165,  Test Auc: 0.54861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 008, Loss: 0.68546, Train Auc: 0.79482,  Test Auc: 0.40278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 009, Loss: 0.68842, Train Auc: 0.69480,  Test Auc: 0.36806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.68656, Train Auc: 0.79293,  Test Auc: 0.53472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 011, Loss: 0.68195, Train Auc: 0.81369,  Test Auc: 0.41667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 012, Loss: 0.70834, Train Auc: 0.56888,  Test Auc: 0.48611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 013, Loss: 0.68760, Train Auc: 0.76222,  Test Auc: 0.50694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 014, Loss: 0.69138, Train Auc: 0.69978,  Test Auc: 0.23611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 015, Loss: 0.67409, Train Auc: 0.78916,  Test Auc: 0.36111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 016, Loss: 0.66591, Train Auc: 0.80528,  Test Auc: 0.33333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 017, Loss: 0.65478, Train Auc: 0.82690,  Test Auc: 0.34722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 018, Loss: 0.64917, Train Auc: 0.82038,  Test Auc: 0.32639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 019, Loss: 0.65302, Train Auc: 0.78092,  Test Auc: 0.41667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 020, Loss: 0.67647, Train Auc: 0.64179,  Test Auc: 0.21528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 021, Loss: 0.63203, Train Auc: 0.82330,  Test Auc: 0.48611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 022, Loss: 0.63315, Train Auc: 0.84440,  Test Auc: 0.38194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 023, Loss: 0.55994, Train Auc: 0.87940,  Test Auc: 0.40972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 024, Loss: 0.52362, Train Auc: 0.92949,  Test Auc: 0.34722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 025, Loss: 0.45737, Train Auc: 0.95334,  Test Auc: 0.32639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 026, Loss: 0.37516, Train Auc: 0.97324,  Test Auc: 0.33333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 027, Loss: 0.30559, Train Auc: 0.97135,  Test Auc: 0.33333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 028, Loss: 0.30865, Train Auc: 0.98147,  Test Auc: 0.43056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 029, Loss: 0.25778, Train Auc: 0.99657,  Test Auc: 0.43056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 030, Loss: 0.27139, Train Auc: 0.99674,  Test Auc: 0.38194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 031, Loss: 0.15738, Train Auc: 0.99966,  Test Auc: 0.41667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 032, Loss: 0.10497, Train Auc: 1.00000,  Test Auc: 0.41667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 033, Loss: 0.03424, Train Auc: 1.00000,  Test Auc: 0.43056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 034, Loss: 0.02138, Train Auc: 1.00000,  Test Auc: 0.40972\n"
          ]
        }
      ],
      "source": [
        "loss = train_net() #85-15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NHsS01fejLgd"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "def train_net():\n",
        "    torch.manual_seed(7)\n",
        "    np.random.seed(7)\n",
        "    best_acc = 0\n",
        "\n",
        "    model = Net()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    model = model\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    train_loader = list_data[0:163]\n",
        "    test_loader = list_data[164:182]\n",
        "    # val_loader = list_data[172:182]\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(0, 40):\n",
        "        train_loss = train(train_loader=train_loader,\n",
        "                           model=model,\n",
        "                           criterion=criterion,\n",
        "                           optimizer=optimizer,\n",
        "                           epoch=epoch)\n",
        "\n",
        "\n",
        "        train_acc = evaluate(train_loader, model)\n",
        "        # val_acc = evaluate(val_loader, model)\n",
        "        test_acc = evaluate(test_loader, model)\n",
        "        print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f},  Test Auc: {:.5f}'.\n",
        "              format(epoch, train_loss, train_acc,  test_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN9z98FgcMDh",
        "outputId": "54941b9e-0ce1-41dc-d3a8-3d755d6dd269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): SAGEConv()\n",
            "  (pool1): TopKPooling(131, ratio=0.8, multiplier=1.0)\n",
            "  (conv2): SAGEConv()\n",
            "  (pool2): TopKPooling(131, ratio=0.8, multiplier=1.0)\n",
            "  (item_embedding): Embedding(393, 131)\n",
            "  (lin1): Linear(in_features=262, out_features=65, bias=True)\n",
            "  (lin3): Linear(in_features=65, out_features=1, bias=True)\n",
            "  (act1): ReLU()\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 0.72109, Train Auc: 0.55328,  Test Auc: 0.59615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 0.70070, Train Auc: 0.65064,  Test Auc: 0.15385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 002, Loss: 0.69199, Train Auc: 0.73377,  Test Auc: 0.19231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 003, Loss: 0.68190, Train Auc: 0.77863,  Test Auc: 0.13462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004, Loss: 0.69925, Train Auc: 0.81032,  Test Auc: 0.23077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 005, Loss: 0.68410, Train Auc: 0.83925,  Test Auc: 0.21154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 006, Loss: 0.68531, Train Auc: 0.86941,  Test Auc: 0.28846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 007, Loss: 0.68546, Train Auc: 0.86513,  Test Auc: 0.30769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 008, Loss: 0.68512, Train Auc: 0.87921,  Test Auc: 0.44231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 009, Loss: 0.66413, Train Auc: 0.85242,  Test Auc: 0.30769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 010, Loss: 0.67921, Train Auc: 0.84798,  Test Auc: 0.50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 011, Loss: 0.64930, Train Auc: 0.84966,  Test Auc: 0.53846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 012, Loss: 0.68275, Train Auc: 0.84982,  Test Auc: 0.61538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 013, Loss: 0.57848, Train Auc: 0.89100,  Test Auc: 0.65385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 014, Loss: 0.50335, Train Auc: 0.92131,  Test Auc: 0.59615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 015, Loss: 0.48335, Train Auc: 0.91871,  Test Auc: 0.59615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 016, Loss: 0.45618, Train Auc: 0.95729,  Test Auc: 0.67308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 017, Loss: 0.41920, Train Auc: 0.96999,  Test Auc: 0.69231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 018, Loss: 0.38484, Train Auc: 0.97642,  Test Auc: 0.69231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 019, Loss: 0.37152, Train Auc: 0.98898,  Test Auc: 0.73077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 020, Loss: 0.26085, Train Auc: 0.99219,  Test Auc: 0.75000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 021, Loss: 0.21290, Train Auc: 0.99908,  Test Auc: 0.78846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 022, Loss: 0.20100, Train Auc: 0.99954,  Test Auc: 0.69231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 023, Loss: 0.15811, Train Auc: 1.00000,  Test Auc: 0.80769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 024, Loss: 0.09433, Train Auc: 0.99939,  Test Auc: 0.73077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 025, Loss: 0.05910, Train Auc: 1.00000,  Test Auc: 0.80769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 026, Loss: 0.11314, Train Auc: 0.99923,  Test Auc: 0.73077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 027, Loss: 0.14880, Train Auc: 0.99816,  Test Auc: 0.78846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 028, Loss: 0.14845, Train Auc: 0.99985,  Test Auc: 0.82692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 029, Loss: 0.03560, Train Auc: 1.00000,  Test Auc: 0.83654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 030, Loss: 0.00915, Train Auc: 1.00000,  Test Auc: 0.87500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 031, Loss: 0.00364, Train Auc: 1.00000,  Test Auc: 0.87500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 032, Loss: 0.00278, Train Auc: 1.00000,  Test Auc: 0.81731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 033, Loss: 0.00128, Train Auc: 1.00000,  Test Auc: 0.80769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 034, Loss: 0.00187, Train Auc: 1.00000,  Test Auc: 0.80769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 035, Loss: 0.00057, Train Auc: 1.00000,  Test Auc: 0.82692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 036, Loss: 0.00098, Train Auc: 1.00000,  Test Auc: 0.78846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 037, Loss: 0.00067, Train Auc: 1.00000,  Test Auc: 0.80769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 038, Loss: 0.00094, Train Auc: 1.00000,  Test Auc: 0.82692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 039, Loss: 0.00016, Train Auc: 1.00000,  Test Auc: 0.80769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "loss = train_net() #90-10"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
