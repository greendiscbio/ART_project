{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model using Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload Clinic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.315205</td>\n",
       "      <td>-0.407536</td>\n",
       "      <td>0.531673</td>\n",
       "      <td>0.808408</td>\n",
       "      <td>-0.810542</td>\n",
       "      <td>0.193779</td>\n",
       "      <td>0.034024</td>\n",
       "      <td>-0.164311</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646639</td>\n",
       "      <td>-0.484226</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.428195</td>\n",
       "      <td>-0.997664</td>\n",
       "      <td>-0.198929</td>\n",
       "      <td>0.558472</td>\n",
       "      <td>-0.711090</td>\n",
       "      <td>-0.625051</td>\n",
       "      <td>1.313173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.399706</td>\n",
       "      <td>-0.359715</td>\n",
       "      <td>0.589118</td>\n",
       "      <td>0.689009</td>\n",
       "      <td>-0.934274</td>\n",
       "      <td>0.590328</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.579490</td>\n",
       "      <td>-0.014040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367153</td>\n",
       "      <td>-0.127431</td>\n",
       "      <td>0.453080</td>\n",
       "      <td>0.222101</td>\n",
       "      <td>0.063686</td>\n",
       "      <td>-0.350376</td>\n",
       "      <td>0.585483</td>\n",
       "      <td>-0.723964</td>\n",
       "      <td>-0.614908</td>\n",
       "      <td>1.041820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.257777</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>-0.369965</td>\n",
       "      <td>0.256681</td>\n",
       "      <td>-0.647283</td>\n",
       "      <td>-0.009628</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>-0.395371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180099</td>\n",
       "      <td>0.149861</td>\n",
       "      <td>0.336687</td>\n",
       "      <td>0.759315</td>\n",
       "      <td>-0.011072</td>\n",
       "      <td>0.195970</td>\n",
       "      <td>0.454717</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>-0.548280</td>\n",
       "      <td>0.754466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.193269</td>\n",
       "      <td>-0.121839</td>\n",
       "      <td>-0.275106</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>-0.259090</td>\n",
       "      <td>-0.195940</td>\n",
       "      <td>0.075242</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>0.122252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.112763</td>\n",
       "      <td>0.223452</td>\n",
       "      <td>-0.481063</td>\n",
       "      <td>0.166170</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>-0.113602</td>\n",
       "      <td>-0.069602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.054664</td>\n",
       "      <td>-0.326593</td>\n",
       "      <td>-0.267536</td>\n",
       "      <td>0.490474</td>\n",
       "      <td>-0.725889</td>\n",
       "      <td>-0.157597</td>\n",
       "      <td>0.261997</td>\n",
       "      <td>0.182627</td>\n",
       "      <td>-0.072347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146497</td>\n",
       "      <td>-0.214596</td>\n",
       "      <td>0.316881</td>\n",
       "      <td>0.412167</td>\n",
       "      <td>0.322099</td>\n",
       "      <td>-0.438647</td>\n",
       "      <td>0.382818</td>\n",
       "      <td>-0.143397</td>\n",
       "      <td>-0.469160</td>\n",
       "      <td>0.382200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target         0         1         2         3         4         5  \\\n",
       "0       1 -0.315205 -0.407536  0.531673  0.808408 -0.810542  0.193779   \n",
       "1       0 -0.399706 -0.359715  0.589118  0.689009 -0.934274  0.590328   \n",
       "2       2 -0.257777  0.017325 -0.369965  0.256681 -0.647283 -0.009628   \n",
       "3       0  0.193269 -0.121839 -0.275106  0.063980 -0.259090 -0.195940   \n",
       "4       2 -0.054664 -0.326593 -0.267536  0.490474 -0.725889 -0.157597   \n",
       "\n",
       "          6         7         8  ...       428       429       430       431  \\\n",
       "0  0.034024 -0.164311  0.014579  ...  0.646639 -0.484226  0.024023  0.428195   \n",
       "1  0.000470 -0.579490 -0.014040  ...  0.367153 -0.127431  0.453080  0.222101   \n",
       "2  0.178241  0.039518 -0.395371  ... -0.180099  0.149861  0.336687  0.759315   \n",
       "3  0.075242  0.029794  0.122252  ...  0.021265  0.002938  0.010013  0.112763   \n",
       "4  0.261997  0.182627 -0.072347  ...  0.146497 -0.214596  0.316881  0.412167   \n",
       "\n",
       "        432       433       434       435       436       437  \n",
       "0 -0.997664 -0.198929  0.558472 -0.711090 -0.625051  1.313173  \n",
       "1  0.063686 -0.350376  0.585483 -0.723964 -0.614908  1.041820  \n",
       "2 -0.011072  0.195970  0.454717  0.462148 -0.548280  0.754466  \n",
       "3  0.223452 -0.481063  0.166170  0.020349 -0.113602 -0.069602  \n",
       "4  0.322099 -0.438647  0.382818 -0.143397 -0.469160  0.382200  \n",
       "\n",
       "[5 rows x 439 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =\"../../../Data_preprocessing/RNA_post_autoencoder/encoded_data_multiclass.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.reset_index\n",
    "data.round(4)\n",
    "data=data.iloc[:,1:440  ] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0   -0.315205 -0.407536  0.531673  0.808408 -0.810542  0.193779  0.034024   \n",
      "1   -0.399706 -0.359715  0.589118  0.689009 -0.934274  0.590328  0.000470   \n",
      "2   -0.257777  0.017325 -0.369965  0.256681 -0.647283 -0.009628  0.178241   \n",
      "3    0.193269 -0.121839 -0.275106  0.063980 -0.259090 -0.195940  0.075242   \n",
      "4   -0.054664 -0.326593 -0.267536  0.490474 -0.725889 -0.157597  0.261997   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "176  0.015191 -0.250067 -0.247737  0.428315 -0.673884 -0.122022  0.161610   \n",
      "177  0.025750 -0.248474 -0.427581  0.390085 -0.543150 -0.102631  0.184679   \n",
      "178 -0.380961 -0.304403  0.498039  0.549402  0.040175  0.282321 -0.007317   \n",
      "179 -0.394782 -0.050161  0.336075  0.524383 -0.065044  0.317751 -0.014208   \n",
      "180 -0.000122 -0.274288 -0.315658  0.305076 -0.167984 -0.064459  0.178613   \n",
      "\n",
      "            7         8         9  ...       428       429       430  \\\n",
      "0   -0.164311  0.014579 -1.164002  ...  0.646639 -0.484226  0.024023   \n",
      "1   -0.579490 -0.014040 -0.487263  ...  0.367153 -0.127431  0.453080   \n",
      "2    0.039518 -0.395371 -0.067909  ... -0.180099  0.149861  0.336687   \n",
      "3    0.029794  0.122252 -0.155608  ...  0.021265  0.002938  0.010013   \n",
      "4    0.182627 -0.072347 -0.379019  ...  0.146497 -0.214596  0.316881   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "176  0.234842 -0.342666 -0.298978  ... -0.030921 -0.183486  0.097117   \n",
      "177  0.181936 -0.148537 -0.413107  ... -0.003591 -0.105326  0.007203   \n",
      "178 -0.541125 -0.104559 -0.492848  ...  0.260310 -0.189189 -0.260205   \n",
      "179 -0.458082  0.055129 -0.567953  ...  0.464125 -0.106669 -0.226037   \n",
      "180  0.024021 -0.032355 -0.560349  ... -0.005819 -0.061995 -0.431180   \n",
      "\n",
      "          431       432       433       434       435       436       437  \n",
      "0    0.428195 -0.997664 -0.198929  0.558472 -0.711090 -0.625051  1.313173  \n",
      "1    0.222101  0.063686 -0.350376  0.585483 -0.723964 -0.614908  1.041820  \n",
      "2    0.759315 -0.011072  0.195970  0.454717  0.462148 -0.548280  0.754466  \n",
      "3    0.112763  0.223452 -0.481063  0.166170  0.020349 -0.113602 -0.069602  \n",
      "4    0.412167  0.322099 -0.438647  0.382818 -0.143397 -0.469160  0.382200  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "176  0.511050  0.285751 -0.355884  0.250968  0.015874 -0.544252  0.655665  \n",
      "177  0.425173  0.203884 -0.371995  0.313673 -0.131466 -0.543264  0.549663  \n",
      "178  0.128143 -0.060350 -0.665909  0.241845 -0.706364 -0.790269  1.305419  \n",
      "179  0.334272 -0.423706 -0.482886  0.481219 -0.851859 -0.556799  1.057744  \n",
      "180  0.555499  0.245627 -0.355982  0.431241 -0.124537 -0.535278  0.659070  \n",
      "\n",
      "[181 rows x 438 columns]\n",
      "Numero de pacientes:  181\n"
     ]
    }
   ],
   "source": [
    "Y = data.Target # Target column\n",
    "\n",
    "X = data.iloc[:,1:439] # I selected all the columns by removing the Unnamed column (row id) and the Target column.\n",
    "\n",
    "\n",
    "print(X)\n",
    "print('Numero de pacientes: ',len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train-Test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 144\n",
      "Target column size of the training set: 144\n",
      "Test set size: 37\n",
      "Target column size of the test set: 37\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125, stratify=Y)\n",
    "yTrain=yTrain.to_numpy()\n",
    "yTest=yTest.to_numpy()\n",
    "print('Training set size:', len(XTrain))\n",
    "print('Target column size of the training set:', len(yTrain))\n",
    "print('Test set size:', len(XTest))\n",
    "print('Target column size of the test set:', len(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 5, 10, 50],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4, 5],\n",
       "                         'n_estimators': [10, 20], 'random_state': [125]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'min_samples_leaf': [1, 2, 3],\n",
    "              'min_samples_split': [2, 3, 4, 5],\n",
    "              'random_state':[125],\n",
    "              'n_estimators': [10, 20],\n",
    "              'bootstrap': [True, False],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth':[None, 2, 5, 10,50]\n",
    "              }\n",
    "\n",
    "# I created a GridSearchCV which allows us to systematically evaluate and select the parameters of our model.\n",
    "# By indicating a model and the parameters to test, you can evaluate the performance of the first one based on the\n",
    "# seconds through cross validation.\n",
    "clf = GridSearchCV(\n",
    "        estimator  = RandomForestClassifier(),\n",
    "        param_grid = param_grid,\n",
    "        cv=5\n",
    "       )\n",
    "\n",
    "clf.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimate of parameters according to GridSearchCV:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=2,\n",
       "                       min_samples_leaf=3, n_estimators=20, random_state=125)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best estimate of parameters according to GridSearchCV:\")\n",
    "model = clf.best_estimator_\n",
    "# Fit the model with the best parameters\n",
    "model.fit(XTrain , yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result of the cross validation of the model with the best paramters:0.47955665024630545\n"
     ]
    }
   ],
   "source": [
    "print(\"Best result of the cross validation of the model with the best paramters:\" +str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the training dataset\n",
    "yhatTrain = model.predict(XTrain)\n",
    "contTrain = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTrain),1) :\n",
    "    if (yhatTrain[i] == yTrain[i]):\n",
    "        contTrain = contTrain + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the optimal model on the test dataset\n",
    "yhatTest = model.predict(XTest)\n",
    "contTest = 0\n",
    "\n",
    "# Comparing with the Target column and check how many hits there have been\n",
    "for i in range(0,len(yTest),1) :\n",
    "    if (yhatTest[i] == yTest[i]):\n",
    "        contTest = contTest + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the training dataset:0.6597222222222222\n",
      "Final accuracy on the testing dataset: 0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "print('Final accuracy on the training dataset:' + str(contTrain/len(yTrain)))\n",
    "print('Final accuracy on the testing dataset: ' + str(contTest/len(yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Training)------------------\n",
      "[[67  0  0]\n",
      " [19  2  4]\n",
      " [26  0 26]]\n",
      "Input data:  [1 0 2 0 2 2 0 0 2 0 2 0 1 0 2 2 0 2 2 2 0 0 0 2 0 0 0 0 1 1 2 2 2 2 0 1 2\n",
      " 0 0 2 1 2 2 1 0 0 2 2 1 0 0 0 2 0 0 2 0 2 1 2 0 2 1 0 0 0 0 2 2 2 0 2 0 0\n",
      " 0 2 0 2 0 0 0 1 2 0 0 1 2 2 1 1 0 2 0 2 0 0 1 0 1 0 0 2 0 0 2 2 2 1 0 2 2\n",
      " 1 2 0 1 0 0 0 2 0 1 0 2 0 0 2 1 1 0 0 0 2 0 1 0 0 0 2 2 2 1 2 0 1]\n",
      "Prediction:        [2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 1 0 2 2 2 0 0 2\n",
      " 0 0 2 0 2 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 2 0 2 0 2 0 0 0 0 0 0 2 0 0 2 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 2 0 0 0 2 0 0 0 2 0 0 2 0 2 0 0 0 2 0 0 0 0 0 0 2 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('----------------Confusion Matrix (Training)------------------')\n",
    "print(confusion_matrix(yTrain,yhatTrain))\n",
    "print('Input data:  ' + str(np.array(yTrain)))\n",
    "print('Prediction:        ' +str(yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        67\n",
      "           1       1.00      0.08      0.15        25\n",
      "           2       0.87      0.50      0.63        52\n",
      "\n",
      "    accuracy                           0.66       144\n",
      "   macro avg       0.82      0.53      0.51       144\n",
      "weighted avg       0.76      0.66      0.60       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain,yhatTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Confusion Matrix (Test)------------------\n",
      "[[17  0  1]\n",
      " [ 2  0  4]\n",
      " [10  0  3]]\n",
      "Input data:  [0 1 0 2 0 2 1 0 1 0 2 2 1 2 2 0 1 2 0 0 0 2 1 0 0 2 0 2 2 0 0 0 2 2 0 0 0]\n",
      "Prediction:        [0 0 0 0 0 0 2 0 2 0 0 0 2 0 2 0 0 0 0 0 0 0 2 0 0 2 2 0 2 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('----------------Confusion Matrix (Test)------------------')\n",
    "print(confusion_matrix(yTest,yhatTest))\n",
    "print('Input data:  ' + str(np.array(yTest)))\n",
    "print('Prediction:        ' +str(yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.72        18\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.38      0.23      0.29        13\n",
      "\n",
      "    accuracy                           0.54        37\n",
      "   macro avg       0.32      0.39      0.34        37\n",
      "weighted avg       0.42      0.54      0.45        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sandr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sandr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,yhatTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 0.0\n",
      "1 = 0.014270615253210129\n",
      "2 = 0.0\n",
      "3 = 0.0\n",
      "4 = 0.0\n",
      "5 = 0.0\n",
      "6 = 0.0\n",
      "7 = 0.0\n",
      "8 = 0.0\n",
      "9 = 0.0\n",
      "10 = 0.0\n",
      "11 = 0.0\n",
      "12 = 0.0\n",
      "13 = 0.0\n",
      "14 = 0.0\n",
      "15 = 0.0\n",
      "16 = 0.0\n",
      "17 = 0.01886270514137343\n",
      "18 = 0.0\n",
      "19 = 0.0\n",
      "20 = 0.0\n",
      "21 = 0.0\n",
      "22 = 0.0\n",
      "23 = 0.0\n",
      "24 = 0.0\n",
      "25 = 0.024595829906455445\n",
      "26 = 0.0\n",
      "27 = 0.0\n",
      "28 = 0.0\n",
      "29 = 0.0\n",
      "30 = 0.0\n",
      "31 = 0.02913131135869355\n",
      "32 = 0.0\n",
      "33 = 0.0\n",
      "34 = 0.0\n",
      "35 = 0.011045700965631075\n",
      "36 = 0.0\n",
      "37 = 0.0\n",
      "38 = 0.034019085559175564\n",
      "39 = 0.0\n",
      "40 = 0.0\n",
      "41 = 0.0\n",
      "42 = 0.0\n",
      "43 = 0.0\n",
      "44 = 0.0\n",
      "45 = 0.0\n",
      "46 = 0.0\n",
      "47 = 0.0\n",
      "48 = 0.0\n",
      "49 = 0.0\n",
      "50 = 0.0\n",
      "51 = 0.0\n",
      "52 = 0.0\n",
      "53 = 0.0\n",
      "54 = 0.0\n",
      "55 = 0.0\n",
      "56 = 0.0\n",
      "57 = 0.01730596759245986\n",
      "58 = 0.0\n",
      "59 = 0.0\n",
      "60 = 0.0\n",
      "61 = 0.0\n",
      "62 = 0.0\n",
      "63 = 0.0\n",
      "64 = 0.0\n",
      "65 = 0.0\n",
      "66 = 0.0\n",
      "67 = 0.0\n",
      "68 = 0.0\n",
      "69 = 0.0\n",
      "70 = 0.0\n",
      "71 = 0.019541094716505968\n",
      "72 = 0.020358978629019905\n",
      "73 = 0.0\n",
      "74 = 0.0\n",
      "75 = 0.015435755660774536\n",
      "76 = 0.0\n",
      "77 = 0.0\n",
      "78 = 0.0\n",
      "79 = 0.0\n",
      "80 = 0.019058417138197014\n",
      "81 = 0.0\n",
      "82 = 0.0\n",
      "83 = 0.0\n",
      "84 = 0.035810649198728\n",
      "85 = 0.0\n",
      "86 = 0.014607685946628604\n",
      "87 = 0.0\n",
      "88 = 0.0\n",
      "89 = 0.0\n",
      "90 = 0.0\n",
      "91 = 0.0\n",
      "92 = 0.02225355919812808\n",
      "93 = 0.0\n",
      "94 = 0.0\n",
      "95 = 0.0\n",
      "96 = 0.018583448431617335\n",
      "97 = 0.0\n",
      "98 = 0.0\n",
      "99 = 0.0\n",
      "100 = 0.0\n",
      "101 = 0.0\n",
      "102 = 0.0\n",
      "103 = 0.0\n",
      "104 = 0.04216216406218888\n",
      "105 = 0.0\n",
      "106 = 0.0\n",
      "107 = 0.0\n",
      "108 = 0.0\n",
      "109 = 0.0\n",
      "110 = 0.0\n",
      "111 = 0.0\n",
      "112 = 0.017337126863777332\n",
      "113 = 0.0\n",
      "114 = 0.0\n",
      "115 = 0.0\n",
      "116 = 0.0\n",
      "117 = 0.0\n",
      "118 = 0.0\n",
      "119 = 0.0\n",
      "120 = 0.0\n",
      "121 = 0.0\n",
      "122 = 0.0\n",
      "123 = 0.0\n",
      "124 = 0.0\n",
      "125 = 0.0\n",
      "126 = 0.01304777493822929\n",
      "127 = 0.0\n",
      "128 = 0.0\n",
      "129 = 0.0\n",
      "130 = 0.0\n",
      "131 = 0.0\n",
      "132 = 0.0\n",
      "133 = 0.0\n",
      "134 = 0.0\n",
      "135 = 0.0\n",
      "136 = 0.0\n",
      "137 = 0.0\n",
      "138 = 0.0\n",
      "139 = 0.0\n",
      "140 = 0.0\n",
      "141 = 0.0\n",
      "142 = 0.0\n",
      "143 = 0.0\n",
      "144 = 0.0\n",
      "145 = 0.0\n",
      "146 = 0.0\n",
      "147 = 0.0\n",
      "148 = 0.0\n",
      "149 = 0.0\n",
      "150 = 0.008276863831782107\n",
      "151 = 0.0\n",
      "152 = 0.0\n",
      "153 = 0.0\n",
      "154 = 0.0\n",
      "155 = 0.0\n",
      "156 = 0.0\n",
      "157 = 0.0\n",
      "158 = 0.0\n",
      "159 = 0.0\n",
      "160 = 0.0\n",
      "161 = 0.012833974793204356\n",
      "162 = 0.026571546042777377\n",
      "163 = 0.0\n",
      "164 = 0.0\n",
      "165 = 0.0\n",
      "166 = 0.018649547871622846\n",
      "167 = 0.0\n",
      "168 = 0.0\n",
      "169 = 0.0\n",
      "170 = 0.0\n",
      "171 = 0.0\n",
      "172 = 0.0\n",
      "173 = 0.0\n",
      "174 = 0.0\n",
      "175 = 0.0\n",
      "176 = 0.0\n",
      "177 = 0.015606712416440374\n",
      "178 = 0.0\n",
      "179 = 0.0\n",
      "180 = 0.0\n",
      "181 = 0.0\n",
      "182 = 0.0\n",
      "183 = 0.0\n",
      "184 = 0.0\n",
      "185 = 0.0\n",
      "186 = 0.0\n",
      "187 = 0.0\n",
      "188 = 0.0\n",
      "189 = 0.0\n",
      "190 = 0.0\n",
      "191 = 0.0\n",
      "192 = 0.0\n",
      "193 = 0.0\n",
      "194 = 0.0\n",
      "195 = 0.0\n",
      "196 = 0.0\n",
      "197 = 0.0\n",
      "198 = 0.0\n",
      "199 = 0.0\n",
      "200 = 0.012078877720429551\n",
      "201 = 0.0\n",
      "202 = 0.0\n",
      "203 = 0.0\n",
      "204 = 0.0\n",
      "205 = 0.0\n",
      "206 = 0.0\n",
      "207 = 0.0\n",
      "208 = 0.0\n",
      "209 = 0.0\n",
      "210 = 0.0\n",
      "211 = 0.020060324114016294\n",
      "212 = 0.0\n",
      "213 = 0.0\n",
      "214 = 0.0\n",
      "215 = 0.0\n",
      "216 = 0.0\n",
      "217 = 0.0\n",
      "218 = 0.0\n",
      "219 = 0.0\n",
      "220 = 0.0\n",
      "221 = 0.0\n",
      "222 = 0.018429832440021793\n",
      "223 = 0.0\n",
      "224 = 0.0\n",
      "225 = 0.0\n",
      "226 = 0.0\n",
      "227 = 0.008417429677635707\n",
      "228 = 0.0\n",
      "229 = 0.0\n",
      "230 = 0.0\n",
      "231 = 0.0\n",
      "232 = 0.019761871788238843\n",
      "233 = 0.0\n",
      "234 = 0.011124698792345357\n",
      "235 = 0.0\n",
      "236 = 0.0\n",
      "237 = 0.01884427229353656\n",
      "238 = 0.010440473209412063\n",
      "239 = 0.0\n",
      "240 = 0.0\n",
      "241 = 0.0\n",
      "242 = 0.0\n",
      "243 = 0.0\n",
      "244 = 0.05545254611438775\n",
      "245 = 0.0\n",
      "246 = 0.0\n",
      "247 = 0.0\n",
      "248 = 0.0\n",
      "249 = 0.0\n",
      "250 = 0.0\n",
      "251 = 0.014871249335407552\n",
      "252 = 0.0\n",
      "253 = 0.0\n",
      "254 = 0.0\n",
      "255 = 0.04658739406235287\n",
      "256 = 0.0\n",
      "257 = 0.009780280178402958\n",
      "258 = 0.0\n",
      "259 = 0.0\n",
      "260 = 0.0\n",
      "261 = 0.015217571305248142\n",
      "262 = 0.0\n",
      "263 = 0.0\n",
      "264 = 0.0\n",
      "265 = 0.0\n",
      "266 = 0.0\n",
      "267 = 0.0\n",
      "268 = 0.0\n",
      "269 = 0.0\n",
      "270 = 0.0\n",
      "271 = 0.0\n",
      "272 = 0.0\n",
      "273 = 0.0\n",
      "274 = 0.0\n",
      "275 = 0.0\n",
      "276 = 0.0\n",
      "277 = 0.0\n",
      "278 = 0.0\n",
      "279 = 0.0\n",
      "280 = 0.0\n",
      "281 = 0.0\n",
      "282 = 0.0\n",
      "283 = 0.0\n",
      "284 = 0.0\n",
      "285 = 0.0\n",
      "286 = 0.0\n",
      "287 = 0.0\n",
      "288 = 0.0\n",
      "289 = 0.0\n",
      "290 = 0.0\n",
      "291 = 0.0\n",
      "292 = 0.0\n",
      "293 = 0.0\n",
      "294 = 0.0\n",
      "295 = 0.0\n",
      "296 = 0.0\n",
      "297 = 0.0\n",
      "298 = 0.0\n",
      "299 = 0.0\n",
      "300 = 0.0\n",
      "301 = 0.0\n",
      "302 = 0.0\n",
      "303 = 0.0\n",
      "304 = 0.0\n",
      "305 = 0.0\n",
      "306 = 0.0\n",
      "307 = 0.015784263869374447\n",
      "308 = 0.0\n",
      "309 = 0.0\n",
      "310 = 0.0\n",
      "311 = 0.0\n",
      "312 = 0.0\n",
      "313 = 0.016189626785751306\n",
      "314 = 0.0\n",
      "315 = 0.0\n",
      "316 = 0.0\n",
      "317 = 0.0\n",
      "318 = 0.0\n",
      "319 = 0.0648036415442201\n",
      "320 = 0.0\n",
      "321 = 0.0\n",
      "322 = 0.0\n",
      "323 = 0.012497539302150484\n",
      "324 = 0.0\n",
      "325 = 0.0\n",
      "326 = 0.0\n",
      "327 = 0.0\n",
      "328 = 0.0\n",
      "329 = 0.0\n",
      "330 = 0.0\n",
      "331 = 0.0\n",
      "332 = 0.0\n",
      "333 = 0.025416042067276233\n",
      "334 = 0.0\n",
      "335 = 0.0\n",
      "336 = 0.0\n",
      "337 = 0.0\n",
      "338 = 0.0\n",
      "339 = 0.0\n",
      "340 = 0.0\n",
      "341 = 0.0\n",
      "342 = 0.016584940077854438\n",
      "343 = 0.0\n",
      "344 = 0.0\n",
      "345 = 0.0\n",
      "346 = 0.0\n",
      "347 = 0.0\n",
      "348 = 0.0\n",
      "349 = 0.0\n",
      "350 = 0.011174225782112007\n",
      "351 = 0.0\n",
      "352 = 0.0\n",
      "353 = 0.0\n",
      "354 = 0.0\n",
      "355 = 0.0\n",
      "356 = 0.0\n",
      "357 = 0.0\n",
      "358 = 0.0\n",
      "359 = 0.0\n",
      "360 = 0.0\n",
      "361 = 0.0\n",
      "362 = 0.0\n",
      "363 = 0.0\n",
      "364 = 0.0\n",
      "365 = 0.0\n",
      "366 = 0.0\n",
      "367 = 0.0\n",
      "368 = 0.0\n",
      "369 = 0.0\n",
      "370 = 0.0\n",
      "371 = 0.0\n",
      "372 = 0.0\n",
      "373 = 0.0\n",
      "374 = 0.0\n",
      "375 = 0.0\n",
      "376 = 0.02181407086431939\n",
      "377 = 0.01450392022520917\n",
      "378 = 0.0\n",
      "379 = 0.015160825342625844\n",
      "380 = 0.0\n",
      "381 = 0.0\n",
      "382 = 0.0\n",
      "383 = 0.0\n",
      "384 = 0.0\n",
      "385 = 0.0\n",
      "386 = 0.0\n",
      "387 = 0.0\n",
      "388 = 0.0\n",
      "389 = 0.0\n",
      "390 = 0.0\n",
      "391 = 0.0\n",
      "392 = 0.0\n",
      "393 = 0.0\n",
      "394 = 0.0\n",
      "395 = 0.0\n",
      "396 = 0.0\n",
      "397 = 0.0\n",
      "398 = 0.0\n",
      "399 = 0.0\n",
      "400 = 0.0\n",
      "401 = 0.0\n",
      "402 = 0.0\n",
      "403 = 0.0\n",
      "404 = 0.0\n",
      "405 = 0.0\n",
      "406 = 0.0\n",
      "407 = 0.0\n",
      "408 = 0.0\n",
      "409 = 0.0\n",
      "410 = 0.0\n",
      "411 = 0.0\n",
      "412 = 0.0\n",
      "413 = 0.0\n",
      "414 = 0.0\n",
      "415 = 0.0\n",
      "416 = 0.0\n",
      "417 = 0.0\n",
      "418 = 0.0\n",
      "419 = 0.0\n",
      "420 = 0.0\n",
      "421 = 0.0\n",
      "422 = 0.0\n",
      "423 = 0.0\n",
      "424 = 0.0\n",
      "425 = 0.0\n",
      "426 = 0.0\n",
      "427 = 0.0\n",
      "428 = 0.0\n",
      "429 = 0.0\n",
      "430 = 0.0\n",
      "431 = 0.0\n",
      "432 = 0.0\n",
      "433 = 0.0219484539015475\n",
      "434 = 0.0145756842700868\n",
      "435 = 0.019113429419415802\n",
      "436 = 0.0\n",
      "437 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Through the created model we can see which attributes are the most significant to make a decision.\n",
    "# The most relevant attributes will be the ones placed at the top of the tree.\n",
    "features = list(X)\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Attribute relevance')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative importance')\n",
    "plt.show()\n",
    "\n",
    "for name, importance in zip(X, model.feature_importances_):\n",
    "    print(name, \"=\", importance)\n",
    "\n",
    "# Attributes whose relevance is 0, will not be necessary to make the prediction of the target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
