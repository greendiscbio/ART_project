{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176c13f7-2cd0-4338-add4-778da779634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import mygene\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e7cc858-246f-462b-8f93-661b2b46f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4c3cfe5-9ca0-46ae-b099-20dd402921f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch.nn import Linear, ReLU,Dropout\n",
    "from torch_geometric.nn import Sequential, GCNConv, TopKPooling, SimpleConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GNNExample(nn.Module):\n",
    "    def __init__(self, num_features, input_dim, L, batch_size):\n",
    "        super(GNNExample, self).__init__()\n",
    "        self.conv = GCNConv(num_features, num_features) #SimpleConv(aggr = \"median\", combine_root = \"self_loop\") # aggr :: [sum, mean, mul]\n",
    "        model = MWE_AE(input_dim, L)\n",
    "        self.encoder = model.encoder\n",
    "        self.decoder = model.decoder\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = input_dim\n",
    "        self.num_features = num_features\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "    def convolute(self, data):\n",
    "        xs = torch.tensor([]).to(self.device)\n",
    "        for i in range(len(data)):\n",
    "            x, edge_index = data[i].x, data[i].edge_index\n",
    "            h = self.conv(x, edge_index)\n",
    "            h = h.tanh()\n",
    "            h = self.dropout(h)\n",
    "            xs = torch.cat([xs, h])\n",
    "        return xs\n",
    "\n",
    "    def forward(self, data):\n",
    "        xs = self.convolute(data)\n",
    "        xs = torch.reshape(xs, (len(data), self.input_dim))\n",
    "        encoded = self.encoder(xs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def get_latent_space(self, data):\n",
    "        xs = self.convolute(data)\n",
    "        xs = torch.reshape(xs, (-1, self.input_dim))\n",
    "        encoded = self.encoder(xs)\n",
    "        return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c14c8a08-2d31-41e4-8d8c-8c301abd09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class MWE_AE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, L):\n",
    "        super().__init__()\n",
    "\n",
    "        print(\"Initializing Minimal Working Example AE with input dim: \", input_dim)\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            custom_block(input_dim, 2400),\n",
    "            custom_block(2400, 2000),\n",
    "            custom_block(2000, 1500),\n",
    "            custom_block(1500, 1000),\n",
    "            custom_block_encoder(1000, L)\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            custom_block(L, 600),\n",
    "            custom_block(600, 800),\n",
    "            custom_block(800, 1000),\n",
    "            custom_block(1000, 1200),\n",
    "            custom_block(1200, 1500),\n",
    "            custom_block(1500, 1800),\n",
    "            custom_block(1800, 2000),\n",
    "            custom_block(2000, 2400),\n",
    "            custom_block_decoder(2400, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def get_latent_space(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "def custom_block(input_dim, output_dim, dropout_rate=0.25):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_dim, output_dim),\n",
    "        torch.nn.BatchNorm1d(output_dim),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Tanh(),\n",
    "    )\n",
    "\n",
    "def custom_block_encoder(input_dim, output_dim, dropout_rate = 0.1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_dim, output_dim),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "def custom_block_decoder(input_dim, output_dim, dropout_rate = 0.1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_dim, output_dim),\n",
    "        torch.nn.Dropout(dropout_rate),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e0c6b49-afa7-4286-8090-8f2ea447602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    \"\"\"\n",
    "    This class is used to have all types of data in one place. For example, the entire train set can be housed\n",
    "    within this class. This way when we need to merge genData and cliData together, it can be done easily, as well\n",
    "    as checking the labels for later use.\n",
    "    \"\"\"\n",
    "    def __init__(self, genData, cliData, labels):\n",
    "        self.genData = genData\n",
    "        self.cliData = cliData\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.genData)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.genData[idx], self.cliData[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf18b95-03d0-40ae-9e45-88cdb712890d",
   "metadata": {},
   "source": [
    "### GRAPH SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab1a719-b8a9-43fd-a502-8bc9be0c172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', 'Data', 'RNA_dataset_graph_R3.pkl'))\n",
    "\n",
    "with open(somepath, 'rb') as f:\n",
    "    loaded_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8abd442-81d0-4786-9ef2-5e338d6ff015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inigo\\Desktop\\AAU\\Cursos\\4th semester\\P10\\Implementation\\Logic\n",
      "C:\\Users\\inigo\\Desktop\\AAU\\Cursos\\4th semester\\P10\\Notebooks\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     11\u001b[0m FOLDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 12\u001b[0m d \u001b[38;5;241m=\u001b[39m GraphDataLoader(somepath, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPFS_P\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPFS_P_CNSR\u001b[39m\u001b[38;5;124m'\u001b[39m], clinicalVars, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     13\u001b[0m                             BATCH_SIZE, FOLDS, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\AAU\\Cursos\\4th semester\\P10\\Implementation\\Logic\\GraphDataLoader.py:41\u001b[0m, in \u001b[0;36mGraphDataLoader.__init__\u001b[1;34m(self, file_path, pred_vars, cli_vars, test_ratio, val_ratio, batch_size, folds, cohort)\u001b[0m\n\u001b[0;32m     37\u001b[0m graphs \u001b[38;5;241m=\u001b[39m shift_data(graphs, folds)\n\u001b[0;32m     39\u001b[0m train_set, test_set, val_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_test_val_split(graphs, test_ratio, val_ratio)\n\u001b[1;32m---> 41\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_loader(train_set)\n\u001b[0;32m     42\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_loader(test_set)\n\u001b[0;32m     43\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_loader(val_set)\n",
      "File \u001b[1;32m~\\Desktop\\AAU\\Cursos\\4th semester\\P10\\Implementation\\Logic\\GraphDataLoader.py:85\u001b[0m, in \u001b[0;36mGraphDataLoader.custom_loader\u001b[1;34m(self, graphs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     pred_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [tmp]\n\u001b[0;32m     83\u001b[0m pred_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_labels(pd\u001b[38;5;241m.\u001b[39mDataFrame(pred_data, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_vars))\n\u001b[1;32m---> 85\u001b[0m cd \u001b[38;5;241m=\u001b[39m CustomDataset(gen_data, torch\u001b[38;5;241m.\u001b[39mtensor(cli_data)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), torch\u001b[38;5;241m.\u001b[39mtensor(pred_data)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cd\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\inigo\\Desktop\\AAU\\Cursos\\4th semester\\P10\\Implementation\\Logic\n",
    "from GraphDataLoader import GraphDataLoader\n",
    "%cd C:\\Users\\inigo\\Desktop\\AAU\\Cursos\\4th semester\\P10\\Notebooks\n",
    "\n",
    "\n",
    "clinicalVars = ['MATH', 'HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA', 'PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA',\n",
    "                    'CD8_POSITIVE_CELLS_TUMOR_CENTER', 'CD8_POSITIVE_CELLS_TOTAL_AREA']\n",
    "BATCH_SIZE = 32\n",
    "FOLDS = 3\n",
    "d = GraphDataLoader(somepath, ['PFS_P', 'PFS_P_CNSR'], clinicalVars, 0.2, 0.1,\n",
    "                            BATCH_SIZE, FOLDS, 'ALL')  # 70% train, 20% test, 10% val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a18a4-3266-4078-aea9-0091c54b0036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
