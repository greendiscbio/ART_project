{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb8d37c",
   "metadata": {},
   "source": [
    "### Set up - working directory, imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c786dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354efcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b186c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the new directory path\n",
    "project_dir = os.getcwd()+\"/../\"\n",
    "\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# Verify the change\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def66569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the randomness to 42 for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Latent dimensionality, penalty hyperparameters, and the clinical (+ histology) features to consider\n",
    "L = 64\n",
    "FOLDS = 10\n",
    "loss_args = {'noise_factor': 0.001, 'reg_param': 0.10, 'rho': 0.001}\n",
    "clinicalVars = ['MATH', 'HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA', 'PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA',\n",
    "            'CD8_POSITIVE_CELLS_TUMOR_CENTER', 'CD8_POSITIVE_CELLS_TOTAL_AREA']\n",
    "\n",
    "COHORTS = ['Avelumab+Axitinib','Sunitinib']\n",
    "BATCH_SIZES = [255, 255]\n",
    "\n",
    "WITH_HISTOLOGY = False\n",
    "\n",
    "if WITH_HISTOLOGY is False:\n",
    "    clinicalVars = ['HE_TUMOR_CELL_CONTENT_IN_TUMOR_AREA', 'PD-L1_TOTAL_IMMUNE_CELLS_PER_TUMOR_AREA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0604013-85fb-44d2-8c7c-190871d2b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the new directory path\n",
    "project_dir = os.getcwd()+\"/Implementation\"\n",
    "\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# Verify the change\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logic.FoldObject import FoldObject\n",
    "from Logic.Losses.LossHandler import LossHandler\n",
    "from Logic.Losses.LossType import LossType\n",
    "from Logic.CustomKFoldScikit import CustomKFold\n",
    "from Logic.TabularDataLoader import TabularDataLoader\n",
    "from Logic.Trainer import Trainer, draw_latent_space, plot_cindex, plot_coefs, plot_tsne_coefs, plot_auc, evaluate_demographic_data\n",
    "from Logic.TrainingModel import TrainingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312c6ad-7aca-4588-917b-80b34a82a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "somepath = os.path.abspath(\n",
    "    os.path.join(current_directory, '..', '..', 'P10', 'Data', 'RNA_dataset_tabular_R3.csv'))\n",
    "\n",
    "cohort = COHORTS[1]\n",
    "BATCH_SIZE = BATCH_SIZES[1]\n",
    "\n",
    "d = TabularDataLoader(somepath, ['PFS_P', 'PFS_P_CNSR'], clinicalVars, (1/FOLDS), 0.2, BATCH_SIZE, FOLDS, cohort)\n",
    "foldObject = FoldObject('PCA', FOLDS, d.allDatasets)\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    instanceModel = TrainingModel(\"PCA_test\", d, foldObject.iterations[fold], clinicalVars,\n",
    "                     None, None, None, None, BATCH_SIZE, L, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9575a8-3c3b-485c-9ec0-be0f6163b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingmodel -> train loader -> (genetic, clinical, pfs)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "instanceModel = TrainingModel(\"PCA_test\", d, foldObject.iterations[ITERATION], clinicalVars,\n",
    "                     None, None, None, None, BATCH_SIZE, L, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdfb3ad-72e3-4585-8e17-423240301963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gen = instanceModel.train_loader[0][0].cpu()\n",
    "X_cli = instanceModel.train_loader[0][1].cpu()\n",
    "X_pfs = instanceModel.train_loader[0][2].cpu()\n",
    "\n",
    "Y_gen = instanceModel.test_loader[0][0].cpu()\n",
    "Y_cli = instanceModel.test_loader[0][1].cpu()\n",
    "Y_pfs = instanceModel.test_loader[0][2].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c6778-3dc9-4baf-9b66-08d155267981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=L)\n",
    "\n",
    "# Fit PCA to the data and transform (encode)\n",
    "pca.fit(X_gen)\n",
    "X_gen_encoded = pca.transform(X_gen)\n",
    "Y_gen_encoded = pca.transform(Y_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90e295-5ee8-4cb2-9020-d48ca518799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gencli = np.concatenate((X_gen_encoded, X_cli), axis=1)\n",
    "Y_gencli = np.concatenate((Y_gen_encoded, Y_cli), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c89a5-ee6b-47e6-8e50-5e1b848495cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pfs_transformed = np.array([(bool(event), float(time)) for event, time in X_pfs], dtype=[('event', bool), ('time', float)])\n",
    "Y_pfs_transformed = np.array([(bool(event), float(time)) for event, time in Y_pfs], dtype=[('event', bool), ('time', float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958f7af-8659-4293-b09f-0a79edbf2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_DF = pd.DataFrame()\n",
    "demographic_DF['PFS_P'] = Y_pfs_transformed['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e8ae2-6885-4008-8894-375438123ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import cumulative_dynamic_auc, as_concordance_index_ipcw_scorer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from Logic.CustomKFoldScikit import CustomKFold\n",
    "from Logic.TrainingModel import TrainingModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import xlsxwriter\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2ccc8-b83b-405d-ba31-f6907c34e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRIES = 3\n",
    "non_zero = 0\n",
    "offset = 0.9\n",
    "\n",
    "start = 0.0001\n",
    "stop = 0.01\n",
    "step = 0.0002\n",
    "\n",
    "latent_cols = [\"Latent \" + str(x) for x in list(range(L))]\n",
    "latent_cols += clinicalVars\n",
    "latent_idxs = np.arange(L + len(clinicalVars))\n",
    "\n",
    "OK = False\n",
    "while not OK:\n",
    "    OK = True\n",
    "    estimated_alphas = np.arange(start, stop + step, step)\n",
    "\n",
    "    # we remove warnings when coefficients in Cox PH model are 0\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "    warnings.simplefilter(\"ignore\", ArithmeticError)\n",
    "\n",
    "    # we scale for better performance.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_gencli)\n",
    "    scaled_latent_space_train = scaler.transform(X_gencli)\n",
    "    scaled_latent_space_test = scaler.transform(Y_gencli)\n",
    "\n",
    "    # We perform grid search to find the best alpha to test with\n",
    "    cv = CustomKFold(n_splits=7, shuffle=True, random_state=40)\n",
    "    gcv = GridSearchCV(\n",
    "        as_concordance_index_ipcw_scorer(\n",
    "            CoxnetSurvivalAnalysis(l1_ratio=0.5, fit_baseline_model=True, max_iter=80000, normalize=False)),\n",
    "        param_grid={\"estimator__alphas\": [[v] for v in estimated_alphas]},\n",
    "        cv=cv,\n",
    "        error_score=0,\n",
    "        n_jobs=5,\n",
    "    ).fit(scaled_latent_space_train, X_pfs_transformed)\n",
    "\n",
    "    cv_results = pd.DataFrame(gcv.cv_results_)\n",
    "\n",
    "    alphas = cv_results.param_estimator__alphas.map(lambda x: x[0])\n",
    "    mean = cv_results.mean_test_score\n",
    "    std = cv_results.std_test_score\n",
    "\n",
    "    best_model = gcv.best_estimator_.estimator\n",
    "    best_coefs = pd.DataFrame(best_model.coef_, index=latent_cols, columns=[\"coefficient\"])\n",
    "    best_alpha = gcv.best_params_[\"estimator__alphas\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5faa3c-3836-416a-8e4b-e4b3b389b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cindex(alphas, mean, std, best_alpha, \"pca_c-index\")\n",
    "\n",
    "non_zero = np.sum(best_coefs.iloc[:, 0] != 0)\n",
    "print(f\"Number of non-zero coefficients: {non_zero}\")\n",
    "\n",
    "survival_functions_tmp = best_model.predict_survival_function(scaled_latent_space_test, best_alpha)\n",
    "\n",
    "# if the coefs are all zero OR if for some reason the survival functions couldn't be estimated, try again\n",
    "if non_zero == 0 or np.isnan(survival_functions_tmp[0].y).any():\n",
    "    OK = False\n",
    "    TRIES -= 1\n",
    "    start *= offset\n",
    "    step *= offset\n",
    "    stop *= offset\n",
    "    print(\"All coefficients are 0 or survival functions are undefined... Tries left: \" + str(\n",
    "        TRIES) + \" with start: \" + str(start))\n",
    "    if TRIES == 0:\n",
    "        print(\"FAIL!\")\n",
    "\n",
    "non_zero_coefs = best_coefs.query(\"coefficient != 0\")\n",
    "coef_order = non_zero_coefs.abs().sort_values(\"coefficient\").index\n",
    "\n",
    "# we plot a figure showing how much weight each coef has\n",
    "plot_coefs(non_zero_coefs, coef_order, \"relevant_features\")\n",
    "\n",
    "latent_data = zip(latent_cols, latent_idxs)\n",
    "idxs_interest = []\n",
    "cols_interest = list(coef_order)\n",
    "\n",
    "for col, idx in latent_data:\n",
    "    if col in list(coef_order):\n",
    "        idxs_interest += [idx]\n",
    "\n",
    "data_points = X_gencli[:, idxs_interest]\n",
    "\n",
    "# if we have more than 2 coefs, we perform  tsne. However this isn't uesful in our work.\n",
    "if non_zero >= 2:\n",
    "    plot_tsne_coefs(data_points, cols_interest, \"tsne\")\n",
    "\n",
    "# We keep the best 5 coefficients for the correlation plots (check method for more info)\n",
    "latent_data = zip(latent_cols, latent_idxs)\n",
    "best_coefs = coef_order[-5:]\n",
    "best_indices = [idx for col, idx in latent_data if col in best_coefs]\n",
    "\n",
    "print(\"Best index is\", best_indices)\n",
    "data_points_best_coef = np.array(X_gencli)[:, best_indices]\n",
    "\n",
    "\n",
    "# Predict using the best model and the test latent space\n",
    "cph_risk_scores = best_model.predict(scaled_latent_space_test, alpha = best_alpha)\n",
    "\n",
    "times = Y_pfs_transformed['time']\n",
    "\n",
    "va_times = np.arange(min(times), max(times), 0.5)\n",
    "cph_auc, _ = cumulative_dynamic_auc(X_pfs_transformed, Y_pfs_transformed, cph_risk_scores, va_times)\n",
    "\n",
    "# we plot the Area under ROC\n",
    "meanRes = plot_auc(va_times, cph_auc, \"ROC\")\n",
    "\n",
    "# Using survival functions, obtain median OR mean and assign it to each patient.\n",
    "survival_functions = best_model.predict_survival_function(scaled_latent_space_test, best_alpha)\n",
    "predicted_times = []\n",
    "\n",
    "\n",
    "# we can either use mean or median to predict PFS with.\n",
    "mode = \"Mean\"\n",
    "print(\"Using prediction mode: \", mode)\n",
    "\n",
    "if mode == \"Mean\":\n",
    "    for g in range(len(survival_functions)):\n",
    "        mean_value = np.trapz(survival_functions[g].y, survival_functions[g].x) # area under survival function\n",
    "        predicted_times += [mean_value]\n",
    "elif mode == \"Median\":\n",
    "    for g in range(len(survival_functions)):\n",
    "        median_value = np.interp(0.5, survival_functions[g].y[::-1], survival_functions[g].x[::-1])\n",
    "        predicted_times += [median_value]\n",
    "\n",
    "demographic_DF['predicted_PFS'] = predicted_times\n",
    "\n",
    "# we get the overall plot that shows how the model performed with the predictions\n",
    "mseError = evaluate_demographic_data(\"PCA_test\", survival_functions, demographic_DF)\n",
    "# we obtain the percentage of overestimation in our PFS predictions\n",
    "percentageOverEstimation = (demographic_DF['predicted_PFS'] > demographic_DF['PFS_P']).mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf8d8a-9931-4aa4-8f71-13218cb92958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
