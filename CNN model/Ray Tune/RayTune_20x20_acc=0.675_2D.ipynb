{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraies and packages"
      ],
      "metadata": {
        "id": "PXjVxSG4yt-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVA_ZA7c5BE0",
        "outputId": "627ae47a-3e75-4f03-f2cd-5cff684572c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.12.1-cp37-cp37m-manylinux2014_x86_64.whl (53.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 53.2 MB 263 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 36.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: platformdirs, frozenlist, distlib, virtualenv, grpcio, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.1\n",
            "    Uninstalling grpcio-1.46.1:\n",
            "      Successfully uninstalled grpcio-1.46.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed aiosignal-1.2.0 distlib-0.3.4 frozenlist-1.3.0 grpcio-1.43.0 platformdirs-2.5.2 ray-1.12.1 virtualenv-20.14.1\n"
          ]
        }
      ],
      "source": [
        "pip install ray torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlaA55u5HNx",
        "outputId": "d0392d6f-13ec-4330-89af-968e77e194c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=5a2237c593b69fcfe4420ab89543e92d71e2a870a7cd47dd1e43f453974a5e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3nVLl1gV5Ize"
      },
      "outputs": [],
      "source": [
        "# # Solucion par ael error int-float\n",
        "# import psutil\n",
        "# import ray\n",
        "# ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lU9kk9xU5K4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yvgorDkMN429"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "d1f61bca-713c-4c84-a2da-dd130e0a794f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "XoUYbBj2yxpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def augment_images(x, config):\n",
        "    if config['use_contrast'] == \"True\":\n",
        "        x = tf.keras.layers.experimental.preprocessing.RandomContrast(\n",
        "            config['contrast_factor']\n",
        "        )(x)\n",
        "\n",
        "    if config['use_rotation'] == \"True\":\n",
        "        x = tf.keras.layers.experimental.preprocessing.RandomRotation(\n",
        "            config['rotation_factor']\n",
        "        )(x)\n",
        "    \n",
        "    if config['use_flip'] == \"True\":\n",
        "        x = tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
        "            config['flip_mode']\n",
        "        )(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(20, 20, 1))\n",
        "    # x = augment_images(input, config)\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv2D(filters=config['conv_block1_filters'], kernel_size=3, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=config['conv_block2_filters'], kernel_size=3, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=config['conv_block3_filters'], kernel_size=3, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=config['conv_block4_filters'], kernel_size=2, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=config['conv_block5_filters'], kernel_size=1, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv2D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv2D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "Y7vViFfkzJTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras import backend as K\n",
        "\n",
        "# def recall_m(y_true, y_pred):\n",
        "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "#     recall = true_positives / (possible_positives + K.epsilon())\n",
        "#     return recall\n",
        "\n",
        "# def precision_m(y_true, y_pred):\n",
        "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
        "#     return precision\n",
        "\n",
        "# def f1_m(y_true, y_pred):\n",
        "#     precision = precision_m(y_true, y_pred)\n",
        "#     recall = recall_m(y_true, y_pred)\n",
        "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training function"
      ],
      "metadata": {
        "id": "oss9TBkZzMYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist( config):\n",
        "  path ='/content/drive/MyDrive/UPM/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  # data_frame = data_frame.set_index(\"gene_name\")\n",
        "  # data_frame=data_frame.T\n",
        "  # data_frame.head()\n",
        "  # data_frame=data_frame.iloc[np.repeat(np.arange(len(data_frame)), 3)]\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame[['5S_rRNA', 'AADACL2-AS1', 'AB015752.3', 'AB019438.66', 'ABHD17AP7', 'AC000077.2', 'AC000111.3', 'AC000111.5', 'AC000124.1', 'AC002368.4', 'AC002472.11', 'AC002486.3', 'AC002542.2', 'AC003084.2', 'AC003682.16', 'AC003682.17', 'AC003986.5', 'AC004006.2', 'AC004012.1', 'AC004014.3', 'AC004066.3', 'AC004112.4', 'AC004158.3', 'AC004221.2', 'AC004449.6', 'AC004510.3', 'AC004549.6', 'AC004862.6', 'AC004870.3', 'AC004941.3', 'AC004947.2', 'AC005008.2', 'AC005094.2', 'AC005178.1', 'AC005197.2', 'AC005235.1', 'AC005307.1', 'AC005355.1', 'AC005387.3', 'AC005392.13', 'AC005498.4', 'AC005518.2', 'AC005550.5', 'AC005597.1', 'AC005624.2', 'AC005722.4', 'AC005740.5', 'AC006003.3', 'AC006007.1', 'AC006041.1', 'AC006116.14', 'AC006130.4', 'AC006153.3', 'AC006296.2', 'AC006372.4', 'AC006372.5', 'AC006372.6', 'AC006373.1', 'AC006427.2', 'AC006499.1', 'AC006499.3', 'AC006499.5', 'AC006499.6', 'AC006509.4', 'AC006960.7', 'AC006987.5', 'AC007128.1', 'AC007131.2', 'AC007163.6', 'AC007193.9', 'AC007249.3', 'AC007253.1', 'AC007292.7', 'AC007322.1', 'AC007349.7', 'AC007391.2', 'AC007403.3', 'AC007463.2', 'AC007557.4', 'AC007563.3', 'AC007563.5', 'AC007568.1', 'AC007679.3', 'AC007682.1', 'AC007740.1', 'AC007742.3', 'AC007796.1', 'AC007879.1', 'AC007879.3', 'AC008067.2', 'AC008074.4', 'AC008154.4', 'AC008278.2', 'AC008281.1', 'AC008746.10', 'AC008746.9', 'AC008834.2', 'AC008940.1', 'AC009161.1', 'AC009237.16', 'AC009237.17', 'AC009238.7', 'AC009238.8', 'AC009310.1', 'AC009312.1', 'AC009313.1', 'AC009410.1', 'AC009477.7', 'AC009487.4', 'AC009487.5', 'AC009541.1', 'AC009970.1', 'AC010096.2', 'AC010141.1', 'AC010518.3', 'AC010729.1', 'AC010729.2', 'AC010731.2', 'AC010731.6', 'AC010884.1', 'AC010907.5', 'AC010967.1', 'AC010967.2', 'AC010974.3', 'AC010983.1', 'AC010987.6', 'AC011196.3', 'AC011243.1', 'AC011286.1', 'AC011343.1', 'AC011516.2', 'AC011524.3', 'AC011648.1', 'AC011742.5', 'AC012074.2', 'AC012075.2', 'AC012322.1', 'AC012354.6', 'AC012363.13', 'AC012456.4', 'AC012506.1', 'AC012506.2', 'AC012506.3', 'AC012506.4', 'AC012507.3', 'AC012507.4', 'AC012513.6', 'AC012668.1', 'AC013402.5', 'AC013429.4', 'AC013448.2', 'AC013480.2', 'AC013733.3', 'AC015936.3', 'AC016694.2', 'AC016735.1', 'AC016745.3', 'AC016831.3', 'AC016831.5', 'AC016912.3', 'AC017019.1', 'AC017048.2', 'AC018359.1', 'AC018643.4', 'AC018685.1', 'AC018717.1', 'AC018799.1', 'AC018804.3', 'AC018880.1', 'AC018880.2', 'AC018892.3', 'AC019064.1', 'AC019118.4', 'AC020595.1', 'AC020743.2', 'AC020915.2', 'AC022201.4', 'AC023115.4', 'AC023128.1', 'AC024082.4', 'AC024704.2', 'AC026202.5', 'AC026954.6', 'AC027124.2', 'AC034228.2', 'AC060834.3', 'AC062016.1', 'AC062022.1', 'AC063976.1', 'AC063976.3', 'AC064834.1', 'AC064834.2', 'AC067945.2', 'AC067956.1', 'AC068057.1', 'AC068490.1', 'AC068492.1', 'AC068535.3', 'AC068831.3', 'AC069155.1', 'AC073218.1', 'AC073464.6', 'AC073641.2', 'AC074338.4', 'AC078842.3', 'AC078882.1', 'AC079112.1', 'AC079117.1', 'AC079145.4', 'AC079154.1', 'AC079325.6', 'AC079586.1', 'AC079610.1', 'AC079776.1', 'AC079987.2', 'AC083864.3', 'AC083939.1', 'AC090018.1', 'AC090952.5', 'AC090957.2', 'AC091133.1', 'AC091729.8', 'AC091814.2', 'AC092155.4', 'AC092159.3', 'AC092168.3', 'AC092566.1', 'AC092570.1', 'AC092570.2', 'AC092578.1', 'AC092601.1', 'AC092635.1', 'AC092657.2', 'AC092933.4', 'AC093063.2', 'AC093084.1', 'AC093106.4', 'AC093326.1', 'AC093381.2', 'AC093590.1', 'AC093642.6', 'AC096582.9', 'AC096669.2', 'AC096732.2', 'AC097468.7', 'AC097713.3', 'AC097713.4', 'AC098592.6', 'AC098828.3', 'AC098872.3', 'AC098973.1', 'AC099344.2', 'AC099344.3', 'AC099552.3', 'AC102948.2', 'AC103563.5', 'AC103563.7', 'AC103563.8', 'AC104076.3', 'AC104306.4', 'AC104777.2', 'AC104777.4', 'AC107083.1', 'AC108032.1', 'AC108066.1', 'AC109589.1', 'AC110620.1', 'AC110754.3', 'AC112198.1', 'AC112220.2', 'AC112518.3', 'AC113167.1', 'AC113167.2', 'AC113607.2', 'AC114752.3', 'AC114814.2', 'AC114877.3', 'AC118653.2', 'AC123900.2', 'AC124057.5', 'AC125421.1', 'AC128709.2', 'AC128709.3', 'AC128709.4', 'AC133633.1', 'AC133680.1', 'AC133785.1', 'AC140481.8', 'AC142119.1', 'AC142293.3', 'AC144450.1', 'AC144833.1', 'ADI1P2', 'AE000661.36', 'AF186192.6', 'AHCYP3', 'AL133249.1', 'AP000345.4', 'AP000356.2', 'AP000619.5', 'AP000648.6', 'AP000997.2', 'AP006285.7', 'ATP5F1P4', 'ATP5G1P8', 'BAATP1', 'BOK-AS1', 'BRI3BPP1', 'BSN-AS1', 'BSN-AS2', 'CASC16', 'CDCA4P3', 'CDKN2AIPNLP2', 'CICP1', 'CLUHP4', 'CNN2P2', 'CTA-392E5.1', 'CTB-138E5.1', 'CTB-164N12.1', 'CTB-49A3.1', 'CTC-304I17.5', 'CTC-339O9.2', 'CTC-501O10.1', 'CTD-2130F23.2', 'CTD-2269E23.3', 'CTD-2308B18.1', 'CTD-2319I12.5', 'CTD-2555O16.1', 'CTD-3187F8.11', 'CYCSP26', 'CYP2T3P', 'DDX43P2', 'DLG3-AS1', 'DPRXP6', 'GLUD1P4', 'GLULP6', 'GRAMD4P7', 'GS1-114I9.1', 'GS1-251I9.2', 'GTSCR1', 'HNRNPH3P1', 'IFT74-AS1', 'IGKV7-3', 'KRT8P6', 'KRTAP20-3', 'LINC00309', 'LINC00364', 'LINC00391', 'LINC00466', 'LINC00838', 'LINC00856', 'LINC00864', 'LINC00879', 'LINC01326', 'LINC01524', 'LRRC34P1', 'MARCKSL1P2', 'MIR1273F', 'MIR4290HG', 'MRLN', 'MTATP6P23', 'MTCO2P16', 'NHEG1', 'NOS2P4', 'OR10B1P', 'OR13Z2P', 'OR2AD1P', 'OR2B8P', 'OR5BN2P', 'OSBPL9P1', 'PDX1-AS1', 'PGBD4P5', 'RN7SKP238', 'RNA5SP205', 'RNF212', 'RNU6-1090P', 'RP1-151B14.9', 'RP11-100K18.1', 'RP11-107N7.1', 'RP11-123J14.1', 'RP11-203B7.2', 'RP11-2H8.3', 'RP11-307O10.1', 'RP11-359G22.2', 'RP11-361A23.3', 'RP11-378I6.1', 'RP11-430C1.1', 'RP11-434D11.4', 'RP11-438B23.2', 'RP11-520D19.2', 'RP11-661A12.12', 'RP11-846C15.2', 'RP11-97F8.1', 'RP13-631K18.2', 'RP3-406P24.4', 'RP4-581O6.1', 'RP5-998G20.1', 'RPL35AP', 'XXyac-YR12DB5.1', 'YBX1P9']].astype(float)\n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.Target[i]=='NR': # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      else:\n",
        "          Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  # scaled_df.head()\n",
        "  # for i in X[:0]:\n",
        "  #   # print(X[i])\n",
        "  #   X[i] = X[i] /X[i].abs().max() \n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # print(\"hola\")\n",
        "  # XTrain.to_xarray()\n",
        "  # XTest.to_xarray()\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  # yTrain=yTrain.to_xarray()\n",
        "  # yTest=yTest.to_xarray()\n",
        "  # building the input vector from the 28x28 pixels\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 20 , 20, 1)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 20, 20, 1)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "# Create FCN model\n",
        "  model = ConvNet(config)\n",
        "\n",
        "  # Compile model with losses and metrics\n",
        "  # tensorflow.keras.optimizers.RMSprop(learning_rate = 0.0001), metrics=['accuracy'])\n",
        "  # tf.keras.optimizers.Nadam(learning_rate\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'#, f1_m,precision_m, recall_m\n",
        "                           ])\n",
        "  \n",
        "  # Create callbacks to be used during model training\n",
        "  # callbacks = create_callbacks()#self.final_run, self.snapshot_dir)\n",
        "  print(\"hhhhhhhhhhhhhhhhhhh\")\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      # steps_per_epoch=len(X_train),\n",
        "                      epochs=1,\n",
        "                      # callbacks=callbacks,\n",
        "                      validation_data=(X_test, yTest),\n",
        "                      # validation_steps=len(yTrain)\n",
        "                      )\n",
        "  # print(type(history_m[\"loss\"]))\n",
        "  print(\"tipado\")\n",
        "  print(type(history_m))\n",
        "  # print(history_m)\n",
        "  print(\"diccionario\")\n",
        "  print(history_m.history)\n",
        "  # history_m = yield from history_m.items()\n",
        "  print(history_m.history[\"val_loss\"][0])\n",
        "  print(type(history_m.history[\"val_loss\"][0]))\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search space\n"
      ],
      "metadata": {
        "id": "kWGKevOoy1JC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ElCuvsvA5SIn"
      },
      "outputs": [],
      "source": [
        "from hyperopt import hp\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "\n",
        "search_space = {\"lr\": hp.choice(\"lr\", [0.0001, 0.001, 0.01, 0.1]),\n",
        "                    \"batch_size\": hp.choice(\"batch_size\", [8, 16, 32, 64]), \n",
        "                    # \"use_contrast\": hp.choice(\"use_contrast\", [\"True\", \"False\"]),\n",
        "                    # \"contrast_factor\": hp.choice('contrast_factor', [0.1, 0.2, 0.3, 0.4]),\n",
        "                    # \"use_rotation\": hp.choice(\"use_rotation\", [\"True\", \"False\"]),\n",
        "                    # \"rotation_factor\": hp.choice('rotation_factor', [0.1, 0.2, 0.3, 0.4]),\n",
        "                    # \"use_flip\": hp.choice(\"use_flip\", [\"True\", \"False\"]),\n",
        "                    # \"flip_mode\": hp.choice('flip_mode', [\"horizontal\", \"vertical\"]),\n",
        "                    \"dropout_rate\": hp.choice(\"dropout_rate\", [0.1, 0.2, 0.3, 0.4, 0.5]),\n",
        "                    \"conv_block1_filters\":hp.choice(\"conv_block1_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block2_filters\":hp.choice(\"conv_block2_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block3_filters\":hp.choice(\"conv_block3_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block4_filters\":hp.choice(\"conv_block4_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block5_filters\":hp.choice(\"conv_block5_filters\", [32, 64, 128, 256]),\n",
        "                    \"fc_layer_type\": hp.choice(\"fc_layer_type\", ['dense', 'convolution']),\n",
        "                    \"pool_type\": hp.choice(\"pool_type\", ['max', 'average']),\n",
        "                    \"fc1_units\":hp.choice(\"fc1_units\", [32, 64, 128, 256, 512])\n",
        "  }\n",
        "\n",
        "# hyperopt_search = HyperOptSearch(search_space, metric=\"mean_accuracy\", mode=\"max\")\n",
        "\n",
        "intial_best_config = [{\"lr\": 0.1,\n",
        "                            \"batch_size\": 8, \n",
        "                            # \"use_contrast\": 1,\n",
        "                            # \"contrast_factor\": 0,\n",
        "                            # \"use_rotation\": 1,\n",
        "                            # \"rotation_factor\": 0,\n",
        "                            # \"use_flip\": 1,\n",
        "                            # \"flip_mode\": 0,\n",
        "                            \"dropout_rate\": 0.1,\n",
        "                            \"conv_block1_filters\": 32,\n",
        "                            \"conv_block2_filters\": 32,\n",
        "                            \"conv_block3_filters\": 32,\n",
        "                            \"conv_block4_filters\": 32,\n",
        "                            \"conv_block5_filters\": 32,\n",
        "                            \"fc_layer_type\": 'dense',\n",
        "                            \"pool_type\": 'max',\n",
        "                            \"fc1_units\": 32}]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Optimization"
      ],
      "metadata": {
        "id": "8QP5Zl8izRcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gN4lI32z5VOp"
      },
      "outputs": [],
      "source": [
        "scheduler = AsyncHyperBandScheduler(time_attr='training_iteration',\n",
        "                                            metric=\"val_accuracy\",\n",
        "                                            mode=\"max\",\n",
        "                                            grace_period=10)\n",
        "hyperopt_search = HyperOptSearch(search_space, metric=\"val_accuracy\", mode=\"max\", points_to_evaluate=intial_best_config)\n",
        "search_alg = ConcurrencyLimiter(hyperopt_search, max_concurrent=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6zeXsJFj5Wql",
        "outputId": "75fd5d38-fb46-40a4-8eb2-8b9541284193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:18:29,286\tWARNING function_runner.py:599 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
            "2022-05-19 11:18:29,313\tINFO logger.py:618 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2022-05-19 11:18:29,315\tWARNING callback.py:126 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
            "2022-05-19 11:18:29,485\tINFO trial_runner.py:803 -- starting train_mnist_68eb5a08\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:18:38 (running for 00:00:08.89)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:18:43 (running for 00:00:13.91)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:18:48 (running for 00:00:18.92)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m 2022-05-19 11:18:53.143380: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:18:53 (running for 00:00:23.94)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  global_max_pooling2d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  dense (Dense)               (None, 32)                1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  dropout (Dropout)           (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization_5 (Batc  (None, 32)               128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  activation_5 (Activation)   (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  dense_1 (Dense)             (None, 2)                 66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m Total params: 25,901\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m Trainable params: 25,513\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m Non-trainable params: 388\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:18:58 (running for 00:00:28.98)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:03 (running for 00:00:33.99)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:08 (running for 00:00:39.01)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 1:12 - loss: 0.6164 - accuracy: 0.6875\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.5000  \n",
            "Result for train_mnist_68eb5a08:\n",
            "  accuracy: 0.5\n",
            "  date: 2022-05-19_11-19-13\n",
            "  done: false\n",
            "  experiment_id: cb59b5a569f34ad0b1a996070bc76fe5\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7345594763755798\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 600\n",
            "  time_since_restore: 35.118512868881226\n",
            "  time_this_iter_s: 35.118512868881226\n",
            "  time_total_s: 35.118512868881226\n",
            "  timestamp: 1652959153\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 68eb5a08\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 191.3994903564453\n",
            "  warmup_time: 0.004825115203857422\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:13 (running for 00:00:44.03)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>RUNNING </td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_68eb5a08:\n",
            "  accuracy: 0.5\n",
            "  date: 2022-05-19_11-19-13\n",
            "  done: true\n",
            "  experiment_id: cb59b5a569f34ad0b1a996070bc76fe5\n",
            "  experiment_tag: 1_batch_size=8,conv_block1_filters=32,conv_block2_filters=32,conv_block3_filters=32,conv_block4_filters=32,conv_block5_filters=32,dropout_rate=0.1,fc1_units=32,fc_layer_type=dense,lr=0.1,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7345594763755798\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 600\n",
            "  time_since_restore: 35.118512868881226\n",
            "  time_this_iter_s: 35.118512868881226\n",
            "  time_total_s: 35.118512868881226\n",
            "  timestamp: 1652959153\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 68eb5a08\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 191.3994903564453\n",
            "  warmup_time: 0.004825115203857422\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 19s 148ms/step - loss: 0.7346 - accuracy: 0.5000 - val_loss: 191.3995 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m {'loss': [0.7345594763755798], 'accuracy': [0.5], 'val_loss': [191.3994903564453], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m 191.3994903564453\n",
            "\u001b[2m\u001b[36m(train_mnist pid=600)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:19:13,858\tINFO trial_runner.py:803 -- starting train_mnist_832702aa\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:18 (running for 00:00:49.55)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_832702aa</td><td>RUNNING   </td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:23 (running for 00:00:54.57)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_832702aa</td><td>RUNNING   </td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:28 (running for 00:00:59.60)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_832702aa</td><td>RUNNING   </td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:33 (running for 00:01:04.62)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_832702aa</td><td>RUNNING   </td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:38 (running for 00:01:09.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_832702aa</td><td>RUNNING   </td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m 2022-05-19 11:19:39.930574: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       36992     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        16416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m Total params: 81,773\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m Trainable params: 80,745\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m Non-trainable params: 1,028\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 1.5910 - accuracy: 0.5312\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:43 (running for 00:01:14.67)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_832702aa</td><td>RUNNING   </td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">   191.399</td><td style=\"text-align: right;\">       0.5</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 0.5486 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:19:44,861\tINFO trial_runner.py:803 -- starting train_mnist_95d26c50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_832702aa:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-19-44\n",
            "  done: false\n",
            "  experiment_id: c4a5cc1dfae64ba281bc98ed0ab16755\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4496068954467773\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 685\n",
            "  time_since_restore: 26.37736201286316\n",
            "  time_this_iter_s: 26.37736201286316\n",
            "  time_total_s: 26.37736201286316\n",
            "  timestamp: 1652959184\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 832702aa\n",
            "  val_accuracy: 0.4054054021835327\n",
            "  val_loss: 0.6962077617645264\n",
            "  warmup_time: 0.004548788070678711\n",
            "  \n",
            "Result for train_mnist_832702aa:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-19-44\n",
            "  done: true\n",
            "  experiment_id: c4a5cc1dfae64ba281bc98ed0ab16755\n",
            "  experiment_tag: 2_batch_size=64,conv_block1_filters=32,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=32,conv_block5_filters=256,dropout_rate=0.5,fc1_units=32,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4496068954467773\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 685\n",
            "  time_since_restore: 26.37736201286316\n",
            "  time_this_iter_s: 26.37736201286316\n",
            "  time_total_s: 26.37736201286316\n",
            "  timestamp: 1652959184\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 832702aa\n",
            "  val_accuracy: 0.4054054021835327\n",
            "  val_loss: 0.6962077617645264\n",
            "  warmup_time: 0.004548788070678711\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 4s 192ms/step - loss: 1.4496 - accuracy: 0.5486 - val_loss: 0.6962 - val_accuracy: 0.4054\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m {'loss': [1.4496068954467773], 'accuracy': [0.5486111044883728], 'val_loss': [0.6962077617645264], 'val_accuracy': [0.4054054021835327]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m 0.6962077617645264\n",
            "\u001b[2m\u001b[36m(train_mnist pid=685)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:49 (running for 00:01:20.55)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95d26c50</td><td>RUNNING   </td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:54 (running for 00:01:25.58)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95d26c50</td><td>RUNNING   </td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:19:59 (running for 00:01:30.60)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95d26c50</td><td>RUNNING   </td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m 2022-05-19 11:19:59.930650: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        147488    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  global_max_pooling2d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  dense (Dense)               (None, 32)                1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  dropout (Dropout)           (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization_5 (Batc  (None, 32)               128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  activation_5 (Activation)   (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  dense_1 (Dense)             (None, 2)                 66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m Total params: 1,340,109\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m Trainable params: 1,338,313\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m Non-trainable params: 1,796\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.8365 - accuracy: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.8255 - accuracy: 0.4896 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:04 (running for 00:01:35.62)<br>Memory usage on this node: 3.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95d26c50</td><td>RUNNING   </td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - ETA: 0s - loss: 0.7978 - accuracy: 0.5208\n",
            "5/5 [==============================] - 5s 273ms/step - loss: 0.7978 - accuracy: 0.5208 - val_loss: 1.8471 - val_accuracy: 0.5405\n",
            "Result for train_mnist_95d26c50:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-20-07\n",
            "  done: false\n",
            "  experiment_id: 035e9d438f6a4bba8320845d89b2845f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7977529764175415\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 762\n",
            "  time_since_restore: 18.361523628234863\n",
            "  time_this_iter_s: 18.361523628234863\n",
            "  time_total_s: 18.361523628234863\n",
            "  timestamp: 1652959207\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 95d26c50\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 1.8471498489379883\n",
            "  warmup_time: 0.004323720932006836\n",
            "  \n",
            "Result for train_mnist_95d26c50:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-20-07\n",
            "  done: true\n",
            "  experiment_id: 035e9d438f6a4bba8320845d89b2845f\n",
            "  experiment_tag: 3_batch_size=64,conv_block1_filters=256,conv_block2_filters=512,conv_block3_filters=32,conv_block4_filters=32,conv_block5_filters=32,dropout_rate=0.2,fc1_units=32,fc_layer_type=dense,lr=0.01,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7977529764175415\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 762\n",
            "  time_since_restore: 18.361523628234863\n",
            "  time_this_iter_s: 18.361523628234863\n",
            "  time_total_s: 18.361523628234863\n",
            "  timestamp: 1652959207\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 95d26c50\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 1.8471498489379883\n",
            "  warmup_time: 0.004323720932006836\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m {'loss': [0.7977529764175415], 'accuracy': [0.5208333134651184], 'val_loss': [1.8471498489379883], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m 1.8471498489379883\n",
            "\u001b[2m\u001b[36m(train_mnist pid=762)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:20:08,863\tINFO trial_runner.py:803 -- starting train_mnist_a39f1860\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:13 (running for 00:01:44.56)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 4/50 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a39f1860</td><td>RUNNING   </td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:18 (running for 00:01:49.58)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 4/50 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a39f1860</td><td>RUNNING   </td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m 2022-05-19 11:20:23.798954: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:23 (running for 00:01:54.60)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 4/50 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a39f1860</td><td>RUNNING   </td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       295424    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       1179904   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       131200    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m Total params: 1,653,485\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m Trainable params: 1,650,985\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m Non-trainable params: 2,500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 3.0696 - accuracy: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 2.9031 - accuracy: 0.4792 \n",
            "5/5 [==============================] - ETA: 0s - loss: 3.0615 - accuracy: 0.4514\n",
            "Result for train_mnist_a39f1860:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-19_11-20-28\n",
            "  done: false\n",
            "  experiment_id: 89f742f07cbc40d7b45efae46ebf74cd\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 3.061464548110962\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 838\n",
            "  time_since_restore: 15.548993587493896\n",
            "  time_this_iter_s: 15.548993587493896\n",
            "  time_total_s: 15.548993587493896\n",
            "  timestamp: 1652959228\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a39f1860\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.692285418510437\n",
            "  warmup_time: 0.004288196563720703\n",
            "  \n",
            "Result for train_mnist_a39f1860:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-19_11-20-28\n",
            "  done: true\n",
            "  experiment_id: 89f742f07cbc40d7b45efae46ebf74cd\n",
            "  experiment_tag: 4_batch_size=16,conv_block1_filters=64,conv_block2_filters=512,conv_block3_filters=256,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.4,fc1_units=32,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 3.061464548110962\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 838\n",
            "  time_since_restore: 15.548993587493896\n",
            "  time_this_iter_s: 15.548993587493896\n",
            "  time_total_s: 15.548993587493896\n",
            "  timestamp: 1652959228\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a39f1860\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.692285418510437\n",
            "  warmup_time: 0.004288196563720703\n",
            "  \n",
            "5/5 [==============================] - 5s 245ms/step - loss: 3.0615 - accuracy: 0.4514 - val_loss: 0.6923 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m {'loss': [3.061464548110962], 'accuracy': [0.4513888955116272], 'val_loss': [0.692285418510437], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m 0.692285418510437\n",
            "\u001b[2m\u001b[36m(train_mnist pid=838)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:20:29,868\tINFO trial_runner.py:803 -- starting train_mnist_b02fbfe4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:29 (running for 00:02:00.56)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>RUNNING   </td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:39 (running for 00:02:10.05)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>RUNNING   </td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:44 (running for 00:02:15.07)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>RUNNING   </td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m 2022-05-19 11:20:45.422031: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        147488    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  global_max_pooling2d (Globa  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  dense (Dense)               (None, 128)               16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m Total params: 241,261\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m Trainable params: 239,273\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m Non-trainable params: 1,988\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:49 (running for 00:02:20.10)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>RUNNING   </td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m \r1/5 [=====>........................] - ETA: 15s - loss: 0.7066 - accuracy: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7080 - accuracy: 0.5729 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.5417\n",
            "5/5 [==============================] - 5s 196ms/step - loss: 0.7506 - accuracy: 0.5417 - val_loss: 0.6936 - val_accuracy: 0.4595\n",
            "Result for train_mnist_b02fbfe4:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-19_11-20-50\n",
            "  done: false\n",
            "  experiment_id: f52f1824aa574f7ba5ef6ef0ab1cd7f2\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7505596280097961\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 914\n",
            "  time_since_restore: 16.45838952064514\n",
            "  time_this_iter_s: 16.45838952064514\n",
            "  time_total_s: 16.45838952064514\n",
            "  timestamp: 1652959250\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b02fbfe4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.693584680557251\n",
            "  warmup_time: 0.004461765289306641\n",
            "  \n",
            "Result for train_mnist_b02fbfe4:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-19_11-20-50\n",
            "  done: true\n",
            "  experiment_id: f52f1824aa574f7ba5ef6ef0ab1cd7f2\n",
            "  experiment_tag: 5_batch_size=8,conv_block1_filters=512,conv_block2_filters=32,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=128,dropout_rate=0.3,fc1_units=128,fc_layer_type=dense,lr=0.0001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7505596280097961\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 914\n",
            "  time_since_restore: 16.45838952064514\n",
            "  time_this_iter_s: 16.45838952064514\n",
            "  time_total_s: 16.45838952064514\n",
            "  timestamp: 1652959250\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b02fbfe4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.693584680557251\n",
            "  warmup_time: 0.004461765289306641\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m {'loss': [0.7505596280097961], 'accuracy': [0.5416666865348816], 'val_loss': [0.693584680557251], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m 0.693584680557251\n",
            "\u001b[2m\u001b[36m(train_mnist pid=914)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:20:51,871\tINFO trial_runner.py:803 -- starting train_mnist_bd3c0756\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:20:56 (running for 00:02:27.56)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>RUNNING   </td><td>172.28.0.2:987</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:01 (running for 00:02:32.60)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>RUNNING   </td><td>172.28.0.2:987</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m 2022-05-19 11:21:06.842323: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:06 (running for 00:02:37.62)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>RUNNING   </td><td>172.28.0.2:987</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        32832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        2080      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  global_average_pooling2d (G  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  dense (Dense)               (None, 128)               4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m Total params: 190,509\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m Trainable params: 189,417\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m Non-trainable params: 1,092\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.8935 - accuracy: 0.3125\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7763 - accuracy: 0.4141 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7730 - accuracy: 0.3958\n",
            "5/5 [==============================] - 5s 183ms/step - loss: 0.7730 - accuracy: 0.3958 - val_loss: 2203.3445 - val_accuracy: 0.5405\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:11 (running for 00:02:42.65)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>RUNNING   </td><td>172.28.0.2:987</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_bd3c0756:\n",
            "  accuracy: 0.3958333432674408\n",
            "  date: 2022-05-19_11-21-12\n",
            "  done: false\n",
            "  experiment_id: a3e55eb95c0c48c58d2e7d203c83e230\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7730053067207336\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 987\n",
            "  time_since_restore: 15.897021055221558\n",
            "  time_this_iter_s: 15.897021055221558\n",
            "  time_total_s: 15.897021055221558\n",
            "  timestamp: 1652959272\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bd3c0756\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 2203.344482421875\n",
            "  warmup_time: 0.004220485687255859\n",
            "  \n",
            "Result for train_mnist_bd3c0756:\n",
            "  accuracy: 0.3958333432674408\n",
            "  date: 2022-05-19_11-21-12\n",
            "  done: true\n",
            "  experiment_id: a3e55eb95c0c48c58d2e7d203c83e230\n",
            "  experiment_tag: 6_batch_size=32,conv_block1_filters=128,conv_block2_filters=64,conv_block3_filters=128,conv_block4_filters=64,conv_block5_filters=32,dropout_rate=0.5,fc1_units=128,fc_layer_type=dense,lr=0.1,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7730053067207336\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 987\n",
            "  time_since_restore: 15.897021055221558\n",
            "  time_this_iter_s: 15.897021055221558\n",
            "  time_total_s: 15.897021055221558\n",
            "  timestamp: 1652959272\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bd3c0756\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 2203.344482421875\n",
            "  warmup_time: 0.004220485687255859\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m {'loss': [0.7730053067207336], 'accuracy': [0.3958333432674408], 'val_loss': [2203.344482421875], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m 2203.344482421875\n",
            "\u001b[2m\u001b[36m(train_mnist pid=987)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:21:12,873\tINFO trial_runner.py:803 -- starting train_mnist_c9fe012e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:17 (running for 00:02:48.57)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>RUNNING   </td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:22 (running for 00:02:53.61)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>RUNNING   </td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:27 (running for 00:02:58.63)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>RUNNING   </td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m 2022-05-19 11:21:28.033088: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       589952    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        65600     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  global_max_pooling2d (Globa  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  dense (Dense)               (None, 128)               32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m Total params: 1,011,021\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m Trainable params: 1,008,329\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.8468 - accuracy: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.8137 - accuracy: 0.5104 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.5278\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:32 (running for 00:03:03.66)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>RUNNING   </td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 219ms/step - loss: 0.7949 - accuracy: 0.5278 - val_loss: 0.6919 - val_accuracy: 0.4595\n",
            "Result for train_mnist_c9fe012e:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-19_11-21-33\n",
            "  done: false\n",
            "  experiment_id: 948c68d40eee4f8bbea5b4852480e8bd\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.794908344745636\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1061\n",
            "  time_since_restore: 15.661087989807129\n",
            "  time_this_iter_s: 15.661087989807129\n",
            "  time_total_s: 15.661087989807129\n",
            "  timestamp: 1652959293\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c9fe012e\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6919361352920532\n",
            "  warmup_time: 0.004230976104736328\n",
            "  \n",
            "Result for train_mnist_c9fe012e:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-19_11-21-33\n",
            "  done: true\n",
            "  experiment_id: 948c68d40eee4f8bbea5b4852480e8bd\n",
            "  experiment_tag: 7_batch_size=64,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=256,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.5,fc1_units=128,fc_layer_type=dense,lr=0.001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.794908344745636\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1061\n",
            "  time_since_restore: 15.661087989807129\n",
            "  time_this_iter_s: 15.661087989807129\n",
            "  time_total_s: 15.661087989807129\n",
            "  timestamp: 1652959293\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c9fe012e\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6919361352920532\n",
            "  warmup_time: 0.004230976104736328\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m {'loss': [0.794908344745636], 'accuracy': [0.5277777910232544], 'val_loss': [0.6919361352920532], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m 0.6919361352920532\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1061)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:21:33,873\tINFO trial_runner.py:803 -- starting train_mnist_d6a1467a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:38 (running for 00:03:09.57)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>RUNNING   </td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:43 (running for 00:03:14.60)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>RUNNING   </td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:48 (running for 00:03:19.62)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>RUNNING   </td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m 2022-05-19 11:21:49.547594: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       262272    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  global_average_pooling2d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  dense (Dense)               (None, 64)                4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  dropout (Dropout)           (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization_5 (Batc  (None, 64)               256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  activation_5 (Activation)   (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  dense_1 (Dense)             (None, 2)                 130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m Total params: 943,501\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m Trainable params: 941,577\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m Non-trainable params: 1,924\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:21:53 (running for 00:03:24.64)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>RUNNING   </td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.7282 - accuracy: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.5208\n",
            "Result for train_mnist_d6a1467a:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-21-54\n",
            "  done: false\n",
            "  experiment_id: 0b7f30b71add4a6faeed25cd58715f05\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7056145071983337\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1136\n",
            "  time_since_restore: 16.389852046966553\n",
            "  time_this_iter_s: 16.389852046966553\n",
            "  time_total_s: 16.389852046966553\n",
            "  timestamp: 1652959314\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d6a1467a\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6932504177093506\n",
            "  warmup_time: 0.004351139068603516\n",
            "  \n",
            "Result for train_mnist_d6a1467a:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-21-54\n",
            "  done: true\n",
            "  experiment_id: 0b7f30b71add4a6faeed25cd58715f05\n",
            "  experiment_tag: 8_batch_size=32,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=128,conv_block5_filters=64,dropout_rate=0.1,fc1_units=64,fc_layer_type=dense,lr=0.0001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7056145071983337\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1136\n",
            "  time_since_restore: 16.389852046966553\n",
            "  time_this_iter_s: 16.389852046966553\n",
            "  time_total_s: 16.389852046966553\n",
            "  timestamp: 1652959314\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d6a1467a\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6932504177093506\n",
            "  warmup_time: 0.004351139068603516\n",
            "  \n",
            "5/5 [==============================] - 5s 218ms/step - loss: 0.7056 - accuracy: 0.5208 - val_loss: 0.6933 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m {'loss': [0.7056145071983337], 'accuracy': [0.5208333134651184], 'val_loss': [0.6932504177093506], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m 0.6932504177093506\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1136)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:21:55,882\tINFO trial_runner.py:803 -- starting train_mnist_e367a9bc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:00 (running for 00:03:31.57)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>RUNNING   </td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:06 (running for 00:03:36.81)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>RUNNING   </td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:11 (running for 00:03:41.83)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>RUNNING   </td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m 2022-05-19 11:22:11.597840: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       589952    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  dense (Dense)               (None, 512)               131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  dropout (Dropout)           (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization_5 (Batc  (None, 512)              2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  activation_5 (Activation)   (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  dense_1 (Dense)             (None, 2)                 1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m Total params: 1,473,741\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m Trainable params: 1,469,769\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m Non-trainable params: 3,972\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.9945 - accuracy: 0.3438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:16 (running for 00:03:46.86)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>RUNNING   </td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.8377 - accuracy: 0.4792 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7865 - accuracy: 0.5278\n",
            "Result for train_mnist_e367a9bc:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-19_11-22-16\n",
            "  done: false\n",
            "  experiment_id: d3b9cf80d4094c29b8e15d98f3d68e65\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7864726781845093\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1207\n",
            "  time_since_restore: 15.884093999862671\n",
            "  time_this_iter_s: 15.884093999862671\n",
            "  time_total_s: 15.884093999862671\n",
            "  timestamp: 1652959336\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e367a9bc\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6765990853309631\n",
            "  warmup_time: 0.0038678646087646484\n",
            "  \n",
            "Result for train_mnist_e367a9bc:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-19_11-22-16\n",
            "  done: true\n",
            "  experiment_id: d3b9cf80d4094c29b8e15d98f3d68e65\n",
            "  experiment_tag: 9_batch_size=8,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=512,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7864726781845093\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1207\n",
            "  time_since_restore: 15.884093999862671\n",
            "  time_this_iter_s: 15.884093999862671\n",
            "  time_total_s: 15.884093999862671\n",
            "  timestamp: 1652959336\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e367a9bc\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6765990853309631\n",
            "  warmup_time: 0.0038678646087646484\n",
            "  \n",
            "5/5 [==============================] - 5s 225ms/step - loss: 0.7865 - accuracy: 0.5278 - val_loss: 0.6766 - val_accuracy: 0.5946\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m {'loss': [0.7864726781845093], 'accuracy': [0.5277777910232544], 'val_loss': [0.6765990853309631], 'val_accuracy': [0.5945945978164673]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m 0.6765990853309631\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1207)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:22:17,883\tINFO trial_runner.py:803 -- starting train_mnist_f09b7de8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:22 (running for 00:03:53.58)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>RUNNING   </td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:27 (running for 00:03:58.62)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>RUNNING   </td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m 2022-05-19 11:22:32.837120: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:32 (running for 00:04:03.63)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>RUNNING   </td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 256)       73984     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       262272    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  global_average_pooling2d (G  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  dense (Dense)               (None, 128)               16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m Total params: 1,554,765\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m Trainable params: 1,552,393\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m Non-trainable params: 2,372\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 0.7835 - accuracy: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7429 - accuracy: 0.5208 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7852 - accuracy: 0.4792\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:37 (running for 00:04:08.67)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>RUNNING   </td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 275ms/step - loss: 0.7852 - accuracy: 0.4792 - val_loss: 0.6921 - val_accuracy: 0.5405\n",
            "Result for train_mnist_f09b7de8:\n",
            "  accuracy: 0.4791666567325592\n",
            "  date: 2022-05-19_11-22-40\n",
            "  done: false\n",
            "  experiment_id: 26d9e800bbfa4bffb0aa1351579e6f55\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7852179408073425\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1277\n",
            "  time_since_restore: 18.502410173416138\n",
            "  time_this_iter_s: 18.502410173416138\n",
            "  time_total_s: 18.502410173416138\n",
            "  timestamp: 1652959360\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f09b7de8\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6921399831771851\n",
            "  warmup_time: 0.0038864612579345703\n",
            "  \n",
            "Result for train_mnist_f09b7de8:\n",
            "  accuracy: 0.4791666567325592\n",
            "  date: 2022-05-19_11-22-40\n",
            "  done: true\n",
            "  experiment_id: 26d9e800bbfa4bffb0aa1351579e6f55\n",
            "  experiment_tag: 10_batch_size=16,conv_block1_filters=32,conv_block2_filters=256,conv_block3_filters=512,conv_block4_filters=128,conv_block5_filters=128,dropout_rate=0.3,fc1_units=128,fc_layer_type=dense,lr=0.0001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7852179408073425\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1277\n",
            "  time_since_restore: 18.502410173416138\n",
            "  time_this_iter_s: 18.502410173416138\n",
            "  time_total_s: 18.502410173416138\n",
            "  timestamp: 1652959360\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f09b7de8\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6921399831771851\n",
            "  warmup_time: 0.0038864612579345703\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m {'loss': [0.7852179408073425], 'accuracy': [0.4791666567325592], 'val_loss': [0.6921399831771851], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m 0.6921399831771851\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1277)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:22:41,885\tINFO trial_runner.py:803 -- starting train_mnist_fed5f4c4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:46 (running for 00:04:17.57)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 11/50 (1 RUNNING, 10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>RUNNING   </td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:51 (running for 00:04:22.61)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 11/50 (1 RUNNING, 10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>RUNNING   </td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m 2022-05-19 11:22:56.587120: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        18464     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        16416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 64)        2112      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  dropout (Dropout)           (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m Total params: 143,821\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m Trainable params: 142,281\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m Non-trainable params: 1,540\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:22:56 (running for 00:04:27.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 11/50 (1 RUNNING, 10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>RUNNING   </td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 14s - loss: 1.0456 - accuracy: 0.4062\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4254 - accuracy: 0.4236 \n",
            "Result for train_mnist_fed5f4c4:\n",
            "  accuracy: 0.4236111044883728\n",
            "  date: 2022-05-19_11-23-01\n",
            "  done: false\n",
            "  experiment_id: f58375b4d96046838ed1ceb2eb23c5bf\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4254449605941772\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1352\n",
            "  time_since_restore: 14.867238283157349\n",
            "  time_this_iter_s: 14.867238283157349\n",
            "  time_total_s: 14.867238283157349\n",
            "  timestamp: 1652959381\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fed5f4c4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 5991.82568359375\n",
            "  warmup_time: 0.004207611083984375\n",
            "  \n",
            "Result for train_mnist_fed5f4c4:\n",
            "  accuracy: 0.4236111044883728\n",
            "  date: 2022-05-19_11-23-01\n",
            "  done: true\n",
            "  experiment_id: f58375b4d96046838ed1ceb2eb23c5bf\n",
            "  experiment_tag: 11_batch_size=32,conv_block1_filters=64,conv_block2_filters=64,conv_block3_filters=32,conv_block4_filters=512,conv_block5_filters=32,dropout_rate=0.2,fc1_units=64,fc_layer_type=convolution,lr=0.1,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4254449605941772\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1352\n",
            "  time_since_restore: 14.867238283157349\n",
            "  time_this_iter_s: 14.867238283157349\n",
            "  time_total_s: 14.867238283157349\n",
            "  timestamp: 1652959381\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fed5f4c4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 5991.82568359375\n",
            "  warmup_time: 0.004207611083984375\n",
            "  \n",
            "5/5 [==============================] - 4s 166ms/step - loss: 1.4254 - accuracy: 0.4236 - val_loss: 5991.8257 - val_accuracy: 0.4595\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m {'loss': [1.4254449605941772], 'accuracy': [0.4236111044883728], 'val_loss': [5991.82568359375], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m 5991.82568359375\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1352)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:23:01,887\tINFO trial_runner.py:803 -- starting train_mnist_0aed775a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:06 (running for 00:04:37.60)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 12/50 (1 RUNNING, 11 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_0aed775a</td><td>RUNNING   </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:11 (running for 00:04:42.62)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 12/50 (1 RUNNING, 11 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_0aed775a</td><td>RUNNING   </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m 2022-05-19 11:23:16.317625: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        147520    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 32)        1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m Total params: 264,973\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m Trainable params: 263,561\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:16 (running for 00:04:47.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 12/50 (1 RUNNING, 11 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_0aed775a</td><td>RUNNING   </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/5 [=======================>......] - ETA: 0s - loss: 1.7793 - accuracy: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.6705 - accuracy: 0.5486\n",
            "5/5 [==============================] - 5s 235ms/step - loss: 1.6705 - accuracy: 0.5486 - val_loss: 2.6795 - val_accuracy: 0.4595\n",
            "Result for train_mnist_0aed775a:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-23-21\n",
            "  done: false\n",
            "  experiment_id: 53ffb44cccbb49f7b32b6c6062b8bc9d\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.6705001592636108\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1423\n",
            "  time_since_restore: 15.043261528015137\n",
            "  time_this_iter_s: 15.043261528015137\n",
            "  time_total_s: 15.043261528015137\n",
            "  timestamp: 1652959401\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 0aed775a\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 2.6795365810394287\n",
            "  warmup_time: 0.004180908203125\n",
            "  \n",
            "Result for train_mnist_0aed775a:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-23-21\n",
            "  done: true\n",
            "  experiment_id: 53ffb44cccbb49f7b32b6c6062b8bc9d\n",
            "  experiment_tag: 12_batch_size=16,conv_block1_filters=256,conv_block2_filters=64,conv_block3_filters=64,conv_block4_filters=256,conv_block5_filters=32,dropout_rate=0.3,fc1_units=32,fc_layer_type=convolution,lr=0.01,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.6705001592636108\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1423\n",
            "  time_since_restore: 15.043261528015137\n",
            "  time_this_iter_s: 15.043261528015137\n",
            "  time_total_s: 15.043261528015137\n",
            "  timestamp: 1652959401\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 0aed775a\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 2.6795365810394287\n",
            "  warmup_time: 0.004180908203125\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m {'loss': [1.6705001592636108], 'accuracy': [0.5486111044883728], 'val_loss': [2.6795365810394287], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m 2.6795365810394287\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1423)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:23:21,888\tINFO trial_runner.py:803 -- starting train_mnist_1701dbda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:26 (running for 00:04:57.59)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1701dbda</td><td>RUNNING   </td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:31 (running for 00:05:02.63)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1701dbda</td><td>RUNNING   </td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m 2022-05-19 11:23:36.393289: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       295424    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       524544    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  global_max_pooling2d (Globa  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  dense (Dense)               (None, 64)                8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  dropout (Dropout)           (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization_5 (Batc  (None, 64)               256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  activation_5 (Activation)   (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  dense_1 (Dense)             (None, 2)                 130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m Total params: 3,227,853\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m Trainable params: 3,224,777\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m Non-trainable params: 3,076\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:36 (running for 00:05:07.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1701dbda</td><td>RUNNING   </td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m \r1/5 [=====>........................] - ETA: 17s - loss: 0.7982 - accuracy: 0.5312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/5 [===========>..................] - ETA: 0s - loss: 0.7532 - accuracy: 0.5156 \n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7388 - accuracy: 0.5391\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.5417\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:42 (running for 00:05:12.70)<br>Memory usage on this node: 3.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1701dbda</td><td>RUNNING   </td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_1701dbda:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-19_11-23-42\n",
            "  done: false\n",
            "  experiment_id: 60b7ff9b480248f3b027fe3bd5e8301b\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7225891351699829\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1495\n",
            "  time_since_restore: 16.1045343875885\n",
            "  time_this_iter_s: 16.1045343875885\n",
            "  time_total_s: 16.1045343875885\n",
            "  timestamp: 1652959422\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1701dbda\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.7058698534965515\n",
            "  warmup_time: 0.004191398620605469\n",
            "  \n",
            "Result for train_mnist_1701dbda:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-19_11-23-42\n",
            "  done: true\n",
            "  experiment_id: 60b7ff9b480248f3b027fe3bd5e8301b\n",
            "  experiment_tag: 13_batch_size=16,conv_block1_filters=64,conv_block2_filters=512,conv_block3_filters=512,conv_block4_filters=256,conv_block5_filters=128,dropout_rate=0.2,fc1_units=64,fc_layer_type=dense,lr=0.001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7225891351699829\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1495\n",
            "  time_since_restore: 16.1045343875885\n",
            "  time_this_iter_s: 16.1045343875885\n",
            "  time_total_s: 16.1045343875885\n",
            "  timestamp: 1652959422\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1701dbda\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.7058698534965515\n",
            "  warmup_time: 0.004191398620605469\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 6s 306ms/step - loss: 0.7226 - accuracy: 0.5417 - val_loss: 0.7059 - val_accuracy: 0.4595\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m {'loss': [0.7225891351699829], 'accuracy': [0.5416666865348816], 'val_loss': [0.7058698534965515], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m 0.7058698534965515\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1495)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:23:42,890\tINFO trial_runner.py:803 -- starting train_mnist_2383fb72\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:47 (running for 00:05:18.59)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2383fb72</td><td>RUNNING   </td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:52 (running for 00:05:23.63)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2383fb72</td><td>RUNNING   </td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:23:57 (running for 00:05:28.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2383fb72</td><td>RUNNING   </td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m 2022-05-19 11:23:58.102345: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       73984     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        32800     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  global_max_pooling2d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  dense (Dense)               (None, 128)               4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m Total params: 123,949\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m Trainable params: 122,921\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m Non-trainable params: 1,028\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7160 - accuracy: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7243 - accuracy: 0.5069\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:03 (running for 00:05:33.70)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2383fb72</td><td>RUNNING   </td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_2383fb72:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-19_11-24-03\n",
            "  done: false\n",
            "  experiment_id: fa3d28099b5d4750b2d640bd36237089\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7242746949195862\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1570\n",
            "  time_since_restore: 15.567402124404907\n",
            "  time_this_iter_s: 15.567402124404907\n",
            "  time_total_s: 15.567402124404907\n",
            "  timestamp: 1652959443\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2383fb72\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6936344504356384\n",
            "  warmup_time: 0.004357814788818359\n",
            "  \n",
            "Result for train_mnist_2383fb72:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-19_11-24-03\n",
            "  done: true\n",
            "  experiment_id: fa3d28099b5d4750b2d640bd36237089\n",
            "  experiment_tag: 14_batch_size=16,conv_block1_filters=32,conv_block2_filters=32,conv_block3_filters=256,conv_block4_filters=32,conv_block5_filters=32,dropout_rate=0.5,fc1_units=128,fc_layer_type=dense,lr=0.0001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7242746949195862\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1570\n",
            "  time_since_restore: 15.567402124404907\n",
            "  time_this_iter_s: 15.567402124404907\n",
            "  time_total_s: 15.567402124404907\n",
            "  timestamp: 1652959443\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2383fb72\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6936344504356384\n",
            "  warmup_time: 0.004357814788818359\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 188ms/step - loss: 0.7243 - accuracy: 0.5069 - val_loss: 0.6936 - val_accuracy: 0.4595\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m {'loss': [0.7242746949195862], 'accuracy': [0.5069444179534912], 'val_loss': [0.6936344504356384], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m 0.6936344504356384\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1570)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:24:03,892\tINFO trial_runner.py:803 -- starting train_mnist_2fd1ef88\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:08 (running for 00:05:39.58)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>RUNNING   </td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:13 (running for 00:05:44.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>RUNNING   </td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m 2022-05-19 11:24:18.248160: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       1179904   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       262400    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 512)       66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  dropout (Dropout)           (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m Total params: 3,915,917\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m Trainable params: 3,911,561\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m Non-trainable params: 4,356\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:18 (running for 00:05:49.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>RUNNING   </td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m \r1/5 [=====>........................] - ETA: 17s - loss: 0.7473 - accuracy: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7688 - accuracy: 0.5312\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7665 - accuracy: 0.5234\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7744 - accuracy: 0.5208\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:24 (running for 00:05:54.70)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>RUNNING   </td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 6s 381ms/step - loss: 0.7744 - accuracy: 0.5208 - val_loss: 0.7135 - val_accuracy: 0.4595\n",
            "Result for train_mnist_2fd1ef88:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-24-25\n",
            "  done: false\n",
            "  experiment_id: 575d4b2036ff479e860e2e06be1e226e\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7744189500808716\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1641\n",
            "  time_since_restore: 17.4771089553833\n",
            "  time_this_iter_s: 17.4771089553833\n",
            "  time_total_s: 17.4771089553833\n",
            "  timestamp: 1652959465\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2fd1ef88\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.713470995426178\n",
            "  warmup_time: 0.0038585662841796875\n",
            "  \n",
            "Result for train_mnist_2fd1ef88:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-24-25\n",
            "  done: true\n",
            "  experiment_id: 575d4b2036ff479e860e2e06be1e226e\n",
            "  experiment_tag: 15_batch_size=16,conv_block1_filters=512,conv_block2_filters=512,conv_block3_filters=256,conv_block4_filters=256,conv_block5_filters=128,dropout_rate=0.1,fc1_units=512,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7744189500808716\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1641\n",
            "  time_since_restore: 17.4771089553833\n",
            "  time_this_iter_s: 17.4771089553833\n",
            "  time_total_s: 17.4771089553833\n",
            "  timestamp: 1652959465\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2fd1ef88\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.713470995426178\n",
            "  warmup_time: 0.0038585662841796875\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m {'loss': [0.7744189500808716], 'accuracy': [0.5208333134651184], 'val_loss': [0.713470995426178], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m 0.713470995426178\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1641)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:24:26,893\tINFO trial_runner.py:803 -- starting train_mnist_3d6f9262\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:31 (running for 00:06:02.60)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 16/50 (1 RUNNING, 15 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>RUNNING   </td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:36 (running for 00:06:07.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 16/50 (1 RUNNING, 15 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>RUNNING   </td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m 2022-05-19 11:24:41.466831: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        18464     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 128)       4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  dropout (Dropout)           (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m Total params: 76,269\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m Trainable params: 75,177\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m Non-trainable params: 1,092\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:41 (running for 00:06:12.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 16/50 (1 RUNNING, 15 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>RUNNING   </td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m \r1/5 [=====>........................] - ETA: 14s - loss: 3.2209 - accuracy: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 3.3114 - accuracy: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 3.2392 - accuracy: 0.4514\n",
            "5/5 [==============================] - 4s 191ms/step - loss: 3.2392 - accuracy: 0.4514 - val_loss: 0.6938 - val_accuracy: 0.4595\n",
            "Result for train_mnist_3d6f9262:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-19_11-24-46\n",
            "  done: false\n",
            "  experiment_id: 93b995e6350349768b5181f7adaa6681\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 3.239169120788574\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1715\n",
            "  time_since_restore: 15.229551076889038\n",
            "  time_this_iter_s: 15.229551076889038\n",
            "  time_total_s: 15.229551076889038\n",
            "  timestamp: 1652959486\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 3d6f9262\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6938202977180481\n",
            "  warmup_time: 0.00397038459777832\n",
            "  \n",
            "Result for train_mnist_3d6f9262:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-19_11-24-46\n",
            "  done: true\n",
            "  experiment_id: 93b995e6350349768b5181f7adaa6681\n",
            "  experiment_tag: 16_batch_size=32,conv_block1_filters=64,conv_block2_filters=32,conv_block3_filters=32,conv_block4_filters=256,conv_block5_filters=32,dropout_rate=0.5,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 3.239169120788574\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1715\n",
            "  time_since_restore: 15.229551076889038\n",
            "  time_this_iter_s: 15.229551076889038\n",
            "  time_total_s: 15.229551076889038\n",
            "  timestamp: 1652959486\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 3d6f9262\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6938202977180481\n",
            "  warmup_time: 0.00397038459777832\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m {'loss': [3.239169120788574], 'accuracy': [0.4513888955116272], 'val_loss': [0.6938202977180481], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m 0.6938202977180481\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1715)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:24:46,895\tINFO trial_runner.py:803 -- starting train_mnist_49be775e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:51 (running for 00:06:22.60)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_49be775e</td><td>RUNNING   </td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:24:56 (running for 00:06:27.63)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_49be775e</td><td>RUNNING   </td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m 2022-05-19 11:25:01.238400: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        294976    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        16416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  global_max_pooling2d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  dense (Dense)               (None, 32)                1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  dropout (Dropout)           (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization_5 (Batc  (None, 32)               128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  activation_5 (Activation)   (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  dense_1 (Dense)             (None, 2)                 66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m Total params: 2,815,693\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m Trainable params: 2,812,361\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m Non-trainable params: 3,332\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:01 (running for 00:06:32.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_49be775e</td><td>RUNNING   </td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m \r1/5 [=====>........................] - ETA: 18s - loss: 0.7310 - accuracy: 0.4688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/5 [===========>..................] - ETA: 0s - loss: 0.6818 - accuracy: 0.5312 \n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7042 - accuracy: 0.5312\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.5556\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:07 (running for 00:06:37.69)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_49be775e</td><td>RUNNING   </td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 6s 342ms/step - loss: 0.7042 - accuracy: 0.5556 - val_loss: 10.3024 - val_accuracy: 0.5405\n",
            "Result for train_mnist_49be775e:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-25-09\n",
            "  done: false\n",
            "  experiment_id: 24f84d95957c4f8eaa1dd20bc3957031\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7041733860969543\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1791\n",
            "  time_since_restore: 17.858304500579834\n",
            "  time_this_iter_s: 17.858304500579834\n",
            "  time_total_s: 17.858304500579834\n",
            "  timestamp: 1652959509\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 49be775e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 10.30242919921875\n",
            "  warmup_time: 0.003895282745361328\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m {'loss': [0.7041733860969543], 'accuracy': [0.5555555820465088], 'val_loss': [10.30242919921875], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m 10.30242919921875\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1791)\u001b[0m <class 'float'>\n",
            "Result for train_mnist_49be775e:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-25-09\n",
            "  done: true\n",
            "  experiment_id: 24f84d95957c4f8eaa1dd20bc3957031\n",
            "  experiment_tag: 17_batch_size=64,conv_block1_filters=512,conv_block2_filters=512,conv_block3_filters=64,conv_block4_filters=512,conv_block5_filters=32,dropout_rate=0.1,fc1_units=32,fc_layer_type=dense,lr=0.01,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7041733860969543\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1791\n",
            "  time_since_restore: 17.858304500579834\n",
            "  time_this_iter_s: 17.858304500579834\n",
            "  time_total_s: 17.858304500579834\n",
            "  timestamp: 1652959509\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 49be775e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 10.30242919921875\n",
            "  warmup_time: 0.003895282745361328\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:25:09,896\tINFO trial_runner.py:803 -- starting train_mnist_573ed496\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:14 (running for 00:06:45.60)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_573ed496</td><td>RUNNING   </td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:19 (running for 00:06:50.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_573ed496</td><td>RUNNING   </td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m 2022-05-19 11:25:24.239244: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        2080      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  global_average_pooling2d (G  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  dense (Dense)               (None, 128)               4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m Total params: 3,094,637\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m Trainable params: 3,091,881\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m Non-trainable params: 2,756\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:24 (running for 00:06:55.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_573ed496</td><td>RUNNING   </td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m \r1/5 [=====>........................] - ETA: 18s - loss: 0.6703 - accuracy: 0.5625\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7577 - accuracy: 0.5417 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8082 - accuracy: 0.5347\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:30 (running for 00:07:00.70)<br>Memory usage on this node: 3.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_573ed496</td><td>RUNNING   </td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 6s 329ms/step - loss: 0.8082 - accuracy: 0.5347 - val_loss: 0.6840 - val_accuracy: 0.6216\n",
            "Result for train_mnist_573ed496:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-19_11-25-32\n",
            "  done: false\n",
            "  experiment_id: f1967e34a3ee49af85eace37bb3db10f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8082320094108582\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1865\n",
            "  time_since_restore: 17.896633625030518\n",
            "  time_this_iter_s: 17.896633625030518\n",
            "  time_total_s: 17.896633625030518\n",
            "  timestamp: 1652959532\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 573ed496\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6840230226516724\n",
            "  warmup_time: 0.004726409912109375\n",
            "  \n",
            "Result for train_mnist_573ed496:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-19_11-25-32\n",
            "  done: true\n",
            "  experiment_id: f1967e34a3ee49af85eace37bb3db10f\n",
            "  experiment_tag: 18_batch_size=64,conv_block1_filters=128,conv_block2_filters=512,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=32,dropout_rate=0.2,fc1_units=128,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8082320094108582\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1865\n",
            "  time_since_restore: 17.896633625030518\n",
            "  time_this_iter_s: 17.896633625030518\n",
            "  time_total_s: 17.896633625030518\n",
            "  timestamp: 1652959532\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 573ed496\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6840230226516724\n",
            "  warmup_time: 0.004726409912109375\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m {'loss': [0.8082320094108582], 'accuracy': [0.5347222089767456], 'val_loss': [0.6840230226516724], 'val_accuracy': [0.6216216087341309]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m 0.6840230226516724\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1865)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:25:32,898\tINFO trial_runner.py:803 -- starting train_mnist_64f6ca1c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:37 (running for 00:07:08.61)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>RUNNING   </td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:42 (running for 00:07:13.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>RUNNING   </td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m 2022-05-19 11:25:47.663611: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        147488    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  global_max_pooling2d (Globa  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  dense (Dense)               (None, 512)               131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  dropout (Dropout)           (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization_5 (Batc  (None, 512)              2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  activation_5 (Activation)   (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  dense_1 (Dense)             (None, 2)                 1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m Total params: 2,851,757\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m Trainable params: 2,847,081\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m Non-trainable params: 4,676\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:48 (running for 00:07:18.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>RUNNING   </td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m \r1/5 [=====>........................] - ETA: 17s - loss: 0.8370 - accuracy: 0.5625\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7175 - accuracy: 0.5703\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7094 - accuracy: 0.5764"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:25:53 (running for 00:07:23.72)<br>Memory usage on this node: 2.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>RUNNING   </td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5/5 [==============================] - 6s 315ms/step - loss: 0.7094 - accuracy: 0.5764 - val_loss: 12.8308 - val_accuracy: 0.5405\n",
            "Result for train_mnist_64f6ca1c:\n",
            "  accuracy: 0.5763888955116272\n",
            "  date: 2022-05-19_11-25-55\n",
            "  done: false\n",
            "  experiment_id: d4f6828aa2b44b109e08b141fc23f03f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7093533277511597\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1941\n",
            "  time_since_restore: 18.2660870552063\n",
            "  time_this_iter_s: 18.2660870552063\n",
            "  time_total_s: 18.2660870552063\n",
            "  timestamp: 1652959555\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 64f6ca1c\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 12.830840110778809\n",
            "  warmup_time: 0.004178524017333984\n",
            "  \n",
            "Result for train_mnist_64f6ca1c:\n",
            "  accuracy: 0.5763888955116272\n",
            "  date: 2022-05-19_11-25-55\n",
            "  done: true\n",
            "  experiment_id: d4f6828aa2b44b109e08b141fc23f03f\n",
            "  experiment_tag: 19_batch_size=8,conv_block1_filters=512,conv_block2_filters=512,conv_block3_filters=32,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.1,fc1_units=512,fc_layer_type=dense,lr=0.01,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7093533277511597\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1941\n",
            "  time_since_restore: 18.2660870552063\n",
            "  time_this_iter_s: 18.2660870552063\n",
            "  time_total_s: 18.2660870552063\n",
            "  timestamp: 1652959555\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 64f6ca1c\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 12.830840110778809\n",
            "  warmup_time: 0.004178524017333984\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m {'loss': [0.7093533277511597], 'accuracy': [0.5763888955116272], 'val_loss': [12.830840110778809], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m 12.830840110778809\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1941)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:25:55,900\tINFO trial_runner.py:803 -- starting train_mnist_72ea39ce\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:00 (running for 00:07:31.61)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 20/50 (1 RUNNING, 19 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>RUNNING   </td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:05 (running for 00:07:36.64)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 20/50 (1 RUNNING, 19 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>RUNNING   </td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m 2022-05-19 11:26:10.443418: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 256)       73984     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 512)       66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  dropout (Dropout)           (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m Total params: 523,341\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m Trainable params: 520,969\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m Non-trainable params: 2,372\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:11 (running for 00:07:41.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 20/50 (1 RUNNING, 19 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>RUNNING   </td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\">5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m \r1/5 [=====>........................] - ETA: 15s - loss: 1.0780 - accuracy: 0.4688\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1.0067 - accuracy: 0.4792 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9977 - accuracy: 0.4444\n",
            "Result for train_mnist_72ea39ce:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-19_11-26-15\n",
            "  done: false\n",
            "  experiment_id: 1bc86c10ae514e339bac1a476c92f3df\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9977239966392517\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2014\n",
            "  time_since_restore: 14.99677324295044\n",
            "  time_this_iter_s: 14.99677324295044\n",
            "  time_total_s: 14.99677324295044\n",
            "  timestamp: 1652959575\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 72ea39ce\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6919590830802917\n",
            "  warmup_time: 0.004825592041015625\n",
            "  \n",
            "Result for train_mnist_72ea39ce:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-19_11-26-15\n",
            "  done: true\n",
            "  experiment_id: 1bc86c10ae514e339bac1a476c92f3df\n",
            "  experiment_tag: 20_batch_size=8,conv_block1_filters=32,conv_block2_filters=256,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=128,dropout_rate=0.3,fc1_units=512,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9977239966392517\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2014\n",
            "  time_since_restore: 14.99677324295044\n",
            "  time_this_iter_s: 14.99677324295044\n",
            "  time_total_s: 14.99677324295044\n",
            "  timestamp: 1652959575\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 72ea39ce\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6919590830802917\n",
            "  warmup_time: 0.004825592041015625\n",
            "  \n",
            "5/5 [==============================] - 5s 214ms/step - loss: 0.9977 - accuracy: 0.4444 - val_loss: 0.6920 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m {'loss': [0.9977239966392517], 'accuracy': [0.4444444477558136], 'val_loss': [0.6919590830802917], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m 0.6919590830802917\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2014)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:26:15,909\tINFO trial_runner.py:803 -- starting train_mnist_7ebc4da0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:20 (running for 00:07:51.61)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 21/50 (1 RUNNING, 20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>RUNNING   </td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 1 more trials not shown (1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:25 (running for 00:07:56.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 21/50 (1 RUNNING, 20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>RUNNING   </td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 1 more trials not shown (1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m 2022-05-19 11:26:30.421821: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  global_average_pooling2d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  dense (Dense)               (None, 256)               16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m Total params: 896,269\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m Trainable params: 893,961\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m Non-trainable params: 2,308\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:31 (running for 00:08:01.68)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 21/50 (1 RUNNING, 20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>RUNNING   </td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">   0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 1 more trials not shown (1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m \r1/5 [=====>........................] - ETA: 15s - loss: 0.7596 - accuracy: 0.6250\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.8358 - accuracy: 0.4896 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.5347\n",
            "5/5 [==============================] - 5s 198ms/step - loss: 0.7835 - accuracy: 0.5347 - val_loss: 0.6902 - val_accuracy: 0.4595\n",
            "Result for train_mnist_7ebc4da0:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-19_11-26-35\n",
            "  done: false\n",
            "  experiment_id: 5215a9400f594211aa5759779a63af0e\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7835286259651184\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2086\n",
            "  time_since_restore: 15.42069673538208\n",
            "  time_this_iter_s: 15.42069673538208\n",
            "  time_total_s: 15.42069673538208\n",
            "  timestamp: 1652959595\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7ebc4da0\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6901910305023193\n",
            "  warmup_time: 0.0044744014739990234\n",
            "  \n",
            "Result for train_mnist_7ebc4da0:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-19_11-26-35\n",
            "  done: true\n",
            "  experiment_id: 5215a9400f594211aa5759779a63af0e\n",
            "  experiment_tag: 21_batch_size=64,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=64,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7835286259651184\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2086\n",
            "  time_since_restore: 15.42069673538208\n",
            "  time_this_iter_s: 15.42069673538208\n",
            "  time_total_s: 15.42069673538208\n",
            "  timestamp: 1652959595\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7ebc4da0\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6901910305023193\n",
            "  warmup_time: 0.0044744014739990234\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m {'loss': [0.7835286259651184], 'accuracy': [0.5347222089767456], 'val_loss': [0.6901910305023193], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m 0.6901910305023193\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2086)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:26:36,910\tINFO trial_runner.py:803 -- starting train_mnist_8ae5b72e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:36 (running for 00:08:07.63)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>RUNNING   </td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:46 (running for 00:08:17.13)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>RUNNING   </td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:51 (running for 00:08:22.17)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>RUNNING   </td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m 2022-05-19 11:26:51.627072: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.8414 - accuracy: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7633 - accuracy: 0.4792 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:26:56 (running for 00:08:27.20)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>RUNNING   </td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">   0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 203ms/step - loss: 0.7375 - accuracy: 0.5000 - val_loss: 0.6837 - val_accuracy: 0.6757\n",
            "Result for train_mnist_8ae5b72e:\n",
            "  accuracy: 0.5\n",
            "  date: 2022-05-19_11-26-57\n",
            "  done: false\n",
            "  experiment_id: ba073c6b643d42a09793dda440312b90\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.737487256526947\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2161\n",
            "  time_since_restore: 15.66063666343689\n",
            "  time_this_iter_s: 15.66063666343689\n",
            "  time_total_s: 15.66063666343689\n",
            "  timestamp: 1652959617\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8ae5b72e\n",
            "  val_accuracy: 0.6756756901741028\n",
            "  val_loss: 0.6837171316146851\n",
            "  warmup_time: 0.004860639572143555\n",
            "  \n",
            "Result for train_mnist_8ae5b72e:\n",
            "  accuracy: 0.5\n",
            "  date: 2022-05-19_11-26-57\n",
            "  done: true\n",
            "  experiment_id: ba073c6b643d42a09793dda440312b90\n",
            "  experiment_tag: 22_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.737487256526947\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2161\n",
            "  time_since_restore: 15.66063666343689\n",
            "  time_this_iter_s: 15.66063666343689\n",
            "  time_total_s: 15.66063666343689\n",
            "  timestamp: 1652959617\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8ae5b72e\n",
            "  val_accuracy: 0.6756756901741028\n",
            "  val_loss: 0.6837171316146851\n",
            "  warmup_time: 0.004860639572143555\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m {'loss': [0.737487256526947], 'accuracy': [0.5], 'val_loss': [0.6837171316146851], 'val_accuracy': [0.6756756901741028]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m 0.6837171316146851\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2161)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:26:57,912\tINFO trial_runner.py:803 -- starting train_mnist_978e6f48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:02 (running for 00:08:33.62)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_978e6f48</td><td>RUNNING   </td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:07 (running for 00:08:38.65)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_978e6f48</td><td>RUNNING   </td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m =================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m 2022-05-19 11:27:12.796094: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:13 (running for 00:08:43.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_978e6f48</td><td>RUNNING   </td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.8989 - accuracy: 0.5625\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.9056 - accuracy: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.5694\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:18 (running for 00:08:48.74)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_978e6f48</td><td>RUNNING   </td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">   0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 209ms/step - loss: 0.8668 - accuracy: 0.5694 - val_loss: 0.6777 - val_accuracy: 0.6216\n",
            "Result for train_mnist_978e6f48:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-27-18\n",
            "  done: false\n",
            "  experiment_id: d964a6e0902b412fb382e7719ab7330f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8667635321617126\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2235\n",
            "  time_since_restore: 15.804442882537842\n",
            "  time_this_iter_s: 15.804442882537842\n",
            "  time_total_s: 15.804442882537842\n",
            "  timestamp: 1652959638\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 978e6f48\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6777106523513794\n",
            "  warmup_time: 0.004204273223876953\n",
            "  \n",
            "Result for train_mnist_978e6f48:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-27-18\n",
            "  done: true\n",
            "  experiment_id: d964a6e0902b412fb382e7719ab7330f\n",
            "  experiment_tag: 23_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8667635321617126\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2235\n",
            "  time_since_restore: 15.804442882537842\n",
            "  time_this_iter_s: 15.804442882537842\n",
            "  time_total_s: 15.804442882537842\n",
            "  timestamp: 1652959638\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 978e6f48\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6777106523513794\n",
            "  warmup_time: 0.004204273223876953\n",
            "  \u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m {'loss': [0.8667635321617126], 'accuracy': [0.5694444179534912], 'val_loss': [0.6777106523513794], 'val_accuracy': [0.6216216087341309]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m 0.6777106523513794\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2235)\u001b[0m <class 'float'>\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:27:18,914\tINFO trial_runner.py:803 -- starting train_mnist_a42f1c02\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:23 (running for 00:08:54.63)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 24/50 (1 RUNNING, 23 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>RUNNING   </td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 4 more trials not shown (4 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:28 (running for 00:08:59.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 24/50 (1 RUNNING, 23 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>RUNNING   </td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 4 more trials not shown (4 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m 2022-05-19 11:27:33.521724: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:34 (running for 00:09:04.71)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 24/50 (1 RUNNING, 23 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>RUNNING   </td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">   0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 4 more trials not shown (4 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.7997 - accuracy: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7746 - accuracy: 0.5694\n",
            "Result for train_mnist_a42f1c02:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-27-38\n",
            "  done: false\n",
            "  experiment_id: d2a80016cff742eaa251645bf89a9507\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7745754718780518\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2309\n",
            "  time_since_restore: 15.292914152145386\n",
            "  time_this_iter_s: 15.292914152145386\n",
            "  time_total_s: 15.292914152145386\n",
            "  timestamp: 1652959658\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a42f1c02\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.688227653503418\n",
            "  warmup_time: 0.004220247268676758\n",
            "  \n",
            "Result for train_mnist_a42f1c02:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-27-38\n",
            "  done: true\n",
            "  experiment_id: d2a80016cff742eaa251645bf89a9507\n",
            "  experiment_tag: 24_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.4,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7745754718780518\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2309\n",
            "  time_since_restore: 15.292914152145386\n",
            "  time_this_iter_s: 15.292914152145386\n",
            "  time_total_s: 15.292914152145386\n",
            "  timestamp: 1652959658\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a42f1c02\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.688227653503418\n",
            "  warmup_time: 0.004220247268676758\n",
            "  \n",
            "5/5 [==============================] - 5s 203ms/step - loss: 0.7746 - accuracy: 0.5694 - val_loss: 0.6882 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m {'loss': [0.7745754718780518], 'accuracy': [0.5694444179534912], 'val_loss': [0.688227653503418], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m 0.688227653503418\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2309)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:27:38,917\tINFO trial_runner.py:803 -- starting train_mnist_b0559114\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:43 (running for 00:09:14.62)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0559114</td><td>RUNNING   </td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">   0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:48 (running for 00:09:19.66)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0559114</td><td>RUNNING   </td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">   0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m 2022-05-19 11:27:53.176326: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  global_average_pooling2d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  dense (Dense)               (None, 256)               16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m Total params: 1,634,189\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m Trainable params: 1,631,625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:27:54 (running for 00:09:24.70)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0559114</td><td>RUNNING   </td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">   0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\">2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m \r1/5 [=====>........................] - ETA: 16s - loss: 0.8152 - accuracy: 0.5625\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.8601 - accuracy: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8254 - accuracy: 0.5417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:27:58,917\tINFO trial_runner.py:803 -- starting train_mnist_bc4adf60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_b0559114:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-19_11-27-58\n",
            "  done: false\n",
            "  experiment_id: c712a90e2b1045679975748277b24d48\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8253602981567383\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2384\n",
            "  time_since_restore: 15.392102003097534\n",
            "  time_this_iter_s: 15.392102003097534\n",
            "  time_total_s: 15.392102003097534\n",
            "  timestamp: 1652959678\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b0559114\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6844095587730408\n",
            "  warmup_time: 0.004250049591064453\n",
            "  \u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 240ms/step - loss: 0.8254 - accuracy: 0.5417 - val_loss: 0.6844 - val_accuracy: 0.5676\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m {'loss': [0.8253602981567383], 'accuracy': [0.5416666865348816], 'val_loss': [0.6844095587730408], 'val_accuracy': [0.5675675868988037]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m 0.6844095587730408\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2384)\u001b[0m <class 'float'>\n",
            "\n",
            "Result for train_mnist_b0559114:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-19_11-27-58\n",
            "  done: true\n",
            "  experiment_id: c712a90e2b1045679975748277b24d48\n",
            "  experiment_tag: 25_batch_size=64,conv_block1_filters=128,conv_block2_filters=256,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=64,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8253602981567383\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2384\n",
            "  time_since_restore: 15.392102003097534\n",
            "  time_this_iter_s: 15.392102003097534\n",
            "  time_total_s: 15.392102003097534\n",
            "  timestamp: 1652959678\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b0559114\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6844095587730408\n",
            "  warmup_time: 0.004250049591064453\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:03 (running for 00:09:34.64)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 26/50 (1 RUNNING, 25 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bc4adf60</td><td>RUNNING   </td><td>172.28.0.2:2456</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 6 more trials not shown (6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:09 (running for 00:09:39.68)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 26/50 (1 RUNNING, 25 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bc4adf60</td><td>RUNNING   </td><td>172.28.0.2:2456</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 6 more trials not shown (6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m 2022-05-19 11:28:13.602330: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:14 (running for 00:09:44.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 26/50 (1 RUNNING, 25 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bc4adf60</td><td>RUNNING   </td><td>172.28.0.2:2456</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 6 more trials not shown (6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.7934 - accuracy: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.5764\n",
            "Result for train_mnist_bc4adf60:\n",
            "  accuracy: 0.5763888955116272\n",
            "  date: 2022-05-19_11-28-18\n",
            "  done: false\n",
            "  experiment_id: 7a91afb8c8f14ce68d4f838f464cf6d0\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7617602944374084\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2456\n",
            "  time_since_restore: 15.35420823097229\n",
            "  time_this_iter_s: 15.35420823097229\n",
            "  time_total_s: 15.35420823097229\n",
            "  timestamp: 1652959698\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bc4adf60\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6888867616653442\n",
            "  warmup_time: 0.004805326461791992\n",
            "  \n",
            "Result for train_mnist_bc4adf60:\n",
            "  accuracy: 0.5763888955116272\n",
            "  date: 2022-05-19_11-28-18\n",
            "  done: true\n",
            "  experiment_id: 7a91afb8c8f14ce68d4f838f464cf6d0\n",
            "  experiment_tag: 26_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7617602944374084\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2456\n",
            "  time_since_restore: 15.35420823097229\n",
            "  time_this_iter_s: 15.35420823097229\n",
            "  time_total_s: 15.35420823097229\n",
            "  timestamp: 1652959698\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bc4adf60\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6888867616653442\n",
            "  warmup_time: 0.004805326461791992\n",
            "  \n",
            "5/5 [==============================] - 5s 196ms/step - loss: 0.7618 - accuracy: 0.5764 - val_loss: 0.6889 - val_accuracy: 0.5946\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m {'loss': [0.7617602944374084], 'accuracy': [0.5763888955116272], 'val_loss': [0.6888867616653442], 'val_accuracy': [0.5945945978164673]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m 0.6888867616653442\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2456)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:28:18,925\tINFO trial_runner.py:803 -- starting train_mnist_c834f9aa\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:23 (running for 00:09:54.62)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c834f9aa</td><td>RUNNING   </td><td>172.28.0.2:2527</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:28 (running for 00:09:59.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c834f9aa</td><td>RUNNING   </td><td>172.28.0.2:2527</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m 2022-05-19 11:28:33.840842: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:34 (running for 00:10:04.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c834f9aa</td><td>RUNNING   </td><td>172.28.0.2:2527</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7650 - accuracy: 0.4479 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7412 - accuracy: 0.4444\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:39 (running for 00:10:09.74)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c834f9aa</td><td>RUNNING   </td><td>172.28.0.2:2527</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_c834f9aa:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-19_11-28-39\n",
            "  done: false\n",
            "  experiment_id: 4becc73c9c934c10956869e2aaf1b379\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7412305474281311\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2527\n",
            "  time_since_restore: 15.925708055496216\n",
            "  time_this_iter_s: 15.925708055496216\n",
            "  time_total_s: 15.925708055496216\n",
            "  timestamp: 1652959719\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c834f9aa\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 4312.40966796875\n",
            "  warmup_time: 0.0044269561767578125\n",
            "  \n",
            "Result for train_mnist_c834f9aa:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-19_11-28-39\n",
            "  done: true\n",
            "  experiment_id: 4becc73c9c934c10956869e2aaf1b379\n",
            "  experiment_tag: 27_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.1,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7412305474281311\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2527\n",
            "  time_since_restore: 15.925708055496216\n",
            "  time_this_iter_s: 15.925708055496216\n",
            "  time_total_s: 15.925708055496216\n",
            "  timestamp: 1652959719\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c834f9aa\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 4312.40966796875\n",
            "  warmup_time: 0.0044269561767578125\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 214ms/step - loss: 0.7412 - accuracy: 0.4444 - val_loss: 4312.4097 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m {'loss': [0.7412305474281311], 'accuracy': [0.4444444477558136], 'val_loss': [4312.40966796875], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m 4312.40966796875\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2527)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:28:39,927\tINFO trial_runner.py:803 -- starting train_mnist_d48161ee\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:44 (running for 00:10:15.62)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48161ee</td><td>RUNNING   </td><td>172.28.0.2:2603</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:49 (running for 00:10:20.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48161ee</td><td>RUNNING   </td><td>172.28.0.2:2603</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m 2022-05-19 11:28:54.864991: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:28:55 (running for 00:10:25.70)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48161ee</td><td>RUNNING   </td><td>172.28.0.2:2603</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1.0277 - accuracy: 0.4792 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9775 - accuracy: 0.4792\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:00 (running for 00:10:30.73)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48161ee</td><td>RUNNING   </td><td>172.28.0.2:2603</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 210ms/step - loss: 0.9775 - accuracy: 0.4792 - val_loss: 0.6870 - val_accuracy: 0.5946\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m {'loss': [0.9774740934371948], 'accuracy': [0.4791666567325592], 'val_loss': [0.6870181560516357], 'val_accuracy': [0.5945945978164673]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m 0.6870181560516357\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2603)\u001b[0m <class 'float'>\n",
            "Result for train_mnist_d48161ee:\n",
            "  accuracy: 0.4791666567325592\n",
            "  date: 2022-05-19_11-29-00\n",
            "  done: false\n",
            "  experiment_id: 0aa2f36e7ffd46dfa761097f6aa937af\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9774740934371948\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2603\n",
            "  time_since_restore: 15.57483172416687\n",
            "  time_this_iter_s: 15.57483172416687\n",
            "  time_total_s: 15.57483172416687\n",
            "  timestamp: 1652959740\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d48161ee\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6870181560516357\n",
            "  warmup_time: 0.004208087921142578\n",
            "  \n",
            "Result for train_mnist_d48161ee:\n",
            "  accuracy: 0.4791666567325592\n",
            "  date: 2022-05-19_11-29-00\n",
            "  done: true\n",
            "  experiment_id: 0aa2f36e7ffd46dfa761097f6aa937af\n",
            "  experiment_tag: 28_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.4,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9774740934371948\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2603\n",
            "  time_since_restore: 15.57483172416687\n",
            "  time_this_iter_s: 15.57483172416687\n",
            "  time_total_s: 15.57483172416687\n",
            "  timestamp: 1652959740\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d48161ee\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6870181560516357\n",
            "  warmup_time: 0.004208087921142578\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:29:00,929\tINFO trial_runner.py:803 -- starting train_mnist_e0e0fd82\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:05 (running for 00:10:36.64)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e0fd82</td><td>RUNNING   </td><td>172.28.0.2:2675</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:11 (running for 00:10:41.68)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e0fd82</td><td>RUNNING   </td><td>172.28.0.2:2675</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m 2022-05-19 11:29:15.880832: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:16 (running for 00:10:46.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e0fd82</td><td>RUNNING   </td><td>172.28.0.2:2675</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        131136    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m Total params: 958,669\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m Trainable params: 955,977\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.6461 - accuracy: 0.6250\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7688 - accuracy: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.5139\n",
            "Result for train_mnist_e0e0fd82:\n",
            "  accuracy: 0.5138888955116272\n",
            "  date: 2022-05-19_11-29-21\n",
            "  done: false\n",
            "  experiment_id: b7c0d98ed22e4d37998caebf5d177b7f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7444592118263245\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2675\n",
            "  time_since_restore: 15.565117597579956\n",
            "  time_this_iter_s: 15.565117597579956\n",
            "  time_total_s: 15.565117597579956\n",
            "  timestamp: 1652959761\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e0e0fd82\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 8062.94677734375\n",
            "  warmup_time: 0.004387378692626953\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:21 (running for 00:10:51.73)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e0fd82</td><td>RUNNING   </td><td>172.28.0.2:2675</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5651</td><td style=\"text-align: right;\">0.744459</td><td style=\"text-align: right;\">8062.95    </td><td style=\"text-align: right;\">  0.513889</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">   2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">   0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">   0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">   0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">   0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">  10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">   0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">  12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\"> 191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">   0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">   0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">   0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">   0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">   1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">   0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">   0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">   0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">   0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">   0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_e0e0fd82:\n",
            "  accuracy: 0.5138888955116272\n",
            "  date: 2022-05-19_11-29-21\n",
            "  done: true\n",
            "  experiment_id: b7c0d98ed22e4d37998caebf5d177b7f\n",
            "  experiment_tag: 29_batch_size=8,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.1,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7444592118263245\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2675\n",
            "  time_since_restore: 15.565117597579956\n",
            "  time_this_iter_s: 15.565117597579956\n",
            "  time_total_s: 15.565117597579956\n",
            "  timestamp: 1652959761\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e0e0fd82\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 8062.94677734375\n",
            "  warmup_time: 0.004387378692626953\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 207ms/step - loss: 0.7445 - accuracy: 0.5139 - val_loss: 8062.9468 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m {'loss': [0.7444592118263245], 'accuracy': [0.5138888955116272], 'val_loss': [8062.94677734375], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m 8062.94677734375\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2675)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:29:21,930\tINFO trial_runner.py:803 -- starting train_mnist_ed617924\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:26 (running for 00:10:57.63)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 30/50 (1 RUNNING, 29 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ed617924</td><td>RUNNING   </td><td>172.28.0.2:2748</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:31 (running for 00:11:02.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 30/50 (1 RUNNING, 29 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ed617924</td><td>RUNNING   </td><td>172.28.0.2:2748</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m 2022-05-19 11:29:36.524626: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 64)        32832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  dense (Dense)               (None, 256)               65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m Total params: 565,325\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m Trainable params: 563,145\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m Non-trainable params: 2,180\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:37 (running for 00:11:07.71)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 30/50 (1 RUNNING, 29 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ed617924</td><td>RUNNING   </td><td>172.28.0.2:2748</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m \r1/5 [=====>........................] - ETA: 16s - loss: 0.8951 - accuracy: 0.5000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7829 - accuracy: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7725 - accuracy: 0.4653\n",
            "5/5 [==============================] - 5s 196ms/step - loss: 0.7725 - accuracy: 0.4653 - val_loss: 0.6958 - val_accuracy: 0.4595\n",
            "Result for train_mnist_ed617924:\n",
            "  accuracy: 0.4652777910232544\n",
            "  date: 2022-05-19_11-29-41\n",
            "  done: false\n",
            "  experiment_id: 942645f713284e6ab9e2139373840fec\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7725032567977905\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2748\n",
            "  time_since_restore: 15.57314944267273\n",
            "  time_this_iter_s: 15.57314944267273\n",
            "  time_total_s: 15.57314944267273\n",
            "  timestamp: 1652959781\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: ed617924\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.69584059715271\n",
            "  warmup_time: 0.004038810729980469\n",
            "  \n",
            "Result for train_mnist_ed617924:\n",
            "  accuracy: 0.4652777910232544\n",
            "  date: 2022-05-19_11-29-41\n",
            "  done: true\n",
            "  experiment_id: 942645f713284e6ab9e2139373840fec\n",
            "  experiment_tag: 30_batch_size=8,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7725032567977905\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2748\n",
            "  time_since_restore: 15.57314944267273\n",
            "  time_this_iter_s: 15.57314944267273\n",
            "  time_total_s: 15.57314944267273\n",
            "  timestamp: 1652959781\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: ed617924\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.69584059715271\n",
            "  warmup_time: 0.004038810729980469\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m {'loss': [0.7725032567977905], 'accuracy': [0.4652777910232544], 'val_loss': [0.69584059715271], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m 0.69584059715271\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2748)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:29:42,933\tINFO trial_runner.py:803 -- starting train_mnist_f9ddd152\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:42 (running for 00:11:13.63)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f9ddd152</td><td>RUNNING   </td><td>172.28.0.2:2823</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:52 (running for 00:11:23.01)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f9ddd152</td><td>RUNNING   </td><td>172.28.0.2:2823</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:29:57 (running for 00:11:28.05)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f9ddd152</td><td>RUNNING   </td><td>172.28.0.2:2823</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m 2022-05-19 11:29:57.444098: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        294976    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        2112      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  global_average_pooling2d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  dense (Dense)               (None, 128)               8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m Total params: 909,229\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m Trainable params: 907,369\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m Non-trainable params: 1,860\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 0.7237 - accuracy: 0.4375\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6859 - accuracy: 0.5391 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.5625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:02 (running for 00:11:33.12)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f9ddd152</td><td>RUNNING   </td><td>172.28.0.2:2823</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_f9ddd152:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-19_11-30-02\n",
            "  done: false\n",
            "  experiment_id: 5ed086f4a0f44de5908edfbdee1c0e61\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6798231601715088\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2823\n",
            "  time_since_restore: 15.290278434753418\n",
            "  time_this_iter_s: 15.290278434753418\n",
            "  time_total_s: 15.290278434753418\n",
            "  timestamp: 1652959802\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f9ddd152\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6920521855354309\n",
            "  warmup_time: 0.004023075103759766\n",
            "  \n",
            "Result for train_mnist_f9ddd152:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-19_11-30-02\n",
            "  done: true\n",
            "  experiment_id: 5ed086f4a0f44de5908edfbdee1c0e61\n",
            "  experiment_tag: 31_batch_size=64,conv_block1_filters=128,conv_block2_filters=512,conv_block3_filters=64,conv_block4_filters=32,conv_block5_filters=64,dropout_rate=0.2,fc1_units=128,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6798231601715088\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2823\n",
            "  time_since_restore: 15.290278434753418\n",
            "  time_this_iter_s: 15.290278434753418\n",
            "  time_total_s: 15.290278434753418\n",
            "  timestamp: 1652959802\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f9ddd152\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6920521855354309\n",
            "  warmup_time: 0.004023075103759766\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 206ms/step - loss: 0.6798 - accuracy: 0.5625 - val_loss: 0.6921 - val_accuracy: 0.6216\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m {'loss': [0.6798231601715088], 'accuracy': [0.5625], 'val_loss': [0.6920521855354309], 'val_accuracy': [0.6216216087341309]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m 0.6920521855354309\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2823)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:30:02,934\tINFO trial_runner.py:803 -- starting train_mnist_06208298\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:07 (running for 00:11:38.64)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_06208298</td><td>RUNNING   </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:13 (running for 00:11:43.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_06208298</td><td>RUNNING   </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m 2022-05-19 11:30:17.720554: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 128)       1280      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  activation (Activation)     (None, 18, 18, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 512)       590336    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        294976    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        2112      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  global_average_pooling2d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  dense (Dense)               (None, 64)                4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  dropout (Dropout)           (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization_5 (Batc  (None, 64)               256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  activation_5 (Activation)   (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  dense_1 (Dense)             (None, 2)                 130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m Total params: 904,685\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m Trainable params: 902,953\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m Non-trainable params: 1,732\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:18 (running for 00:11:48.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_06208298</td><td>RUNNING   </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.8276 - accuracy: 0.5417 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7986 - accuracy: 0.5486\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:23 (running for 00:11:53.75)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_06208298</td><td>RUNNING   </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">  0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 213ms/step - loss: 0.7986 - accuracy: 0.5486 - val_loss: 7.7572 - val_accuracy: 0.5405\n",
            "Result for train_mnist_06208298:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-30-23\n",
            "  done: false\n",
            "  experiment_id: 6306425fea354ab9a7e388614e6a9ca9\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.798599123954773\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2893\n",
            "  time_since_restore: 15.717397451400757\n",
            "  time_this_iter_s: 15.717397451400757\n",
            "  time_total_s: 15.717397451400757\n",
            "  timestamp: 1652959823\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 06208298\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 7.757208824157715\n",
            "  warmup_time: 0.004797697067260742\n",
            "  \n",
            "Result for train_mnist_06208298:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-30-23\n",
            "  done: true\n",
            "  experiment_id: 6306425fea354ab9a7e388614e6a9ca9\n",
            "  experiment_tag: 32_batch_size=64,conv_block1_filters=128,conv_block2_filters=512,conv_block3_filters=64,conv_block4_filters=32,conv_block5_filters=64,dropout_rate=0.4,fc1_units=64,fc_layer_type=dense,lr=0.01,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.798599123954773\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2893\n",
            "  time_since_restore: 15.717397451400757\n",
            "  time_this_iter_s: 15.717397451400757\n",
            "  time_total_s: 15.717397451400757\n",
            "  timestamp: 1652959823\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 06208298\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 7.757208824157715\n",
            "  warmup_time: 0.004797697067260742\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m {'loss': [0.798599123954773], 'accuracy': [0.5486111044883728], 'val_loss': [7.757208824157715], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m 7.757208824157715\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2893)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:30:23,939\tINFO trial_runner.py:803 -- starting train_mnist_125ed5d2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:28 (running for 00:11:59.64)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 33/50 (1 RUNNING, 32 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>RUNNING   </td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">  7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 13 more trials not shown (13 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:34 (running for 00:12:04.68)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 33/50 (1 RUNNING, 32 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>RUNNING   </td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">  7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 13 more trials not shown (13 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m Total params: 911,629\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m Trainable params: 908,553\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m Non-trainable params: 3,076\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m 2022-05-19 11:30:38.838791: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:39 (running for 00:12:09.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 33/50 (1 RUNNING, 32 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>RUNNING   </td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">  7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">  0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 13 more trials not shown (13 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m \r1/5 [=====>........................] - ETA: 14s - loss: 0.6988 - accuracy: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7136 - accuracy: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7000 - accuracy: 0.5556\n",
            "Result for train_mnist_125ed5d2:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-30-43\n",
            "  done: false\n",
            "  experiment_id: 1e067730de2940fcac3629ec81ed9a9b\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6999636888504028\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2962\n",
            "  time_since_restore: 15.365854263305664\n",
            "  time_this_iter_s: 15.365854263305664\n",
            "  time_total_s: 15.365854263305664\n",
            "  timestamp: 1652959843\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 125ed5d2\n",
            "  val_accuracy: 0.6756756901741028\n",
            "  val_loss: 0.6711761951446533\n",
            "  warmup_time: 0.003879547119140625\n",
            "  \n",
            "Result for train_mnist_125ed5d2:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-30-43\n",
            "  done: true\n",
            "  experiment_id: 1e067730de2940fcac3629ec81ed9a9b\n",
            "  experiment_tag: 33_batch_size=8,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6999636888504028\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2962\n",
            "  time_since_restore: 15.365854263305664\n",
            "  time_this_iter_s: 15.365854263305664\n",
            "  time_total_s: 15.365854263305664\n",
            "  timestamp: 1652959843\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 125ed5d2\n",
            "  val_accuracy: 0.6756756901741028\n",
            "  val_loss: 0.6711761951446533\n",
            "  warmup_time: 0.003879547119140625\n",
            "  \n",
            "5/5 [==============================] - 5s 225ms/step - loss: 0.7000 - accuracy: 0.5556 - val_loss: 0.6712 - val_accuracy: 0.6757\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m {'loss': [0.6999636888504028], 'accuracy': [0.5555555820465088], 'val_loss': [0.6711761951446533], 'val_accuracy': [0.6756756901741028]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m 0.6711761951446533\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2962)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:30:44,941\tINFO trial_runner.py:803 -- starting train_mnist_1eb5e636\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:44 (running for 00:12:15.66)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>RUNNING   </td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">  7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">  0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:54 (running for 00:12:25.13)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>RUNNING   </td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">  7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">  0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m 2022-05-19 11:30:59.358369: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:30:59 (running for 00:12:30.17)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>RUNNING   </td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">  7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">  2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">  0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">  0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">  0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">  0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">  0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\"> 10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">  0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\"> 12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">  0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">  0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">  0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">  0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">  1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">  0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">  0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">  0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m Total params: 911,629\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m Trainable params: 908,553\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m Non-trainable params: 3,076\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.6904 - accuracy: 0.4375\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.8286 - accuracy: 0.3958 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7851 - accuracy: 0.4444\n",
            "Result for train_mnist_1eb5e636:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-19_11-31-04\n",
            "  done: false\n",
            "  experiment_id: bcadeb5ed44443b0a0d276517c347e0f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7850714921951294\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3032\n",
            "  time_since_restore: 15.100081443786621\n",
            "  time_this_iter_s: 15.100081443786621\n",
            "  time_total_s: 15.100081443786621\n",
            "  timestamp: 1652959864\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1eb5e636\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 42271.67578125\n",
            "  warmup_time: 0.004126310348510742\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:04 (running for 00:12:35.21)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>RUNNING   </td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">    0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">    0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_1eb5e636:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-19_11-31-04\n",
            "  done: true\n",
            "  experiment_id: bcadeb5ed44443b0a0d276517c347e0f\n",
            "  experiment_tag: 34_batch_size=8,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=convolution,lr=0.1,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7850714921951294\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3032\n",
            "  time_since_restore: 15.100081443786621\n",
            "  time_this_iter_s: 15.100081443786621\n",
            "  time_total_s: 15.100081443786621\n",
            "  timestamp: 1652959864\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1eb5e636\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 42271.67578125\n",
            "  warmup_time: 0.004126310348510742\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 232ms/step - loss: 0.7851 - accuracy: 0.4444 - val_loss: 42271.6758 - val_accuracy: 0.4595\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m {'loss': [0.7850714921951294], 'accuracy': [0.4444444477558136], 'val_loss': [42271.67578125], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m 42271.67578125\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3032)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:31:04,942\tINFO trial_runner.py:803 -- starting train_mnist_2b0d3254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:09 (running for 00:12:40.65)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 35/50 (1 RUNNING, 34 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>RUNNING   </td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">    0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 15 more trials not shown (15 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:15 (running for 00:12:45.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 35/50 (1 RUNNING, 34 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>RUNNING   </td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">    0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 15 more trials not shown (15 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m 2022-05-19 11:31:19.616412: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        147520    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m Total params: 690,125\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m Trainable params: 687,177\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m Non-trainable params: 2,948\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:20 (running for 00:12:50.73)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 35/50 (1 RUNNING, 34 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>RUNNING   </td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">    0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 15 more trials not shown (15 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.6767 - accuracy: 0.5729 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6865 - accuracy: 0.5625\n",
            "5/5 [==============================] - 5s 224ms/step - loss: 0.6865 - accuracy: 0.5625 - val_loss: 0.6948 - val_accuracy: 0.4595\n",
            "Result for train_mnist_2b0d3254:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-19_11-31-24\n",
            "  done: false\n",
            "  experiment_id: f1f52b6ab3054ed9b146da0bfcef8526\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6864852905273438\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3104\n",
            "  time_since_restore: 15.367128372192383\n",
            "  time_this_iter_s: 15.367128372192383\n",
            "  time_total_s: 15.367128372192383\n",
            "  timestamp: 1652959884\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2b0d3254\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6948117017745972\n",
            "  warmup_time: 0.0037424564361572266\n",
            "  \n",
            "Result for train_mnist_2b0d3254:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-19_11-31-24\n",
            "  done: true\n",
            "  experiment_id: f1f52b6ab3054ed9b146da0bfcef8526\n",
            "  experiment_tag: 35_batch_size=8,conv_block1_filters=256,conv_block2_filters=64,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.4,fc1_units=256,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6864852905273438\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3104\n",
            "  time_since_restore: 15.367128372192383\n",
            "  time_this_iter_s: 15.367128372192383\n",
            "  time_total_s: 15.367128372192383\n",
            "  timestamp: 1652959884\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2b0d3254\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6948117017745972\n",
            "  warmup_time: 0.0037424564361572266\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:31:24,944\tINFO trial_runner.py:803 -- starting train_mnist_3717f4ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m {'loss': [0.6864852905273438], 'accuracy': [0.5625], 'val_loss': [0.6948117017745972], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m 0.6948117017745972\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3104)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:29 (running for 00:13:00.65)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>RUNNING   </td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:35 (running for 00:13:05.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>RUNNING   </td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m 2022-05-19 11:31:39.971558: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:40 (running for 00:13:10.73)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>RUNNING   </td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        73760     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       36992     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m Total params: 520,461\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m Trainable params: 518,025\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m Non-trainable params: 2,436\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 0.6807 - accuracy: 0.5938\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6752 - accuracy: 0.6042 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.5903\n",
            "5/5 [==============================] - 5s 218ms/step - loss: 0.6752 - accuracy: 0.5903 - val_loss: 0.6798 - val_accuracy: 0.5405\n",
            "Result for train_mnist_3717f4ee:\n",
            "  accuracy: 0.5902777910232544\n",
            "  date: 2022-05-19_11-31-45\n",
            "  done: false\n",
            "  experiment_id: 83d45622873945a5a60faadd4dc3a22c\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6751578450202942\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3176\n",
            "  time_since_restore: 15.692713975906372\n",
            "  time_this_iter_s: 15.692713975906372\n",
            "  time_total_s: 15.692713975906372\n",
            "  timestamp: 1652959905\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 3717f4ee\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.679836094379425\n",
            "  warmup_time: 0.0037407875061035156\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:45 (running for 00:13:15.77)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>RUNNING   </td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_3717f4ee:\n",
            "  accuracy: 0.5902777910232544\n",
            "  date: 2022-05-19_11-31-45\n",
            "  done: true\n",
            "  experiment_id: 83d45622873945a5a60faadd4dc3a22c\n",
            "  experiment_tag: 36_batch_size=8,conv_block1_filters=256,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.3,fc1_units=32,fc_layer_type=convolution,lr=0.01,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6751578450202942\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3176\n",
            "  time_since_restore: 15.692713975906372\n",
            "  time_this_iter_s: 15.692713975906372\n",
            "  time_total_s: 15.692713975906372\n",
            "  timestamp: 1652959905\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 3717f4ee\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.679836094379425\n",
            "  warmup_time: 0.0037407875061035156\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m {'loss': [0.6751578450202942], 'accuracy': [0.5902777910232544], 'val_loss': [0.679836094379425], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m 0.679836094379425\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3176)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:31:45,946\tINFO trial_runner.py:803 -- starting train_mnist_433c4112\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:50 (running for 00:13:21.65)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_433c4112</td><td>RUNNING   </td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:31:56 (running for 00:13:26.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_433c4112</td><td>RUNNING   </td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:01 (running for 00:13:31.73)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_433c4112</td><td>RUNNING   </td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m 2022-05-19 11:32:01.322962: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m Total params: 1,354,637\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m Trainable params: 1,351,305\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m Non-trainable params: 3,332\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.6917 - accuracy: 0.5312\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6894 - accuracy: 0.5729 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.5556\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:06 (running for 00:13:36.77)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_433c4112</td><td>RUNNING   </td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_433c4112:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-32-06\n",
            "  done: false\n",
            "  experiment_id: d2689871cfac4152a3e1d6f243bb2719\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.690255880355835\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3247\n",
            "  time_since_restore: 16.19905114173889\n",
            "  time_this_iter_s: 16.19905114173889\n",
            "  time_total_s: 16.19905114173889\n",
            "  timestamp: 1652959926\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 433c4112\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6901743412017822\n",
            "  warmup_time: 0.006646871566772461\n",
            "  \n",
            "Result for train_mnist_433c4112:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-32-06\n",
            "  done: true\n",
            "  experiment_id: d2689871cfac4152a3e1d6f243bb2719\n",
            "  experiment_tag: 37_batch_size=32,conv_block1_filters=256,conv_block2_filters=256,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.5,fc1_units=256,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.690255880355835\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3247\n",
            "  time_since_restore: 16.19905114173889\n",
            "  time_this_iter_s: 16.19905114173889\n",
            "  time_total_s: 16.19905114173889\n",
            "  timestamp: 1652959926\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 433c4112\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6901743412017822\n",
            "  warmup_time: 0.006646871566772461\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 289ms/step - loss: 0.6903 - accuracy: 0.5556 - val_loss: 0.6902 - val_accuracy: 0.5946\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m {'loss': [0.690255880355835], 'accuracy': [0.5555555820465088], 'val_loss': [0.6901743412017822], 'val_accuracy': [0.5945945978164673]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m 0.6901743412017822\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3247)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:32:06,947\tINFO trial_runner.py:803 -- starting train_mnist_50150e8c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:11 (running for 00:13:42.64)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 38/50 (1 RUNNING, 37 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50150e8c</td><td>RUNNING   </td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br>... 18 more trials not shown (18 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:17 (running for 00:13:47.69)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 38/50 (1 RUNNING, 37 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50150e8c</td><td>RUNNING   </td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br>... 18 more trials not shown (18 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m 2022-05-19 11:32:21.873358: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:22 (running for 00:13:52.73)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 38/50 (1 RUNNING, 37 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50150e8c</td><td>RUNNING   </td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br>... 18 more trials not shown (18 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m Total params: 911,629\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m Trainable params: 908,553\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m Non-trainable params: 3,076\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 0.7389 - accuracy: 0.3125\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7128 - accuracy: 0.4792 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7059 - accuracy: 0.5069\n",
            "Result for train_mnist_50150e8c:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-19_11-32-26\n",
            "  done: false\n",
            "  experiment_id: 9d5c67f238684cbb976d0421fa145340\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7058955430984497\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3315\n",
            "  time_since_restore: 15.551594495773315\n",
            "  time_this_iter_s: 15.551594495773315\n",
            "  time_total_s: 15.551594495773315\n",
            "  timestamp: 1652959946\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 50150e8c\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6917151212692261\n",
            "  warmup_time: 0.0042572021484375\n",
            "  \n",
            "Result for train_mnist_50150e8c:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-19_11-32-26\n",
            "  done: true\n",
            "  experiment_id: 9d5c67f238684cbb976d0421fa145340\n",
            "  experiment_tag: 38_batch_size=8,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7058955430984497\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3315\n",
            "  time_since_restore: 15.551594495773315\n",
            "  time_this_iter_s: 15.551594495773315\n",
            "  time_total_s: 15.551594495773315\n",
            "  timestamp: 1652959946\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 50150e8c\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6917151212692261\n",
            "  warmup_time: 0.0042572021484375\n",
            "  \n",
            "5/5 [==============================] - 5s 224ms/step - loss: 0.7059 - accuracy: 0.5069 - val_loss: 0.6917 - val_accuracy: 0.4595\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m {'loss': [0.7058955430984497], 'accuracy': [0.5069444179534912], 'val_loss': [0.6917151212692261], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m 0.6917151212692261\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3315)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:32:27,949\tINFO trial_runner.py:803 -- starting train_mnist_5c293464\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:27 (running for 00:13:58.68)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 39/50 (1 RUNNING, 38 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5c293464</td><td>RUNNING   </td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 19 more trials not shown (19 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:37 (running for 00:14:08.09)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 39/50 (1 RUNNING, 38 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5c293464</td><td>RUNNING   </td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 19 more trials not shown (19 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m 2022-05-19 11:32:42.257870: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:42 (running for 00:14:13.13)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 39/50 (1 RUNNING, 38 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5c293464</td><td>RUNNING   </td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 19 more trials not shown (19 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       131200    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Total params: 567,245\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Trainable params: 565,129\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Non-trainable params: 2,116\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7296 - accuracy: 0.5729 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.5694\n",
            "5/5 [==============================] - 5s 215ms/step - loss: 0.7055 - accuracy: 0.5694 - val_loss: 0.6951 - val_accuracy: 0.4595\n",
            "Result for train_mnist_5c293464:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-32-47\n",
            "  done: false\n",
            "  experiment_id: 11848e7fbb354644b421f996cd896fbd\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7054870128631592\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3385\n",
            "  time_since_restore: 14.963304042816162\n",
            "  time_this_iter_s: 14.963304042816162\n",
            "  time_total_s: 14.963304042816162\n",
            "  timestamp: 1652959967\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 5c293464\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6951428055763245\n",
            "  warmup_time: 0.0045986175537109375\n",
            "  \n",
            "Result for train_mnist_5c293464:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-32-47\n",
            "  done: true\n",
            "  experiment_id: 11848e7fbb354644b421f996cd896fbd\n",
            "  experiment_tag: 39_batch_size=8,conv_block1_filters=32,conv_block2_filters=128,conv_block3_filters=256,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.1,fc1_units=256,fc_layer_type=convolution,lr=0.0001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7054870128631592\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3385\n",
            "  time_since_restore: 14.963304042816162\n",
            "  time_this_iter_s: 14.963304042816162\n",
            "  time_total_s: 14.963304042816162\n",
            "  timestamp: 1652959967\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 5c293464\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6951428055763245\n",
            "  warmup_time: 0.0045986175537109375\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m {'loss': [0.7054870128631592], 'accuracy': [0.5694444179534912], 'val_loss': [0.6951428055763245], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m 0.6951428055763245\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:32:47,952\tINFO trial_runner.py:803 -- starting train_mnist_685531de\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:47 (running for 00:14:18.66)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_685531de</td><td>RUNNING   </td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:32:57 (running for 00:14:28.15)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_685531de</td><td>RUNNING   </td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:02 (running for 00:14:33.18)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_685531de</td><td>RUNNING   </td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m 2022-05-19 11:33:02.622336: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        147520    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        18464     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 64)        8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  dropout (Dropout)           (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m Total params: 187,597\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m Trainable params: 186,441\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m Non-trainable params: 1,156\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 0.6833 - accuracy: 0.5625\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7602 - accuracy: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7520 - accuracy: 0.5347\n",
            "5/5 [==============================] - 4s 181ms/step - loss: 0.7520 - accuracy: 0.5347 - val_loss: 6292.1353 - val_accuracy: 0.5405\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:07 (running for 00:14:38.22)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_685531de</td><td>RUNNING   </td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_685531de:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-19_11-33-07\n",
            "  done: false\n",
            "  experiment_id: ab0a5b020a8f494c9a208f2d98ed11a3\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7519557476043701\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3457\n",
            "  time_since_restore: 15.301514863967896\n",
            "  time_this_iter_s: 15.301514863967896\n",
            "  time_total_s: 15.301514863967896\n",
            "  timestamp: 1652959987\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 685531de\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 6292.13525390625\n",
            "  warmup_time: 0.004156827926635742\n",
            "  \n",
            "Result for train_mnist_685531de:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-19_11-33-07\n",
            "  done: true\n",
            "  experiment_id: ab0a5b020a8f494c9a208f2d98ed11a3\n",
            "  experiment_tag: 40_batch_size=32,conv_block1_filters=256,conv_block2_filters=64,conv_block3_filters=32,conv_block4_filters=32,conv_block5_filters=128,dropout_rate=0.2,fc1_units=64,fc_layer_type=convolution,lr=0.1,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7519557476043701\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3457\n",
            "  time_since_restore: 15.301514863967896\n",
            "  time_this_iter_s: 15.301514863967896\n",
            "  time_total_s: 15.301514863967896\n",
            "  timestamp: 1652959987\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 685531de\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 6292.13525390625\n",
            "  warmup_time: 0.004156827926635742\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m {'loss': [0.7519557476043701], 'accuracy': [0.5347222089767456], 'val_loss': [6292.13525390625], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m 6292.13525390625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3457)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:33:07,961\tINFO trial_runner.py:803 -- starting train_mnist_747b8c88\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:12 (running for 00:14:43.67)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_747b8c88</td><td>RUNNING   </td><td>172.28.0.2:3528</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:18 (running for 00:14:48.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_747b8c88</td><td>RUNNING   </td><td>172.28.0.2:3528</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m 2022-05-19 11:33:23.070585: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:23 (running for 00:14:53.77)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_747b8c88</td><td>RUNNING   </td><td>172.28.0.2:3528</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        73760     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       36992     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m Total params: 520,461\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m Trainable params: 518,025\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m Non-trainable params: 2,436\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.6926 - accuracy: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.5278\n",
            "5/5 [==============================] - 5s 221ms/step - loss: 0.6834 - accuracy: 0.5278 - val_loss: 0.6920 - val_accuracy: 0.4595\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:28 (running for 00:14:58.81)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_747b8c88</td><td>RUNNING   </td><td>172.28.0.2:3528</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_747b8c88:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-19_11-33-28\n",
            "  done: false\n",
            "  experiment_id: 511a73dbdd6c44719ab9ed3720251f5b\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6834200024604797\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3528\n",
            "  time_since_restore: 15.648484706878662\n",
            "  time_this_iter_s: 15.648484706878662\n",
            "  time_total_s: 15.648484706878662\n",
            "  timestamp: 1652960008\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 747b8c88\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6919925808906555\n",
            "  warmup_time: 0.0072705745697021484\n",
            "  \n",
            "Result for train_mnist_747b8c88:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-19_11-33-28\n",
            "  done: true\n",
            "  experiment_id: 511a73dbdd6c44719ab9ed3720251f5b\n",
            "  experiment_tag: 41_batch_size=8,conv_block1_filters=256,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.3,fc1_units=32,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6834200024604797\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3528\n",
            "  time_since_restore: 15.648484706878662\n",
            "  time_this_iter_s: 15.648484706878662\n",
            "  time_total_s: 15.648484706878662\n",
            "  timestamp: 1652960008\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 747b8c88\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6919925808906555\n",
            "  warmup_time: 0.0072705745697021484\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m {'loss': [0.6834200024604797], 'accuracy': [0.5277777910232544], 'val_loss': [0.6919925808906555], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m 0.6919925808906555\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3528)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:33:28,956\tINFO trial_runner.py:803 -- starting train_mnist_80b135c0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:33 (running for 00:15:04.66)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 42/50 (1 RUNNING, 41 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_80b135c0</td><td>RUNNING   </td><td>172.28.0.2:3606</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 22 more trials not shown (22 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:39 (running for 00:15:09.71)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 42/50 (1 RUNNING, 41 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_80b135c0</td><td>RUNNING   </td><td>172.28.0.2:3606</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 22 more trials not shown (22 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m 2022-05-19 11:33:43.554605: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       262400    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 512)       33280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  dropout (Dropout)           (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m Total params: 687,949\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m Trainable params: 685,385\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:44 (running for 00:15:14.74)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 42/50 (1 RUNNING, 41 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_80b135c0</td><td>RUNNING   </td><td>172.28.0.2:3606</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 22 more trials not shown (22 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.6871 - accuracy: 0.5521 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6759 - accuracy: 0.5694\n",
            "5/5 [==============================] - 5s 208ms/step - loss: 0.6759 - accuracy: 0.5694 - val_loss: 0.6923 - val_accuracy: 0.5405\n",
            "Result for train_mnist_80b135c0:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-33-48\n",
            "  done: false\n",
            "  experiment_id: 37fb781e99674de88d6f3f265f469946\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6758852601051331\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3606\n",
            "  time_since_restore: 14.955502033233643\n",
            "  time_this_iter_s: 14.955502033233643\n",
            "  time_total_s: 14.955502033233643\n",
            "  timestamp: 1652960028\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 80b135c0\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6922862529754639\n",
            "  warmup_time: 0.004148006439208984\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m {'loss': [0.6758852601051331], 'accuracy': [0.5694444179534912], 'val_loss': [0.6922862529754639], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m 0.6922862529754639\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3606)\u001b[0m <class 'float'>\n",
            "Result for train_mnist_80b135c0:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-19_11-33-48\n",
            "  done: true\n",
            "  experiment_id: 37fb781e99674de88d6f3f265f469946\n",
            "  experiment_tag: 42_batch_size=8,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=256,conv_block4_filters=256,conv_block5_filters=64,dropout_rate=0.5,fc1_units=512,fc_layer_type=convolution,lr=0.0001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6758852601051331\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3606\n",
            "  time_since_restore: 14.955502033233643\n",
            "  time_this_iter_s: 14.955502033233643\n",
            "  time_total_s: 14.955502033233643\n",
            "  timestamp: 1652960028\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 80b135c0\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6922862529754639\n",
            "  warmup_time: 0.004148006439208984\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:33:48,957\tINFO trial_runner.py:803 -- starting train_mnist_8cba064e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:54 (running for 00:15:24.68)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 43/50 (1 RUNNING, 42 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8cba064e</td><td>RUNNING   </td><td>172.28.0.2:3676</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 23 more trials not shown (23 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:33:59 (running for 00:15:29.71)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 43/50 (1 RUNNING, 42 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8cba064e</td><td>RUNNING   </td><td>172.28.0.2:3676</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 23 more trials not shown (23 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m 2022-05-19 11:34:03.616866: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 256)       73984     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m Total params: 538,573\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m Trainable params: 536,457\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m Non-trainable params: 2,116\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:04 (running for 00:15:34.79)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 43/50 (1 RUNNING, 42 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8cba064e</td><td>RUNNING   </td><td>172.28.0.2:3676</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 23 more trials not shown (23 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.8094 - accuracy: 0.4271 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8562 - accuracy: 0.4375\n",
            "5/5 [==============================] - 5s 206ms/step - loss: 0.8562 - accuracy: 0.4375 - val_loss: 153.6520 - val_accuracy: 0.5405\n",
            "Result for train_mnist_8cba064e:\n",
            "  accuracy: 0.4375\n",
            "  date: 2022-05-19_11-34-08\n",
            "  done: false\n",
            "  experiment_id: 8af288f19c4d491788d1c039705c4dcd\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.856229305267334\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3676\n",
            "  time_since_restore: 15.24363374710083\n",
            "  time_this_iter_s: 15.24363374710083\n",
            "  time_total_s: 15.24363374710083\n",
            "  timestamp: 1652960048\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8cba064e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 153.65203857421875\n",
            "  warmup_time: 0.003915071487426758\n",
            "  \n",
            "Result for train_mnist_8cba064e:\n",
            "  accuracy: 0.4375\n",
            "  date: 2022-05-19_11-34-08\n",
            "  done: true\n",
            "  experiment_id: 8af288f19c4d491788d1c039705c4dcd\n",
            "  experiment_tag: 43_batch_size=16,conv_block1_filters=32,conv_block2_filters=256,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=convolution,lr=0.01,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.856229305267334\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3676\n",
            "  time_since_restore: 15.24363374710083\n",
            "  time_this_iter_s: 15.24363374710083\n",
            "  time_total_s: 15.24363374710083\n",
            "  timestamp: 1652960048\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8cba064e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 153.65203857421875\n",
            "  warmup_time: 0.003915071487426758\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m {'loss': [0.856229305267334], 'accuracy': [0.4375], 'val_loss': [153.65203857421875], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m 153.65203857421875\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3676)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:34:08,958\tINFO trial_runner.py:803 -- starting train_mnist_98d7bc32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:13 (running for 00:15:44.67)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 44/50 (1 RUNNING, 43 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_98d7bc32</td><td>RUNNING   </td><td>172.28.0.2:3744</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 24 more trials not shown (24 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:19 (running for 00:15:49.71)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 44/50 (1 RUNNING, 43 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_98d7bc32</td><td>RUNNING   </td><td>172.28.0.2:3744</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 24 more trials not shown (24 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m 2022-05-19 11:34:23.520056: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        147520    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        18464     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 64)        8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  dropout (Dropout)           (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m Total params: 312,877\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m Trainable params: 310,761\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m Non-trainable params: 2,116\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:24 (running for 00:15:54.75)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 44/50 (1 RUNNING, 43 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_98d7bc32</td><td>RUNNING   </td><td>172.28.0.2:3744</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 24 more trials not shown (24 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6897 - accuracy: 0.5781 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.5625\n",
            "5/5 [==============================] - 5s 205ms/step - loss: 0.6958 - accuracy: 0.5625 - val_loss: 0.6954 - val_accuracy: 0.4595\n",
            "Result for train_mnist_98d7bc32:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-19_11-34-28\n",
            "  done: false\n",
            "  experiment_id: 441b6644cdbd403a829f5faa5032545f\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6958404779434204\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3744\n",
            "  time_since_restore: 15.235590934753418\n",
            "  time_this_iter_s: 15.235590934753418\n",
            "  time_total_s: 15.235590934753418\n",
            "  timestamp: 1652960068\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 98d7bc32\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6954182386398315\n",
            "  warmup_time: 0.004329204559326172\n",
            "  \n",
            "Result for train_mnist_98d7bc32:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-19_11-34-28\n",
            "  done: true\n",
            "  experiment_id: 441b6644cdbd403a829f5faa5032545f\n",
            "  experiment_tag: 44_batch_size=32,conv_block1_filters=256,conv_block2_filters=64,conv_block3_filters=32,conv_block4_filters=512,conv_block5_filters=128,dropout_rate=0.4,fc1_units=64,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6958404779434204\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3744\n",
            "  time_since_restore: 15.235590934753418\n",
            "  time_this_iter_s: 15.235590934753418\n",
            "  time_total_s: 15.235590934753418\n",
            "  timestamp: 1652960068\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 98d7bc32\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6954182386398315\n",
            "  warmup_time: 0.004329204559326172\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m {'loss': [0.6958404779434204], 'accuracy': [0.5625], 'val_loss': [0.6954182386398315], 'val_accuracy': [0.45945945382118225]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m 0.6954182386398315\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3744)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:34:28,959\tINFO trial_runner.py:803 -- starting train_mnist_a4bb3f56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:34 (running for 00:16:04.68)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 45/50 (1 RUNNING, 44 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a4bb3f56</td><td>RUNNING   </td><td>172.28.0.2:3817</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 25 more trials not shown (25 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:39 (running for 00:16:09.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 45/50 (1 RUNNING, 44 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a4bb3f56</td><td>RUNNING   </td><td>172.28.0.2:3817</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 25 more trials not shown (25 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m 2022-05-19 11:34:43.799473: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:44 (running for 00:16:14.75)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 45/50 (1 RUNNING, 44 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a4bb3f56</td><td>RUNNING   </td><td>172.28.0.2:3817</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 25 more trials not shown (25 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        73792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m Total params: 175,565\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m Trainable params: 174,409\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m Non-trainable params: 1,156\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 0.6977 - accuracy: 0.4062\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.4236 \n",
            "Result for train_mnist_a4bb3f56:\n",
            "  accuracy: 0.4236111044883728\n",
            "  date: 2022-05-19_11-34-48\n",
            "  done: false\n",
            "  experiment_id: 4a1f425f4f3546179b5982c28684f2e0\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7142012119293213\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3817\n",
            "  time_since_restore: 15.256882429122925\n",
            "  time_this_iter_s: 15.256882429122925\n",
            "  time_total_s: 15.256882429122925\n",
            "  timestamp: 1652960088\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a4bb3f56\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 934.0078125\n",
            "  warmup_time: 0.004019260406494141\n",
            "  \n",
            "Result for train_mnist_a4bb3f56:\n",
            "  accuracy: 0.4236111044883728\n",
            "  date: 2022-05-19_11-34-48\n",
            "  done: true\n",
            "  experiment_id: 4a1f425f4f3546179b5982c28684f2e0\n",
            "  experiment_tag: 45_batch_size=16,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=32,conv_block5_filters=256,dropout_rate=0.2,fc1_units=32,fc_layer_type=convolution,lr=0.1,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7142012119293213\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3817\n",
            "  time_since_restore: 15.256882429122925\n",
            "  time_this_iter_s: 15.256882429122925\n",
            "  time_total_s: 15.256882429122925\n",
            "  timestamp: 1652960088\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a4bb3f56\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 934.0078125\n",
            "  warmup_time: 0.004019260406494141\n",
            "  \n",
            "5/5 [==============================] - 5s 197ms/step - loss: 0.7142 - accuracy: 0.4236 - val_loss: 934.0078 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m {'loss': [0.7142012119293213], 'accuracy': [0.4236111044883728], 'val_loss': [934.0078125], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m 934.0078125\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3817)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:34:48,961\tINFO trial_runner.py:803 -- starting train_mnist_b09bae78\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:53 (running for 00:16:24.66)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 46/50 (1 RUNNING, 45 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b09bae78</td><td>RUNNING   </td><td>172.28.0.2:3890</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 26 more trials not shown (26 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:34:59 (running for 00:16:29.71)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 46/50 (1 RUNNING, 45 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b09bae78</td><td>RUNNING   </td><td>172.28.0.2:3890</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 26 more trials not shown (26 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m 2022-05-19 11:35:03.670214: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 32)        147488    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 256)       73984     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       262400    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 512)       16896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  dropout (Dropout)           (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  global_average_pooling2d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m Total params: 521,549\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m Trainable params: 518,345\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m Non-trainable params: 3,204\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:04 (running for 00:16:34.75)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 46/50 (1 RUNNING, 45 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b09bae78</td><td>RUNNING   </td><td>172.28.0.2:3890</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 26 more trials not shown (26 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m \r1/5 [=====>........................] - ETA: 15s - loss: 0.7135 - accuracy: 0.5000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.7355 - accuracy: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.5208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:35:08,963\tINFO trial_runner.py:803 -- starting train_mnist_bc9fea18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_b09bae78:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-35-08\n",
            "  done: false\n",
            "  experiment_id: 6ca62d97fc93444d8d3b4de62cabd11a\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.722083568572998\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3890\n",
            "  time_since_restore: 15.36802625656128\n",
            "  time_this_iter_s: 15.36802625656128\n",
            "  time_total_s: 15.36802625656128\n",
            "  timestamp: 1652960108\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b09bae78\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6873375177383423\n",
            "  warmup_time: 0.004125833511352539\n",
            "  \n",
            "Result for train_mnist_b09bae78:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-19_11-35-08\n",
            "  done: true\n",
            "  experiment_id: 6ca62d97fc93444d8d3b4de62cabd11a\n",
            "  experiment_tag: 46_batch_size=8,conv_block1_filters=512,conv_block2_filters=32,conv_block3_filters=256,conv_block4_filters=256,conv_block5_filters=32,dropout_rate=0.1,fc1_units=512,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.722083568572998\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3890\n",
            "  time_since_restore: 15.36802625656128\n",
            "  time_this_iter_s: 15.36802625656128\n",
            "  time_total_s: 15.36802625656128\n",
            "  timestamp: 1652960108\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b09bae78\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6873375177383423\n",
            "  warmup_time: 0.004125833511352539\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 5s 235ms/step - loss: 0.7221 - accuracy: 0.5208 - val_loss: 0.6873 - val_accuracy: 0.6216\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m {'loss': [0.722083568572998], 'accuracy': [0.5208333134651184], 'val_loss': [0.6873375177383423], 'val_accuracy': [0.6216216087341309]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m 0.6873375177383423\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3890)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:14 (running for 00:16:44.68)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 47/50 (1 RUNNING, 46 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bc9fea18</td><td>RUNNING   </td><td>172.28.0.2:3962</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 27 more trials not shown (27 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:19 (running for 00:16:49.72)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 47/50 (1 RUNNING, 46 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bc9fea18</td><td>RUNNING   </td><td>172.28.0.2:3962</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 27 more trials not shown (27 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m 2022-05-19 11:35:23.314213: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 32)        320       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  activation (Activation)     (None, 18, 18, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 128)       65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 256)       33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  dropout (Dropout)           (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m Total params: 551,501\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m Trainable params: 549,129\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m Non-trainable params: 2,372\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:24 (running for 00:16:54.76)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 47/50 (1 RUNNING, 46 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_bc9fea18</td><td>RUNNING   </td><td>172.28.0.2:3962</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 27 more trials not shown (27 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 1.5486 - accuracy: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.5610 - accuracy: 0.5486\n",
            "Result for train_mnist_bc9fea18:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-35-28\n",
            "  done: false\n",
            "  experiment_id: 48ab468b8b11418491cba1a3da95e550\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.5610147714614868\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3962\n",
            "  time_since_restore: 14.746320247650146\n",
            "  time_this_iter_s: 14.746320247650146\n",
            "  time_total_s: 14.746320247650146\n",
            "  timestamp: 1652960128\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bc9fea18\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6929923295974731\n",
            "  warmup_time: 0.004096508026123047\n",
            "  \n",
            "Result for train_mnist_bc9fea18:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-35-28\n",
            "  done: true\n",
            "  experiment_id: 48ab468b8b11418491cba1a3da95e550\n",
            "  experiment_tag: 47_batch_size=32,conv_block1_filters=32,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=128,dropout_rate=0.5,fc1_units=256,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.5610147714614868\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3962\n",
            "  time_since_restore: 14.746320247650146\n",
            "  time_this_iter_s: 14.746320247650146\n",
            "  time_total_s: 14.746320247650146\n",
            "  timestamp: 1652960128\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: bc9fea18\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6929923295974731\n",
            "  warmup_time: 0.004096508026123047\n",
            "  \n",
            "5/5 [==============================] - 4s 200ms/step - loss: 1.5610 - accuracy: 0.5486 - val_loss: 0.6930 - val_accuracy: 0.5405\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m {'loss': [1.5610147714614868], 'accuracy': [0.5486111044883728], 'val_loss': [0.6929923295974731], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m 0.6929923295974731\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3962)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:35:28,964\tINFO trial_runner.py:803 -- starting train_mnist_c822e5e8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:33 (running for 00:17:04.68)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 48/50 (1 RUNNING, 47 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c822e5e8</td><td>RUNNING   </td><td>172.28.0.2:4032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 28 more trials not shown (28 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:39 (running for 00:17:09.73)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 48/50 (1 RUNNING, 47 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c822e5e8</td><td>RUNNING   </td><td>172.28.0.2:4032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 28 more trials not shown (28 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m 2022-05-19 11:35:43.471060: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 256)       2560      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  activation (Activation)     (None, 18, 18, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 32)        36896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 512)       66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  global_average_pooling2d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  dense (Dense)               (None, 64)                16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  dropout (Dropout)           (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization_5 (Batc  (None, 64)               256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  activation_5 (Activation)   (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  dense_1 (Dense)             (None, 2)                 130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m Total params: 553,453\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m Trainable params: 550,953\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m Non-trainable params: 2,500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:44 (running for 00:17:14.76)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 48/50 (1 RUNNING, 47 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c822e5e8</td><td>RUNNING   </td><td>172.28.0.2:4032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 28 more trials not shown (28 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/5 [=================>............] - ETA: 0s - loss: 0.6995 - accuracy: 0.5208 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.5556\n",
            "5/5 [==============================] - 5s 201ms/step - loss: 0.6890 - accuracy: 0.5556 - val_loss: 0.6928 - val_accuracy: 0.5946\n",
            "Result for train_mnist_c822e5e8:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-35-48\n",
            "  done: false\n",
            "  experiment_id: 32dc115e88f643779bd9336332cd4e23\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6889854669570923\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4032\n",
            "  time_since_restore: 15.542670249938965\n",
            "  time_this_iter_s: 15.542670249938965\n",
            "  time_total_s: 15.542670249938965\n",
            "  timestamp: 1652960148\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c822e5e8\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6928279399871826\n",
            "  warmup_time: 0.0039708614349365234\n",
            "  \n",
            "Result for train_mnist_c822e5e8:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-19_11-35-48\n",
            "  done: true\n",
            "  experiment_id: 32dc115e88f643779bd9336332cd4e23\n",
            "  experiment_tag: 48_batch_size=8,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=32,conv_block4_filters=512,conv_block5_filters=256,dropout_rate=0.3,fc1_units=64,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6889854669570923\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4032\n",
            "  time_since_restore: 15.542670249938965\n",
            "  time_this_iter_s: 15.542670249938965\n",
            "  time_total_s: 15.542670249938965\n",
            "  timestamp: 1652960148\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c822e5e8\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6928279399871826\n",
            "  warmup_time: 0.0039708614349365234\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m {'loss': [0.6889854669570923], 'accuracy': [0.5555555820465088], 'val_loss': [0.6928279399871826], 'val_accuracy': [0.5945945978164673]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m 0.6928279399871826\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4032)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:35:49,966\tINFO trial_runner.py:803 -- starting train_mnist_d48af8e8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:50 (running for 00:17:20.69)<br>Memory usage on this node: 1.9/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48af8e8</td><td>RUNNING   </td><td>172.28.0.2:4104</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:35:59 (running for 00:17:30.17)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48af8e8</td><td>RUNNING   </td><td>172.28.0.2:4104</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m 2022-05-19 11:36:04.453173: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:36:04 (running for 00:17:35.22)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48af8e8</td><td>RUNNING   </td><td>172.28.0.2:4104</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 512)       5120      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 512)      2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  activation (Activation)     (None, 18, 18, 512)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 64)        294976    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 128)       32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 64)        8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d_5 (Conv2D)           (None, 13, 13, 128)       8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  dropout (Dropout)           (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 13, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  activation_5 (Activation)   (None, 13, 13, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  conv2d_6 (Conv2D)           (None, 13, 13, 2)         258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  dropout_1 (Dropout)         (None, 13, 13, 2)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 13, 2)        8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  global_max_pooling2d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  lMaxPooling2D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m Total params: 390,605\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m Trainable params: 388,681\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m Non-trainable params: 1,924\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m hhhhhhhhhhhhhhhhhhh\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.4204 - accuracy: 0.5547 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3611 - accuracy: 0.5486\n",
            "5/5 [==============================] - 5s 223ms/step - loss: 1.3611 - accuracy: 0.5486 - val_loss: 0.8095 - val_accuracy: 0.5405\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:36:09 (running for 00:17:40.26)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d48af8e8</td><td>RUNNING   </td><td>172.28.0.2:4104</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m {'loss': [1.3611470460891724], 'accuracy': [0.5486111044883728], 'val_loss': [0.8094571232795715], 'val_accuracy': [0.5405405163764954]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m 0.8094571232795715\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4104)\u001b[0m <class 'float'>\n",
            "Result for train_mnist_d48af8e8:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-36-09\n",
            "  done: false\n",
            "  experiment_id: fbe33619242546d1813431b1031801d3\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.3611470460891724\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4104\n",
            "  time_since_restore: 15.19167184829712\n",
            "  time_this_iter_s: 15.19167184829712\n",
            "  time_total_s: 15.19167184829712\n",
            "  timestamp: 1652960169\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d48af8e8\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.8094571232795715\n",
            "  warmup_time: 0.004361152648925781\n",
            "  \n",
            "Result for train_mnist_d48af8e8:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-19_11-36-09\n",
            "  done: true\n",
            "  experiment_id: fbe33619242546d1813431b1031801d3\n",
            "  experiment_tag: 49_batch_size=16,conv_block1_filters=512,conv_block2_filters=64,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=64,dropout_rate=0.2,fc1_units=128,fc_layer_type=convolution,lr=0.01,pool_type=max\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.3611470460891724\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4104\n",
            "  time_since_restore: 15.19167184829712\n",
            "  time_this_iter_s: 15.19167184829712\n",
            "  time_total_s: 15.19167184829712\n",
            "  timestamp: 1652960169\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d48af8e8\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.8094571232795715\n",
            "  warmup_time: 0.004361152648925781\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:36:09,968\tINFO trial_runner.py:803 -- starting train_mnist_e0e980b4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:36:15 (running for 00:17:45.69)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e980b4</td><td>RUNNING   </td><td>172.28.0.2:4176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 30 more trials not shown (30 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:36:20 (running for 00:17:50.73)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e980b4</td><td>RUNNING   </td><td>172.28.0.2:4176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 30 more trials not shown (30 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m 2022-05-19 11:36:24.590635: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20, 1)]       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  conv2d (Conv2D)             (None, 18, 18, 64)        640       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization (BatchN  (None, 18, 18, 64)       256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  activation (Activation)     (None, 18, 18, 64)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  conv2d_1 (Conv2D)           (None, 16, 16, 256)       147712    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  activation_1 (Activation)   (None, 16, 16, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  conv2d_2 (Conv2D)           (None, 14, 14, 128)       295040    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  activation_2 (Activation)   (None, 14, 14, 128)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  conv2d_3 (Conv2D)           (None, 13, 13, 256)       131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 13, 256)      1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  activation_3 (Activation)   (None, 13, 13, 256)       0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  conv2d_4 (Conv2D)           (None, 13, 13, 32)        8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 13, 32)       128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  activation_4 (Activation)   (None, 13, 13, 32)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  global_average_pooling2d (G  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  lobalAveragePooling2D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  dense (Dense)               (None, 256)               8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m Total params: 595,885\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m Trainable params: 593,897\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m Non-trainable params: 1,988\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m Total number of layers: 25\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m hhhhhhhhhhhhhhhhhhh\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:36:25 (running for 00:17:55.76)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e0e980b4</td><td>RUNNING   </td><td>172.28.0.2:4176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 30 more trials not shown (30 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/5 [=======================>......] - ETA: 0s - loss: 0.7089 - accuracy: 0.6250 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.6042\n",
            "Result for train_mnist_e0e980b4:\n",
            "  accuracy: 0.6041666865348816\n",
            "  date: 2022-05-19_11-36-29\n",
            "  done: false\n",
            "  experiment_id: 9fd59256628841529d096ee472cac0d4\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7142836451530457\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4176\n",
            "  time_since_restore: 15.321443319320679\n",
            "  time_this_iter_s: 15.321443319320679\n",
            "  time_total_s: 15.321443319320679\n",
            "  timestamp: 1652960189\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e0e980b4\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6855979561805725\n",
            "  warmup_time: 0.0039370059967041016\n",
            "  \n",
            "Result for train_mnist_e0e980b4:\n",
            "  accuracy: 0.6041666865348816\n",
            "  date: 2022-05-19_11-36-29\n",
            "  done: true\n",
            "  experiment_id: 9fd59256628841529d096ee472cac0d4\n",
            "  experiment_tag: 50_batch_size=8,conv_block1_filters=64,conv_block2_filters=256,conv_block3_filters=128,conv_block4_filters=256,conv_block5_filters=32,dropout_rate=0.1,fc1_units=256,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 341ac1e1dc5b\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7142836451530457\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4176\n",
            "  time_since_restore: 15.321443319320679\n",
            "  time_this_iter_s: 15.321443319320679\n",
            "  time_total_s: 15.321443319320679\n",
            "  timestamp: 1652960189\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e0e980b4\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6855979561805725\n",
            "  warmup_time: 0.0039370059967041016\n",
            "  \n",
            "5/5 [==============================] - 5s 194ms/step - loss: 0.7143 - accuracy: 0.6042 - val_loss: 0.6856 - val_accuracy: 0.5676\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m tipado\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m <class 'keras.callbacks.History'>\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m diccionario\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m {'loss': [0.7142836451530457], 'accuracy': [0.6041666865348816], 'val_loss': [0.6855979561805725], 'val_accuracy': [0.5675675868988037]}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m 0.6855979561805725\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4176)\u001b[0m <class 'float'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-19 11:36:29 (running for 00:18:00.48)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /root/ray_results/train_mnist_2022-05-19_11-18-29<br>Number of trials: 50/50 (50 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_68eb5a08</td><td>TERMINATED</td><td>172.28.0.2:600 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.1185</td><td style=\"text-align: right;\">0.734559</td><td style=\"text-align: right;\">  191.399   </td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_832702aa</td><td>TERMINATED</td><td>172.28.0.2:685 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.3774</td><td style=\"text-align: right;\">1.44961 </td><td style=\"text-align: right;\">    0.696208</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_95d26c50</td><td>TERMINATED</td><td>172.28.0.2:762 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3615</td><td style=\"text-align: right;\">0.797753</td><td style=\"text-align: right;\">    1.84715 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a39f1860</td><td>TERMINATED</td><td>172.28.0.2:838 </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.549 </td><td style=\"text-align: right;\">3.06146 </td><td style=\"text-align: right;\">    0.692285</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b02fbfe4</td><td>TERMINATED</td><td>172.28.0.2:914 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4584</td><td style=\"text-align: right;\">0.75056 </td><td style=\"text-align: right;\">    0.693585</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bd3c0756</td><td>TERMINATED</td><td>172.28.0.2:987 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.897 </td><td style=\"text-align: right;\">0.773005</td><td style=\"text-align: right;\"> 2203.34    </td><td style=\"text-align: right;\">  0.395833</td></tr>\n",
              "<tr><td>train_mnist_c9fe012e</td><td>TERMINATED</td><td>172.28.0.2:1061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6611</td><td style=\"text-align: right;\">0.794908</td><td style=\"text-align: right;\">    0.691936</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_d6a1467a</td><td>TERMINATED</td><td>172.28.0.2:1136</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3899</td><td style=\"text-align: right;\">0.705615</td><td style=\"text-align: right;\">    0.69325 </td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_e367a9bc</td><td>TERMINATED</td><td>172.28.0.2:1207</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8841</td><td style=\"text-align: right;\">0.786473</td><td style=\"text-align: right;\">    0.676599</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_f09b7de8</td><td>TERMINATED</td><td>172.28.0.2:1277</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.5024</td><td style=\"text-align: right;\">0.785218</td><td style=\"text-align: right;\">    0.69214 </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_fed5f4c4</td><td>TERMINATED</td><td>172.28.0.2:1352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.8672</td><td style=\"text-align: right;\">1.42544 </td><td style=\"text-align: right;\"> 5991.83    </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_0aed775a</td><td>TERMINATED</td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.0433</td><td style=\"text-align: right;\">1.6705  </td><td style=\"text-align: right;\">    2.67954 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1701dbda</td><td>TERMINATED</td><td>172.28.0.2:1495</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1045</td><td style=\"text-align: right;\">0.722589</td><td style=\"text-align: right;\">    0.70587 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2383fb72</td><td>TERMINATED</td><td>172.28.0.2:1570</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5674</td><td style=\"text-align: right;\">0.724275</td><td style=\"text-align: right;\">    0.693634</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_2fd1ef88</td><td>TERMINATED</td><td>172.28.0.2:1641</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.4771</td><td style=\"text-align: right;\">0.774419</td><td style=\"text-align: right;\">    0.713471</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_3d6f9262</td><td>TERMINATED</td><td>172.28.0.2:1715</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2296</td><td style=\"text-align: right;\">3.23917 </td><td style=\"text-align: right;\">    0.69382 </td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_49be775e</td><td>TERMINATED</td><td>172.28.0.2:1791</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8583</td><td style=\"text-align: right;\">0.704173</td><td style=\"text-align: right;\">   10.3024  </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_573ed496</td><td>TERMINATED</td><td>172.28.0.2:1865</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8966</td><td style=\"text-align: right;\">0.808232</td><td style=\"text-align: right;\">    0.684023</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_64f6ca1c</td><td>TERMINATED</td><td>172.28.0.2:1941</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.2661</td><td style=\"text-align: right;\">0.709353</td><td style=\"text-align: right;\">   12.8308  </td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_72ea39ce</td><td>TERMINATED</td><td>172.28.0.2:2014</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9968</td><td style=\"text-align: right;\">0.997724</td><td style=\"text-align: right;\">    0.691959</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7ebc4da0</td><td>TERMINATED</td><td>172.28.0.2:2086</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4207</td><td style=\"text-align: right;\">0.783529</td><td style=\"text-align: right;\">    0.690191</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_8ae5b72e</td><td>TERMINATED</td><td>172.28.0.2:2161</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6606</td><td style=\"text-align: right;\">0.737487</td><td style=\"text-align: right;\">    0.683717</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_978e6f48</td><td>TERMINATED</td><td>172.28.0.2:2235</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.8044</td><td style=\"text-align: right;\">0.866764</td><td style=\"text-align: right;\">    0.677711</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_a42f1c02</td><td>TERMINATED</td><td>172.28.0.2:2309</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2929</td><td style=\"text-align: right;\">0.774575</td><td style=\"text-align: right;\">    0.688228</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_b0559114</td><td>TERMINATED</td><td>172.28.0.2:2384</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3921</td><td style=\"text-align: right;\">0.82536 </td><td style=\"text-align: right;\">    0.68441 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_bc4adf60</td><td>TERMINATED</td><td>172.28.0.2:2456</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3542</td><td style=\"text-align: right;\">0.76176 </td><td style=\"text-align: right;\">    0.688887</td><td style=\"text-align: right;\">  0.576389</td></tr>\n",
              "<tr><td>train_mnist_c834f9aa</td><td>TERMINATED</td><td>172.28.0.2:2527</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9257</td><td style=\"text-align: right;\">0.741231</td><td style=\"text-align: right;\"> 4312.41    </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_d48161ee</td><td>TERMINATED</td><td>172.28.0.2:2603</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5748</td><td style=\"text-align: right;\">0.977474</td><td style=\"text-align: right;\">    0.687018</td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_e0e0fd82</td><td>TERMINATED</td><td>172.28.0.2:2675</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5651</td><td style=\"text-align: right;\">0.744459</td><td style=\"text-align: right;\"> 8062.95    </td><td style=\"text-align: right;\">  0.513889</td></tr>\n",
              "<tr><td>train_mnist_ed617924</td><td>TERMINATED</td><td>172.28.0.2:2748</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5731</td><td style=\"text-align: right;\">0.772503</td><td style=\"text-align: right;\">    0.695841</td><td style=\"text-align: right;\">  0.465278</td></tr>\n",
              "<tr><td>train_mnist_f9ddd152</td><td>TERMINATED</td><td>172.28.0.2:2823</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2903</td><td style=\"text-align: right;\">0.679823</td><td style=\"text-align: right;\">    0.692052</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_06208298</td><td>TERMINATED</td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.7174</td><td style=\"text-align: right;\">0.798599</td><td style=\"text-align: right;\">    7.75721 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_125ed5d2</td><td>TERMINATED</td><td>172.28.0.2:2962</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3659</td><td style=\"text-align: right;\">0.699964</td><td style=\"text-align: right;\">    0.671176</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_1eb5e636</td><td>TERMINATED</td><td>172.28.0.2:3032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1001</td><td style=\"text-align: right;\">0.785071</td><td style=\"text-align: right;\">42271.7     </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_2b0d3254</td><td>TERMINATED</td><td>172.28.0.2:3104</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3671</td><td style=\"text-align: right;\">0.686485</td><td style=\"text-align: right;\">    0.694812</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3717f4ee</td><td>TERMINATED</td><td>172.28.0.2:3176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6927</td><td style=\"text-align: right;\">0.675158</td><td style=\"text-align: right;\">    0.679836</td><td style=\"text-align: right;\">  0.590278</td></tr>\n",
              "<tr><td>train_mnist_433c4112</td><td>TERMINATED</td><td>172.28.0.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1991</td><td style=\"text-align: right;\">0.690256</td><td style=\"text-align: right;\">    0.690174</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_50150e8c</td><td>TERMINATED</td><td>172.28.0.2:3315</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5516</td><td style=\"text-align: right;\">0.705896</td><td style=\"text-align: right;\">    0.691715</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_5c293464</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9633</td><td style=\"text-align: right;\">0.705487</td><td style=\"text-align: right;\">    0.695143</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_685531de</td><td>TERMINATED</td><td>172.28.0.2:3457</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3015</td><td style=\"text-align: right;\">0.751956</td><td style=\"text-align: right;\"> 6292.14    </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_747b8c88</td><td>TERMINATED</td><td>172.28.0.2:3528</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.6485</td><td style=\"text-align: right;\">0.68342 </td><td style=\"text-align: right;\">    0.691993</td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_80b135c0</td><td>TERMINATED</td><td>172.28.0.2:3606</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.9555</td><td style=\"text-align: right;\">0.675885</td><td style=\"text-align: right;\">    0.692286</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_8cba064e</td><td>TERMINATED</td><td>172.28.0.2:3676</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2436</td><td style=\"text-align: right;\">0.856229</td><td style=\"text-align: right;\">  153.652   </td><td style=\"text-align: right;\">  0.4375  </td></tr>\n",
              "<tr><td>train_mnist_98d7bc32</td><td>TERMINATED</td><td>172.28.0.2:3744</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2356</td><td style=\"text-align: right;\">0.69584 </td><td style=\"text-align: right;\">    0.695418</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_a4bb3f56</td><td>TERMINATED</td><td>172.28.0.2:3817</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2569</td><td style=\"text-align: right;\">0.714201</td><td style=\"text-align: right;\">  934.008   </td><td style=\"text-align: right;\">  0.423611</td></tr>\n",
              "<tr><td>train_mnist_b09bae78</td><td>TERMINATED</td><td>172.28.0.2:3890</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.368 </td><td style=\"text-align: right;\">0.722084</td><td style=\"text-align: right;\">    0.687338</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_bc9fea18</td><td>TERMINATED</td><td>172.28.0.2:3962</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.7463</td><td style=\"text-align: right;\">1.56101 </td><td style=\"text-align: right;\">    0.692992</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_c822e5e8</td><td>TERMINATED</td><td>172.28.0.2:4032</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.5427</td><td style=\"text-align: right;\">0.688985</td><td style=\"text-align: right;\">    0.692828</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_d48af8e8</td><td>TERMINATED</td><td>172.28.0.2:4104</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1917</td><td style=\"text-align: right;\">1.36115 </td><td style=\"text-align: right;\">    0.809457</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_e0e980b4</td><td>TERMINATED</td><td>172.28.0.2:4176</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.3214</td><td style=\"text-align: right;\">0.714284</td><td style=\"text-align: right;\">    0.685598</td><td style=\"text-align: right;\">  0.604167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-19 11:36:29,986\tINFO tune.py:702 -- Total run time: 1080.70 seconds (1080.47 seconds for the tuning loop).\n"
          ]
        }
      ],
      "source": [
        "analysis = tune.run(train_mnist, num_samples=50, search_alg=search_alg,  scheduler=scheduler, resources_per_trial={'gpu': 1})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_config = analysis.get_best_config(metric=\"val_accuracy\", mode='max')"
      ],
      "metadata": {
        "id": "VBVHyGGOLdiy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfHqUIITX0Wp",
        "outputId": "dc95b047-df22-4290-e443-a2eda1db9009"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 8,\n",
              " 'conv_block1_filters': 128,\n",
              " 'conv_block2_filters': 128,\n",
              " 'conv_block3_filters': 512,\n",
              " 'conv_block4_filters': 64,\n",
              " 'conv_block5_filters': 256,\n",
              " 'dropout_rate': 0.2,\n",
              " 'fc1_units': 256,\n",
              " 'fc_layer_type': 'dense',\n",
              " 'lr': 0.001,\n",
              " 'pool_type': 'average'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_mnist(best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orD96f4nCmDX",
        "outputId": "1d51cba1-8c68-428c-a232-5c3b732d590c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 20, 20, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 18, 18, 128)       1280      \n",
            "                                                                 \n",
            " batch_normalization_70 (Bat  (None, 18, 18, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_70 (Activation)  (None, 18, 18, 128)       0         \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_71 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_71 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 14, 14, 512)       590336    \n",
            "                                                                 \n",
            " batch_normalization_72 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_72 (Activation)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 13, 13, 64)        131136    \n",
            "                                                                 \n",
            " batch_normalization_73 (Bat  (None, 13, 13, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_73 (Activation)  (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 13, 13, 256)       16640     \n",
            "                                                                 \n",
            " batch_normalization_74 (Bat  (None, 13, 13, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_74 (Activation)  (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " global_average_pooling2d_10  (None, 256)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_75 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_75 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_76 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 958,669\n",
            "Trainable params: 955,977\n",
            "Non-trainable params: 2,692\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 25\n",
            "hhhhhhhhhhhhhhhhhhh\n",
            "5/5 [==============================] - 3s 119ms/step - loss: 0.8325 - accuracy: 0.5069 - val_loss: 0.6829 - val_accuracy: 0.6216\n",
            "tipado\n",
            "<class 'keras.callbacks.History'>\n",
            "diccionario\n",
            "{'loss': [0.8325129747390747], 'accuracy': [0.5069444179534912], 'val_loss': [0.6828562021255493], 'val_accuracy': [0.6216216087341309]}\n",
            "0.6828562021255493\n",
            "<class 'float'>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RayTuneFinal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}