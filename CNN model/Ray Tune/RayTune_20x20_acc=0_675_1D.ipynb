{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraies and packages"
      ],
      "metadata": {
        "id": "PXjVxSG4yt-o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVA_ZA7c5BE0",
        "outputId": "315b0dd5-5625-4569-802d-69e16dbea8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.12.1-cp37-cp37m-manylinux2014_x86_64.whl (53.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 53.2 MB 163 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 32.2 MB/s \n",
            "\u001b[?25hCollecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 52.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: platformdirs, frozenlist, distlib, virtualenv, grpcio, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.1\n",
            "    Uninstalling grpcio-1.46.1:\n",
            "      Successfully uninstalled grpcio-1.46.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed aiosignal-1.2.0 distlib-0.3.4 frozenlist-1.3.0 grpcio-1.43.0 platformdirs-2.5.2 ray-1.12.1 virtualenv-20.14.1\n"
          ]
        }
      ],
      "source": [
        "pip install ray torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlaA55u5HNx",
        "outputId": "7b9566b5-146e-4355-fc2b-b89b8cd29132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=1b6451a71a9c83d0a4d59ad3e5dab7793bfe9d043610c4cbd5e5e08f388147da\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3nVLl1gV5Ize"
      },
      "outputs": [],
      "source": [
        "# # Solucion par ael error int-float\n",
        "# import psutil\n",
        "# import ray\n",
        "# ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lU9kk9xU5K4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yvgorDkMN429"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "25d22ed5-5d8b-4be5-fe0b-07634022c8f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "XoUYbBj2yxpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(20, 20))\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block1_filters'], kernel_size=3, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block2_filters'], kernel_size=3, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block3_filters'], kernel_size=3, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block4_filters'], kernel_size=2, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block5_filters'], kernel_size=1, strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv1D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv1D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "Y7vViFfkzJTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training function"
      ],
      "metadata": {
        "id": "oss9TBkZzMYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist( config):\n",
        "  path ='/content/drive/MyDrive/UPM/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame[['5S_rRNA', 'AADACL2-AS1', 'AB015752.3', 'AB019438.66', 'ABHD17AP7', 'AC000077.2', 'AC000111.3', 'AC000111.5', 'AC000124.1', 'AC002368.4', 'AC002472.11', 'AC002486.3', 'AC002542.2', 'AC003084.2', 'AC003682.16', 'AC003682.17', 'AC003986.5', 'AC004006.2', 'AC004012.1', 'AC004014.3', 'AC004066.3', 'AC004112.4', 'AC004158.3', 'AC004221.2', 'AC004449.6', 'AC004510.3', 'AC004549.6', 'AC004862.6', 'AC004870.3', 'AC004941.3', 'AC004947.2', 'AC005008.2', 'AC005094.2', 'AC005178.1', 'AC005197.2', 'AC005235.1', 'AC005307.1', 'AC005355.1', 'AC005387.3', 'AC005392.13', 'AC005498.4', 'AC005518.2', 'AC005550.5', 'AC005597.1', 'AC005624.2', 'AC005722.4', 'AC005740.5', 'AC006003.3', 'AC006007.1', 'AC006041.1', 'AC006116.14', 'AC006130.4', 'AC006153.3', 'AC006296.2', 'AC006372.4', 'AC006372.5', 'AC006372.6', 'AC006373.1', 'AC006427.2', 'AC006499.1', 'AC006499.3', 'AC006499.5', 'AC006499.6', 'AC006509.4', 'AC006960.7', 'AC006987.5', 'AC007128.1', 'AC007131.2', 'AC007163.6', 'AC007193.9', 'AC007249.3', 'AC007253.1', 'AC007292.7', 'AC007322.1', 'AC007349.7', 'AC007391.2', 'AC007403.3', 'AC007463.2', 'AC007557.4', 'AC007563.3', 'AC007563.5', 'AC007568.1', 'AC007679.3', 'AC007682.1', 'AC007740.1', 'AC007742.3', 'AC007796.1', 'AC007879.1', 'AC007879.3', 'AC008067.2', 'AC008074.4', 'AC008154.4', 'AC008278.2', 'AC008281.1', 'AC008746.10', 'AC008746.9', 'AC008834.2', 'AC008940.1', 'AC009161.1', 'AC009237.16', 'AC009237.17', 'AC009238.7', 'AC009238.8', 'AC009310.1', 'AC009312.1', 'AC009313.1', 'AC009410.1', 'AC009477.7', 'AC009487.4', 'AC009487.5', 'AC009541.1', 'AC009970.1', 'AC010096.2', 'AC010141.1', 'AC010518.3', 'AC010729.1', 'AC010729.2', 'AC010731.2', 'AC010731.6', 'AC010884.1', 'AC010907.5', 'AC010967.1', 'AC010967.2', 'AC010974.3', 'AC010983.1', 'AC010987.6', 'AC011196.3', 'AC011243.1', 'AC011286.1', 'AC011343.1', 'AC011516.2', 'AC011524.3', 'AC011648.1', 'AC011742.5', 'AC012074.2', 'AC012075.2', 'AC012322.1', 'AC012354.6', 'AC012363.13', 'AC012456.4', 'AC012506.1', 'AC012506.2', 'AC012506.3', 'AC012506.4', 'AC012507.3', 'AC012507.4', 'AC012513.6', 'AC012668.1', 'AC013402.5', 'AC013429.4', 'AC013448.2', 'AC013480.2', 'AC013733.3', 'AC015936.3', 'AC016694.2', 'AC016735.1', 'AC016745.3', 'AC016831.3', 'AC016831.5', 'AC016912.3', 'AC017019.1', 'AC017048.2', 'AC018359.1', 'AC018643.4', 'AC018685.1', 'AC018717.1', 'AC018799.1', 'AC018804.3', 'AC018880.1', 'AC018880.2', 'AC018892.3', 'AC019064.1', 'AC019118.4', 'AC020595.1', 'AC020743.2', 'AC020915.2', 'AC022201.4', 'AC023115.4', 'AC023128.1', 'AC024082.4', 'AC024704.2', 'AC026202.5', 'AC026954.6', 'AC027124.2', 'AC034228.2', 'AC060834.3', 'AC062016.1', 'AC062022.1', 'AC063976.1', 'AC063976.3', 'AC064834.1', 'AC064834.2', 'AC067945.2', 'AC067956.1', 'AC068057.1', 'AC068490.1', 'AC068492.1', 'AC068535.3', 'AC068831.3', 'AC069155.1', 'AC073218.1', 'AC073464.6', 'AC073641.2', 'AC074338.4', 'AC078842.3', 'AC078882.1', 'AC079112.1', 'AC079117.1', 'AC079145.4', 'AC079154.1', 'AC079325.6', 'AC079586.1', 'AC079610.1', 'AC079776.1', 'AC079987.2', 'AC083864.3', 'AC083939.1', 'AC090018.1', 'AC090952.5', 'AC090957.2', 'AC091133.1', 'AC091729.8', 'AC091814.2', 'AC092155.4', 'AC092159.3', 'AC092168.3', 'AC092566.1', 'AC092570.1', 'AC092570.2', 'AC092578.1', 'AC092601.1', 'AC092635.1', 'AC092657.2', 'AC092933.4', 'AC093063.2', 'AC093084.1', 'AC093106.4', 'AC093326.1', 'AC093381.2', 'AC093590.1', 'AC093642.6', 'AC096582.9', 'AC096669.2', 'AC096732.2', 'AC097468.7', 'AC097713.3', 'AC097713.4', 'AC098592.6', 'AC098828.3', 'AC098872.3', 'AC098973.1', 'AC099344.2', 'AC099344.3', 'AC099552.3', 'AC102948.2', 'AC103563.5', 'AC103563.7', 'AC103563.8', 'AC104076.3', 'AC104306.4', 'AC104777.2', 'AC104777.4', 'AC107083.1', 'AC108032.1', 'AC108066.1', 'AC109589.1', 'AC110620.1', 'AC110754.3', 'AC112198.1', 'AC112220.2', 'AC112518.3', 'AC113167.1', 'AC113167.2', 'AC113607.2', 'AC114752.3', 'AC114814.2', 'AC114877.3', 'AC118653.2', 'AC123900.2', 'AC124057.5', 'AC125421.1', 'AC128709.2', 'AC128709.3', 'AC128709.4', 'AC133633.1', 'AC133680.1', 'AC133785.1', 'AC140481.8', 'AC142119.1', 'AC142293.3', 'AC144450.1', 'AC144833.1', 'ADI1P2', 'AE000661.36', 'AF186192.6', 'AHCYP3', 'AL133249.1', 'AP000345.4', 'AP000356.2', 'AP000619.5', 'AP000648.6', 'AP000997.2', 'AP006285.7', 'ATP5F1P4', 'ATP5G1P8', 'BAATP1', 'BOK-AS1', 'BRI3BPP1', 'BSN-AS1', 'BSN-AS2', 'CASC16', 'CDCA4P3', 'CDKN2AIPNLP2', 'CICP1', 'CLUHP4', 'CNN2P2', 'CTA-392E5.1', 'CTB-138E5.1', 'CTB-164N12.1', 'CTB-49A3.1', 'CTC-304I17.5', 'CTC-339O9.2', 'CTC-501O10.1', 'CTD-2130F23.2', 'CTD-2269E23.3', 'CTD-2308B18.1', 'CTD-2319I12.5', 'CTD-2555O16.1', 'CTD-3187F8.11', 'CYCSP26', 'CYP2T3P', 'DDX43P2', 'DLG3-AS1', 'DPRXP6', 'GLUD1P4', 'GLULP6', 'GRAMD4P7', 'GS1-114I9.1', 'GS1-251I9.2', 'GTSCR1', 'HNRNPH3P1', 'IFT74-AS1', 'IGKV7-3', 'KRT8P6', 'KRTAP20-3', 'LINC00309', 'LINC00364', 'LINC00391', 'LINC00466', 'LINC00838', 'LINC00856', 'LINC00864', 'LINC00879', 'LINC01326', 'LINC01524', 'LRRC34P1', 'MARCKSL1P2', 'MIR1273F', 'MIR4290HG', 'MRLN', 'MTATP6P23', 'MTCO2P16', 'NHEG1', 'NOS2P4', 'OR10B1P', 'OR13Z2P', 'OR2AD1P', 'OR2B8P', 'OR5BN2P', 'OSBPL9P1', 'PDX1-AS1', 'PGBD4P5', 'RN7SKP238', 'RNA5SP205', 'RNF212', 'RNU6-1090P', 'RP1-151B14.9', 'RP11-100K18.1', 'RP11-107N7.1', 'RP11-123J14.1', 'RP11-203B7.2', 'RP11-2H8.3', 'RP11-307O10.1', 'RP11-359G22.2', 'RP11-361A23.3', 'RP11-378I6.1', 'RP11-430C1.1', 'RP11-434D11.4', 'RP11-438B23.2', 'RP11-520D19.2', 'RP11-661A12.12', 'RP11-846C15.2', 'RP11-97F8.1', 'RP13-631K18.2', 'RP3-406P24.4', 'RP4-581O6.1', 'RP5-998G20.1', 'RPL35AP', 'XXyac-YR12DB5.1', 'YBX1P9']].astype(float)\n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.Target[i]=='NR': # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      else:\n",
        "          Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, random_state=125)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  # building the input vector from the 20x20 pixels\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 20 , 20)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 20, 20)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # Create model\n",
        "  model = ConvNet(config)\n",
        "\n",
        "  # Compile model with losses and metrics\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', f1_m,precision_m, recall_m\n",
        "                           ])\n",
        "\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      epochs=1,\n",
        "                      validation_data=(X_test, yTest),\n",
        "                      )\n",
        "\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search space\n"
      ],
      "metadata": {
        "id": "kWGKevOoy1JC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ElCuvsvA5SIn"
      },
      "outputs": [],
      "source": [
        "from hyperopt import hp\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "\n",
        "search_space = {\"lr\": hp.choice(\"lr\", [0.0001, 0.001, 0.01, 0.1]),\n",
        "                    \"batch_size\": hp.choice(\"batch_size\", [8, 16, 32, 64]), \n",
        "                    \"dropout_rate\": hp.choice(\"dropout_rate\", [0.1, 0.2, 0.3, 0.4, 0.5]),\n",
        "                    \"conv_block1_filters\":hp.choice(\"conv_block1_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block2_filters\":hp.choice(\"conv_block2_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block3_filters\":hp.choice(\"conv_block3_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block4_filters\":hp.choice(\"conv_block4_filters\", [32, 64, 128, 256, 512]),\n",
        "                    \"conv_block5_filters\":hp.choice(\"conv_block5_filters\", [32, 64, 128, 256]),\n",
        "                    \"fc_layer_type\": hp.choice(\"fc_layer_type\", ['dense', 'convolution']),\n",
        "                    \"pool_type\": hp.choice(\"pool_type\", ['max', 'average']),\n",
        "                    \"fc1_units\":hp.choice(\"fc1_units\", [32, 64, 128, 256, 512])\n",
        "  }\n",
        "\n",
        "intial_best_config = [{\"lr\": 0.1,\n",
        "                            \"batch_size\": 8, \n",
        "                            \"dropout_rate\": 0.1,\n",
        "                            \"conv_block1_filters\": 32,\n",
        "                            \"conv_block2_filters\": 32,\n",
        "                            \"conv_block3_filters\": 32,\n",
        "                            \"conv_block4_filters\": 32,\n",
        "                            \"conv_block5_filters\": 32,\n",
        "                            \"fc_layer_type\": 'dense',\n",
        "                            \"pool_type\": 'max',\n",
        "                            \"fc1_units\": 32}]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Optimization"
      ],
      "metadata": {
        "id": "8QP5Zl8izRcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gN4lI32z5VOp"
      },
      "outputs": [],
      "source": [
        "scheduler = AsyncHyperBandScheduler(time_attr='training_iteration',\n",
        "                                            metric=\"val_accuracy\",\n",
        "                                            mode=\"max\",\n",
        "                                            grace_period=10)\n",
        "hyperopt_search = HyperOptSearch(search_space, metric=\"val_accuracy\", mode=\"max\", points_to_evaluate=intial_best_config)\n",
        "search_alg = ConcurrencyLimiter(hyperopt_search, max_concurrent=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6zeXsJFj5Wql",
        "outputId": "732657c2-3db5-435f-da8d-7ee29dcdf6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:00:56,189\tWARNING function_runner.py:599 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
            "2022-05-22 09:00:56,219\tINFO logger.py:618 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2022-05-22 09:00:56,222\tWARNING callback.py:126 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
            "2022-05-22 09:00:56,376\tINFO trial_runner.py:803 -- starting train_mnist_b0ed70e4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:00:59 (running for 00:00:03.65)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>RUNNING </td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:04 (running for 00:00:08.65)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>RUNNING </td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:09 (running for 00:00:13.66)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>RUNNING </td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m 2022-05-22 09:01:11.320667: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            3104      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            3104      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            2080      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  global_max_pooling1d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  dense (Dense)               (None, 32)                1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  dropout (Dropout)           (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization_5 (Batc  (None, 32)               128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  activation_5 (Activation)   (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  dense_1 (Dense)             (None, 2)                 66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Total params: 13,197\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Trainable params: 12,809\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Non-trainable params: 388\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f31358ac050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f31358ac050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f31358b4830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f31358b4830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f30ce7def80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f30ce7def80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:14 (running for 00:00:18.67)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>RUNNING </td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:19 (running for 00:00:23.68)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>RUNNING </td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:24 (running for 00:00:28.68)<br>Memory usage on this node: 3.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 1/50 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>RUNNING </td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=577)\u001b[0m \r1/5 [=====>........................] - ETA: 58s - loss: 0.9255 - accuracy: 0.3750 - f1_m: 0.3333 - precision_m: 0.3333 - recall_m: 0.3333\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7649 - accuracy: 0.4583 - f1_m: 0.4474 - precision_m: 0.4855 - recall_m: 0.4432 \n",
            "Result for train_mnist_b0ed70e4:\n",
            "  accuracy: 0.4583333432674408\n",
            "  date: 2022-05-22_09-01-27\n",
            "  done: false\n",
            "  experiment_id: 1d7c4195f20b41e18e38f806bf2812ab\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7648990750312805\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 577\n",
            "  time_since_restore: 27.42066764831543\n",
            "  time_this_iter_s: 27.42066764831543\n",
            "  time_total_s: 27.42066764831543\n",
            "  timestamp: 1653210087\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b0ed70e4\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 441.3279724121094\n",
            "  warmup_time: 0.005377769470214844\n",
            "  \n",
            "Result for train_mnist_b0ed70e4:\n",
            "  accuracy: 0.4583333432674408\n",
            "  date: 2022-05-22_09-01-27\n",
            "  done: true\n",
            "  experiment_id: 1d7c4195f20b41e18e38f806bf2812ab\n",
            "  experiment_tag: 1_batch_size=8,conv_block1_filters=32,conv_block2_filters=32,conv_block3_filters=32,conv_block4_filters=32,conv_block5_filters=32,dropout_rate=0.1,fc1_units=32,fc_layer_type=dense,lr=0.1,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7648990750312805\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 577\n",
            "  time_since_restore: 27.42066764831543\n",
            "  time_this_iter_s: 27.42066764831543\n",
            "  time_total_s: 27.42066764831543\n",
            "  timestamp: 1653210087\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b0ed70e4\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 441.3279724121094\n",
            "  warmup_time: 0.005377769470214844\n",
            "  \n",
            "5/5 [==============================] - 15s 181ms/step - loss: 0.7649 - accuracy: 0.4583 - f1_m: 0.4474 - precision_m: 0.4855 - recall_m: 0.4432 - val_loss: 441.3280 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:01:27,557\tINFO trial_runner.py:803 -- starting train_mnist_c36f447c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:32 (running for 00:00:36.35)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c36f447c</td><td>RUNNING   </td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\"> 0.1</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">   441.328</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:37 (running for 00:00:41.37)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c36f447c</td><td>RUNNING   </td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\"> 0.1</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">   441.328</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m 2022-05-22 09:01:38.719920: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d (Conv1D)             (None, 18, 256)           15616     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization (BatchN  (None, 18, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  activation (Activation)     (None, 18, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            32832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Total params: 341,197\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Trainable params: 338,761\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Non-trainable params: 2,436\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f0803140050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f0803140050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f0803148830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f0803148830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f079c073f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f079c073f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=660)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:42 (running for 00:00:46.38)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 2/50 (1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c36f447c</td><td>RUNNING   </td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\"> 0.1</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\"> 0.1</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">   441.328</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7700 - accuracy: 0.2500 - f1_m: 0.2500 - precision_m: 0.2667 - recall_m: 0.2353\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7180 - accuracy: 0.5417 - f1_m: 0.5776 - precision_m: 0.5582 - recall_m: 0.6605 \n",
            "Result for train_mnist_c36f447c:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-01-44\n",
            "  done: false\n",
            "  experiment_id: bfc3bff496d44118be5f8100575cb0b0\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7179723381996155\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 660\n",
            "  time_since_restore: 13.81654405593872\n",
            "  time_this_iter_s: 13.81654405593872\n",
            "  time_total_s: 13.81654405593872\n",
            "  timestamp: 1653210104\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c36f447c\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 25683.099609375\n",
            "  warmup_time: 0.0030400753021240234\n",
            "  \n",
            "Result for train_mnist_c36f447c:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-01-44\n",
            "  done: true\n",
            "  experiment_id: bfc3bff496d44118be5f8100575cb0b0\n",
            "  experiment_tag: 2_batch_size=64,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=64,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.1,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7179723381996155\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 660\n",
            "  time_since_restore: 13.81654405593872\n",
            "  time_this_iter_s: 13.81654405593872\n",
            "  time_total_s: 13.81654405593872\n",
            "  timestamp: 1653210104\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c36f447c\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 25683.099609375\n",
            "  warmup_time: 0.0030400753021240234\n",
            "  \n",
            "5/5 [==============================] - 6s 174ms/step - loss: 0.7180 - accuracy: 0.5417 - f1_m: 0.5776 - precision_m: 0.5582 - recall_m: 0.6605 - val_loss: 25683.0996 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:01:45,559\tINFO trial_runner.py:803 -- starting train_mnist_cde06864\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:50 (running for 00:00:54.35)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_cde06864</td><td>RUNNING   </td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">   441.328</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\"> 25683.1  </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:01:55 (running for 00:00:59.37)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_cde06864</td><td>RUNNING   </td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">   441.328</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\"> 25683.1  </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m 2022-05-22 09:01:58.212616: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            12320     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            6208      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  global_average_pooling1d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  dense (Dense)               (None, 128)               8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Total params: 61,869\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Trainable params: 60,777\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Non-trainable params: 1,092\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fbb89cd2050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fbb89cd2050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fbb89cda830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fbb89cda830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fbb22c05f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fbb22c05f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=733)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:00 (running for 00:01:04.38)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 3/50 (1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_cde06864</td><td>RUNNING   </td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">   441.328</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\"> 25683.1  </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.9927 - accuracy: 0.5938 - f1_m: 0.6286 - precision_m: 0.6875 - recall_m: 0.5789\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.5347 - f1_m: 0.5539 - precision_m: 0.5675 - recall_m: 0.5877 \n",
            "Result for train_mnist_cde06864:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-02-04\n",
            "  done: false\n",
            "  experiment_id: 8bed99c60ecb4f1eb264d0b419fee8c9\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8454043865203857\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 733\n",
            "  time_since_restore: 14.084097862243652\n",
            "  time_this_iter_s: 14.084097862243652\n",
            "  time_total_s: 14.084097862243652\n",
            "  timestamp: 1653210124\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: cde06864\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 1.8596055507659912\n",
            "  warmup_time: 0.003089427947998047\n",
            "  \n",
            "Result for train_mnist_cde06864:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-02-04\n",
            "  done: true\n",
            "  experiment_id: 8bed99c60ecb4f1eb264d0b419fee8c9\n",
            "  experiment_tag: 3_batch_size=32,conv_block1_filters=128,conv_block2_filters=32,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=64,dropout_rate=0.1,fc1_units=128,fc_layer_type=dense,lr=0.01,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8454043865203857\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 733\n",
            "  time_since_restore: 14.084097862243652\n",
            "  time_this_iter_s: 14.084097862243652\n",
            "  time_total_s: 14.084097862243652\n",
            "  timestamp: 1653210124\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: cde06864\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 1.8596055507659912\n",
            "  warmup_time: 0.003089427947998047\n",
            "  \n",
            "5/5 [==============================] - 6s 199ms/step - loss: 0.8454 - accuracy: 0.5347 - f1_m: 0.5539 - precision_m: 0.5675 - recall_m: 0.5877 - val_loss: 1.8596 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:02:04,560\tINFO trial_runner.py:803 -- starting train_mnist_d96f7256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:09 (running for 00:01:13.35)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 4/50 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d96f7256</td><td>RUNNING   </td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328  </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1    </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:14 (running for 00:01:18.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 4/50 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d96f7256</td><td>RUNNING   </td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328  </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1    </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m 2022-05-22 09:02:15.862822: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            49184     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           12416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            16416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  global_max_pooling1d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  dense (Dense)               (None, 256)               8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Total params: 255,693\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Trainable params: 252,745\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Non-trainable params: 2,948\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fef2fd41050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fef2fd41050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fef2fd49830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fef2fd49830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7feec8c73f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7feec8c73f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=808)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:19 (running for 00:01:23.39)<br>Memory usage on this node: 2.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 4/50 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">  lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d96f7256</td><td>RUNNING   </td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328  </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1    </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.7394 - accuracy: 0.5000 - f1_m: 0.4286 - precision_m: 0.5000 - recall_m: 0.3750\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.5347 - f1_m: 0.6370 - precision_m: 0.5608 - recall_m: 0.8228 \n",
            "Result for train_mnist_d96f7256:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-02-21\n",
            "  done: false\n",
            "  experiment_id: 81a6a07b7fb047cba35e6fa545ae8b61\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.772037923336029\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 808\n",
            "  time_since_restore: 13.853663682937622\n",
            "  time_this_iter_s: 13.853663682937622\n",
            "  time_total_s: 13.853663682937622\n",
            "  timestamp: 1653210141\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d96f7256\n",
            "  val_accuracy: 0.5135135054588318\n",
            "  val_loss: 2.2136356830596924\n",
            "  warmup_time: 0.0031969547271728516\n",
            "  \n",
            "Result for train_mnist_d96f7256:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-02-21\n",
            "  done: true\n",
            "  experiment_id: 81a6a07b7fb047cba35e6fa545ae8b61\n",
            "  experiment_tag: 4_batch_size=64,conv_block1_filters=512,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=32,dropout_rate=0.4,fc1_units=256,fc_layer_type=dense,lr=0.1,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.772037923336029\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 808\n",
            "  time_since_restore: 13.853663682937622\n",
            "  time_this_iter_s: 13.853663682937622\n",
            "  time_total_s: 13.853663682937622\n",
            "  timestamp: 1653210141\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d96f7256\n",
            "  val_accuracy: 0.5135135054588318\n",
            "  val_loss: 2.2136356830596924\n",
            "  warmup_time: 0.0031969547271728516\n",
            "  \n",
            "5/5 [==============================] - 6s 190ms/step - loss: 0.7720 - accuracy: 0.5347 - f1_m: 0.6370 - precision_m: 0.5608 - recall_m: 0.8228 - val_loss: 2.2136 - val_accuracy: 0.5135 - val_f1_m: 0.2000 - val_precision_m: 0.2273 - val_recall_m: 0.1786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:02:22,564\tINFO trial_runner.py:803 -- starting train_mnist_e3eeca74\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:27 (running for 00:01:31.35)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>RUNNING   </td><td>172.28.0.2:878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328  </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1    </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:32 (running for 00:01:36.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>RUNNING   </td><td>172.28.0.2:878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328  </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1    </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m 2022-05-22 09:02:34.002457: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 64)            6208      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  activation_1 (Activation)   (None, 16, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 256)           49408     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  activation_2 (Activation)   (None, 14, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           262656    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  global_max_pooling1d (Globa  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  dense (Dense)               (None, 32)                4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  dropout (Dropout)           (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization_5 (Batc  (None, 32)               128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  activation_5 (Activation)   (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  dense_1 (Dense)             (None, 2)                 66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Total params: 394,189\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Trainable params: 392,137\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Non-trainable params: 2,052\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f9240874050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f9240874050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f924087c830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f924087c830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f91d97a7f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f91d97a7f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=878)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:37 (running for 00:01:41.39)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 5/50 (1 RUNNING, 4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">   lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>RUNNING   </td><td>172.28.0.2:878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328  </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1    </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.7130 - accuracy: 0.5938 - f1_m: 0.6486 - precision_m: 0.7500 - recall_m: 0.5714\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.5556 - f1_m: 0.5711 - precision_m: 0.6021 - recall_m: 0.5504 \n",
            "Result for train_mnist_e3eeca74:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-02-39\n",
            "  done: false\n",
            "  experiment_id: a20e200c952141c781561d5f1936bec3\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7339248657226562\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 878\n",
            "  time_since_restore: 13.883643627166748\n",
            "  time_this_iter_s: 13.883643627166748\n",
            "  time_total_s: 13.883643627166748\n",
            "  timestamp: 1653210159\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e3eeca74\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6945669054985046\n",
            "  warmup_time: 0.0032842159271240234\n",
            "  \n",
            "Result for train_mnist_e3eeca74:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-02-39\n",
            "  done: true\n",
            "  experiment_id: a20e200c952141c781561d5f1936bec3\n",
            "  experiment_tag: 5_batch_size=64,conv_block1_filters=32,conv_block2_filters=64,conv_block3_filters=256,conv_block4_filters=512,conv_block5_filters=128,dropout_rate=0.3,fc1_units=32,fc_layer_type=dense,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7339248657226562\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 878\n",
            "  time_since_restore: 13.883643627166748\n",
            "  time_this_iter_s: 13.883643627166748\n",
            "  time_total_s: 13.883643627166748\n",
            "  timestamp: 1653210159\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e3eeca74\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6945669054985046\n",
            "  warmup_time: 0.0032842159271240234\n",
            "  \n",
            "5/5 [==============================] - 6s 193ms/step - loss: 0.7339 - accuracy: 0.5556 - f1_m: 0.5711 - precision_m: 0.6021 - recall_m: 0.5504 - val_loss: 0.6946 - val_accuracy: 0.5676 - val_f1_m: 0.5243 - val_precision_m: 0.5109 - val_recall_m: 0.5952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:02:40,566\tINFO trial_runner.py:803 -- starting train_mnist_eeb5b9f4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:45 (running for 00:01:49.36)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>RUNNING   </td><td>172.28.0.2:948</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:50 (running for 00:01:54.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>RUNNING   </td><td>172.28.0.2:948</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m 2022-05-22 09:02:52.059007: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           98816     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            98368     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 32)            4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  dropout (Dropout)           (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  activation_5 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Total params: 225,325\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Trainable params: 223,593\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Non-trainable params: 1,732\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f00000b4050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f00000b4050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f00000bc830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f00000bc830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7eff98fe6f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7eff98fe6f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=948)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:02:55 (running for 00:01:59.40)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 6/50 (1 RUNNING, 5 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>RUNNING   </td><td>172.28.0.2:948</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.6960 - accuracy: 0.5312 - f1_m: 0.5161 - precision_m: 0.5714 - recall_m: 0.4706\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6851 - accuracy: 0.5833 - f1_m: 0.5692 - precision_m: 0.6419 - recall_m: 0.5163 \n",
            "5/5 [==============================] - 6s 195ms/step - loss: 0.6851 - accuracy: 0.5833 - f1_m: 0.5692 - precision_m: 0.6419 - recall_m: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n",
            "Result for train_mnist_eeb5b9f4:\n",
            "  accuracy: 0.5833333134651184\n",
            "  date: 2022-05-22_09-03-00\n",
            "  done: false\n",
            "  experiment_id: 2494158a4b7e492fa6ff7d3f3d0e2a0a\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6850716471672058\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 948\n",
            "  time_since_restore: 16.20864510536194\n",
            "  time_this_iter_s: 16.20864510536194\n",
            "  time_total_s: 16.20864510536194\n",
            "  timestamp: 1653210180\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: eeb5b9f4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6930848956108093\n",
            "  warmup_time: 0.003343820571899414\n",
            "  \n",
            "Result for train_mnist_eeb5b9f4:\n",
            "  accuracy: 0.5833333134651184\n",
            "  date: 2022-05-22_09-03-00\n",
            "  done: true\n",
            "  experiment_id: 2494158a4b7e492fa6ff7d3f3d0e2a0a\n",
            "  experiment_tag: 6_batch_size=64,conv_block1_filters=64,conv_block2_filters=512,conv_block3_filters=64,conv_block4_filters=64,conv_block5_filters=128,dropout_rate=0.3,fc1_units=32,fc_layer_type=convolution,lr=0.0001,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6850716471672058\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 948\n",
            "  time_since_restore: 16.20864510536194\n",
            "  time_this_iter_s: 16.20864510536194\n",
            "  time_total_s: 16.20864510536194\n",
            "  timestamp: 1653210180\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: eeb5b9f4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6930848956108093\n",
            "  warmup_time: 0.003343820571899414\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:03:00,567\tINFO trial_runner.py:803 -- starting train_mnist_facf12e4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:05 (running for 00:02:09.35)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_facf12e4</td><td>RUNNING   </td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:10 (running for 00:02:14.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_facf12e4</td><td>RUNNING   </td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m 2022-05-22 09:03:11.881337: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 256)           393472    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  activation_1 (Activation)   (None, 16, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           393728    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           131200    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 512)           16896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  dropout (Dropout)           (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  activation_5 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Total params: 979,501\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Trainable params: 975,593\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Non-trainable params: 3,908\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7ff4bbf5d050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7ff4bbf5d050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7ff4bbf65830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7ff4bbf65830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7ff454e8ff80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7ff454e8ff80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1022)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:15 (running for 00:02:19.39)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 7/50 (1 RUNNING, 6 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_facf12e4</td><td>RUNNING   </td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.6757 - accuracy: 0.4375 - f1_m: 0.4706 - precision_m: 0.6154 - recall_m: 0.3810\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.5486 - f1_m: 0.5792 - precision_m: 0.6008 - recall_m: 0.5841 \n",
            "Result for train_mnist_facf12e4:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-03-18\n",
            "  done: false\n",
            "  experiment_id: 3319015b79cd43f780a172179e836e70\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6844730377197266\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 14.103808641433716\n",
            "  time_this_iter_s: 14.103808641433716\n",
            "  time_total_s: 14.103808641433716\n",
            "  timestamp: 1653210198\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: facf12e4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6911097168922424\n",
            "  warmup_time: 0.0029714107513427734\n",
            "  \n",
            "Result for train_mnist_facf12e4:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-03-18\n",
            "  done: true\n",
            "  experiment_id: 3319015b79cd43f780a172179e836e70\n",
            "  experiment_tag: 7_batch_size=8,conv_block1_filters=512,conv_block2_filters=256,conv_block3_filters=512,conv_block4_filters=128,conv_block5_filters=32,dropout_rate=0.4,fc1_units=512,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6844730377197266\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 14.103808641433716\n",
            "  time_this_iter_s: 14.103808641433716\n",
            "  time_total_s: 14.103808641433716\n",
            "  timestamp: 1653210198\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: facf12e4\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6911097168922424\n",
            "  warmup_time: 0.0029714107513427734\n",
            "  \n",
            "5/5 [==============================] - 6s 189ms/step - loss: 0.6845 - accuracy: 0.5486 - f1_m: 0.5792 - precision_m: 0.6008 - recall_m: 0.5841 - val_loss: 0.6911 - val_accuracy: 0.4595 - val_f1_m: 0.0952 - val_precision_m: 0.1429 - val_recall_m: 0.0714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:03:18,568\tINFO trial_runner.py:803 -- starting train_mnist_057c5cba\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:23 (running for 00:02:27.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_057c5cba</td><td>RUNNING   </td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:28 (running for 00:02:32.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_057c5cba</td><td>RUNNING   </td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m 2022-05-22 09:03:30.158381: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Total params: 381,453\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Trainable params: 378,889\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f49142a4050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f49142a4050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f49142ac830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f49142ac830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f48ad1d7f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f48ad1d7f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1094)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:33 (running for 00:02:37.40)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 8/50 (1 RUNNING, 7 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_057c5cba</td><td>RUNNING   </td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.8181 - accuracy: 0.4062 - f1_m: 0.3871 - precision_m: 0.5455 - recall_m: 0.3000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7766 - accuracy: 0.5208 - f1_m: 0.5209 - precision_m: 0.5841 - recall_m: 0.4791 \n",
            "Result for train_mnist_057c5cba:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-03-36\n",
            "  done: false\n",
            "  experiment_id: 5b4166af141c4c85a022a705224c827d\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.776576578617096\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1094\n",
            "  time_since_restore: 14.240880727767944\n",
            "  time_this_iter_s: 14.240880727767944\n",
            "  time_total_s: 14.240880727767944\n",
            "  timestamp: 1653210216\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 057c5cba\n",
            "  val_accuracy: 0.6756756901741028\n",
            "  val_loss: 0.6862649917602539\n",
            "  warmup_time: 0.003228425979614258\n",
            "  \n",
            "Result for train_mnist_057c5cba:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-03-36\n",
            "  done: true\n",
            "  experiment_id: 5b4166af141c4c85a022a705224c827d\n",
            "  experiment_tag: 8_batch_size=16,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.776576578617096\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1094\n",
            "  time_since_restore: 14.240880727767944\n",
            "  time_this_iter_s: 14.240880727767944\n",
            "  time_total_s: 14.240880727767944\n",
            "  timestamp: 1653210216\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 057c5cba\n",
            "  val_accuracy: 0.6756756901741028\n",
            "  val_loss: 0.6862649917602539\n",
            "  warmup_time: 0.003228425979614258\n",
            "  \n",
            "5/5 [==============================] - 6s 194ms/step - loss: 0.7766 - accuracy: 0.5208 - f1_m: 0.5209 - precision_m: 0.5841 - recall_m: 0.4791 - val_loss: 0.6863 - val_accuracy: 0.6757 - val_f1_m: 0.5548 - val_precision_m: 0.5735 - val_recall_m: 0.5595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:03:36,571\tINFO trial_runner.py:803 -- starting train_mnist_105b4a06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:41 (running for 00:02:45.36)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_105b4a06</td><td>RUNNING   </td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:46 (running for 00:02:50.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_105b4a06</td><td>RUNNING   </td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m 2022-05-22 09:03:47.935884: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           197120    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           786944    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 256)           262400    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  activation_3 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  global_average_pooling1d (G  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  dense (Dense)               (None, 256)               8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Total params: 1,278,253\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Trainable params: 1,274,857\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Non-trainable params: 3,396\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fdbaac33050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fdbaac33050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fdbaac3b830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fdbaac3b830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fdb43b66f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fdb43b66f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1167)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:51 (running for 00:02:55.40)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 9/50 (1 RUNNING, 8 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_105b4a06</td><td>RUNNING   </td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7369 - accuracy: 0.5000 - f1_m: 0.5294 - precision_m: 0.7500 - recall_m: 0.4091\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8075 - accuracy: 0.4792 - f1_m: 0.5250 - precision_m: 0.5369 - recall_m: 0.5626 \n",
            "Result for train_mnist_105b4a06:\n",
            "  accuracy: 0.4791666567325592\n",
            "  date: 2022-05-22_09-03-54\n",
            "  done: false\n",
            "  experiment_id: bef1cf361cc742c9800797cd1164a692\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8074622750282288\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1167\n",
            "  time_since_restore: 14.145120620727539\n",
            "  time_this_iter_s: 14.145120620727539\n",
            "  time_total_s: 14.145120620727539\n",
            "  timestamp: 1653210234\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 105b4a06\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 16.026792526245117\n",
            "  warmup_time: 0.0032014846801757812\n",
            "  \n",
            "Result for train_mnist_105b4a06:\n",
            "  accuracy: 0.4791666567325592\n",
            "  date: 2022-05-22_09-03-54\n",
            "  done: true\n",
            "  experiment_id: bef1cf361cc742c9800797cd1164a692\n",
            "  experiment_tag: 9_batch_size=16,conv_block1_filters=128,conv_block2_filters=512,conv_block3_filters=512,conv_block4_filters=256,conv_block5_filters=32,dropout_rate=0.3,fc1_units=256,fc_layer_type=dense,lr=0.01,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8074622750282288\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1167\n",
            "  time_since_restore: 14.145120620727539\n",
            "  time_this_iter_s: 14.145120620727539\n",
            "  time_total_s: 14.145120620727539\n",
            "  timestamp: 1653210234\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 105b4a06\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 16.026792526245117\n",
            "  warmup_time: 0.0032014846801757812\n",
            "  \n",
            "5/5 [==============================] - 6s 211ms/step - loss: 0.8075 - accuracy: 0.4792 - f1_m: 0.5250 - precision_m: 0.5369 - recall_m: 0.5626 - val_loss: 16.0268 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:03:54,572\tINFO trial_runner.py:803 -- starting train_mnist_1af5ee4e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:03:59 (running for 00:03:03.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>RUNNING   </td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:04 (running for 00:03:08.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>RUNNING   </td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m 2022-05-22 09:04:06.053165: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d (Conv1D)             (None, 18, 256)           15616     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization (BatchN  (None, 18, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  activation (Activation)     (None, 18, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 256)           98560     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  activation_2 (Activation)   (None, 14, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            32832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 32)            8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  dropout (Dropout)           (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  activation_5 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Total params: 274,349\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Trainable params: 272,361\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Non-trainable params: 1,988\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fe159f55050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fe159f55050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fe159f5d830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fe159f5d830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fe0f2e88f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fe0f2e88f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1236)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:09 (running for 00:03:13.41)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 10/50 (1 RUNNING, 9 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>RUNNING   </td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.0911 - accuracy: 0.3750 - f1_m: 0.2857 - precision_m: 0.5714 - recall_m: 0.1905\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9857 - accuracy: 0.4722 - f1_m: 0.4826 - precision_m: 0.5146 - recall_m: 0.5081 \n",
            "5/5 [==============================] - 6s 191ms/step - loss: 0.9857 - accuracy: 0.4722 - f1_m: 0.4826 - precision_m: 0.5146 - recall_m: 0.5081 - val_loss: 0.6749 - val_accuracy: 0.5405 - val_f1_m: 0.1111 - val_precision_m: 0.2500 - val_recall_m: 0.0714\n",
            "Result for train_mnist_1af5ee4e:\n",
            "  accuracy: 0.4722222089767456\n",
            "  date: 2022-05-22_09-04-14\n",
            "  done: false\n",
            "  experiment_id: f479d189fe4c43d597bf4961ebc1eb36\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.985682487487793\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1236\n",
            "  time_since_restore: 16.17590308189392\n",
            "  time_this_iter_s: 16.17590308189392\n",
            "  time_total_s: 16.17590308189392\n",
            "  timestamp: 1653210254\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1af5ee4e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6749324202537537\n",
            "  warmup_time: 0.0035369396209716797\n",
            "  \n",
            "Result for train_mnist_1af5ee4e:\n",
            "  accuracy: 0.4722222089767456\n",
            "  date: 2022-05-22_09-04-14\n",
            "  done: true\n",
            "  experiment_id: f479d189fe4c43d597bf4961ebc1eb36\n",
            "  experiment_tag: 10_batch_size=8,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=256,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.5,fc1_units=32,fc_layer_type=convolution,lr=0.01,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.985682487487793\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1236\n",
            "  time_since_restore: 16.17590308189392\n",
            "  time_this_iter_s: 16.17590308189392\n",
            "  time_total_s: 16.17590308189392\n",
            "  timestamp: 1653210254\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1af5ee4e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6749324202537537\n",
            "  warmup_time: 0.0035369396209716797\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:04:14,574\tINFO trial_runner.py:803 -- starting train_mnist_26f48228\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:19 (running for 00:03:23.36)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 11/50 (1 RUNNING, 10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_26f48228</td><td>RUNNING   </td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:24 (running for 00:03:28.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 11/50 (1 RUNNING, 10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_26f48228</td><td>RUNNING   </td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m 2022-05-22 09:04:26.127230: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           786944    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            49184     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            2080      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            2112      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 32)            2080      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  dropout (Dropout)           (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  activation_5 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Total params: 878,445\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Trainable params: 876,073\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Non-trainable params: 2,372\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fa4d3723050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fa4d3723050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fa4d372b830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fa4d372b830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fa46c657f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fa46c657f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1309)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:29 (running for 00:03:33.42)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 11/50 (1 RUNNING, 10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_26f48228</td><td>RUNNING   </td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 0.7075 - accuracy: 0.5000 - f1_m: 0.6190 - precision_m: 0.6500 - recall_m: 0.5909\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.5417 - f1_m: 0.5643 - precision_m: 0.5853 - recall_m: 0.5792 \n",
            "5/5 [==============================] - 6s 205ms/step - loss: 0.6837 - accuracy: 0.5417 - f1_m: 0.5643 - precision_m: 0.5853 - recall_m: 0.5792 - val_loss: 0.6941 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n",
            "Result for train_mnist_26f48228:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-04-34\n",
            "  done: false\n",
            "  experiment_id: 7854873b065f467db50fc2d18b5821ba\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6837465763092041\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1309\n",
            "  time_since_restore: 16.181849241256714\n",
            "  time_this_iter_s: 16.181849241256714\n",
            "  time_total_s: 16.181849241256714\n",
            "  timestamp: 1653210274\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 26f48228\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6940946578979492\n",
            "  warmup_time: 0.0032188892364501953\n",
            "  \n",
            "Result for train_mnist_26f48228:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-04-34\n",
            "  done: true\n",
            "  experiment_id: 7854873b065f467db50fc2d18b5821ba\n",
            "  experiment_tag: 11_batch_size=16,conv_block1_filters=512,conv_block2_filters=512,conv_block3_filters=32,conv_block4_filters=32,conv_block5_filters=64,dropout_rate=0.1,fc1_units=32,fc_layer_type=convolution,lr=0.001,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6837465763092041\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1309\n",
            "  time_since_restore: 16.181849241256714\n",
            "  time_this_iter_s: 16.181849241256714\n",
            "  time_total_s: 16.181849241256714\n",
            "  timestamp: 1653210274\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 26f48228\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6940946578979492\n",
            "  warmup_time: 0.0032188892364501953\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:04:34,575\tINFO trial_runner.py:803 -- starting train_mnist_32d62b46\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:39 (running for 00:03:43.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 12/50 (1 RUNNING, 11 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_32d62b46</td><td>RUNNING   </td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:44 (running for 00:03:48.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 12/50 (1 RUNNING, 11 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_32d62b46</td><td>RUNNING   </td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m 2022-05-22 09:04:46.273551: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           49664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           786944    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           524800    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            32832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Total params: 1,407,277\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Trainable params: 1,403,881\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Non-trainable params: 3,396\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f8eea627050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f8eea627050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f8eea62f830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f8eea62f830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f8e8355af80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f8e8355af80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1378)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:49 (running for 00:03:53.43)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 12/50 (1 RUNNING, 11 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_32d62b46</td><td>RUNNING   </td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 0.8374 - accuracy: 0.4062 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7641 - accuracy: 0.5347 - f1_m: 0.3485 - precision_m: 0.6600 - recall_m: 0.2386             \n",
            "5/5 [==============================] - 6s 205ms/step - loss: 0.7641 - accuracy: 0.5347 - f1_m: 0.3485 - precision_m: 0.6600 - recall_m: 0.2386 - val_loss: 0.6718 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_32d62b46:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-04-54\n",
            "  done: false\n",
            "  experiment_id: 03c91f812e1f4d9abcb8631a9bad02e0\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7640697956085205\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1378\n",
            "  time_since_restore: 16.231326818466187\n",
            "  time_this_iter_s: 16.231326818466187\n",
            "  time_total_s: 16.231326818466187\n",
            "  timestamp: 1653210294\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 32d62b46\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6717743277549744\n",
            "  warmup_time: 0.0033342838287353516\n",
            "  \n",
            "Result for train_mnist_32d62b46:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-04-54\n",
            "  done: true\n",
            "  experiment_id: 03c91f812e1f4d9abcb8631a9bad02e0\n",
            "  experiment_tag: 12_batch_size=16,conv_block1_filters=32,conv_block2_filters=512,conv_block3_filters=512,conv_block4_filters=512,conv_block5_filters=64,dropout_rate=0.2,fc1_units=64,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7640697956085205\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1378\n",
            "  time_since_restore: 16.231326818466187\n",
            "  time_this_iter_s: 16.231326818466187\n",
            "  time_total_s: 16.231326818466187\n",
            "  timestamp: 1653210294\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 32d62b46\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6717743277549744\n",
            "  warmup_time: 0.0033342838287353516\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:04:54,577\tINFO trial_runner.py:803 -- starting train_mnist_3edc7f8a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:04:59 (running for 00:04:03.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>RUNNING   </td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:04 (running for 00:04:08.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>RUNNING   </td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m 2022-05-22 09:05:06.073512: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  conv1d (Conv1D)             (None, 18, 256)           15616     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization (BatchN  (None, 18, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  activation (Activation)     (None, 18, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           197120    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            65600     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  global_average_pooling1d (G  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  dense (Dense)               (None, 128)               32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Total params: 431,949\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Trainable params: 429,257\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f9246014050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f9246014050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f924601c830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f924601c830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f91def47f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f91def47f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1451)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:09 (running for 00:04:13.41)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 13/50 (1 RUNNING, 12 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>RUNNING   </td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.7480 - accuracy: 0.5938 - f1_m: 0.6667 - precision_m: 0.6500 - recall_m: 0.6842\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.5556 - f1_m: 0.5647 - precision_m: 0.5693 - recall_m: 0.5818 \n",
            "Result for train_mnist_3edc7f8a:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-05-12\n",
            "  done: false\n",
            "  experiment_id: 8893a515124a4e4bbb9cf1f598d993ae\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8222701549530029\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1451\n",
            "  time_since_restore: 14.033194065093994\n",
            "  time_this_iter_s: 14.033194065093994\n",
            "  time_total_s: 14.033194065093994\n",
            "  timestamp: 1653210312\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 3edc7f8a\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6935874223709106\n",
            "  warmup_time: 0.0033288002014160156\n",
            "  \n",
            "Result for train_mnist_3edc7f8a:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-05-12\n",
            "  done: true\n",
            "  experiment_id: 8893a515124a4e4bbb9cf1f598d993ae\n",
            "  experiment_tag: 13_batch_size=32,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.5,fc1_units=128,fc_layer_type=dense,lr=0.0001,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8222701549530029\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1451\n",
            "  time_since_restore: 14.033194065093994\n",
            "  time_this_iter_s: 14.033194065093994\n",
            "  time_total_s: 14.033194065093994\n",
            "  timestamp: 1653210312\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 3edc7f8a\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6935874223709106\n",
            "  warmup_time: 0.0033288002014160156\n",
            "  \n",
            "5/5 [==============================] - 6s 204ms/step - loss: 0.8223 - accuracy: 0.5556 - f1_m: 0.5647 - precision_m: 0.5693 - recall_m: 0.5818 - val_loss: 0.6936 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:05:12,578\tINFO trial_runner.py:803 -- starting train_mnist_496a691c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:17 (running for 00:04:21.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_496a691c</td><td>RUNNING   </td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:22 (running for 00:04:26.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_496a691c</td><td>RUNNING   </td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m 2022-05-22 09:05:24.274604: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            32832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  global_average_pooling1d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  dense (Dense)               (None, 512)               33280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  dropout (Dropout)           (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization_5 (Batc  (None, 512)              2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  activation_5 (Activation)   (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  dense_1 (Dense)             (None, 2)                 1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Total params: 191,821\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Trainable params: 189,129\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fb860e2f050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fb860e2f050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fb860e37830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fb860e37830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fb7f9d61f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fb7f9d61f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1526)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:27 (running for 00:04:31.42)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 14/50 (1 RUNNING, 13 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_496a691c</td><td>RUNNING   </td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.9959 - accuracy: 0.3125 - f1_m: 0.3889 - precision_m: 0.3684 - recall_m: 0.4118\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7565 - accuracy: 0.5069 - f1_m: 0.5683 - precision_m: 0.5637 - recall_m: 0.6082 \n",
            "5/5 [==============================] - 6s 213ms/step - loss: 0.7565 - accuracy: 0.5069 - f1_m: 0.5683 - precision_m: 0.5637 - recall_m: 0.6082 - val_loss: 3863.8235 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_496a691c:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-22_09-05-32\n",
            "  done: false\n",
            "  experiment_id: 4af81559d32e4318b956b1316c2184cb\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.756511390209198\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1526\n",
            "  time_since_restore: 16.287288188934326\n",
            "  time_this_iter_s: 16.287288188934326\n",
            "  time_total_s: 16.287288188934326\n",
            "  timestamp: 1653210332\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 496a691c\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 3863.823486328125\n",
            "  warmup_time: 0.0031402111053466797\n",
            "  \n",
            "Result for train_mnist_496a691c:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-22_09-05-32\n",
            "  done: true\n",
            "  experiment_id: 4af81559d32e4318b956b1316c2184cb\n",
            "  experiment_tag: 14_batch_size=64,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=512,conv_block5_filters=64,dropout_rate=0.4,fc1_units=512,fc_layer_type=dense,lr=0.1,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.756511390209198\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1526\n",
            "  time_since_restore: 16.287288188934326\n",
            "  time_this_iter_s: 16.287288188934326\n",
            "  time_total_s: 16.287288188934326\n",
            "  timestamp: 1653210332\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 496a691c\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 3863.823486328125\n",
            "  warmup_time: 0.0031402111053466797\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:05:32,579\tINFO trial_runner.py:803 -- starting train_mnist_55717afc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:37 (running for 00:04:41.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_55717afc</td><td>RUNNING   </td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:42 (running for 00:04:46.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_55717afc</td><td>RUNNING   </td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m 2022-05-22 09:05:44.017509: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 256)           49408     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  activation_1 (Activation)   (None, 16, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            24608     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  global_average_pooling1d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  dense (Dense)               (None, 256)               16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Total params: 114,861\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Trainable params: 113,257\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Non-trainable params: 1,604\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f88230ec050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f88230ec050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f88230f4830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f88230f4830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f87bc01ef80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f87bc01ef80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:47 (running for 00:04:51.44)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 15/50 (1 RUNNING, 14 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_55717afc</td><td>RUNNING   </td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1598)\u001b[0m \r1/5 [=====>........................] - ETA: 19s - loss: 0.7383 - accuracy: 0.3750 - f1_m: 0.4118 - precision_m: 0.3684 - recall_m: 0.4667\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.4931 - f1_m: 0.4988 - precision_m: 0.4320 - recall_m: 0.6018 \n",
            "Result for train_mnist_55717afc:\n",
            "  accuracy: 0.4930555522441864\n",
            "  date: 2022-05-22_09-05-49\n",
            "  done: false\n",
            "  experiment_id: 0842ed28d9ca41cfa26129784ae6b099\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6995667219161987\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1598\n",
            "  time_since_restore: 13.790136098861694\n",
            "  time_this_iter_s: 13.790136098861694\n",
            "  time_total_s: 13.790136098861694\n",
            "  timestamp: 1653210349\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 55717afc\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 2993.133544921875\n",
            "  warmup_time: 0.003080129623413086\n",
            "  \n",
            "Result for train_mnist_55717afc:\n",
            "  accuracy: 0.4930555522441864\n",
            "  date: 2022-05-22_09-05-49\n",
            "  done: true\n",
            "  experiment_id: 0842ed28d9ca41cfa26129784ae6b099\n",
            "  experiment_tag: 15_batch_size=32,conv_block1_filters=64,conv_block2_filters=256,conv_block3_filters=32,conv_block4_filters=128,conv_block5_filters=64,dropout_rate=0.2,fc1_units=256,fc_layer_type=dense,lr=0.1,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6995667219161987\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1598\n",
            "  time_since_restore: 13.790136098861694\n",
            "  time_this_iter_s: 13.790136098861694\n",
            "  time_total_s: 13.790136098861694\n",
            "  timestamp: 1653210349\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 55717afc\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 2993.133544921875\n",
            "  warmup_time: 0.003080129623413086\n",
            "  \n",
            "5/5 [==============================] - 6s 189ms/step - loss: 0.6996 - accuracy: 0.4931 - f1_m: 0.4988 - precision_m: 0.4320 - recall_m: 0.6018 - val_loss: 2993.1335 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:05:50,580\tINFO trial_runner.py:803 -- starting train_mnist_5feb42f6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:05:55 (running for 00:04:59.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 16/50 (1 RUNNING, 15 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>RUNNING   </td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:00 (running for 00:05:04.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 16/50 (1 RUNNING, 15 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>RUNNING   </td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m 2022-05-22 09:06:01.922347: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            12320     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            3104      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  global_average_pooling1d (G  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  dense (Dense)               (None, 32)                4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  dropout (Dropout)           (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization_5 (Batc  (None, 32)               128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  activation_5 (Activation)   (None, 32)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  dense_1 (Dense)             (None, 2)                 66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Total params: 41,581\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Trainable params: 40,745\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Non-trainable params: 836\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f67d5fc8050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f67d5fc8050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f67d5fd0830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f67d5fd0830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f676eefaf80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f676eefaf80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:05 (running for 00:05:09.41)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 16/50 (1 RUNNING, 15 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>RUNNING   </td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1671)\u001b[0m \r1/5 [=====>........................] - ETA: 19s - loss: 0.9167 - accuracy: 0.4688 - f1_m: 0.5641 - precision_m: 0.5789 - recall_m: 0.5500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7809 - accuracy: 0.5278 - f1_m: 0.6042 - precision_m: 0.5573 - recall_m: 0.6833 \n",
            "Result for train_mnist_5feb42f6:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-22_09-06-07\n",
            "  done: false\n",
            "  experiment_id: 8f788a452e704da2afccbaaf2b3975fd\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7809460163116455\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1671\n",
            "  time_since_restore: 13.890119552612305\n",
            "  time_this_iter_s: 13.890119552612305\n",
            "  time_total_s: 13.890119552612305\n",
            "  timestamp: 1653210367\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 5feb42f6\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 133.92494201660156\n",
            "  warmup_time: 0.0037262439727783203\n",
            "  \n",
            "Result for train_mnist_5feb42f6:\n",
            "  accuracy: 0.5277777910232544\n",
            "  date: 2022-05-22_09-06-07\n",
            "  done: true\n",
            "  experiment_id: 8f788a452e704da2afccbaaf2b3975fd\n",
            "  experiment_tag: 16_batch_size=64,conv_block1_filters=128,conv_block2_filters=32,conv_block3_filters=32,conv_block4_filters=64,conv_block5_filters=128,dropout_rate=0.3,fc1_units=32,fc_layer_type=dense,lr=0.1,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7809460163116455\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1671\n",
            "  time_since_restore: 13.890119552612305\n",
            "  time_this_iter_s: 13.890119552612305\n",
            "  time_total_s: 13.890119552612305\n",
            "  timestamp: 1653210367\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 5feb42f6\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 133.92494201660156\n",
            "  warmup_time: 0.0037262439727783203\n",
            "  \n",
            "5/5 [==============================] - 6s 206ms/step - loss: 0.7809 - accuracy: 0.5278 - f1_m: 0.6042 - precision_m: 0.5573 - recall_m: 0.6833 - val_loss: 133.9249 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:06:08,582\tINFO trial_runner.py:803 -- starting train_mnist_6aaf0ed4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:13 (running for 00:05:17.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>RUNNING   </td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:18 (running for 00:05:22.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>RUNNING   </td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m 2022-05-22 09:06:20.050825: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 32)            8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  dropout (Dropout)           (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  activation_5 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Total params: 113,773\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Trainable params: 112,425\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Non-trainable params: 1,348\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fc64b23c050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fc64b23c050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fc64b244830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fc64b244830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fc5e416ff80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fc5e416ff80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1743)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:23 (running for 00:05:27.43)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 17/50 (1 RUNNING, 16 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>RUNNING   </td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.7808 - accuracy: 0.4688 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.7990 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "Result for train_mnist_6aaf0ed4:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-06-26\n",
            "  done: false\n",
            "  experiment_id: 2d0d52443fa943be9b1fa6b67f51fc61\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.7990292310714722\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1743\n",
            "  time_since_restore: 14.089089155197144\n",
            "  time_this_iter_s: 14.089089155197144\n",
            "  time_total_s: 14.089089155197144\n",
            "  timestamp: 1653210386\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 6aaf0ed4\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6827585101127625\n",
            "  warmup_time: 0.003379344940185547\n",
            "  \n",
            "Result for train_mnist_6aaf0ed4:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-06-26\n",
            "  done: true\n",
            "  experiment_id: 2d0d52443fa943be9b1fa6b67f51fc61\n",
            "  experiment_tag: 17_batch_size=8,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.3,fc1_units=32,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.7990292310714722\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1743\n",
            "  time_since_restore: 14.089089155197144\n",
            "  time_this_iter_s: 14.089089155197144\n",
            "  time_total_s: 14.089089155197144\n",
            "  timestamp: 1653210386\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 6aaf0ed4\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6827585101127625\n",
            "  warmup_time: 0.003379344940185547\n",
            "  \n",
            "5/5 [==============================] - 6s 178ms/step - loss: 1.7990 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6828 - val_accuracy: 0.5946 - val_f1_m: 0.2381 - val_precision_m: 0.3571 - val_recall_m: 0.1786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:06:26,583\tINFO trial_runner.py:803 -- starting train_mnist_75949288\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:31 (running for 00:05:35.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_75949288</td><td>RUNNING   </td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:36 (running for 00:05:40.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_75949288</td><td>RUNNING   </td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m 2022-05-22 09:06:38.010916: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           12416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            2112      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            4160      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Total params: 51,085\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Trainable params: 50,313\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Non-trainable params: 772\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f5a98c3b050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f5a98c3b050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f5a98c43830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f5a98c43830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f5a31b6ef80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f5a31b6ef80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1814)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:41 (running for 00:05:45.43)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 18/50 (1 RUNNING, 17 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_75949288</td><td>RUNNING   </td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.6948 - accuracy: 0.4688 - f1_m: 0.5143 - precision_m: 0.5625 - recall_m: 0.4737\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5000 - f1_m: 0.5215 - precision_m: 0.5913 - recall_m: 0.5039 \n",
            "Result for train_mnist_75949288:\n",
            "  accuracy: 0.5\n",
            "  date: 2022-05-22_09-06-44\n",
            "  done: false\n",
            "  experiment_id: 3f34a996b6d44489990f6ef55450037c\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6876169443130493\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1814\n",
            "  time_since_restore: 13.952444791793823\n",
            "  time_this_iter_s: 13.952444791793823\n",
            "  time_total_s: 13.952444791793823\n",
            "  timestamp: 1653210404\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: '75949288'\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.7195826768875122\n",
            "  warmup_time: 0.003248929977416992\n",
            "  \n",
            "Result for train_mnist_75949288:\n",
            "  accuracy: 0.5\n",
            "  date: 2022-05-22_09-06-44\n",
            "  done: true\n",
            "  experiment_id: 3f34a996b6d44489990f6ef55450037c\n",
            "  experiment_tag: 18_batch_size=8,conv_block1_filters=32,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=32,conv_block5_filters=64,dropout_rate=0.2,fc1_units=64,fc_layer_type=convolution,lr=0.01,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6876169443130493\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1814\n",
            "  time_since_restore: 13.952444791793823\n",
            "  time_this_iter_s: 13.952444791793823\n",
            "  time_total_s: 13.952444791793823\n",
            "  timestamp: 1653210404\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: '75949288'\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.7195826768875122\n",
            "  warmup_time: 0.003248929977416992\n",
            "  \n",
            "5/5 [==============================] - 6s 176ms/step - loss: 0.6876 - accuracy: 0.5000 - f1_m: 0.5215 - precision_m: 0.5913 - recall_m: 0.5039 - val_loss: 0.7196 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:06:44,584\tINFO trial_runner.py:803 -- starting train_mnist_8034ff48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:49 (running for 00:05:53.37)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8034ff48</td><td>RUNNING   </td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:54 (running for 00:05:58.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8034ff48</td><td>RUNNING   </td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m 2022-05-22 09:06:56.058497: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            6176      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           12416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 32)            1056      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  dropout (Dropout)           (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  activation_5 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Total params: 34,189\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Trainable params: 33,545\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Non-trainable params: 644\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f53131c1050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f53131c1050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f53131c9830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f53131c9830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f52ac0f3f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f52ac0f3f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1882)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:06:59 (running for 00:06:03.44)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 19/50 (1 RUNNING, 18 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8034ff48</td><td>RUNNING   </td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.9421 - accuracy: 0.4688 - f1_m: 0.5405 - precision_m: 0.4545 - recall_m: 0.6667\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9437 - accuracy: 0.5208 - f1_m: 0.6475 - precision_m: 0.5643 - recall_m: 0.7647 \n",
            "5/5 [==============================] - 6s 187ms/step - loss: 0.9437 - accuracy: 0.5208 - f1_m: 0.6475 - precision_m: 0.5643 - recall_m: 0.7647 - val_loss: 0.6926 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_8034ff48:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-07-02\n",
            "  done: false\n",
            "  experiment_id: 31e898433b0e4f2bb45d3af0fa7f6560\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9437099099159241\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1882\n",
            "  time_since_restore: 14.152326583862305\n",
            "  time_this_iter_s: 14.152326583862305\n",
            "  time_total_s: 14.152326583862305\n",
            "  timestamp: 1653210422\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8034ff48\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6926383972167969\n",
            "  warmup_time: 0.0035932064056396484\n",
            "  \n",
            "Result for train_mnist_8034ff48:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-07-02\n",
            "  done: true\n",
            "  experiment_id: 31e898433b0e4f2bb45d3af0fa7f6560\n",
            "  experiment_tag: 19_batch_size=8,conv_block1_filters=64,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=32,conv_block5_filters=32,dropout_rate=0.4,fc1_units=32,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9437099099159241\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1882\n",
            "  time_since_restore: 14.152326583862305\n",
            "  time_this_iter_s: 14.152326583862305\n",
            "  time_total_s: 14.152326583862305\n",
            "  timestamp: 1653210422\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8034ff48\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6926383972167969\n",
            "  warmup_time: 0.0035932064056396484\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:07:02,586\tINFO trial_runner.py:803 -- starting train_mnist_8b0920fc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:07 (running for 00:06:11.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 20/50 (1 RUNNING, 19 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>RUNNING   </td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:12 (running for 00:06:16.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 20/50 (1 RUNNING, 19 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>RUNNING   </td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m 2022-05-22 09:07:14.082270: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 256)           49408     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  activation_1 (Activation)   (None, 16, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            24608     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 256)           16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  activation_3 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Total params: 110,349\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Trainable params: 108,809\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Non-trainable params: 1,540\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f1141863050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f1141863050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f114186b830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f114186b830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f10da796f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f10da796f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1953)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:17 (running for 00:06:21.43)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 20/50 (1 RUNNING, 19 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>RUNNING   </td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7974 - accuracy: 0.5000 - f1_m: 0.4667 - precision_m: 0.4667 - recall_m: 0.4667\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.4861 - f1_m: 0.4494 - precision_m: 0.6227 - recall_m: 0.4964 \n",
            "Result for train_mnist_8b0920fc:\n",
            "  accuracy: 0.4861111044883728\n",
            "  date: 2022-05-22_09-07-20\n",
            "  done: false\n",
            "  experiment_id: 5b17acd85c52442b81ac5acf9ca51a12\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.875612735748291\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1953\n",
            "  time_since_restore: 14.189269542694092\n",
            "  time_this_iter_s: 14.189269542694092\n",
            "  time_total_s: 14.189269542694092\n",
            "  timestamp: 1653210440\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8b0920fc\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 389.1307678222656\n",
            "  warmup_time: 0.003221273422241211\n",
            "  \n",
            "Result for train_mnist_8b0920fc:\n",
            "  accuracy: 0.4861111044883728\n",
            "  date: 2022-05-22_09-07-20\n",
            "  done: true\n",
            "  experiment_id: 5b17acd85c52442b81ac5acf9ca51a12\n",
            "  experiment_tag: 20_batch_size=8,conv_block1_filters=64,conv_block2_filters=256,conv_block3_filters=32,conv_block4_filters=256,conv_block5_filters=32,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.1,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.875612735748291\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1953\n",
            "  time_since_restore: 14.189269542694092\n",
            "  time_this_iter_s: 14.189269542694092\n",
            "  time_total_s: 14.189269542694092\n",
            "  timestamp: 1653210440\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8b0920fc\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 389.1307678222656\n",
            "  warmup_time: 0.003221273422241211\n",
            "  \n",
            "5/5 [==============================] - 6s 196ms/step - loss: 0.8756 - accuracy: 0.4861 - f1_m: 0.4494 - precision_m: 0.6227 - recall_m: 0.4964 - val_loss: 389.1308 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:07:20,586\tINFO trial_runner.py:803 -- starting train_mnist_95ca9ffc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:25 (running for 00:06:29.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 21/50 (1 RUNNING, 20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>RUNNING   </td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 1 more trials not shown (1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:30 (running for 00:06:34.42)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 21/50 (1 RUNNING, 20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>RUNNING   </td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 1 more trials not shown (1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m 2022-05-22 09:07:32.162366: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Total params: 381,453\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Trainable params: 378,889\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f34ffcd5050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f34ffcd5050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f34ffcdd830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f34ffcdd830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f3498c07f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f3498c07f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2021)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:35 (running for 00:06:39.45)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 21/50 (1 RUNNING, 20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>RUNNING   </td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 1 more trials not shown (1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.6682 - accuracy: 0.6562 - f1_m: 0.5217 - precision_m: 0.8571 - recall_m: 0.3750\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7426 - accuracy: 0.5208 - f1_m: 0.4122 - precision_m: 0.6359 - recall_m: 0.3077 \n",
            "Result for train_mnist_95ca9ffc:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-07-38\n",
            "  done: false\n",
            "  experiment_id: b4727d2553be40049caa67693ee2cb83\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7426334023475647\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2021\n",
            "  time_since_restore: 14.29157567024231\n",
            "  time_this_iter_s: 14.29157567024231\n",
            "  time_total_s: 14.29157567024231\n",
            "  timestamp: 1653210458\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 95ca9ffc\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6926364302635193\n",
            "  warmup_time: 0.003301382064819336\n",
            "  \n",
            "Result for train_mnist_95ca9ffc:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-07-38\n",
            "  done: true\n",
            "  experiment_id: b4727d2553be40049caa67693ee2cb83\n",
            "  experiment_tag: 21_batch_size=16,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.3,fc1_units=128,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7426334023475647\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2021\n",
            "  time_since_restore: 14.29157567024231\n",
            "  time_this_iter_s: 14.29157567024231\n",
            "  time_total_s: 14.29157567024231\n",
            "  timestamp: 1653210458\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 95ca9ffc\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6926364302635193\n",
            "  warmup_time: 0.003301382064819336\n",
            "  \n",
            "5/5 [==============================] - 6s 183ms/step - loss: 0.7426 - accuracy: 0.5208 - f1_m: 0.4122 - precision_m: 0.6359 - recall_m: 0.3077 - val_loss: 0.6926 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:07:38,587\tINFO trial_runner.py:803 -- starting train_mnist_a0981b58\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:43 (running for 00:06:47.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a0981b58</td><td>RUNNING   </td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:48 (running for 00:06:52.42)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a0981b58</td><td>RUNNING   </td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m 2022-05-22 09:07:50.096579: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 64)            98368     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  activation_1 (Activation)   (None, 16, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Total params: 258,253\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Trainable params: 255,817\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Non-trainable params: 2,436\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f2b78de7050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f2b78de7050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f2b78def830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f2b78def830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f2b11d18f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f2b11d18f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2089)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:07:53 (running for 00:06:57.44)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 22/50 (1 RUNNING, 21 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a0981b58</td><td>RUNNING   </td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 2 more trials not shown (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7747 - accuracy: 0.5938 - f1_m: 0.7451 - precision_m: 0.5938 - recall_m: 1.0000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8764 - accuracy: 0.5417 - f1_m: 0.6776 - precision_m: 0.5724 - recall_m: 0.8830 \n",
            "5/5 [==============================] - 6s 198ms/step - loss: 0.8764 - accuracy: 0.5417 - f1_m: 0.6776 - precision_m: 0.5724 - recall_m: 0.8830 - val_loss: 0.6944 - val_accuracy: 0.3514 - val_f1_m: 0.4667 - val_precision_m: 0.4583 - val_recall_m: 0.4762\n",
            "Result for train_mnist_a0981b58:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-07-58\n",
            "  done: false\n",
            "  experiment_id: 766efece8cbf40238e8f2745a476a4d8\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8764386773109436\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2089\n",
            "  time_since_restore: 16.197885036468506\n",
            "  time_this_iter_s: 16.197885036468506\n",
            "  time_total_s: 16.197885036468506\n",
            "  timestamp: 1653210478\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a0981b58\n",
            "  val_accuracy: 0.3513513505458832\n",
            "  val_loss: 0.6944432258605957\n",
            "  warmup_time: 0.0030868053436279297\n",
            "  \n",
            "Result for train_mnist_a0981b58:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-07-58\n",
            "  done: true\n",
            "  experiment_id: 766efece8cbf40238e8f2745a476a4d8\n",
            "  experiment_tag: 22_batch_size=16,conv_block1_filters=512,conv_block2_filters=64,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.3,fc1_units=128,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8764386773109436\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2089\n",
            "  time_since_restore: 16.197885036468506\n",
            "  time_this_iter_s: 16.197885036468506\n",
            "  time_total_s: 16.197885036468506\n",
            "  timestamp: 1653210478\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a0981b58\n",
            "  val_accuracy: 0.3513513505458832\n",
            "  val_loss: 0.6944432258605957\n",
            "  warmup_time: 0.0030868053436279297\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:07:58,589\tINFO trial_runner.py:803 -- starting train_mnist_ac6fe19a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:03 (running for 00:07:07.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>RUNNING   </td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:08 (running for 00:07:12.42)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>RUNNING   </td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m 2022-05-22 09:08:10.148494: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Total params: 122,189\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Trainable params: 120,777\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f94ef312050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f94ef312050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f94ef31a830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f94ef31a830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f9488245f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f9488245f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2158)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:13 (running for 00:07:17.45)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 23/50 (1 RUNNING, 22 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>RUNNING   </td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 3 more trials not shown (3 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.8621 - accuracy: 0.5625 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0505 - accuracy: 0.4514 - f1_m: 0.0211 - precision_m: 0.2000 - recall_m: 0.0111             \n",
            "5/5 [==============================] - 6s 204ms/step - loss: 1.0505 - accuracy: 0.4514 - f1_m: 0.0211 - precision_m: 0.2000 - recall_m: 0.0111 - val_loss: 0.6918 - val_accuracy: 0.6216 - val_f1_m: 0.5103 - val_precision_m: 0.5500 - val_recall_m: 0.4881\n",
            "Result for train_mnist_ac6fe19a:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-08-18\n",
            "  done: false\n",
            "  experiment_id: 17b24d8a70724fe4b83b8f12b54e6e88\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.050545573234558\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2158\n",
            "  time_since_restore: 16.17221760749817\n",
            "  time_this_iter_s: 16.17221760749817\n",
            "  time_total_s: 16.17221760749817\n",
            "  timestamp: 1653210498\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: ac6fe19a\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6918191909790039\n",
            "  warmup_time: 0.003251314163208008\n",
            "  \n",
            "Result for train_mnist_ac6fe19a:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-08-18\n",
            "  done: true\n",
            "  experiment_id: 17b24d8a70724fe4b83b8f12b54e6e88\n",
            "  experiment_tag: 23_batch_size=16,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.050545573234558\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2158\n",
            "  time_since_restore: 16.17221760749817\n",
            "  time_this_iter_s: 16.17221760749817\n",
            "  time_total_s: 16.17221760749817\n",
            "  timestamp: 1653210498\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: ac6fe19a\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6918191909790039\n",
            "  warmup_time: 0.003251314163208008\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:08:18,594\tINFO trial_runner.py:803 -- starting train_mnist_b866141a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:23 (running for 00:07:27.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 24/50 (1 RUNNING, 23 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b866141a</td><td>RUNNING   </td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 4 more trials not shown (4 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:28 (running for 00:07:32.43)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 24/50 (1 RUNNING, 23 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b866141a</td><td>RUNNING   </td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 4 more trials not shown (4 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m 2022-05-22 09:08:30.366220: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Total params: 323,341\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Trainable params: 321,033\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Non-trainable params: 2,308\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fe8057d5050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fe8057d5050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fe8057dd830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fe8057dd830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fe79e707f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fe79e707f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2231)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:33 (running for 00:07:37.46)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 24/50 (1 RUNNING, 23 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b866141a</td><td>RUNNING   </td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 4 more trials not shown (4 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.6459 - accuracy: 0.5625 - f1_m: 0.6316 - precision_m: 0.6000 - recall_m: 0.6667\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7283 - accuracy: 0.5347 - f1_m: 0.5893 - precision_m: 0.5790 - recall_m: 0.6061 \n",
            "5/5 [==============================] - 6s 182ms/step - loss: 0.7283 - accuracy: 0.5347 - f1_m: 0.5893 - precision_m: 0.5790 - recall_m: 0.6061 - val_loss: 0.6956 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n",
            "Result for train_mnist_b866141a:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-08-38\n",
            "  done: false\n",
            "  experiment_id: 3f5c7a8db3e04d6083e9bdf8bbce3eab\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7282525300979614\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2231\n",
            "  time_since_restore: 16.33062434196472\n",
            "  time_this_iter_s: 16.33062434196472\n",
            "  time_total_s: 16.33062434196472\n",
            "  timestamp: 1653210518\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b866141a\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6955770254135132\n",
            "  warmup_time: 0.003171205520629883\n",
            "  \n",
            "Result for train_mnist_b866141a:\n",
            "  accuracy: 0.5347222089767456\n",
            "  date: 2022-05-22_09-08-38\n",
            "  done: true\n",
            "  experiment_id: 3f5c7a8db3e04d6083e9bdf8bbce3eab\n",
            "  experiment_tag: 24_batch_size=16,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7282525300979614\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2231\n",
            "  time_since_restore: 16.33062434196472\n",
            "  time_this_iter_s: 16.33062434196472\n",
            "  time_total_s: 16.33062434196472\n",
            "  timestamp: 1653210518\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: b866141a\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6955770254135132\n",
            "  warmup_time: 0.003171205520629883\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:08:39,595\tINFO trial_runner.py:803 -- starting train_mnist_c47257e6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:39 (running for 00:07:43.39)<br>Memory usage on this node: 1.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c47257e6</td><td>RUNNING   </td><td>172.28.0.2:2303</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:48 (running for 00:07:51.83)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c47257e6</td><td>RUNNING   </td><td>172.28.0.2:2303</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m 2022-05-22 09:08:51.221639: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 64)            12352     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  activation_1 (Activation)   (None, 16, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Total params: 126,285\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Trainable params: 124,873\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f94e0595050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f94e0595050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f94e059d830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f94e059d830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f94794c7f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f94794c7f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2303)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:53 (running for 00:07:56.86)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c47257e6</td><td>RUNNING   </td><td>172.28.0.2:2303</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.0567 - accuracy: 0.4688 - f1_m: 0.1053 - precision_m: 1.0000 - recall_m: 0.0556\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.5069 - f1_m: 0.2446 - precision_m: 0.8200 - recall_m: 0.1489 \n",
            "5/5 [==============================] - 6s 176ms/step - loss: 0.9170 - accuracy: 0.5069 - f1_m: 0.2446 - precision_m: 0.8200 - recall_m: 0.1489 - val_loss: 0.6896 - val_accuracy: 0.5946 - val_f1_m: 0.5333 - val_precision_m: 0.5227 - val_recall_m: 0.5952\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:08:58 (running for 00:08:01.88)<br>Memory usage on this node: 3.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 25/50 (1 RUNNING, 24 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c47257e6</td><td>RUNNING   </td><td>172.28.0.2:2303</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 5 more trials not shown (5 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:08:59,599\tINFO trial_runner.py:803 -- starting train_mnist_d0ed5a52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_c47257e6:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-22_09-08-59\n",
            "  done: false\n",
            "  experiment_id: 5f12493b694b4623ba6612dce1d43816\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9170273542404175\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2303\n",
            "  time_since_restore: 16.40435218811035\n",
            "  time_this_iter_s: 16.40435218811035\n",
            "  time_total_s: 16.40435218811035\n",
            "  timestamp: 1653210539\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c47257e6\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6895932555198669\n",
            "  warmup_time: 0.003422975540161133\n",
            "  \n",
            "Result for train_mnist_c47257e6:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-22_09-08-59\n",
            "  done: true\n",
            "  experiment_id: 5f12493b694b4623ba6612dce1d43816\n",
            "  experiment_tag: 25_batch_size=16,conv_block1_filters=64,conv_block2_filters=64,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9170273542404175\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2303\n",
            "  time_since_restore: 16.40435218811035\n",
            "  time_this_iter_s: 16.40435218811035\n",
            "  time_total_s: 16.40435218811035\n",
            "  timestamp: 1653210539\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c47257e6\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6895932555198669\n",
            "  warmup_time: 0.003422975540161133\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:04 (running for 00:08:08.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 26/50 (1 RUNNING, 25 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d0ed5a52</td><td>RUNNING   </td><td>172.28.0.2:2373</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 6 more trials not shown (6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:09 (running for 00:08:13.44)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 26/50 (1 RUNNING, 25 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d0ed5a52</td><td>RUNNING   </td><td>172.28.0.2:2373</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 6 more trials not shown (6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m 2022-05-22 09:09:11.341288: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 256)           98560     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  activation_2 (Activation)   (None, 14, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Total params: 447,181\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Trainable params: 444,489\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Non-trainable params: 2,692\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fcd632a6050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fcd632a6050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fcd632ae830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fcd632ae830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fccfc1d9f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fccfc1d9f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2373)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:14 (running for 00:08:18.47)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 26/50 (1 RUNNING, 25 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d0ed5a52</td><td>RUNNING   </td><td>172.28.0.2:2373</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 6 more trials not shown (6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 0.7541 - accuracy: 0.3750 - f1_m: 0.4118 - precision_m: 0.5385 - recall_m: 0.3333\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7150 - accuracy: 0.5139 - f1_m: 0.5372 - precision_m: 0.5695 - recall_m: 0.5176 \n",
            "Result for train_mnist_d0ed5a52:\n",
            "  accuracy: 0.5138888955116272\n",
            "  date: 2022-05-22_09-09-17\n",
            "  done: false\n",
            "  experiment_id: f1f8b21649fe4effbeb125bfe1203e87\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7150403261184692\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2373\n",
            "  time_since_restore: 14.571076154708862\n",
            "  time_this_iter_s: 14.571076154708862\n",
            "  time_total_s: 14.571076154708862\n",
            "  timestamp: 1653210557\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d0ed5a52\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6936854720115662\n",
            "  warmup_time: 0.0032606124877929688\n",
            "  \n",
            "Result for train_mnist_d0ed5a52:\n",
            "  accuracy: 0.5138888955116272\n",
            "  date: 2022-05-22_09-09-17\n",
            "  done: true\n",
            "  experiment_id: f1f8b21649fe4effbeb125bfe1203e87\n",
            "  experiment_tag: 26_batch_size=16,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=256,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7150403261184692\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2373\n",
            "  time_since_restore: 14.571076154708862\n",
            "  time_this_iter_s: 14.571076154708862\n",
            "  time_total_s: 14.571076154708862\n",
            "  timestamp: 1653210557\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d0ed5a52\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6936854720115662\n",
            "  warmup_time: 0.0032606124877929688\n",
            "  \n",
            "5/5 [==============================] - 6s 184ms/step - loss: 0.7150 - accuracy: 0.5139 - f1_m: 0.5372 - precision_m: 0.5695 - recall_m: 0.5176 - val_loss: 0.6937 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:09:18,601\tINFO trial_runner.py:803 -- starting train_mnist_dbc93748\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:23 (running for 00:08:27.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_dbc93748</td><td>RUNNING   </td><td>172.28.0.2:2444</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:28 (running for 00:08:32.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_dbc93748</td><td>RUNNING   </td><td>172.28.0.2:2444</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m 2022-05-22 09:09:30.086387: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  activation_3 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Total params: 373,133\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Trainable params: 370,569\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f851c5c0050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f851c5c0050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f851c5c8830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f851c5c8830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f84b54f3f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f84b54f3f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2444)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:33 (running for 00:08:37.45)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 27/50 (1 RUNNING, 26 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_dbc93748</td><td>RUNNING   </td><td>172.28.0.2:2444</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 7 more trials not shown (7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 1.2407 - accuracy: 0.6250 - f1_m: 0.7692 - precision_m: 0.6250 - recall_m: 1.0000\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4112 - accuracy: 0.5486 - f1_m: 0.6879 - precision_m: 0.5312 - recall_m: 1.0000 \n",
            "Result for train_mnist_dbc93748:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-09-36\n",
            "  done: false\n",
            "  experiment_id: e5e540d5805a40668451bc572e259646\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4112168550491333\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2444\n",
            "  time_since_restore: 14.293967008590698\n",
            "  time_this_iter_s: 14.293967008590698\n",
            "  time_total_s: 14.293967008590698\n",
            "  timestamp: 1653210576\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: dbc93748\n",
            "  val_accuracy: 0.5135135054588318\n",
            "  val_loss: 0.6931931972503662\n",
            "  warmup_time: 0.003198862075805664\n",
            "  \n",
            "Result for train_mnist_dbc93748:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-09-36\n",
            "  done: true\n",
            "  experiment_id: e5e540d5805a40668451bc572e259646\n",
            "  experiment_tag: 27_batch_size=16,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=256,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4112168550491333\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2444\n",
            "  time_since_restore: 14.293967008590698\n",
            "  time_this_iter_s: 14.293967008590698\n",
            "  time_total_s: 14.293967008590698\n",
            "  timestamp: 1653210576\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: dbc93748\n",
            "  val_accuracy: 0.5135135054588318\n",
            "  val_loss: 0.6931931972503662\n",
            "  warmup_time: 0.003198862075805664\n",
            "  \n",
            "5/5 [==============================] - 6s 182ms/step - loss: 1.4112 - accuracy: 0.5486 - f1_m: 0.6879 - precision_m: 0.5312 - recall_m: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.5135 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:09:36,602\tINFO trial_runner.py:803 -- starting train_mnist_e6efa17a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:41 (running for 00:08:45.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e6efa17a</td><td>RUNNING   </td><td>172.28.0.2:2512</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:46 (running for 00:08:50.42)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e6efa17a</td><td>RUNNING   </td><td>172.28.0.2:2512</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m 2022-05-22 09:09:48.032721: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  dropout (Dropout)           (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  activation_5 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Total params: 281,293\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Trainable params: 278,857\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Non-trainable params: 2,436\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f7fe8bef050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f7fe8bef050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f7fe8bf7830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f7fe8bf7830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f7f81b21f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f7f81b21f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2512)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:09:51 (running for 00:08:55.45)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 28/50 (1 RUNNING, 27 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_e6efa17a</td><td>RUNNING   </td><td>172.28.0.2:2512</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 8 more trials not shown (8 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7679 - accuracy: 0.5000 - f1_m: 0.6667 - precision_m: 0.5000 - recall_m: 1.0000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7648 - accuracy: 0.5486 - f1_m: 0.7029 - precision_m: 0.5437 - recall_m: 1.0000 \n",
            "5/5 [==============================] - 6s 198ms/step - loss: 0.7648 - accuracy: 0.5486 - f1_m: 0.7029 - precision_m: 0.5437 - recall_m: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_e6efa17a:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-09-56\n",
            "  done: false\n",
            "  experiment_id: 9988ff504b854a86b290299231476e11\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7648389935493469\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2512\n",
            "  time_since_restore: 16.150214195251465\n",
            "  time_this_iter_s: 16.150214195251465\n",
            "  time_total_s: 16.150214195251465\n",
            "  timestamp: 1653210596\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e6efa17a\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6883720755577087\n",
            "  warmup_time: 0.003215789794921875\n",
            "  \n",
            "Result for train_mnist_e6efa17a:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-09-56\n",
            "  done: true\n",
            "  experiment_id: 9988ff504b854a86b290299231476e11\n",
            "  experiment_tag: 28_batch_size=16,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.5,fc1_units=512,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7648389935493469\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2512\n",
            "  time_since_restore: 16.150214195251465\n",
            "  time_this_iter_s: 16.150214195251465\n",
            "  time_total_s: 16.150214195251465\n",
            "  timestamp: 1653210596\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: e6efa17a\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6883720755577087\n",
            "  warmup_time: 0.003215789794921875\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:09:56,604\tINFO trial_runner.py:803 -- starting train_mnist_f2c13cf2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:01 (running for 00:09:05.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f2c13cf2</td><td>RUNNING   </td><td>172.28.0.2:2580</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:06 (running for 00:09:10.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f2c13cf2</td><td>RUNNING   </td><td>172.28.0.2:2580</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m 2022-05-22 09:10:08.186721: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d (Conv1D)             (None, 18, 256)           15616     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization (BatchN  (None, 18, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  activation (Activation)     (None, 18, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Total params: 266,509\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Trainable params: 264,457\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Non-trainable params: 2,052\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f32bc127050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f32bc127050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f32bc12f830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f32bc12f830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f325505af80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f325505af80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2580)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:11 (running for 00:09:15.47)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 29/50 (1 RUNNING, 28 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_f2c13cf2</td><td>RUNNING   </td><td>172.28.0.2:2580</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 9 more trials not shown (9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.7389 - accuracy: 0.4375 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4118 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "Result for train_mnist_f2c13cf2:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-10-14\n",
            "  done: false\n",
            "  experiment_id: 460dedd3251a4aa5b319cfda8172cbbf\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4118236303329468\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2580\n",
            "  time_since_restore: 14.240838527679443\n",
            "  time_this_iter_s: 14.240838527679443\n",
            "  time_total_s: 14.240838527679443\n",
            "  timestamp: 1653210614\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f2c13cf2\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6904928684234619\n",
            "  warmup_time: 0.0032618045806884766\n",
            "  \n",
            "Result for train_mnist_f2c13cf2:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-10-14\n",
            "  done: true\n",
            "  experiment_id: 460dedd3251a4aa5b319cfda8172cbbf\n",
            "  experiment_tag: 29_batch_size=16,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.1,fc1_units=128,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4118236303329468\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2580\n",
            "  time_since_restore: 14.240838527679443\n",
            "  time_this_iter_s: 14.240838527679443\n",
            "  time_total_s: 14.240838527679443\n",
            "  timestamp: 1653210614\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f2c13cf2\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6904928684234619\n",
            "  warmup_time: 0.0032618045806884766\n",
            "  \n",
            "5/5 [==============================] - 6s 196ms/step - loss: 1.4118 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6905 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:10:14,605\tINFO trial_runner.py:803 -- starting train_mnist_fd9282ee\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:19 (running for 00:09:23.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 30/50 (1 RUNNING, 29 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fd9282ee</td><td>RUNNING   </td><td>172.28.0.2:2654</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:24 (running for 00:09:28.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 30/50 (1 RUNNING, 29 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fd9282ee</td><td>RUNNING   </td><td>172.28.0.2:2654</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m 2022-05-22 09:10:26.115807: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  activation_1 (Activation)   (None, 16, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            12352     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Total params: 113,741\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Trainable params: 112,329\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f39d5048050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f39d5048050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f39d5050830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f39d5050830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f396df7af80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f396df7af80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2654)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:29 (running for 00:09:33.45)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 30/50 (1 RUNNING, 29 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_fd9282ee</td><td>RUNNING   </td><td>172.28.0.2:2654</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 10 more trials not shown (10 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.0755 - accuracy: 0.4688 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9314 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "5/5 [==============================] - 6s 194ms/step - loss: 0.9314 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6917 - val_accuracy: 0.5946 - val_f1_m: 0.5333 - val_precision_m: 0.5227 - val_recall_m: 0.5952\n",
            "Result for train_mnist_fd9282ee:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-10-34\n",
            "  done: false\n",
            "  experiment_id: 78bf7b3d86e94d1da0357f9ead1816d7\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9313967227935791\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2654\n",
            "  time_since_restore: 16.153781414031982\n",
            "  time_this_iter_s: 16.153781414031982\n",
            "  time_total_s: 16.153781414031982\n",
            "  timestamp: 1653210634\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fd9282ee\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6916815042495728\n",
            "  warmup_time: 0.0033752918243408203\n",
            "  \n",
            "Result for train_mnist_fd9282ee:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-10-34\n",
            "  done: true\n",
            "  experiment_id: 78bf7b3d86e94d1da0357f9ead1816d7\n",
            "  experiment_tag: 30_batch_size=16,conv_block1_filters=128,conv_block2_filters=64,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.4,fc1_units=64,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9313967227935791\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2654\n",
            "  time_since_restore: 16.153781414031982\n",
            "  time_this_iter_s: 16.153781414031982\n",
            "  time_total_s: 16.153781414031982\n",
            "  timestamp: 1653210634\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fd9282ee\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6916815042495728\n",
            "  warmup_time: 0.0033752918243408203\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:10:34,606\tINFO trial_runner.py:803 -- starting train_mnist_096e863a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:39 (running for 00:09:43.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_096e863a</td><td>RUNNING   </td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:44 (running for 00:09:48.43)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_096e863a</td><td>RUNNING   </td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m 2022-05-22 09:10:46.212997: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 256)           24832     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  activation_1 (Activation)   (None, 16, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 256)           196864    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  activation_2 (Activation)   (None, 14, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 256)           131328    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  activation_3 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Total params: 408,877\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Trainable params: 406,761\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Non-trainable params: 2,116\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fbb880fb050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fbb880fb050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fbb88103830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fbb88103830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fbb2102ef80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fbb2102ef80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2726)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:49 (running for 00:09:53.46)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 31/50 (1 RUNNING, 30 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_096e863a</td><td>RUNNING   </td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 11 more trials not shown (11 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.7822 - accuracy: 0.5625 - f1_m: 0.7200 - precision_m: 0.5625 - recall_m: 1.0000\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.6085 - accuracy: 0.5486 - f1_m: 0.7183 - precision_m: 0.5750 - recall_m: 1.0000 \n",
            "5/5 [==============================] - 6s 202ms/step - loss: 1.6085 - accuracy: 0.5486 - f1_m: 0.7183 - precision_m: 0.5750 - recall_m: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.3243 - val_f1_m: 0.4368 - val_precision_m: 0.4333 - val_recall_m: 0.4405\n",
            "Result for train_mnist_096e863a:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-10-54\n",
            "  done: false\n",
            "  experiment_id: 6464f45e9d2f4b959d7560ea287f8d09\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.60847008228302\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2726\n",
            "  time_since_restore: 16.248554706573486\n",
            "  time_this_iter_s: 16.248554706573486\n",
            "  time_total_s: 16.248554706573486\n",
            "  timestamp: 1653210654\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 096e863a\n",
            "  val_accuracy: 0.3243243098258972\n",
            "  val_loss: 0.696412205696106\n",
            "  warmup_time: 0.003157377243041992\n",
            "  \n",
            "Result for train_mnist_096e863a:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-10-54\n",
            "  done: true\n",
            "  experiment_id: 6464f45e9d2f4b959d7560ea287f8d09\n",
            "  experiment_tag: 31_batch_size=32,conv_block1_filters=32,conv_block2_filters=256,conv_block3_filters=256,conv_block4_filters=256,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.60847008228302\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2726\n",
            "  time_since_restore: 16.248554706573486\n",
            "  time_this_iter_s: 16.248554706573486\n",
            "  time_total_s: 16.248554706573486\n",
            "  timestamp: 1653210654\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 096e863a\n",
            "  val_accuracy: 0.3243243098258972\n",
            "  val_loss: 0.696412205696106\n",
            "  warmup_time: 0.003157377243041992\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:10:54,607\tINFO trial_runner.py:803 -- starting train_mnist_1567a50c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:10:59 (running for 00:10:03.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1567a50c</td><td>RUNNING   </td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\"> 441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">   0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:04 (running for 00:10:08.44)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1567a50c</td><td>RUNNING   </td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\"> 441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">   0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m 2022-05-22 09:11:06.354732: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d (Conv1D)             (None, 18, 256)           15616     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization (BatchN  (None, 18, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  activation (Activation)     (None, 18, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            8224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  dropout (Dropout)           (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  activation_5 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Total params: 317,869\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Trainable params: 315,241\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Non-trainable params: 2,628\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f63c688a050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f63c688a050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f63c6892830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f63c6892830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f635f7bef80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f635f7bef80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2801)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:09 (running for 00:10:13.47)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 32/50 (1 RUNNING, 31 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_1567a50c</td><td>RUNNING   </td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\"> 441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">   0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 12 more trials not shown (12 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.3537 - accuracy: 0.3750 - f1_m: 0.0909 - precision_m: 1.0000 - recall_m: 0.0476\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8413 - accuracy: 0.5417 - f1_m: 0.3641 - precision_m: 0.6422 - recall_m: 0.3030 \n",
            "Result for train_mnist_1567a50c:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-11-12\n",
            "  done: false\n",
            "  experiment_id: 36e935512540401ab26ac71eef38ac19\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8413347005844116\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2801\n",
            "  time_since_restore: 14.366403341293335\n",
            "  time_this_iter_s: 14.366403341293335\n",
            "  time_total_s: 14.366403341293335\n",
            "  timestamp: 1653210672\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1567a50c\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 5.01468563079834\n",
            "  warmup_time: 0.004329681396484375\n",
            "  \n",
            "Result for train_mnist_1567a50c:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-11-12\n",
            "  done: true\n",
            "  experiment_id: 36e935512540401ab26ac71eef38ac19\n",
            "  experiment_tag: 32_batch_size=16,conv_block1_filters=256,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=32,conv_block5_filters=256,dropout_rate=0.1,fc1_units=512,fc_layer_type=convolution,lr=0.01,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8413347005844116\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2801\n",
            "  time_since_restore: 14.366403341293335\n",
            "  time_this_iter_s: 14.366403341293335\n",
            "  time_total_s: 14.366403341293335\n",
            "  timestamp: 1653210672\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 1567a50c\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 5.01468563079834\n",
            "  warmup_time: 0.004329681396484375\n",
            "  \n",
            "5/5 [==============================] - 6s 196ms/step - loss: 0.8413 - accuracy: 0.5417 - f1_m: 0.3641 - precision_m: 0.6422 - recall_m: 0.3030 - val_loss: 5.0147 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:11:13,608\tINFO trial_runner.py:803 -- starting train_mnist_20460e00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:18 (running for 00:10:22.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 33/50 (1 RUNNING, 32 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_20460e00</td><td>RUNNING   </td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\"> 441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 13 more trials not shown (13 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:23 (running for 00:10:27.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 33/50 (1 RUNNING, 32 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_20460e00</td><td>RUNNING   </td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\"> 441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 13 more trials not shown (13 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m 2022-05-22 09:11:25.002413: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            49184     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            6208      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 256)           65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  dropout (Dropout)           (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  activation_5 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Total params: 207,469\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Trainable params: 204,969\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Non-trainable params: 2,500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f0122ad5050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f0122ad5050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f0122add830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f0122add830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f00bba06f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f00bba06f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2874)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:28 (running for 00:10:32.47)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 33/50 (1 RUNNING, 32 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_20460e00</td><td>RUNNING   </td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\"> 441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 13 more trials not shown (13 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7654 - accuracy: 0.5000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7849 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "5/5 [==============================] - 6s 193ms/step - loss: 0.7849 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6930 - val_accuracy: 0.5946 - val_f1_m: 0.5333 - val_precision_m: 0.5227 - val_recall_m: 0.5952\n",
            "Result for train_mnist_20460e00:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-11-33\n",
            "  done: false\n",
            "  experiment_id: 23f40116bde24dbc820ff307fc22b709\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7848585247993469\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2874\n",
            "  time_since_restore: 16.06528902053833\n",
            "  time_this_iter_s: 16.06528902053833\n",
            "  time_total_s: 16.06528902053833\n",
            "  timestamp: 1653210693\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 20460e00\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6929773688316345\n",
            "  warmup_time: 0.003168344497680664\n",
            "  \n",
            "Result for train_mnist_20460e00:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-11-33\n",
            "  done: true\n",
            "  experiment_id: 23f40116bde24dbc820ff307fc22b709\n",
            "  experiment_tag: 33_batch_size=32,conv_block1_filters=512,conv_block2_filters=32,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.2,fc1_units=256,fc_layer_type=convolution,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7848585247993469\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2874\n",
            "  time_since_restore: 16.06528902053833\n",
            "  time_this_iter_s: 16.06528902053833\n",
            "  time_total_s: 16.06528902053833\n",
            "  timestamp: 1653210693\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 20460e00\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6929773688316345\n",
            "  warmup_time: 0.003168344497680664\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:11:33,609\tINFO trial_runner.py:803 -- starting train_mnist_2c8df4de\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:38 (running for 00:10:42.39)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>RUNNING   </td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:43 (running for 00:10:47.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>RUNNING   </td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m 2022-05-22 09:11:45.156440: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           49280     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Total params: 175,629\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Trainable params: 174,089\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Non-trainable params: 1,540\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7feca45c0050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7feca45c0050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7feca45c8830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7feca45c8830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fec3d4f5f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fec3d4f5f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2944)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:48 (running for 00:10:52.47)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 34/50 (1 RUNNING, 33 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>RUNNING   </td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">   0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 14 more trials not shown (14 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.0271 - accuracy: 0.5312 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0423 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "5/5 [==============================] - 6s 193ms/step - loss: 1.0423 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6856 - val_accuracy: 0.6216 - val_f1_m: 0.5429 - val_precision_m: 0.5357 - val_recall_m: 0.5952\n",
            "Result for train_mnist_2c8df4de:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-11-53\n",
            "  done: false\n",
            "  experiment_id: 34390132bb4d4d978c7ede183af38efe\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.0422582626342773\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2944\n",
            "  time_since_restore: 16.253652095794678\n",
            "  time_this_iter_s: 16.253652095794678\n",
            "  time_total_s: 16.253652095794678\n",
            "  timestamp: 1653210713\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2c8df4de\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6855918765068054\n",
            "  warmup_time: 0.003076791763305664\n",
            "  \n",
            "Result for train_mnist_2c8df4de:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-11-53\n",
            "  done: true\n",
            "  experiment_id: 34390132bb4d4d978c7ede183af38efe\n",
            "  experiment_tag: 34_batch_size=16,conv_block1_filters=128,conv_block2_filters=128,conv_block3_filters=128,conv_block4_filters=128,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.0422582626342773\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 2944\n",
            "  time_since_restore: 16.253652095794678\n",
            "  time_this_iter_s: 16.253652095794678\n",
            "  time_total_s: 16.253652095794678\n",
            "  timestamp: 1653210713\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2c8df4de\n",
            "  val_accuracy: 0.6216216087341309\n",
            "  val_loss: 0.6855918765068054\n",
            "  warmup_time: 0.003076791763305664\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:11:53,610\tINFO trial_runner.py:803 -- starting train_mnist_389478fc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:11:58 (running for 00:11:02.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 35/50 (1 RUNNING, 34 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_389478fc</td><td>RUNNING   </td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 15 more trials not shown (15 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:03 (running for 00:11:07.44)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 35/50 (1 RUNNING, 34 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_389478fc</td><td>RUNNING   </td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 15 more trials not shown (15 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m 2022-05-22 09:12:05.273033: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  activation_1 (Activation)   (None, 16, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  global_max_pooling1d (Globa  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  dense (Dense)               (None, 128)               16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Total params: 275,533\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Trainable params: 273,353\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Non-trainable params: 2,180\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f14e3af3050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f14e3af3050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f14e3afb830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f14e3afb830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f147ca27f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f147ca27f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:08 (running for 00:11:12.47)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 35/50 (1 RUNNING, 34 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_389478fc</td><td>RUNNING   </td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">   0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 15 more trials not shown (15 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.6851 - accuracy: 0.5625 - f1_m: 0.5882 - precision_m: 0.7692 - recall_m: 0.4762\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7255 - accuracy: 0.5625 - f1_m: 0.5806 - precision_m: 0.6372 - recall_m: 0.5419 \n",
            "5/5 [==============================] - 6s 219ms/step - loss: 0.7255 - accuracy: 0.5625 - f1_m: 0.5806 - precision_m: 0.6372 - recall_m: 0.5419 - val_loss: 0.6851 - val_accuracy: 0.5946 - val_f1_m: 0.5333 - val_precision_m: 0.5227 - val_recall_m: 0.5952\n",
            "Result for train_mnist_389478fc:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-22_09-12-13\n",
            "  done: false\n",
            "  experiment_id: 7ef8565c41e446d28cd1553627e8867c\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7254924178123474\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3017\n",
            "  time_since_restore: 16.09854292869568\n",
            "  time_this_iter_s: 16.09854292869568\n",
            "  time_total_s: 16.09854292869568\n",
            "  timestamp: 1653210733\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 389478fc\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6850917935371399\n",
            "  warmup_time: 0.0029463768005371094\n",
            "  \n",
            "Result for train_mnist_389478fc:\n",
            "  accuracy: 0.5625\n",
            "  date: 2022-05-22_09-12-13\n",
            "  done: true\n",
            "  experiment_id: 7ef8565c41e446d28cd1553627e8867c\n",
            "  experiment_tag: 35_batch_size=16,conv_block1_filters=128,conv_block2_filters=64,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=dense,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7254924178123474\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3017\n",
            "  time_since_restore: 16.09854292869568\n",
            "  time_this_iter_s: 16.09854292869568\n",
            "  time_total_s: 16.09854292869568\n",
            "  timestamp: 1653210733\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 389478fc\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6850917935371399\n",
            "  warmup_time: 0.0029463768005371094\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:12:13,611\tINFO trial_runner.py:803 -- starting train_mnist_44709192\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:18 (running for 00:11:22.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_44709192</td><td>RUNNING   </td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:23 (running for 00:11:27.45)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_44709192</td><td>RUNNING   </td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m 2022-05-22 09:12:25.346514: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Total params: 122,189\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Trainable params: 120,777\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fcc4f427050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fcc4f427050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fcc4f42f830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fcc4f42f830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fcbe8359f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fcbe8359f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3092)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:28 (running for 00:11:32.46)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 36/50 (1 RUNNING, 35 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_44709192</td><td>RUNNING   </td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">   0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 16 more trials not shown (16 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 2.1803 - accuracy: 0.4062 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1659 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "5/5 [==============================] - 6s 192ms/step - loss: 1.1659 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.7824 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_44709192:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-12-33\n",
            "  done: false\n",
            "  experiment_id: cd86283feaea43a1b7ddf7614e215391\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.1659201383590698\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3092\n",
            "  time_since_restore: 16.36350154876709\n",
            "  time_this_iter_s: 16.36350154876709\n",
            "  time_total_s: 16.36350154876709\n",
            "  timestamp: 1653210753\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: '44709192'\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.7824212908744812\n",
            "  warmup_time: 0.0030832290649414062\n",
            "  \n",
            "Result for train_mnist_44709192:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-12-33\n",
            "  done: true\n",
            "  experiment_id: cd86283feaea43a1b7ddf7614e215391\n",
            "  experiment_tag: 36_batch_size=64,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.01,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.1659201383590698\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3092\n",
            "  time_since_restore: 16.36350154876709\n",
            "  time_this_iter_s: 16.36350154876709\n",
            "  time_total_s: 16.36350154876709\n",
            "  timestamp: 1653210753\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: '44709192'\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.7824212908744812\n",
            "  warmup_time: 0.0030832290649414062\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:12:34,616\tINFO trial_runner.py:803 -- starting train_mnist_50855102\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:34 (running for 00:11:38.44)<br>Memory usage on this node: 1.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50855102</td><td>RUNNING   </td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:43 (running for 00:11:46.93)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50855102</td><td>RUNNING   </td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m 2022-05-22 09:12:46.294524: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           197120    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Total params: 447,565\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Trainable params: 445,385\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Non-trainable params: 2,180\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fab2a3e3050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fab2a3e3050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fab2a3eb830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fab2a3eb830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7faac3317f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7faac3317f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3165)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:48 (running for 00:11:51.96)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50855102</td><td>RUNNING   </td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 1.0086 - accuracy: 0.4375 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "5/5 [==============================] - 6s 205ms/step - loss: 0.9175 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6882 - val_accuracy: 0.4595 - val_f1_m: 0.0952 - val_precision_m: 0.1429 - val_recall_m: 0.0714\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:12:53 (running for 00:11:57.00)<br>Memory usage on this node: 3.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 37/50 (1 RUNNING, 36 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_50855102</td><td>RUNNING   </td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\"> 389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 17 more trials not shown (17 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_50855102:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-12-54\n",
            "  done: false\n",
            "  experiment_id: 7e69a336aa8244aa99d939eae50a3162\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9175000786781311\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3165\n",
            "  time_since_restore: 16.37673020362854\n",
            "  time_this_iter_s: 16.37673020362854\n",
            "  time_total_s: 16.37673020362854\n",
            "  timestamp: 1653210774\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: '50855102'\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6881723999977112\n",
            "  warmup_time: 0.006767749786376953\n",
            "  \n",
            "Result for train_mnist_50855102:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-12-54\n",
            "  done: true\n",
            "  experiment_id: 7e69a336aa8244aa99d939eae50a3162\n",
            "  experiment_tag: 37_batch_size=32,conv_block1_filters=128,conv_block2_filters=512,conv_block3_filters=128,conv_block4_filters=64,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9175000786781311\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3165\n",
            "  time_since_restore: 16.37673020362854\n",
            "  time_this_iter_s: 16.37673020362854\n",
            "  time_total_s: 16.37673020362854\n",
            "  timestamp: 1653210774\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: '50855102'\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6881723999977112\n",
            "  warmup_time: 0.006767749786376953\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:12:55,618\tINFO trial_runner.py:803 -- starting train_mnist_5d0bfc64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:00 (running for 00:12:04.42)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 38/50 (1 RUNNING, 37 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>RUNNING   </td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 18 more trials not shown (18 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:05 (running for 00:12:09.44)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 38/50 (1 RUNNING, 37 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>RUNNING   </td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 18 more trials not shown (18 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m 2022-05-22 09:13:07.142503: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            12320     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           12416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 256)           65792     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  activation_3 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           32896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  global_max_pooling1d (Globa  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  dense (Dense)               (None, 128)               16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Total params: 151,213\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Trainable params: 149,609\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Non-trainable params: 1,604\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7ff10b17c050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7ff10b17c050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7ff10b184830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7ff10b184830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7ff0a40aff80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7ff0a40aff80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3238)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:10 (running for 00:12:14.48)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 38/50 (1 RUNNING, 37 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>RUNNING   </td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">   0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 18 more trials not shown (18 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.9677 - accuracy: 0.4375 - f1_m: 0.5263 - precision_m: 0.5263 - recall_m: 0.5263\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9430 - accuracy: 0.5208 - f1_m: 0.5518 - precision_m: 0.5586 - recall_m: 0.5571 \n",
            "5/5 [==============================] - 6s 214ms/step - loss: 0.9430 - accuracy: 0.5208 - f1_m: 0.5518 - precision_m: 0.5586 - recall_m: 0.5571 - val_loss: 0.6910 - val_accuracy: 0.4595 - val_f1_m: 0.2952 - val_precision_m: 0.3929 - val_recall_m: 0.2381\n",
            "Result for train_mnist_5d0bfc64:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-13-15\n",
            "  done: false\n",
            "  experiment_id: a5868e1d5976422eaa9c49b9278076ad\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9429915547370911\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3238\n",
            "  time_since_restore: 15.984364986419678\n",
            "  time_this_iter_s: 15.984364986419678\n",
            "  time_total_s: 15.984364986419678\n",
            "  timestamp: 1653210795\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 5d0bfc64\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6910393238067627\n",
            "  warmup_time: 0.0031232833862304688\n",
            "  \n",
            "Result for train_mnist_5d0bfc64:\n",
            "  accuracy: 0.5208333134651184\n",
            "  date: 2022-05-22_09-13-15\n",
            "  done: true\n",
            "  experiment_id: a5868e1d5976422eaa9c49b9278076ad\n",
            "  experiment_tag: 38_batch_size=16,conv_block1_filters=128,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=256,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=dense,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9429915547370911\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3238\n",
            "  time_since_restore: 15.984364986419678\n",
            "  time_this_iter_s: 15.984364986419678\n",
            "  time_total_s: 15.984364986419678\n",
            "  timestamp: 1653210795\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 5d0bfc64\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6910393238067627\n",
            "  warmup_time: 0.0031232833862304688\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:13:15,619\tINFO trial_runner.py:803 -- starting train_mnist_69570cb6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:20 (running for 00:12:24.40)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 39/50 (1 RUNNING, 38 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_69570cb6</td><td>RUNNING   </td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br>... 19 more trials not shown (19 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:25 (running for 00:12:29.44)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 39/50 (1 RUNNING, 38 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_69570cb6</td><td>RUNNING   </td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br>... 19 more trials not shown (19 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m 2022-05-22 09:13:27.301435: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 256)           98560     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  activation_1 (Activation)   (None, 16, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Total params: 423,949\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Trainable params: 421,385\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f2fb9a27050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f2fb9a27050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f2fb9a2f830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f2fb9a2f830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f2f52957f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f2f52957f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3313)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:30 (running for 00:12:34.47)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 39/50 (1 RUNNING, 38 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_69570cb6</td><td>RUNNING   </td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">   0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "</tbody>\n",
              "</table><br>... 19 more trials not shown (19 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.1914 - accuracy: 0.3438 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8999 - accuracy: 0.4444 - f1_m: 0.0533 - precision_m: 0.1667 - recall_m: 0.0333             \n",
            "Result for train_mnist_69570cb6:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-22_09-13-33\n",
            "  done: false\n",
            "  experiment_id: eb7920bd0928405fb7fb1aacec2aa9a3\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8999338150024414\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3313\n",
            "  time_since_restore: 14.462772846221924\n",
            "  time_this_iter_s: 14.462772846221924\n",
            "  time_total_s: 14.462772846221924\n",
            "  timestamp: 1653210813\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 69570cb6\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6919339299201965\n",
            "  warmup_time: 0.00347137451171875\n",
            "  \n",
            "Result for train_mnist_69570cb6:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-22_09-13-33\n",
            "  done: true\n",
            "  experiment_id: eb7920bd0928405fb7fb1aacec2aa9a3\n",
            "  experiment_tag: 39_batch_size=64,conv_block1_filters=128,conv_block2_filters=256,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8999338150024414\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3313\n",
            "  time_since_restore: 14.462772846221924\n",
            "  time_this_iter_s: 14.462772846221924\n",
            "  time_total_s: 14.462772846221924\n",
            "  timestamp: 1653210813\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 69570cb6\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6919339299201965\n",
            "  warmup_time: 0.00347137451171875\n",
            "  \n",
            "5/5 [==============================] - 6s 201ms/step - loss: 0.8999 - accuracy: 0.4444 - f1_m: 0.0533 - precision_m: 0.1667 - recall_m: 0.0333 - val_loss: 0.6919 - val_accuracy: 0.5405 - val_f1_m: 0.6410 - val_precision_m: 0.5733 - val_recall_m: 0.7619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:13:34,622\tINFO trial_runner.py:803 -- starting train_mnist_7457682c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:39 (running for 00:12:43.44)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7457682c</td><td>RUNNING   </td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:44 (running for 00:12:48.47)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7457682c</td><td>RUNNING   </td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m 2022-05-22 09:13:46.133470: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           197120    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           786944    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            32800     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           4224      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Total params: 1,051,437\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Trainable params: 1,048,553\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Non-trainable params: 2,884\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f18c009c050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f18c009c050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f18c00a4830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f18c00a4830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f1858fcff80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f1858fcff80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3385)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:49 (running for 00:12:53.50)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 40/50 (1 RUNNING, 39 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7457682c</td><td>RUNNING   </td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 20 more trials not shown (20 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 1.2232 - accuracy: 0.4688 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2260 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 \n",
            "Result for train_mnist_7457682c:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-13-52\n",
            "  done: false\n",
            "  experiment_id: 4e4a0c4514c44c8891a5af58db35cc2b\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.2259531021118164\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3385\n",
            "  time_since_restore: 14.255198240280151\n",
            "  time_this_iter_s: 14.255198240280151\n",
            "  time_total_s: 14.255198240280151\n",
            "  timestamp: 1653210832\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7457682c\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6927169561386108\n",
            "  warmup_time: 0.003194093704223633\n",
            "  \n",
            "Result for train_mnist_7457682c:\n",
            "  accuracy: 0.4513888955116272\n",
            "  date: 2022-05-22_09-13-52\n",
            "  done: true\n",
            "  experiment_id: 4e4a0c4514c44c8891a5af58db35cc2b\n",
            "  experiment_tag: 40_batch_size=16,conv_block1_filters=128,conv_block2_filters=512,conv_block3_filters=512,conv_block4_filters=32,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.2259531021118164\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3385\n",
            "  time_since_restore: 14.255198240280151\n",
            "  time_this_iter_s: 14.255198240280151\n",
            "  time_total_s: 14.255198240280151\n",
            "  timestamp: 1653210832\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7457682c\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6927169561386108\n",
            "  warmup_time: 0.003194093704223633\n",
            "  \n",
            "5/5 [==============================] - 6s 195ms/step - loss: 1.2260 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5946 - val_f1_m: 0.5333 - val_precision_m: 0.5227 - val_recall_m: 0.5952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:13:53,623\tINFO trial_runner.py:803 -- starting train_mnist_7f9a9c04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:13:58 (running for 00:13:02.41)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7f9a9c04</td><td>RUNNING   </td><td>172.28.0.2:3458</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:03 (running for 00:13:07.44)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7f9a9c04</td><td>RUNNING   </td><td>172.28.0.2:3458</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m 2022-05-22 09:14:05.109516: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           12416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 256)           98560     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  activation_2 (Activation)   (None, 14, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  global_max_pooling1d (Globa  (None, 32)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  dense (Dense)               (None, 256)               8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Total params: 195,021\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Trainable params: 193,353\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Non-trainable params: 1,668\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7eff011bc050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7eff011bc050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7eff011c4830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7eff011c4830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7efe9a0eef80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7efe9a0eef80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3458)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:08 (running for 00:13:12.48)<br>Memory usage on this node: 2.6/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 41/50 (1 RUNNING, 40 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_7f9a9c04</td><td>RUNNING   </td><td>172.28.0.2:3458</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 21 more trials not shown (21 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.9068 - accuracy: 0.4375 - f1_m: 0.4000 - precision_m: 0.4000 - recall_m: 0.4000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8600 - accuracy: 0.5069 - f1_m: 0.5381 - precision_m: 0.5872 - recall_m: 0.5106 \n",
            "5/5 [==============================] - 6s 193ms/step - loss: 0.8600 - accuracy: 0.5069 - f1_m: 0.5381 - precision_m: 0.5872 - recall_m: 0.5106 - val_loss: 0.6909 - val_accuracy: 0.5676 - val_f1_m: 0.0667 - val_precision_m: 0.5000 - val_recall_m: 0.0357\n",
            "Result for train_mnist_7f9a9c04:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-22_09-14-13\n",
            "  done: false\n",
            "  experiment_id: 71ba7f950d61488a8682a773a3c4a8df\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8599870204925537\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3458\n",
            "  time_since_restore: 16.062697410583496\n",
            "  time_this_iter_s: 16.062697410583496\n",
            "  time_total_s: 16.062697410583496\n",
            "  timestamp: 1653210853\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7f9a9c04\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6909409761428833\n",
            "  warmup_time: 0.003119945526123047\n",
            "  \n",
            "Result for train_mnist_7f9a9c04:\n",
            "  accuracy: 0.5069444179534912\n",
            "  date: 2022-05-22_09-14-13\n",
            "  done: true\n",
            "  experiment_id: 71ba7f950d61488a8682a773a3c4a8df\n",
            "  experiment_tag: 41_batch_size=16,conv_block1_filters=32,conv_block2_filters=128,conv_block3_filters=256,conv_block4_filters=128,conv_block5_filters=32,dropout_rate=0.1,fc1_units=256,fc_layer_type=dense,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8599870204925537\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3458\n",
            "  time_since_restore: 16.062697410583496\n",
            "  time_this_iter_s: 16.062697410583496\n",
            "  time_total_s: 16.062697410583496\n",
            "  timestamp: 1653210853\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7f9a9c04\n",
            "  val_accuracy: 0.5675675868988037\n",
            "  val_loss: 0.6909409761428833\n",
            "  warmup_time: 0.003119945526123047\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:14:13,624\tINFO trial_runner.py:803 -- starting train_mnist_8be92fac\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:18 (running for 00:13:22.45)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 42/50 (1 RUNNING, 41 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8be92fac</td><td>RUNNING   </td><td>172.28.0.2:3531</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 22 more trials not shown (22 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:23 (running for 00:13:27.48)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 42/50 (1 RUNNING, 41 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8be92fac</td><td>RUNNING   </td><td>172.28.0.2:3531</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 22 more trials not shown (22 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m 2022-05-22 09:14:25.267590: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           196736    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           197120    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            65600     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Total params: 530,061\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Trainable params: 526,985\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Non-trainable params: 3,076\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f64f3390050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f64f3390050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f64f3398830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f64f3398830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f648c2c2f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f648c2c2f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3531)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:28 (running for 00:13:32.51)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 42/50 (1 RUNNING, 41 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_8be92fac</td><td>RUNNING   </td><td>172.28.0.2:3531</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 22 more trials not shown (22 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 0.7531 - accuracy: 0.3438 - f1_m: 0.3636 - precision_m: 0.4286 - recall_m: 0.3158\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7198 - accuracy: 0.4444 - f1_m: 0.5421 - precision_m: 0.4829 - recall_m: 0.7158 \n",
            "5/5 [==============================] - 6s 203ms/step - loss: 0.7198 - accuracy: 0.4444 - f1_m: 0.5421 - precision_m: 0.4829 - recall_m: 0.7158 - val_loss: 99.7560 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_8be92fac:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-22_09-14-33\n",
            "  done: false\n",
            "  experiment_id: ea42408d2ef3470386344dfb2b516925\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.71980881690979\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3531\n",
            "  time_since_restore: 16.293561458587646\n",
            "  time_this_iter_s: 16.293561458587646\n",
            "  time_total_s: 16.293561458587646\n",
            "  timestamp: 1653210873\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8be92fac\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 99.75595092773438\n",
            "  warmup_time: 0.0030629634857177734\n",
            "  \n",
            "Result for train_mnist_8be92fac:\n",
            "  accuracy: 0.4444444477558136\n",
            "  date: 2022-05-22_09-14-33\n",
            "  done: true\n",
            "  experiment_id: ea42408d2ef3470386344dfb2b516925\n",
            "  experiment_tag: 42_batch_size=64,conv_block1_filters=512,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=64,conv_block5_filters=256,dropout_rate=0.5,fc1_units=64,fc_layer_type=convolution,lr=0.1,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.71980881690979\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3531\n",
            "  time_since_restore: 16.293561458587646\n",
            "  time_this_iter_s: 16.293561458587646\n",
            "  time_total_s: 16.293561458587646\n",
            "  timestamp: 1653210873\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 8be92fac\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 99.75595092773438\n",
            "  warmup_time: 0.0030629634857177734\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:14:33,634\tINFO trial_runner.py:803 -- starting train_mnist_97fff4ba\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:38 (running for 00:13:42.42)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 43/50 (1 RUNNING, 42 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_97fff4ba</td><td>RUNNING   </td><td>172.28.0.2:3601</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 23 more trials not shown (23 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:43 (running for 00:13:47.46)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 43/50 (1 RUNNING, 42 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_97fff4ba</td><td>RUNNING   </td><td>172.28.0.2:3601</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 23 more trials not shown (23 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m 2022-05-22 09:14:45.085278: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d (Conv1D)             (None, 18, 256)           15616     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization (BatchN  (None, 18, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  activation (Activation)     (None, 18, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           393728    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            49184     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            4128      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 512)           16896     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  dropout (Dropout)           (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  activation_5 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Total params: 494,797\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Trainable params: 491,849\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Non-trainable params: 2,948\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f09b1eec050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f09b1eec050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f09b1ef4830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f09b1ef4830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f094ae1df80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f094ae1df80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3601)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:48 (running for 00:13:52.49)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 43/50 (1 RUNNING, 42 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_97fff4ba</td><td>RUNNING   </td><td>172.28.0.2:3601</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 23 more trials not shown (23 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 1.1654 - accuracy: 0.5625 - f1_m: 0.7200 - precision_m: 0.5625 - recall_m: 1.0000\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9711 - accuracy: 0.5486 - f1_m: 0.7142 - precision_m: 0.5562 - recall_m: 1.0000 \n",
            "5/5 [==============================] - 6s 206ms/step - loss: 0.9711 - accuracy: 0.5486 - f1_m: 0.7142 - precision_m: 0.5562 - recall_m: 1.0000 - val_loss: 5.5215 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_97fff4ba:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-14-53\n",
            "  done: false\n",
            "  experiment_id: 4928f395e4cf412f8e5a45f2c59f2012\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9711465835571289\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3601\n",
            "  time_since_restore: 16.15982699394226\n",
            "  time_this_iter_s: 16.15982699394226\n",
            "  time_total_s: 16.15982699394226\n",
            "  timestamp: 1653210893\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 97fff4ba\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 5.521461009979248\n",
            "  warmup_time: 0.0033321380615234375\n",
            "  \n",
            "Result for train_mnist_97fff4ba:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-14-53\n",
            "  done: true\n",
            "  experiment_id: 4928f395e4cf412f8e5a45f2c59f2012\n",
            "  experiment_tag: 43_batch_size=32,conv_block1_filters=256,conv_block2_filters=512,conv_block3_filters=32,conv_block4_filters=128,conv_block5_filters=32,dropout_rate=0.2,fc1_units=512,fc_layer_type=convolution,lr=0.01,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.9711465835571289\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3601\n",
            "  time_since_restore: 16.15982699394226\n",
            "  time_this_iter_s: 16.15982699394226\n",
            "  time_total_s: 16.15982699394226\n",
            "  timestamp: 1653210893\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 97fff4ba\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 5.521461009979248\n",
            "  warmup_time: 0.0033321380615234375\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:14:53,631\tINFO trial_runner.py:803 -- starting train_mnist_a3d5137e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:14:58 (running for 00:14:02.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 44/50 (1 RUNNING, 43 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a3d5137e</td><td>RUNNING   </td><td>172.28.0.2:3669</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 24 more trials not shown (24 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:03 (running for 00:14:07.46)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 44/50 (1 RUNNING, 43 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a3d5137e</td><td>RUNNING   </td><td>172.28.0.2:3669</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 24 more trials not shown (24 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m 2022-05-22 09:15:05.102500: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  conv1d (Conv1D)             (None, 18, 128)           7808      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization (BatchN  (None, 18, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  activation (Activation)     (None, 18, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 256)           98560     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  activation_1 (Activation)   (None, 16, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           98432     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           65664     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  global_average_pooling1d (G  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  dense (Dense)               (None, 128)               16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization_5 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  activation_5 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Total params: 423,949\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Trainable params: 421,385\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Non-trainable params: 2,564\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f91da2d5050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f91da2d5050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f91da2dd830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f91da2dd830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f9173208f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f9173208f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3669)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:08 (running for 00:14:12.51)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 44/50 (1 RUNNING, 43 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_a3d5137e</td><td>RUNNING   </td><td>172.28.0.2:3669</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 24 more trials not shown (24 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7215 - accuracy: 0.5625 - f1_m: 0.5000 - precision_m: 0.5385 - recall_m: 0.4667\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8222 - accuracy: 0.5694 - f1_m: 0.5564 - precision_m: 0.6025 - recall_m: 0.5200 \n",
            "5/5 [==============================] - 6s 200ms/step - loss: 0.8222 - accuracy: 0.5694 - f1_m: 0.5564 - precision_m: 0.6025 - recall_m: 0.5200 - val_loss: 0.6864 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_a3d5137e:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-22_09-15-13\n",
            "  done: false\n",
            "  experiment_id: c7b1fc59e87e4c718502c9f2038860b0\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8221877217292786\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3669\n",
            "  time_since_restore: 15.968703746795654\n",
            "  time_this_iter_s: 15.968703746795654\n",
            "  time_total_s: 15.968703746795654\n",
            "  timestamp: 1653210913\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a3d5137e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6863973736763\n",
            "  warmup_time: 0.0031592845916748047\n",
            "  \n",
            "Result for train_mnist_a3d5137e:\n",
            "  accuracy: 0.5694444179534912\n",
            "  date: 2022-05-22_09-15-13\n",
            "  done: true\n",
            "  experiment_id: c7b1fc59e87e4c718502c9f2038860b0\n",
            "  experiment_tag: 44_batch_size=16,conv_block1_filters=128,conv_block2_filters=256,conv_block3_filters=128,conv_block4_filters=512,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=dense,lr=0.001,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.8221877217292786\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3669\n",
            "  time_since_restore: 15.968703746795654\n",
            "  time_this_iter_s: 15.968703746795654\n",
            "  time_total_s: 15.968703746795654\n",
            "  timestamp: 1653210913\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: a3d5137e\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 0.6863973736763\n",
            "  warmup_time: 0.0031592845916748047\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:15:13,636\tINFO trial_runner.py:803 -- starting train_mnist_afa3bbc4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:18 (running for 00:14:22.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 45/50 (1 RUNNING, 44 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_afa3bbc4</td><td>RUNNING   </td><td>172.28.0.2:3740</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 25 more trials not shown (25 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:23 (running for 00:14:27.46)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 45/50 (1 RUNNING, 44 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_afa3bbc4</td><td>RUNNING   </td><td>172.28.0.2:3740</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 25 more trials not shown (25 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m 2022-05-22 09:15:25.197686: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 32)            49184     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  activation_1 (Activation)   (None, 16, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 128)           12416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  activation_2 (Activation)   (None, 14, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  activation_3 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  activation_4 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  dropout (Dropout)           (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  activation_5 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Total params: 138,349\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Trainable params: 136,361\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Non-trainable params: 1,988\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fa508448050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fa508448050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fa508450830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fa508450830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fa4a137bf80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fa4a137bf80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3740)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:28 (running for 00:14:32.49)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 45/50 (1 RUNNING, 44 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_afa3bbc4</td><td>RUNNING   </td><td>172.28.0.2:3740</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 25 more trials not shown (25 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 1.6711 - accuracy: 0.4688 - f1_m: 0.6383 - precision_m: 0.4688 - recall_m: 1.0000\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.4543 - accuracy: 0.5486 - f1_m: 0.7186 - precision_m: 0.5688 - recall_m: 1.0000 \n",
            "Result for train_mnist_afa3bbc4:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-15-31\n",
            "  done: false\n",
            "  experiment_id: 40a8bfeba83b4f51b92dba6b0ca2e7b5\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4542731046676636\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3740\n",
            "  time_since_restore: 14.314987897872925\n",
            "  time_this_iter_s: 14.314987897872925\n",
            "  time_total_s: 14.314987897872925\n",
            "  timestamp: 1653210931\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: afa3bbc4\n",
            "  val_accuracy: 0.3243243098258972\n",
            "  val_loss: 0.7091922760009766\n",
            "  warmup_time: 0.0030164718627929688\n",
            "  \n",
            "Result for train_mnist_afa3bbc4:\n",
            "  accuracy: 0.5486111044883728\n",
            "  date: 2022-05-22_09-15-31\n",
            "  done: true\n",
            "  experiment_id: 40a8bfeba83b4f51b92dba6b0ca2e7b5\n",
            "  experiment_tag: 45_batch_size=8,conv_block1_filters=512,conv_block2_filters=32,conv_block3_filters=128,conv_block4_filters=64,conv_block5_filters=128,dropout_rate=0.4,fc1_units=128,fc_layer_type=convolution,lr=0.001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 1.4542731046676636\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3740\n",
            "  time_since_restore: 14.314987897872925\n",
            "  time_this_iter_s: 14.314987897872925\n",
            "  time_total_s: 14.314987897872925\n",
            "  timestamp: 1653210931\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: afa3bbc4\n",
            "  val_accuracy: 0.3243243098258972\n",
            "  val_loss: 0.7091922760009766\n",
            "  warmup_time: 0.0030164718627929688\n",
            "  \n",
            "5/5 [==============================] - 6s 186ms/step - loss: 1.4543 - accuracy: 0.5486 - f1_m: 0.7186 - precision_m: 0.5688 - recall_m: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.3243 - val_f1_m: 0.4624 - val_precision_m: 0.4510 - val_recall_m: 0.4762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:15:31,637\tINFO trial_runner.py:803 -- starting train_mnist_ba905858\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:36 (running for 00:14:40.44)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 46/50 (1 RUNNING, 45 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ba905858</td><td>RUNNING   </td><td>172.28.0.2:3807</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 26 more trials not shown (26 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:41 (running for 00:14:45.47)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 46/50 (1 RUNNING, 45 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ba905858</td><td>RUNNING   </td><td>172.28.0.2:3807</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 26 more trials not shown (26 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m 2022-05-22 09:15:43.150433: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  global_average_pooling1d (G  (None, 64)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  dense (Dense)               (None, 256)               16640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  dropout (Dropout)           (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization_5 (Batc  (None, 256)              1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  activation_5 (Activation)   (None, 256)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  dense_1 (Dense)             (None, 2)                 514       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Total params: 97,997\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Trainable params: 96,585\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f845be94050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f845be94050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f845be9c830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f845be9c830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f83f4dc7f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f83f4dc7f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3807)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:46 (running for 00:14:50.50)<br>Memory usage on this node: 2.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 46/50 (1 RUNNING, 45 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_ba905858</td><td>RUNNING   </td><td>172.28.0.2:3807</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 26 more trials not shown (26 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 19s - loss: 0.9322 - accuracy: 0.4375 - f1_m: 0.4375 - precision_m: 0.4667 - recall_m: 0.4118\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7309 - accuracy: 0.5556 - f1_m: 0.5709 - precision_m: 0.5973 - recall_m: 0.5615 \n",
            "5/5 [==============================] - 6s 199ms/step - loss: 0.7309 - accuracy: 0.5556 - f1_m: 0.5709 - precision_m: 0.5973 - recall_m: 0.5615 - val_loss: 0.6930 - val_accuracy: 0.5946 - val_f1_m: 0.5333 - val_precision_m: 0.5227 - val_recall_m: 0.5952\n",
            "Result for train_mnist_ba905858:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-15-51\n",
            "  done: false\n",
            "  experiment_id: 1750aad8081b43a2a3a8bb460aad3e6a\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7308875918388367\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3807\n",
            "  time_since_restore: 16.00614094734192\n",
            "  time_this_iter_s: 16.00614094734192\n",
            "  time_total_s: 16.00614094734192\n",
            "  timestamp: 1653210951\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: ba905858\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6929910182952881\n",
            "  warmup_time: 0.0031478404998779297\n",
            "  \n",
            "Result for train_mnist_ba905858:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-15-51\n",
            "  done: true\n",
            "  experiment_id: 1750aad8081b43a2a3a8bb460aad3e6a\n",
            "  experiment_tag: 46_batch_size=16,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=128,conv_block5_filters=64,dropout_rate=0.5,fc1_units=256,fc_layer_type=dense,lr=0.0001,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7308875918388367\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3807\n",
            "  time_since_restore: 16.00614094734192\n",
            "  time_this_iter_s: 16.00614094734192\n",
            "  time_total_s: 16.00614094734192\n",
            "  timestamp: 1653210951\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: ba905858\n",
            "  val_accuracy: 0.5945945978164673\n",
            "  val_loss: 0.6929910182952881\n",
            "  warmup_time: 0.0031478404998779297\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:15:51,640\tINFO trial_runner.py:803 -- starting train_mnist_c6538e26\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:15:56 (running for 00:15:00.43)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 47/50 (1 RUNNING, 46 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c6538e26</td><td>RUNNING   </td><td>172.28.0.2:3881</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 27 more trials not shown (27 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:01 (running for 00:15:05.47)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 47/50 (1 RUNNING, 46 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c6538e26</td><td>RUNNING   </td><td>172.28.0.2:3881</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 27 more trials not shown (27 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m 2022-05-22 09:16:03.084956: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d (Conv1D)             (None, 18, 32)            1952      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization (BatchN  (None, 18, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  activation (Activation)     (None, 18, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 64)            6208      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  activation_1 (Activation)   (None, 16, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 256)           49408     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  activation_2 (Activation)   (None, 14, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 32)            16416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  activation_3 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           8448      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Total params: 101,837\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Trainable params: 100,425\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Non-trainable params: 1,412\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f9bfccbe050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f9bfccbe050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f9bfccc6830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f9bfccc6830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f9b95bf1f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f9b95bf1f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3881)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:06 (running for 00:15:10.50)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 47/50 (1 RUNNING, 46 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_c6538e26</td><td>RUNNING   </td><td>172.28.0.2:3881</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 27 more trials not shown (27 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7441 - accuracy: 0.6562 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.5833 - f1_m: 0.5497 - precision_m: 0.4710 - recall_m: 0.6738             \n",
            "5/5 [==============================] - 6s 205ms/step - loss: 0.6896 - accuracy: 0.5833 - f1_m: 0.5497 - precision_m: 0.4710 - recall_m: 0.6738 - val_loss: 636.8002 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_c6538e26:\n",
            "  accuracy: 0.5833333134651184\n",
            "  date: 2022-05-22_09-16-11\n",
            "  done: false\n",
            "  experiment_id: 73248370546b4d1c8ec6680129727220\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6896477937698364\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3881\n",
            "  time_since_restore: 16.19633150100708\n",
            "  time_this_iter_s: 16.19633150100708\n",
            "  time_total_s: 16.19633150100708\n",
            "  timestamp: 1653210971\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c6538e26\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 636.8001708984375\n",
            "  warmup_time: 0.0030291080474853516\n",
            "  \n",
            "Result for train_mnist_c6538e26:\n",
            "  accuracy: 0.5833333134651184\n",
            "  date: 2022-05-22_09-16-11\n",
            "  done: true\n",
            "  experiment_id: 73248370546b4d1c8ec6680129727220\n",
            "  experiment_tag: 47_batch_size=64,conv_block1_filters=32,conv_block2_filters=64,conv_block3_filters=256,conv_block4_filters=32,conv_block5_filters=256,dropout_rate=0.1,fc1_units=64,fc_layer_type=convolution,lr=0.1,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.6896477937698364\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3881\n",
            "  time_since_restore: 16.19633150100708\n",
            "  time_this_iter_s: 16.19633150100708\n",
            "  time_total_s: 16.19633150100708\n",
            "  timestamp: 1653210971\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: c6538e26\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 636.8001708984375\n",
            "  warmup_time: 0.0030291080474853516\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:16:11,644\tINFO trial_runner.py:803 -- starting train_mnist_d253391a\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:16 (running for 00:15:20.47)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 48/50 (1 RUNNING, 47 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d253391a</td><td>RUNNING   </td><td>172.28.0.2:3954</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 28 more trials not shown (28 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:21 (running for 00:15:25.51)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 48/50 (1 RUNNING, 47 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d253391a</td><td>RUNNING   </td><td>172.28.0.2:3954</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 28 more trials not shown (28 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m 2022-05-22 09:16:23.368530: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 512)           197120    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  activation_2 (Activation)   (None, 14, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 256)           262400    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  activation_3 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 64)            16448     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  activation_4 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 32)            2080      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  dropout (Dropout)           (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  activation_5 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             66        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  global_average_pooling1d (G  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Total params: 510,957\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Trainable params: 508,841\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Non-trainable params: 2,116\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f0fdefa4050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f0fdefa4050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f0fdefac830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f0fdefac830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f0f77ed6f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f0f77ed6f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3954)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:26 (running for 00:15:30.54)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 48/50 (1 RUNNING, 47 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_d253391a</td><td>RUNNING   </td><td>172.28.0.2:3954</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 28 more trials not shown (28 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 21s - loss: 0.6972 - accuracy: 0.5625 - f1_m: 0.5882 - precision_m: 0.6667 - recall_m: 0.5263\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.5556 - f1_m: 0.6097 - precision_m: 0.5929 - recall_m: 0.6396 \n",
            "5/5 [==============================] - 6s 188ms/step - loss: 0.6775 - accuracy: 0.5556 - f1_m: 0.6097 - precision_m: 0.5929 - recall_m: 0.6396 - val_loss: 2.4203 - val_accuracy: 0.5405 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Result for train_mnist_d253391a:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-16-31\n",
            "  done: false\n",
            "  experiment_id: 1e197fc733864d91ab81a9f5bd2e6bae\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.677463948726654\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3954\n",
            "  time_since_restore: 16.414107084274292\n",
            "  time_this_iter_s: 16.414107084274292\n",
            "  time_total_s: 16.414107084274292\n",
            "  timestamp: 1653210991\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d253391a\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 2.420289993286133\n",
            "  warmup_time: 0.0032014846801757812\n",
            "  \n",
            "Result for train_mnist_d253391a:\n",
            "  accuracy: 0.5555555820465088\n",
            "  date: 2022-05-22_09-16-31\n",
            "  done: true\n",
            "  experiment_id: 1e197fc733864d91ab81a9f5bd2e6bae\n",
            "  experiment_tag: 48_batch_size=8,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=512,conv_block4_filters=256,conv_block5_filters=64,dropout_rate=0.5,fc1_units=32,fc_layer_type=convolution,lr=0.01,pool_type=average\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.677463948726654\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 3954\n",
            "  time_since_restore: 16.414107084274292\n",
            "  time_this_iter_s: 16.414107084274292\n",
            "  time_total_s: 16.414107084274292\n",
            "  timestamp: 1653210991\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: d253391a\n",
            "  val_accuracy: 0.5405405163764954\n",
            "  val_loss: 2.420289993286133\n",
            "  warmup_time: 0.0032014846801757812\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:16:32,654\tINFO trial_runner.py:803 -- starting train_mnist_de69f702\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:32 (running for 00:15:36.45)<br>Memory usage on this node: 1.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_de69f702</td><td>RUNNING   </td><td>172.28.0.2:4026</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:41 (running for 00:15:44.92)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_de69f702</td><td>RUNNING   </td><td>172.28.0.2:4026</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m 2022-05-22 09:16:44.279845: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  conv1d (Conv1D)             (None, 18, 512)           31232     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization (BatchN  (None, 18, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  activation (Activation)     (None, 18, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 512)           786944    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  activation_1 (Activation)   (None, 16, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 32)            49184     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  activation_2 (Activation)   (None, 14, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 128)           8320      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  activation_3 (Activation)   (None, 13, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 256)           33024     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 256)          1024      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  activation_4 (Activation)   (None, 13, 256)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  global_max_pooling1d (Globa  (None, 256)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  dense (Dense)               (None, 512)               131584    \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  dropout (Dropout)           (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization_5 (Batc  (None, 512)              2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  activation_5 (Activation)   (None, 512)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  dense_1 (Dense)             (None, 2)                 1026      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  batch_normalization_6 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m  dense_2 (Dense)             (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Total params: 1,049,133\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Trainable params: 1,045,225\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Non-trainable params: 3,908\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f65e7ae7050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f65e7ae7050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f65e7aef830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f65e7aef830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f6580a19f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f6580a19f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4026)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:46 (running for 00:15:49.95)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_de69f702</td><td>RUNNING   </td><td>172.28.0.2:4026</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7261 - accuracy: 0.6250 - f1_m: 0.6842 - precision_m: 0.7222 - recall_m: 0.6500\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.5417 - f1_m: 0.5499 - precision_m: 0.6152 - recall_m: 0.5187 \n",
            "5/5 [==============================] - 6s 241ms/step - loss: 0.7308 - accuracy: 0.5417 - f1_m: 0.5499 - precision_m: 0.6152 - recall_m: 0.5187 - val_loss: 0.6929 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:51 (running for 00:15:54.98)<br>Memory usage on this node: 3.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 49/50 (1 RUNNING, 48 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_de69f702</td><td>RUNNING   </td><td>172.28.0.2:4026</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 29 more trials not shown (29 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_mnist_de69f702:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-16-52\n",
            "  done: false\n",
            "  experiment_id: ec0a3fb6b4d74c0584729228fa7ad685\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7308451533317566\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4026\n",
            "  time_since_restore: 16.113588094711304\n",
            "  time_this_iter_s: 16.113588094711304\n",
            "  time_total_s: 16.113588094711304\n",
            "  timestamp: 1653211012\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: de69f702\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6928564310073853\n",
            "  warmup_time: 0.008067131042480469\n",
            "  \n",
            "Result for train_mnist_de69f702:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-16-52\n",
            "  done: true\n",
            "  experiment_id: ec0a3fb6b4d74c0584729228fa7ad685\n",
            "  experiment_tag: 49_batch_size=32,conv_block1_filters=512,conv_block2_filters=512,conv_block3_filters=32,conv_block4_filters=128,conv_block5_filters=256,dropout_rate=0.2,fc1_units=512,fc_layer_type=dense,lr=0.0001,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.7308451533317566\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4026\n",
            "  time_since_restore: 16.113588094711304\n",
            "  time_this_iter_s: 16.113588094711304\n",
            "  time_total_s: 16.113588094711304\n",
            "  timestamp: 1653211012\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: de69f702\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 0.6928564310073853\n",
            "  warmup_time: 0.008067131042480469\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:16:52,655\tINFO trial_runner.py:803 -- starting train_mnist_eabdbffc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:16:57 (running for 00:16:01.44)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_eabdbffc</td><td>RUNNING   </td><td>172.28.0.2:4097</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 30 more trials not shown (30 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:17:02 (running for 00:16:06.49)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_eabdbffc</td><td>RUNNING   </td><td>172.28.0.2:4097</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 30 more trials not shown (30 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m 2022-05-22 09:17:04.203206: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  input_1 (InputLayer)        [(None, 20, 20)]          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d (Conv1D)             (None, 18, 64)            3904      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization (BatchN  (None, 18, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  activation (Activation)     (None, 18, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization_1 (Batc  (None, 16, 128)          512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  activation_1 (Activation)   (None, 16, 128)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d_2 (Conv1D)           (None, 14, 64)            24640     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization_2 (Batc  (None, 14, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  activation_2 (Activation)   (None, 14, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d_3 (Conv1D)           (None, 13, 512)           66048     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization_3 (Batc  (None, 13, 512)          2048      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  activation_3 (Activation)   (None, 13, 512)           0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d_4 (Conv1D)           (None, 13, 32)            16416     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization_4 (Batc  (None, 13, 32)           128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  activation_4 (Activation)   (None, 13, 32)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d_5 (Conv1D)           (None, 13, 64)            2112      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  dropout (Dropout)           (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization_5 (Batc  (None, 13, 64)           256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  activation_5 (Activation)   (None, 13, 64)            0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  conv1d_6 (Conv1D)           (None, 13, 2)             130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  dropout_1 (Dropout)         (None, 13, 2)             0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  batch_normalization_6 (Batc  (None, 13, 2)            8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m  dense (Dense)               (None, 1)                 3         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Total params: 141,421\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Trainable params: 139,689\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Non-trainable params: 1,732\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Total number of layers: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f579e112050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f579e112050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f579e11a830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f579e11a830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f5737044f80> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f5737044f80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4097)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:17:07 (running for 00:16:11.51)<br>Memory usage on this node: 2.5/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">   val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_eabdbffc</td><td>RUNNING   </td><td>172.28.0.2:4097</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">   0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">   0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">  16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">   5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">   0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">   0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">   0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">   0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">   0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">   0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">   0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">   0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\">3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">   0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\">2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">   0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\"> 133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">   0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">   0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "</tbody>\n",
              "</table><br>... 30 more trials not shown (30 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/5 [=====>........................] - ETA: 20s - loss: 0.7054 - accuracy: 0.5000 - f1_m: 0.5000 - precision_m: 0.5333 - recall_m: 0.4706\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7583 - accuracy: 0.5417 - f1_m: 0.6564 - precision_m: 0.5379 - recall_m: 0.8941 \n",
            "Result for train_mnist_eabdbffc:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-17-10\n",
            "  done: false\n",
            "  experiment_id: 93ced75ec9c3491db63b8064c06e3d32\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.758294939994812\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4097\n",
            "  time_since_restore: 14.241926193237305\n",
            "  time_this_iter_s: 14.241926193237305\n",
            "  time_total_s: 14.241926193237305\n",
            "  timestamp: 1653211030\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: eabdbffc\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 85.81880187988281\n",
            "  warmup_time: 0.003145933151245117\n",
            "  \n",
            "Result for train_mnist_eabdbffc:\n",
            "  accuracy: 0.5416666865348816\n",
            "  date: 2022-05-22_09-17-10\n",
            "  done: true\n",
            "  experiment_id: 93ced75ec9c3491db63b8064c06e3d32\n",
            "  experiment_tag: 50_batch_size=16,conv_block1_filters=64,conv_block2_filters=128,conv_block3_filters=64,conv_block4_filters=512,conv_block5_filters=32,dropout_rate=0.3,fc1_units=64,fc_layer_type=convolution,lr=0.1,pool_type=max\n",
            "  hostname: 30dabd0cfd92\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.758294939994812\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4097\n",
            "  time_since_restore: 14.241926193237305\n",
            "  time_this_iter_s: 14.241926193237305\n",
            "  time_total_s: 14.241926193237305\n",
            "  timestamp: 1653211030\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: eabdbffc\n",
            "  val_accuracy: 0.45945945382118225\n",
            "  val_loss: 85.81880187988281\n",
            "  warmup_time: 0.003145933151245117\n",
            "  \n",
            "5/5 [==============================] - 6s 182ms/step - loss: 0.7583 - accuracy: 0.5417 - f1_m: 0.6564 - precision_m: 0.5379 - recall_m: 0.8941 - val_loss: 85.8188 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-05-22 09:17:10 (running for 00:16:14.20)<br>Memory usage on this node: 3.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 40.000: None | Iter 10.000: None<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.33 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/train_mnist_2022-05-22_09-00-56<br>Number of trials: 50/50 (50 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  conv_block2_filters</th><th style=\"text-align: right;\">  conv_block3_filters</th><th style=\"text-align: right;\">  conv_block4_filters</th><th style=\"text-align: right;\">  conv_block5_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_b0ed70e4</td><td>TERMINATED</td><td>172.28.0.2:577 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.4207</td><td style=\"text-align: right;\">0.764899</td><td style=\"text-align: right;\">  441.328   </td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c36f447c</td><td>TERMINATED</td><td>172.28.0.2:660 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8165</td><td style=\"text-align: right;\">0.717972</td><td style=\"text-align: right;\">25683.1     </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_cde06864</td><td>TERMINATED</td><td>172.28.0.2:733 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0841</td><td style=\"text-align: right;\">0.845404</td><td style=\"text-align: right;\">    1.85961 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_d96f7256</td><td>TERMINATED</td><td>172.28.0.2:808 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8537</td><td style=\"text-align: right;\">0.772038</td><td style=\"text-align: right;\">    2.21364 </td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_e3eeca74</td><td>TERMINATED</td><td>172.28.0.2:878 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8836</td><td style=\"text-align: right;\">0.733925</td><td style=\"text-align: right;\">    0.694567</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_eeb5b9f4</td><td>TERMINATED</td><td>172.28.0.2:948 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2086</td><td style=\"text-align: right;\">0.685072</td><td style=\"text-align: right;\">    0.693085</td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_facf12e4</td><td>TERMINATED</td><td>172.28.0.2:1022</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1038</td><td style=\"text-align: right;\">0.684473</td><td style=\"text-align: right;\">    0.69111 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_057c5cba</td><td>TERMINATED</td><td>172.28.0.2:1094</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2409</td><td style=\"text-align: right;\">0.776577</td><td style=\"text-align: right;\">    0.686265</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_105b4a06</td><td>TERMINATED</td><td>172.28.0.2:1167</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1451</td><td style=\"text-align: right;\">0.807462</td><td style=\"text-align: right;\">   16.0268  </td><td style=\"text-align: right;\">  0.479167</td></tr>\n",
              "<tr><td>train_mnist_1af5ee4e</td><td>TERMINATED</td><td>172.28.0.2:1236</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1759</td><td style=\"text-align: right;\">0.985682</td><td style=\"text-align: right;\">    0.674932</td><td style=\"text-align: right;\">  0.472222</td></tr>\n",
              "<tr><td>train_mnist_26f48228</td><td>TERMINATED</td><td>172.28.0.2:1309</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1818</td><td style=\"text-align: right;\">0.683747</td><td style=\"text-align: right;\">    0.694095</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_32d62b46</td><td>TERMINATED</td><td>172.28.0.2:1378</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2313</td><td style=\"text-align: right;\">0.76407 </td><td style=\"text-align: right;\">    0.671774</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_3edc7f8a</td><td>TERMINATED</td><td>172.28.0.2:1451</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0332</td><td style=\"text-align: right;\">0.82227 </td><td style=\"text-align: right;\">    0.693587</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_496a691c</td><td>TERMINATED</td><td>172.28.0.2:1526</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2873</td><td style=\"text-align: right;\">0.756511</td><td style=\"text-align: right;\"> 3863.82    </td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_55717afc</td><td>TERMINATED</td><td>172.28.0.2:1598</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7901</td><td style=\"text-align: right;\">0.699567</td><td style=\"text-align: right;\"> 2993.13    </td><td style=\"text-align: right;\">  0.493056</td></tr>\n",
              "<tr><td>train_mnist_5feb42f6</td><td>TERMINATED</td><td>172.28.0.2:1671</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.8901</td><td style=\"text-align: right;\">0.780946</td><td style=\"text-align: right;\">  133.925   </td><td style=\"text-align: right;\">  0.527778</td></tr>\n",
              "<tr><td>train_mnist_6aaf0ed4</td><td>TERMINATED</td><td>172.28.0.2:1743</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.0891</td><td style=\"text-align: right;\">1.79903 </td><td style=\"text-align: right;\">    0.682759</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_75949288</td><td>TERMINATED</td><td>172.28.0.2:1814</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.9524</td><td style=\"text-align: right;\">0.687617</td><td style=\"text-align: right;\">    0.719583</td><td style=\"text-align: right;\">  0.5     </td></tr>\n",
              "<tr><td>train_mnist_8034ff48</td><td>TERMINATED</td><td>172.28.0.2:1882</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1523</td><td style=\"text-align: right;\">0.94371 </td><td style=\"text-align: right;\">    0.692638</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_8b0920fc</td><td>TERMINATED</td><td>172.28.0.2:1953</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1893</td><td style=\"text-align: right;\">0.875613</td><td style=\"text-align: right;\">  389.131   </td><td style=\"text-align: right;\">  0.486111</td></tr>\n",
              "<tr><td>train_mnist_95ca9ffc</td><td>TERMINATED</td><td>172.28.0.2:2021</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2916</td><td style=\"text-align: right;\">0.742633</td><td style=\"text-align: right;\">    0.692636</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_a0981b58</td><td>TERMINATED</td><td>172.28.0.2:2089</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1979</td><td style=\"text-align: right;\">0.876439</td><td style=\"text-align: right;\">    0.694443</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_ac6fe19a</td><td>TERMINATED</td><td>172.28.0.2:2158</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1722</td><td style=\"text-align: right;\">1.05055 </td><td style=\"text-align: right;\">    0.691819</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_b866141a</td><td>TERMINATED</td><td>172.28.0.2:2231</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3306</td><td style=\"text-align: right;\">0.728253</td><td style=\"text-align: right;\">    0.695577</td><td style=\"text-align: right;\">  0.534722</td></tr>\n",
              "<tr><td>train_mnist_c47257e6</td><td>TERMINATED</td><td>172.28.0.2:2303</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4044</td><td style=\"text-align: right;\">0.917027</td><td style=\"text-align: right;\">    0.689593</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_d0ed5a52</td><td>TERMINATED</td><td>172.28.0.2:2373</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.5711</td><td style=\"text-align: right;\">0.71504 </td><td style=\"text-align: right;\">    0.693685</td><td style=\"text-align: right;\">  0.513889</td></tr>\n",
              "<tr><td>train_mnist_dbc93748</td><td>TERMINATED</td><td>172.28.0.2:2444</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.294 </td><td style=\"text-align: right;\">1.41122 </td><td style=\"text-align: right;\">    0.693193</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_e6efa17a</td><td>TERMINATED</td><td>172.28.0.2:2512</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1502</td><td style=\"text-align: right;\">0.764839</td><td style=\"text-align: right;\">    0.688372</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_f2c13cf2</td><td>TERMINATED</td><td>172.28.0.2:2580</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2408</td><td style=\"text-align: right;\">1.41182 </td><td style=\"text-align: right;\">    0.690493</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_fd9282ee</td><td>TERMINATED</td><td>172.28.0.2:2654</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1538</td><td style=\"text-align: right;\">0.931397</td><td style=\"text-align: right;\">    0.691682</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_096e863a</td><td>TERMINATED</td><td>172.28.0.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2486</td><td style=\"text-align: right;\">1.60847 </td><td style=\"text-align: right;\">    0.696412</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_1567a50c</td><td>TERMINATED</td><td>172.28.0.2:2801</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.3664</td><td style=\"text-align: right;\">0.841335</td><td style=\"text-align: right;\">    5.01469 </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_20460e00</td><td>TERMINATED</td><td>172.28.0.2:2874</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        256</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0653</td><td style=\"text-align: right;\">0.784859</td><td style=\"text-align: right;\">    0.692977</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_2c8df4de</td><td>TERMINATED</td><td>172.28.0.2:2944</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2537</td><td style=\"text-align: right;\">1.04226 </td><td style=\"text-align: right;\">    0.685592</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_389478fc</td><td>TERMINATED</td><td>172.28.0.2:3017</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0985</td><td style=\"text-align: right;\">0.725492</td><td style=\"text-align: right;\">    0.685092</td><td style=\"text-align: right;\">  0.5625  </td></tr>\n",
              "<tr><td>train_mnist_44709192</td><td>TERMINATED</td><td>172.28.0.2:3092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3635</td><td style=\"text-align: right;\">1.16592 </td><td style=\"text-align: right;\">    0.782421</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_50855102</td><td>TERMINATED</td><td>172.28.0.2:3165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.3767</td><td style=\"text-align: right;\">0.9175  </td><td style=\"text-align: right;\">    0.688172</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_5d0bfc64</td><td>TERMINATED</td><td>172.28.0.2:3238</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9844</td><td style=\"text-align: right;\">0.942992</td><td style=\"text-align: right;\">    0.691039</td><td style=\"text-align: right;\">  0.520833</td></tr>\n",
              "<tr><td>train_mnist_69570cb6</td><td>TERMINATED</td><td>172.28.0.2:3313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.4628</td><td style=\"text-align: right;\">0.899934</td><td style=\"text-align: right;\">    0.691934</td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_7457682c</td><td>TERMINATED</td><td>172.28.0.2:3385</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2552</td><td style=\"text-align: right;\">1.22595 </td><td style=\"text-align: right;\">    0.692717</td><td style=\"text-align: right;\">  0.451389</td></tr>\n",
              "<tr><td>train_mnist_7f9a9c04</td><td>TERMINATED</td><td>172.28.0.2:3458</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0627</td><td style=\"text-align: right;\">0.859987</td><td style=\"text-align: right;\">    0.690941</td><td style=\"text-align: right;\">  0.506944</td></tr>\n",
              "<tr><td>train_mnist_8be92fac</td><td>TERMINATED</td><td>172.28.0.2:3531</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.2936</td><td style=\"text-align: right;\">0.719809</td><td style=\"text-align: right;\">   99.756   </td><td style=\"text-align: right;\">  0.444444</td></tr>\n",
              "<tr><td>train_mnist_97fff4ba</td><td>TERMINATED</td><td>172.28.0.2:3601</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1598</td><td style=\"text-align: right;\">0.971147</td><td style=\"text-align: right;\">    5.52146 </td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_a3d5137e</td><td>TERMINATED</td><td>172.28.0.2:3669</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.9687</td><td style=\"text-align: right;\">0.822188</td><td style=\"text-align: right;\">    0.686397</td><td style=\"text-align: right;\">  0.569444</td></tr>\n",
              "<tr><td>train_mnist_afa3bbc4</td><td>TERMINATED</td><td>172.28.0.2:3740</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">        128</td><td>convolution    </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.315 </td><td style=\"text-align: right;\">1.45427 </td><td style=\"text-align: right;\">    0.709192</td><td style=\"text-align: right;\">  0.548611</td></tr>\n",
              "<tr><td>train_mnist_ba905858</td><td>TERMINATED</td><td>172.28.0.2:3807</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">        256</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.0061</td><td style=\"text-align: right;\">0.730888</td><td style=\"text-align: right;\">    0.692991</td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_c6538e26</td><td>TERMINATED</td><td>172.28.0.2:3881</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1963</td><td style=\"text-align: right;\">0.689648</td><td style=\"text-align: right;\">  636.8     </td><td style=\"text-align: right;\">  0.583333</td></tr>\n",
              "<tr><td>train_mnist_d253391a</td><td>TERMINATED</td><td>172.28.0.2:3954</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">         32</td><td>convolution    </td><td style=\"text-align: right;\">0.01  </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.4141</td><td style=\"text-align: right;\">0.677464</td><td style=\"text-align: right;\">    2.42029 </td><td style=\"text-align: right;\">  0.555556</td></tr>\n",
              "<tr><td>train_mnist_de69f702</td><td>TERMINATED</td><td>172.28.0.2:4026</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                  256</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">        512</td><td>dense          </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.1136</td><td style=\"text-align: right;\">0.730845</td><td style=\"text-align: right;\">    0.692856</td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "<tr><td>train_mnist_eabdbffc</td><td>TERMINATED</td><td>172.28.0.2:4097</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">                   64</td><td style=\"text-align: right;\">                  512</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">         64</td><td>convolution    </td><td style=\"text-align: right;\">0.1   </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2419</td><td style=\"text-align: right;\">0.758295</td><td style=\"text-align: right;\">   85.8188  </td><td style=\"text-align: right;\">  0.541667</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 09:17:10,600\tINFO tune.py:702 -- Total run time: 974.41 seconds (974.18 seconds for the tuning loop).\n"
          ]
        }
      ],
      "source": [
        "analysis = tune.run(train_mnist, num_samples=50, search_alg=search_alg,  scheduler=scheduler, resources_per_trial={'gpu': 1})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_config = analysis.get_best_config(metric=\"val_accuracy\", mode='max')"
      ],
      "metadata": {
        "id": "VBVHyGGOLdiy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfHqUIITX0Wp",
        "outputId": "584fd419-0340-40dc-ba77-c98447016c1c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 16,\n",
              " 'conv_block1_filters': 512,\n",
              " 'conv_block2_filters': 128,\n",
              " 'conv_block3_filters': 128,\n",
              " 'conv_block4_filters': 128,\n",
              " 'conv_block5_filters': 256,\n",
              " 'dropout_rate': 0.4,\n",
              " 'fc1_units': 128,\n",
              " 'fc_layer_type': 'convolution',\n",
              " 'lr': 0.001,\n",
              " 'pool_type': 'max'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_mnist(best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orD96f4nCmDX",
        "outputId": "ceee6dec-90bb-4ee7-ac82-b5c5d7f4ccca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20, 20)]          0         \n",
            "                                                                 \n",
            " conv1d_14 (Conv1D)          (None, 18, 512)           31232     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 18, 512)          2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 18, 512)           0         \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 16, 128)           196736    \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 16, 128)          512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 16, 128)           0         \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, 14, 128)           49280     \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 14, 128)          512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 14, 128)           0         \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 13, 128)           32896     \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 13, 128)          512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 13, 128)           0         \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 13, 256)           33024     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 13, 256)          1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 13, 256)           0         \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 13, 128)           32896     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 13, 128)           0         \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 13, 128)          512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 13, 128)           0         \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 13, 2)             258       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 13, 2)             0         \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 13, 2)            8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 2)                0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 381,453\n",
            "Trainable params: 378,889\n",
            "Non-trainable params: 2,564\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 25\n",
            "5/5 [==============================] - 3s 121ms/step - loss: 1.1797 - accuracy: 0.4514 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.7026 - val_accuracy: 0.4595 - val_f1_m: 0.6793 - val_precision_m: 0.5188 - val_recall_m: 1.0000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RayTune_20x20_acc=0.675.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}