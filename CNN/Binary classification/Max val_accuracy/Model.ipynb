{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjVxSG4yt-o"
      },
      "source": [
        "# Import libraies and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lU9kk9xU5K4-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "7bf2c867-072b-497a-ec03-60cf5356e362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUYbBj2yxpO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(43893, 1))\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block1_filters'], kernel_size=(8), strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv1D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv1D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vViFfkzJTH"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "import random\n",
        "\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oss9TBkZzMYA"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist(config):\n",
        "  path ='/content/drive/MyDrive/ART_Inv/CNN/Ray_Tune/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame.iloc[:,28:43921  ]   \n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      else:\n",
        "          Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.10, stratify = Y)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 43893 , 1)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 43893, 1)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # Create model\n",
        "  model = ConvNet(config)\n",
        "\n",
        "  # Compile model with losses and metrics\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', f1_m,precision_m, recall_m\n",
        "                           ])\n",
        "\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      epochs=100,\n",
        "                      validation_data=(X_test, yTest))\n",
        "\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "aLNKDqS6irI5"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        " 'conv_block1_filters': 8,\n",
        " 'dropout_rate': 0.3,\n",
        " 'fc1_units': 16,\n",
        " 'fc_layer_type': 'dense',\n",
        " 'lr': 0.01,\n",
        " 'pool_type': 'average'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyV830YbioOZ",
        "outputId": "154baad9-a946-4c8a-f5f4-f46a794b759d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 43886, 8)          72        \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 43886, 8)         32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 43886, 8)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 8)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 16)               64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 2)                8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357\n",
            "Trainable params: 305\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 101ms/step - loss: 0.7373 - accuracy: 0.5062 - f1_m: 0.5186 - precision_m: 0.6125 - recall_m: 0.4607 - val_loss: 0.6916 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7195 - accuracy: 0.5494 - f1_m: 0.4833 - precision_m: 0.4858 - recall_m: 0.4846 - val_loss: 0.6934 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6842 - accuracy: 0.6173 - f1_m: 0.6351 - precision_m: 0.6204 - recall_m: 0.6859 - val_loss: 0.6958 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6900 - accuracy: 0.5802 - f1_m: 0.6691 - precision_m: 0.6758 - recall_m: 0.6733 - val_loss: 0.6955 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.7053 - accuracy: 0.4938 - f1_m: 0.4028 - precision_m: 0.4411 - recall_m: 0.3849 - val_loss: 0.7002 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6646 - accuracy: 0.5556 - f1_m: 0.6373 - precision_m: 0.6611 - recall_m: 0.6353 - val_loss: 0.7087 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.7065 - accuracy: 0.5679 - f1_m: 0.6141 - precision_m: 0.5733 - recall_m: 0.6902 - val_loss: 0.7089 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6864 - accuracy: 0.5864 - f1_m: 0.6814 - precision_m: 0.6654 - recall_m: 0.7068 - val_loss: 0.7112 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.7084 - accuracy: 0.5062 - f1_m: 0.5837 - precision_m: 0.6022 - recall_m: 0.6063 - val_loss: 0.7119 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6934 - accuracy: 0.5556 - f1_m: 0.5317 - precision_m: 0.4727 - recall_m: 0.6104 - val_loss: 0.7201 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6755 - accuracy: 0.5864 - f1_m: 0.6524 - precision_m: 0.6596 - recall_m: 0.6982 - val_loss: 0.7037 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6788 - accuracy: 0.5679 - f1_m: 0.5320 - precision_m: 0.4834 - recall_m: 0.6001 - val_loss: 0.7041 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6802 - accuracy: 0.5802 - f1_m: 0.5431 - precision_m: 0.4967 - recall_m: 0.6126 - val_loss: 0.7089 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6959 - accuracy: 0.5556 - f1_m: 0.6752 - precision_m: 0.6352 - recall_m: 0.7272 - val_loss: 0.7055 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6775 - accuracy: 0.5494 - f1_m: 0.5085 - precision_m: 0.4813 - recall_m: 0.5509 - val_loss: 0.7082 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6587 - accuracy: 0.6481 - f1_m: 0.5870 - precision_m: 0.5367 - recall_m: 0.6497 - val_loss: 0.7102 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6609 - accuracy: 0.6049 - f1_m: 0.7073 - precision_m: 0.6777 - recall_m: 0.7505 - val_loss: 0.7195 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.7010 - accuracy: 0.5617 - f1_m: 0.6241 - precision_m: 0.6414 - recall_m: 0.6569 - val_loss: 0.7189 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.7017 - accuracy: 0.5494 - f1_m: 0.6181 - precision_m: 0.5493 - recall_m: 0.7311 - val_loss: 0.7078 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6850 - accuracy: 0.5247 - f1_m: 0.6510 - precision_m: 0.6161 - recall_m: 0.7059 - val_loss: 0.7018 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6710 - accuracy: 0.5864 - f1_m: 0.6518 - precision_m: 0.6500 - recall_m: 0.7095 - val_loss: 0.6944 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6814 - accuracy: 0.5432 - f1_m: 0.6809 - precision_m: 0.6261 - recall_m: 0.7837 - val_loss: 0.7012 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6586 - accuracy: 0.6111 - f1_m: 0.7325 - precision_m: 0.6666 - recall_m: 0.8307 - val_loss: 0.7171 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6746 - accuracy: 0.5926 - f1_m: 0.5600 - precision_m: 0.5052 - recall_m: 0.6373 - val_loss: 0.7252 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6555 - accuracy: 0.6358 - f1_m: 0.7349 - precision_m: 0.6862 - recall_m: 0.8032 - val_loss: 0.7331 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6793 - accuracy: 0.5802 - f1_m: 0.6966 - precision_m: 0.6496 - recall_m: 0.7609 - val_loss: 0.7035 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6811 - accuracy: 0.5741 - f1_m: 0.5440 - precision_m: 0.4903 - recall_m: 0.6255 - val_loss: 0.7111 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6750 - accuracy: 0.5988 - f1_m: 0.5547 - precision_m: 0.5067 - recall_m: 0.6321 - val_loss: 0.6962 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6714 - accuracy: 0.5617 - f1_m: 0.5285 - precision_m: 0.4806 - recall_m: 0.5946 - val_loss: 0.6965 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6865 - accuracy: 0.5679 - f1_m: 0.6919 - precision_m: 0.6408 - recall_m: 0.7643 - val_loss: 0.6849 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6696 - accuracy: 0.5741 - f1_m: 0.6581 - precision_m: 0.6411 - recall_m: 0.7339 - val_loss: 0.6881 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6756 - accuracy: 0.5679 - f1_m: 0.7094 - precision_m: 0.6444 - recall_m: 0.8219 - val_loss: 0.6921 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6823 - accuracy: 0.5679 - f1_m: 0.5492 - precision_m: 0.4793 - recall_m: 0.6456 - val_loss: 0.7029 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6678 - accuracy: 0.5679 - f1_m: 0.5408 - precision_m: 0.4827 - recall_m: 0.6192 - val_loss: 0.6871 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6850 - accuracy: 0.5926 - f1_m: 0.5489 - precision_m: 0.5046 - recall_m: 0.6139 - val_loss: 0.6871 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6741 - accuracy: 0.5679 - f1_m: 0.5477 - precision_m: 0.4785 - recall_m: 0.6467 - val_loss: 0.6843 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6808 - accuracy: 0.5741 - f1_m: 0.6929 - precision_m: 0.6458 - recall_m: 0.7590 - val_loss: 0.6881 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6746 - accuracy: 0.5802 - f1_m: 0.5470 - precision_m: 0.4885 - recall_m: 0.6326 - val_loss: 0.6933 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6841 - accuracy: 0.5556 - f1_m: 0.6174 - precision_m: 0.6429 - recall_m: 0.6296 - val_loss: 0.6855 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6679 - accuracy: 0.5988 - f1_m: 0.5697 - precision_m: 0.5017 - recall_m: 0.6596 - val_loss: 0.6886 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6900 - accuracy: 0.5617 - f1_m: 0.6334 - precision_m: 0.5609 - recall_m: 0.7577 - val_loss: 0.6854 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6768 - accuracy: 0.5988 - f1_m: 0.5411 - precision_m: 0.5109 - recall_m: 0.5893 - val_loss: 0.6834 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6891 - accuracy: 0.5432 - f1_m: 0.4858 - precision_m: 0.4799 - recall_m: 0.5071 - val_loss: 0.6849 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6778 - accuracy: 0.5432 - f1_m: 0.5971 - precision_m: 0.6369 - recall_m: 0.5935 - val_loss: 0.6827 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6787 - accuracy: 0.6049 - f1_m: 0.5605 - precision_m: 0.5076 - recall_m: 0.6306 - val_loss: 0.6881 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6815 - accuracy: 0.5802 - f1_m: 0.6373 - precision_m: 0.6516 - recall_m: 0.6664 - val_loss: 0.6862 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6840 - accuracy: 0.5617 - f1_m: 0.6322 - precision_m: 0.6399 - recall_m: 0.6774 - val_loss: 0.6873 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6768 - accuracy: 0.5988 - f1_m: 0.5711 - precision_m: 0.4929 - recall_m: 0.6829 - val_loss: 0.6818 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6731 - accuracy: 0.6235 - f1_m: 0.7306 - precision_m: 0.6804 - recall_m: 0.7981 - val_loss: 0.7232 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6682 - accuracy: 0.5494 - f1_m: 0.6352 - precision_m: 0.6302 - recall_m: 0.6897 - val_loss: 0.7008 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6666 - accuracy: 0.5741 - f1_m: 0.5470 - precision_m: 0.4849 - recall_m: 0.6388 - val_loss: 0.7163 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6783 - accuracy: 0.6173 - f1_m: 0.6852 - precision_m: 0.6640 - recall_m: 0.7655 - val_loss: 0.6942 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6663 - accuracy: 0.5741 - f1_m: 0.6577 - precision_m: 0.6451 - recall_m: 0.7314 - val_loss: 0.6699 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6792 - accuracy: 0.5741 - f1_m: 0.7014 - precision_m: 0.6422 - recall_m: 0.7991 - val_loss: 0.6678 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6838 - accuracy: 0.5679 - f1_m: 0.7034 - precision_m: 0.6338 - recall_m: 0.8244 - val_loss: 0.6914 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6730 - accuracy: 0.5926 - f1_m: 0.5738 - precision_m: 0.4945 - recall_m: 0.6920 - val_loss: 0.7076 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6793 - accuracy: 0.6235 - f1_m: 0.6952 - precision_m: 0.5934 - recall_m: 0.8587 - val_loss: 0.7086 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6715 - accuracy: 0.5864 - f1_m: 0.7142 - precision_m: 0.6497 - recall_m: 0.8291 - val_loss: 0.7241 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6726 - accuracy: 0.5926 - f1_m: 0.5697 - precision_m: 0.4897 - recall_m: 0.6849 - val_loss: 0.7003 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6781 - accuracy: 0.5988 - f1_m: 0.7294 - precision_m: 0.6512 - recall_m: 0.8652 - val_loss: 0.6946 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6827 - accuracy: 0.5494 - f1_m: 0.6914 - precision_m: 0.6215 - recall_m: 0.7944 - val_loss: 0.6556 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6711 - accuracy: 0.5617 - f1_m: 0.7014 - precision_m: 0.6344 - recall_m: 0.7956 - val_loss: 0.6615 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6721 - accuracy: 0.5679 - f1_m: 0.7108 - precision_m: 0.6373 - recall_m: 0.8304 - val_loss: 0.6659 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6528 - accuracy: 0.6173 - f1_m: 0.7358 - precision_m: 0.6719 - recall_m: 0.8252 - val_loss: 0.7196 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6680 - accuracy: 0.5802 - f1_m: 0.5505 - precision_m: 0.4920 - recall_m: 0.6385 - val_loss: 0.6687 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6790 - accuracy: 0.5679 - f1_m: 0.6297 - precision_m: 0.6461 - recall_m: 0.6510 - val_loss: 0.6664 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6815 - accuracy: 0.5802 - f1_m: 0.6532 - precision_m: 0.5690 - recall_m: 0.7877 - val_loss: 0.7083 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6625 - accuracy: 0.6111 - f1_m: 0.6691 - precision_m: 0.6710 - recall_m: 0.7187 - val_loss: 0.6633 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6678 - accuracy: 0.5802 - f1_m: 0.5462 - precision_m: 0.4907 - recall_m: 0.6287 - val_loss: 0.6692 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6804 - accuracy: 0.5556 - f1_m: 0.7032 - precision_m: 0.6304 - recall_m: 0.8331 - val_loss: 0.6615 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6507 - accuracy: 0.6296 - f1_m: 0.6964 - precision_m: 0.6751 - recall_m: 0.7808 - val_loss: 0.6517 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6787 - accuracy: 0.5494 - f1_m: 0.6464 - precision_m: 0.5453 - recall_m: 0.8071 - val_loss: 0.6566 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6789 - accuracy: 0.6173 - f1_m: 0.7422 - precision_m: 0.6619 - recall_m: 0.8616 - val_loss: 0.6466 - val_accuracy: 0.7368 - val_f1_m: 0.7368 - val_precision_m: 0.7778 - val_recall_m: 0.7000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6788 - accuracy: 0.5988 - f1_m: 0.5761 - precision_m: 0.4935 - recall_m: 0.6987 - val_loss: 0.6562 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6804 - accuracy: 0.5617 - f1_m: 0.6618 - precision_m: 0.5508 - recall_m: 0.8529 - val_loss: 0.6729 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6771 - accuracy: 0.5988 - f1_m: 0.5720 - precision_m: 0.4952 - recall_m: 0.6803 - val_loss: 0.6633 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6772 - accuracy: 0.6049 - f1_m: 0.6717 - precision_m: 0.6612 - recall_m: 0.7338 - val_loss: 0.6528 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6768 - accuracy: 0.5802 - f1_m: 0.5579 - precision_m: 0.4844 - recall_m: 0.6725 - val_loss: 0.6757 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6681 - accuracy: 0.6296 - f1_m: 0.7408 - precision_m: 0.6752 - recall_m: 0.8413 - val_loss: 0.7777 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6731 - accuracy: 0.6111 - f1_m: 0.5807 - precision_m: 0.5034 - recall_m: 0.6908 - val_loss: 0.6825 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6831 - accuracy: 0.5741 - f1_m: 0.6477 - precision_m: 0.6385 - recall_m: 0.7114 - val_loss: 0.6683 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6649 - accuracy: 0.6420 - f1_m: 0.5957 - precision_m: 0.5198 - recall_m: 0.7087 - val_loss: 0.6843 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6841 - accuracy: 0.5494 - f1_m: 0.5369 - precision_m: 0.4662 - recall_m: 0.6411 - val_loss: 0.6601 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6764 - accuracy: 0.5494 - f1_m: 0.5287 - precision_m: 0.4704 - recall_m: 0.6073 - val_loss: 0.6615 - val_accuracy: 0.7368 - val_f1_m: 0.7826 - val_precision_m: 0.6923 - val_recall_m: 0.9000\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6648 - accuracy: 0.5741 - f1_m: 0.7126 - precision_m: 0.6453 - recall_m: 0.8109 - val_loss: 0.6491 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6642 - accuracy: 0.5802 - f1_m: 0.6630 - precision_m: 0.6483 - recall_m: 0.7369 - val_loss: 0.6631 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6662 - accuracy: 0.5679 - f1_m: 0.7031 - precision_m: 0.6412 - recall_m: 0.7984 - val_loss: 0.6509 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6624 - accuracy: 0.5864 - f1_m: 0.6621 - precision_m: 0.6479 - recall_m: 0.7389 - val_loss: 0.6475 - val_accuracy: 0.6316 - val_f1_m: 0.6667 - val_precision_m: 0.6364 - val_recall_m: 0.7000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6731 - accuracy: 0.5988 - f1_m: 0.6777 - precision_m: 0.6541 - recall_m: 0.7646 - val_loss: 0.6544 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6714 - accuracy: 0.5988 - f1_m: 0.5754 - precision_m: 0.4991 - recall_m: 0.6802 - val_loss: 0.6871 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6668 - accuracy: 0.6049 - f1_m: 0.5786 - precision_m: 0.4995 - recall_m: 0.6977 - val_loss: 0.6789 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6632 - accuracy: 0.6049 - f1_m: 0.7228 - precision_m: 0.6626 - recall_m: 0.8110 - val_loss: 0.6746 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6816 - accuracy: 0.5556 - f1_m: 0.5311 - precision_m: 0.4742 - recall_m: 0.6119 - val_loss: 0.6562 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6632 - accuracy: 0.6420 - f1_m: 0.6962 - precision_m: 0.6890 - recall_m: 0.7487 - val_loss: 0.6489 - val_accuracy: 0.6316 - val_f1_m: 0.7200 - val_precision_m: 0.6000 - val_recall_m: 0.9000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6607 - accuracy: 0.5926 - f1_m: 0.6538 - precision_m: 0.6576 - recall_m: 0.6960 - val_loss: 0.6516 - val_accuracy: 0.5263 - val_f1_m: 0.6667 - val_precision_m: 0.5294 - val_recall_m: 0.9000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6776 - accuracy: 0.5926 - f1_m: 0.6774 - precision_m: 0.6507 - recall_m: 0.7726 - val_loss: 0.6455 - val_accuracy: 0.7368 - val_f1_m: 0.7826 - val_precision_m: 0.6923 - val_recall_m: 0.9000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6627 - accuracy: 0.5926 - f1_m: 0.7208 - precision_m: 0.6460 - recall_m: 0.8367 - val_loss: 0.6355 - val_accuracy: 0.6842 - val_f1_m: 0.6250 - val_precision_m: 0.8333 - val_recall_m: 0.5000\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6631 - accuracy: 0.6049 - f1_m: 0.6800 - precision_m: 0.6592 - recall_m: 0.7593 - val_loss: 0.6210 - val_accuracy: 0.6842 - val_f1_m: 0.6250 - val_precision_m: 0.8333 - val_recall_m: 0.5000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6672 - accuracy: 0.6049 - f1_m: 0.6804 - precision_m: 0.6604 - recall_m: 0.7632 - val_loss: 0.6398 - val_accuracy: 0.6316 - val_f1_m: 0.7200 - val_precision_m: 0.6000 - val_recall_m: 0.9000\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6807 - accuracy: 0.5309 - f1_m: 0.5229 - precision_m: 0.4580 - recall_m: 0.6269 - val_loss: 0.6345 - val_accuracy: 0.6842 - val_f1_m: 0.7273 - val_precision_m: 0.6667 - val_recall_m: 0.8000\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 43886, 8)          72        \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 43886, 8)         32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 43886, 8)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_3   (None, 8)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357\n",
            "Trainable params: 305\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 93ms/step - loss: 0.6949 - accuracy: 0.6173 - f1_m: 0.6629 - precision_m: 0.7116 - recall_m: 0.6290 - val_loss: 0.6925 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.7178 - accuracy: 0.5185 - f1_m: 0.5350 - precision_m: 0.5417 - recall_m: 0.5635 - val_loss: 0.6928 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.7118 - accuracy: 0.5432 - f1_m: 0.5807 - precision_m: 0.6644 - recall_m: 0.5373 - val_loss: 0.6936 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7025 - accuracy: 0.5370 - f1_m: 0.5440 - precision_m: 0.6447 - recall_m: 0.4879 - val_loss: 0.6927 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6835 - accuracy: 0.5432 - f1_m: 0.4643 - precision_m: 0.4868 - recall_m: 0.4615 - val_loss: 0.6941 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6847 - accuracy: 0.5802 - f1_m: 0.6389 - precision_m: 0.6730 - recall_m: 0.6169 - val_loss: 0.6952 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.7023 - accuracy: 0.5432 - f1_m: 0.6085 - precision_m: 0.6461 - recall_m: 0.5795 - val_loss: 0.6995 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6740 - accuracy: 0.5432 - f1_m: 0.6408 - precision_m: 0.6431 - recall_m: 0.6518 - val_loss: 0.7050 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6729 - accuracy: 0.5926 - f1_m: 0.4878 - precision_m: 0.5311 - recall_m: 0.4562 - val_loss: 0.7049 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.7073 - accuracy: 0.5185 - f1_m: 0.4386 - precision_m: 0.4724 - recall_m: 0.4212 - val_loss: 0.7114 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6717 - accuracy: 0.6235 - f1_m: 0.5394 - precision_m: 0.5627 - recall_m: 0.5289 - val_loss: 0.7183 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6717 - accuracy: 0.5864 - f1_m: 0.6838 - precision_m: 0.6713 - recall_m: 0.7280 - val_loss: 0.7103 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6906 - accuracy: 0.5370 - f1_m: 0.6033 - precision_m: 0.6468 - recall_m: 0.5735 - val_loss: 0.7071 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.7135 - accuracy: 0.4753 - f1_m: 0.3747 - precision_m: 0.4295 - recall_m: 0.3343 - val_loss: 0.7145 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6743 - accuracy: 0.5432 - f1_m: 0.5297 - precision_m: 0.6762 - recall_m: 0.4739 - val_loss: 0.7075 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6369 - accuracy: 0.6235 - f1_m: 0.6068 - precision_m: 0.7335 - recall_m: 0.5279 - val_loss: 0.7041 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6588 - accuracy: 0.5802 - f1_m: 0.6235 - precision_m: 0.6659 - recall_m: 0.6185 - val_loss: 0.7013 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6838 - accuracy: 0.5370 - f1_m: 0.4816 - precision_m: 0.4894 - recall_m: 0.5339 - val_loss: 0.6994 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6558 - accuracy: 0.5802 - f1_m: 0.6879 - precision_m: 0.6585 - recall_m: 0.7266 - val_loss: 0.7030 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6617 - accuracy: 0.5741 - f1_m: 0.5436 - precision_m: 0.4857 - recall_m: 0.6233 - val_loss: 0.7108 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6885 - accuracy: 0.5185 - f1_m: 0.6081 - precision_m: 0.6161 - recall_m: 0.6532 - val_loss: 0.7143 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6606 - accuracy: 0.6235 - f1_m: 0.5719 - precision_m: 0.5192 - recall_m: 0.6434 - val_loss: 0.7161 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6594 - accuracy: 0.5802 - f1_m: 0.6391 - precision_m: 0.6566 - recall_m: 0.6613 - val_loss: 0.7107 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6527 - accuracy: 0.6049 - f1_m: 0.5529 - precision_m: 0.5098 - recall_m: 0.6104 - val_loss: 0.7189 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6914 - accuracy: 0.5617 - f1_m: 0.6672 - precision_m: 0.6480 - recall_m: 0.7033 - val_loss: 0.7334 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6625 - accuracy: 0.5802 - f1_m: 0.5339 - precision_m: 0.4992 - recall_m: 0.5797 - val_loss: 0.7169 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6715 - accuracy: 0.5802 - f1_m: 0.5476 - precision_m: 0.4899 - recall_m: 0.6340 - val_loss: 0.7050 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6752 - accuracy: 0.5679 - f1_m: 0.6220 - precision_m: 0.6455 - recall_m: 0.6419 - val_loss: 0.6970 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6872 - accuracy: 0.5370 - f1_m: 0.5120 - precision_m: 0.4690 - recall_m: 0.5703 - val_loss: 0.6984 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6810 - accuracy: 0.5370 - f1_m: 0.4998 - precision_m: 0.4736 - recall_m: 0.5343 - val_loss: 0.7017 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6879 - accuracy: 0.5185 - f1_m: 0.6199 - precision_m: 0.6208 - recall_m: 0.6629 - val_loss: 0.7246 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6661 - accuracy: 0.5741 - f1_m: 0.6333 - precision_m: 0.6570 - recall_m: 0.6471 - val_loss: 0.7181 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6614 - accuracy: 0.5432 - f1_m: 0.6085 - precision_m: 0.6271 - recall_m: 0.6399 - val_loss: 0.7228 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6599 - accuracy: 0.5617 - f1_m: 0.6935 - precision_m: 0.6405 - recall_m: 0.7708 - val_loss: 0.7196 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6806 - accuracy: 0.5802 - f1_m: 0.7009 - precision_m: 0.6502 - recall_m: 0.7830 - val_loss: 0.7199 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6544 - accuracy: 0.5988 - f1_m: 0.5390 - precision_m: 0.5052 - recall_m: 0.5803 - val_loss: 0.7110 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6602 - accuracy: 0.6481 - f1_m: 0.7267 - precision_m: 0.7120 - recall_m: 0.7491 - val_loss: 0.7440 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6757 - accuracy: 0.5741 - f1_m: 0.5249 - precision_m: 0.4989 - recall_m: 0.5759 - val_loss: 0.7785 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6709 - accuracy: 0.5679 - f1_m: 0.6329 - precision_m: 0.6430 - recall_m: 0.6665 - val_loss: 0.7367 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6688 - accuracy: 0.5802 - f1_m: 0.5552 - precision_m: 0.4899 - recall_m: 0.6484 - val_loss: 0.7264 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6560 - accuracy: 0.6111 - f1_m: 0.6843 - precision_m: 0.6624 - recall_m: 0.7674 - val_loss: 0.7204 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6813 - accuracy: 0.5432 - f1_m: 0.6349 - precision_m: 0.6225 - recall_m: 0.7140 - val_loss: 0.7144 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6839 - accuracy: 0.5741 - f1_m: 0.5615 - precision_m: 0.4802 - recall_m: 0.6794 - val_loss: 0.6986 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6656 - accuracy: 0.5926 - f1_m: 0.5658 - precision_m: 0.4929 - recall_m: 0.6691 - val_loss: 0.7168 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6629 - accuracy: 0.6235 - f1_m: 0.6854 - precision_m: 0.6722 - recall_m: 0.7543 - val_loss: 0.7104 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6574 - accuracy: 0.6296 - f1_m: 0.6984 - precision_m: 0.5898 - recall_m: 0.8827 - val_loss: 0.6954 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6582 - accuracy: 0.5741 - f1_m: 0.7056 - precision_m: 0.6440 - recall_m: 0.7896 - val_loss: 0.7176 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6532 - accuracy: 0.5988 - f1_m: 0.5658 - precision_m: 0.5048 - recall_m: 0.6606 - val_loss: 0.7294 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6621 - accuracy: 0.5926 - f1_m: 0.5486 - precision_m: 0.5014 - recall_m: 0.6332 - val_loss: 0.7133 - val_accuracy: 0.4211 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6647 - accuracy: 0.5802 - f1_m: 0.6399 - precision_m: 0.6553 - recall_m: 0.6699 - val_loss: 0.7378 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6593 - accuracy: 0.5617 - f1_m: 0.6357 - precision_m: 0.6414 - recall_m: 0.6969 - val_loss: 0.7294 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6647 - accuracy: 0.5679 - f1_m: 0.6320 - precision_m: 0.6442 - recall_m: 0.6606 - val_loss: 0.6996 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6811 - accuracy: 0.5741 - f1_m: 0.5311 - precision_m: 0.4854 - recall_m: 0.5947 - val_loss: 0.6900 - val_accuracy: 0.5789 - val_f1_m: 0.6667 - val_precision_m: 0.5714 - val_recall_m: 0.8000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6609 - accuracy: 0.6358 - f1_m: 0.6948 - precision_m: 0.5975 - recall_m: 0.8538 - val_loss: 0.6918 - val_accuracy: 0.4737 - val_f1_m: 0.6154 - val_precision_m: 0.5000 - val_recall_m: 0.8000\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6818 - accuracy: 0.5988 - f1_m: 0.5493 - precision_m: 0.5079 - recall_m: 0.6085 - val_loss: 0.7265 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6638 - accuracy: 0.6049 - f1_m: 0.6589 - precision_m: 0.6742 - recall_m: 0.6819 - val_loss: 0.7089 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6413 - accuracy: 0.6049 - f1_m: 0.7148 - precision_m: 0.6662 - recall_m: 0.7894 - val_loss: 0.7205 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6729 - accuracy: 0.5802 - f1_m: 0.6905 - precision_m: 0.6550 - recall_m: 0.7373 - val_loss: 0.7325 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6527 - accuracy: 0.5988 - f1_m: 0.5653 - precision_m: 0.4992 - recall_m: 0.6633 - val_loss: 0.6981 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6644 - accuracy: 0.6358 - f1_m: 0.7319 - precision_m: 0.6910 - recall_m: 0.7830 - val_loss: 0.6930 - val_accuracy: 0.6316 - val_f1_m: 0.5882 - val_precision_m: 0.7143 - val_recall_m: 0.5000\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.6688 - accuracy: 0.5988 - f1_m: 0.6921 - precision_m: 0.6719 - recall_m: 0.7235 - val_loss: 0.9474 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6551 - accuracy: 0.6049 - f1_m: 0.6435 - precision_m: 0.6807 - recall_m: 0.6379 - val_loss: 0.7220 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6612 - accuracy: 0.5926 - f1_m: 0.5356 - precision_m: 0.5150 - recall_m: 0.5883 - val_loss: 0.8065 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6645 - accuracy: 0.5864 - f1_m: 0.5296 - precision_m: 0.5013 - recall_m: 0.5708 - val_loss: 0.7663 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6570 - accuracy: 0.5988 - f1_m: 0.5351 - precision_m: 0.5202 - recall_m: 0.5547 - val_loss: 0.7365 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6679 - accuracy: 0.5617 - f1_m: 0.6648 - precision_m: 0.6458 - recall_m: 0.6882 - val_loss: 0.7496 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6674 - accuracy: 0.5802 - f1_m: 0.6696 - precision_m: 0.6690 - recall_m: 0.6776 - val_loss: 0.7205 - val_accuracy: 0.4737 - val_f1_m: 0.2857 - val_precision_m: 0.5000 - val_recall_m: 0.2000\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6545 - accuracy: 0.6111 - f1_m: 0.6815 - precision_m: 0.6967 - recall_m: 0.6764 - val_loss: 0.7084 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6792 - accuracy: 0.6235 - f1_m: 0.5513 - precision_m: 0.5314 - recall_m: 0.5787 - val_loss: 0.8318 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6696 - accuracy: 0.5679 - f1_m: 0.5169 - precision_m: 0.4841 - recall_m: 0.5650 - val_loss: 0.7219 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6653 - accuracy: 0.6173 - f1_m: 0.6723 - precision_m: 0.6844 - recall_m: 0.7206 - val_loss: 0.7503 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6674 - accuracy: 0.5741 - f1_m: 0.6451 - precision_m: 0.6488 - recall_m: 0.6906 - val_loss: 0.7784 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6550 - accuracy: 0.6049 - f1_m: 0.5749 - precision_m: 0.4989 - recall_m: 0.6840 - val_loss: 0.7804 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6673 - accuracy: 0.5864 - f1_m: 0.5520 - precision_m: 0.4921 - recall_m: 0.6322 - val_loss: 0.8521 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.6561 - accuracy: 0.6111 - f1_m: 0.7156 - precision_m: 0.6751 - recall_m: 0.7734 - val_loss: 0.8298 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.6455 - accuracy: 0.6235 - f1_m: 0.7219 - precision_m: 0.6870 - recall_m: 0.7778 - val_loss: 0.9831 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.6578 - accuracy: 0.5741 - f1_m: 0.5283 - precision_m: 0.4995 - recall_m: 0.5796 - val_loss: 0.7712 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6609 - accuracy: 0.6481 - f1_m: 0.6836 - precision_m: 0.7057 - recall_m: 0.6986 - val_loss: 0.8617 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.6724 - accuracy: 0.6049 - f1_m: 0.5522 - precision_m: 0.5145 - recall_m: 0.6028 - val_loss: 0.7496 - val_accuracy: 0.4211 - val_f1_m: 0.1538 - val_precision_m: 0.3333 - val_recall_m: 0.1000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.6574 - accuracy: 0.5988 - f1_m: 0.5338 - precision_m: 0.5128 - recall_m: 0.5676 - val_loss: 0.8030 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.6719 - accuracy: 0.6173 - f1_m: 0.7151 - precision_m: 0.6773 - recall_m: 0.7657 - val_loss: 0.9075 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.6585 - accuracy: 0.6296 - f1_m: 0.6789 - precision_m: 0.6867 - recall_m: 0.7149 - val_loss: 0.8721 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6757 - accuracy: 0.6235 - f1_m: 0.5774 - precision_m: 0.5196 - recall_m: 0.6554 - val_loss: 0.8485 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 1s 118ms/step - loss: 0.6461 - accuracy: 0.6358 - f1_m: 0.6784 - precision_m: 0.6839 - recall_m: 0.7179 - val_loss: 0.7102 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.6532 - accuracy: 0.6111 - f1_m: 0.5486 - precision_m: 0.5187 - recall_m: 0.5950 - val_loss: 0.6963 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6697 - accuracy: 0.5679 - f1_m: 0.6120 - precision_m: 0.6520 - recall_m: 0.6121 - val_loss: 0.6932 - val_accuracy: 0.6316 - val_f1_m: 0.6667 - val_precision_m: 0.6364 - val_recall_m: 0.7000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6497 - accuracy: 0.5741 - f1_m: 0.6924 - precision_m: 0.6485 - recall_m: 0.7523 - val_loss: 0.6984 - val_accuracy: 0.5789 - val_f1_m: 0.6364 - val_precision_m: 0.5833 - val_recall_m: 0.7000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6489 - accuracy: 0.5988 - f1_m: 0.5513 - precision_m: 0.5093 - recall_m: 0.6096 - val_loss: 0.6980 - val_accuracy: 0.5263 - val_f1_m: 0.6087 - val_precision_m: 0.5385 - val_recall_m: 0.7000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6749 - accuracy: 0.5864 - f1_m: 0.7011 - precision_m: 0.6525 - recall_m: 0.7675 - val_loss: 0.7117 - val_accuracy: 0.5263 - val_f1_m: 0.4000 - val_precision_m: 0.6000 - val_recall_m: 0.3000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6560 - accuracy: 0.6728 - f1_m: 0.6946 - precision_m: 0.7274 - recall_m: 0.6996 - val_loss: 0.7029 - val_accuracy: 0.6316 - val_f1_m: 0.6667 - val_precision_m: 0.6364 - val_recall_m: 0.7000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6468 - accuracy: 0.6481 - f1_m: 0.5878 - precision_m: 0.5347 - recall_m: 0.6577 - val_loss: 0.7403 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6433 - accuracy: 0.6235 - f1_m: 0.5674 - precision_m: 0.5317 - recall_m: 0.6282 - val_loss: 0.7005 - val_accuracy: 0.5263 - val_f1_m: 0.6400 - val_precision_m: 0.5333 - val_recall_m: 0.8000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6476 - accuracy: 0.6296 - f1_m: 0.7277 - precision_m: 0.6906 - recall_m: 0.7847 - val_loss: 0.7303 - val_accuracy: 0.5789 - val_f1_m: 0.5000 - val_precision_m: 0.6667 - val_recall_m: 0.4000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6645 - accuracy: 0.6235 - f1_m: 0.7195 - precision_m: 0.6827 - recall_m: 0.7654 - val_loss: 0.7158 - val_accuracy: 0.5789 - val_f1_m: 0.5556 - val_precision_m: 0.6250 - val_recall_m: 0.5000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6577 - accuracy: 0.6111 - f1_m: 0.5600 - precision_m: 0.5087 - recall_m: 0.6387 - val_loss: 0.7145 - val_accuracy: 0.6842 - val_f1_m: 0.7000 - val_precision_m: 0.7000 - val_recall_m: 0.7000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6639 - accuracy: 0.5617 - f1_m: 0.6226 - precision_m: 0.6402 - recall_m: 0.6462 - val_loss: 0.7155 - val_accuracy: 0.4737 - val_f1_m: 0.6429 - val_precision_m: 0.5000 - val_recall_m: 0.9000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6684 - accuracy: 0.5864 - f1_m: 0.5381 - precision_m: 0.4985 - recall_m: 0.5929 - val_loss: 0.8740 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6608 - accuracy: 0.6296 - f1_m: 0.5701 - precision_m: 0.5215 - recall_m: 0.6435 - val_loss: 0.8603 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6519 - accuracy: 0.6111 - f1_m: 0.6658 - precision_m: 0.5931 - recall_m: 0.7849 - val_loss: 0.7811 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6711 - accuracy: 0.6728 - f1_m: 0.6065 - precision_m: 0.5590 - recall_m: 0.6774 - val_loss: 0.7735 - val_accuracy: 0.3684 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 43886, 8)          72        \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 43886, 8)         32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 43886, 8)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_4   (None, 8)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357\n",
            "Trainable params: 305\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 99ms/step - loss: 0.7026 - accuracy: 0.5617 - f1_m: 0.5146 - precision_m: 0.4864 - recall_m: 0.5552 - val_loss: 0.6929 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6969 - accuracy: 0.5247 - f1_m: 0.5784 - precision_m: 0.6215 - recall_m: 0.5686 - val_loss: 0.6918 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6870 - accuracy: 0.5432 - f1_m: 0.6616 - precision_m: 0.6274 - recall_m: 0.7134 - val_loss: 0.6912 - val_accuracy: 0.5263 - val_f1_m: 0.6667 - val_precision_m: 0.5294 - val_recall_m: 0.9000\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6803 - accuracy: 0.5617 - f1_m: 0.6817 - precision_m: 0.6424 - recall_m: 0.7357 - val_loss: 0.6902 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6887 - accuracy: 0.5309 - f1_m: 0.6096 - precision_m: 0.6191 - recall_m: 0.6541 - val_loss: 0.6906 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6895 - accuracy: 0.5432 - f1_m: 0.5263 - precision_m: 0.4650 - recall_m: 0.6139 - val_loss: 0.6911 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6925 - accuracy: 0.5123 - f1_m: 0.5013 - precision_m: 0.4444 - recall_m: 0.5900 - val_loss: 0.6912 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6786 - accuracy: 0.5802 - f1_m: 0.5641 - precision_m: 0.4847 - recall_m: 0.6947 - val_loss: 0.6917 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6892 - accuracy: 0.5432 - f1_m: 0.6305 - precision_m: 0.6263 - recall_m: 0.6974 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6953 - accuracy: 0.5123 - f1_m: 0.6655 - precision_m: 0.6024 - recall_m: 0.7548 - val_loss: 0.6927 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6960 - accuracy: 0.5247 - f1_m: 0.6439 - precision_m: 0.5303 - recall_m: 0.8338 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6998 - accuracy: 0.4938 - f1_m: 0.6731 - precision_m: 0.5927 - recall_m: 0.7954 - val_loss: 0.6913 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6949 - accuracy: 0.4938 - f1_m: 0.5138 - precision_m: 0.4341 - recall_m: 0.6493 - val_loss: 0.6912 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6884 - accuracy: 0.5494 - f1_m: 0.5511 - precision_m: 0.4677 - recall_m: 0.6799 - val_loss: 0.6908 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6878 - accuracy: 0.5370 - f1_m: 0.6852 - precision_m: 0.6141 - recall_m: 0.7875 - val_loss: 0.6907 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6920 - accuracy: 0.5370 - f1_m: 0.6999 - precision_m: 0.6162 - recall_m: 0.8237 - val_loss: 0.6902 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6691 - accuracy: 0.6420 - f1_m: 0.7631 - precision_m: 0.6762 - recall_m: 0.8937 - val_loss: 0.6900 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6758 - accuracy: 0.5741 - f1_m: 0.6970 - precision_m: 0.6331 - recall_m: 0.7922 - val_loss: 0.6908 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6996 - accuracy: 0.5617 - f1_m: 0.5436 - precision_m: 0.4754 - recall_m: 0.6395 - val_loss: 0.6901 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6885 - accuracy: 0.5432 - f1_m: 0.6375 - precision_m: 0.6202 - recall_m: 0.7127 - val_loss: 0.6916 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6720 - accuracy: 0.5988 - f1_m: 0.7305 - precision_m: 0.6533 - recall_m: 0.8471 - val_loss: 0.6930 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6712 - accuracy: 0.5988 - f1_m: 0.6797 - precision_m: 0.5774 - recall_m: 0.8480 - val_loss: 0.6924 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6782 - accuracy: 0.5370 - f1_m: 0.6851 - precision_m: 0.6188 - recall_m: 0.7877 - val_loss: 0.6863 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6766 - accuracy: 0.6111 - f1_m: 0.5768 - precision_m: 0.5041 - recall_m: 0.6760 - val_loss: 0.6873 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6913 - accuracy: 0.5062 - f1_m: 0.4851 - precision_m: 0.4464 - recall_m: 0.5506 - val_loss: 0.6875 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6846 - accuracy: 0.5679 - f1_m: 0.6807 - precision_m: 0.6448 - recall_m: 0.7261 - val_loss: 0.6858 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6751 - accuracy: 0.5617 - f1_m: 0.5134 - precision_m: 0.4860 - recall_m: 0.5454 - val_loss: 0.6885 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6772 - accuracy: 0.5864 - f1_m: 0.6853 - precision_m: 0.6556 - recall_m: 0.7293 - val_loss: 0.6867 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6724 - accuracy: 0.5494 - f1_m: 0.6664 - precision_m: 0.6307 - recall_m: 0.7166 - val_loss: 0.6843 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6844 - accuracy: 0.5309 - f1_m: 0.6493 - precision_m: 0.6203 - recall_m: 0.6842 - val_loss: 0.6840 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6622 - accuracy: 0.5926 - f1_m: 0.6885 - precision_m: 0.6658 - recall_m: 0.7214 - val_loss: 0.6811 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6852 - accuracy: 0.5802 - f1_m: 0.5173 - precision_m: 0.5070 - recall_m: 0.5326 - val_loss: 0.6804 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6981 - accuracy: 0.5679 - f1_m: 0.6804 - precision_m: 0.6521 - recall_m: 0.7169 - val_loss: 0.6814 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6844 - accuracy: 0.5185 - f1_m: 0.6447 - precision_m: 0.6128 - recall_m: 0.6863 - val_loss: 0.6810 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6949 - accuracy: 0.5309 - f1_m: 0.4982 - precision_m: 0.4631 - recall_m: 0.5511 - val_loss: 0.6817 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6819 - accuracy: 0.5802 - f1_m: 0.6797 - precision_m: 0.6569 - recall_m: 0.7081 - val_loss: 0.6786 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6734 - accuracy: 0.5679 - f1_m: 0.5222 - precision_m: 0.4975 - recall_m: 0.5641 - val_loss: 0.6801 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6908 - accuracy: 0.5864 - f1_m: 0.6937 - precision_m: 0.6599 - recall_m: 0.7361 - val_loss: 0.6795 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6835 - accuracy: 0.5494 - f1_m: 0.6768 - precision_m: 0.6317 - recall_m: 0.7375 - val_loss: 0.6770 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6681 - accuracy: 0.5679 - f1_m: 0.5250 - precision_m: 0.4838 - recall_m: 0.5832 - val_loss: 0.6801 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6740 - accuracy: 0.5679 - f1_m: 0.6762 - precision_m: 0.6536 - recall_m: 0.7136 - val_loss: 0.6710 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6696 - accuracy: 0.5679 - f1_m: 0.6235 - precision_m: 0.6473 - recall_m: 0.6337 - val_loss: 0.6697 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6867 - accuracy: 0.5617 - f1_m: 0.5203 - precision_m: 0.4791 - recall_m: 0.5826 - val_loss: 0.6716 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6756 - accuracy: 0.5432 - f1_m: 0.5120 - precision_m: 0.4675 - recall_m: 0.5727 - val_loss: 0.6621 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6904 - accuracy: 0.5494 - f1_m: 0.5201 - precision_m: 0.4690 - recall_m: 0.5947 - val_loss: 0.6653 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6720 - accuracy: 0.5679 - f1_m: 0.6981 - precision_m: 0.6409 - recall_m: 0.7807 - val_loss: 0.6586 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6756 - accuracy: 0.5617 - f1_m: 0.5199 - precision_m: 0.4827 - recall_m: 0.5714 - val_loss: 0.6666 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6775 - accuracy: 0.5741 - f1_m: 0.6908 - precision_m: 0.6467 - recall_m: 0.7501 - val_loss: 0.6948 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6657 - accuracy: 0.5988 - f1_m: 0.7232 - precision_m: 0.6569 - recall_m: 0.8148 - val_loss: 0.6916 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6808 - accuracy: 0.5556 - f1_m: 0.5344 - precision_m: 0.4733 - recall_m: 0.6201 - val_loss: 0.6742 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6773 - accuracy: 0.5617 - f1_m: 0.6372 - precision_m: 0.6451 - recall_m: 0.6872 - val_loss: 0.6781 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6803 - accuracy: 0.5864 - f1_m: 0.6480 - precision_m: 0.6581 - recall_m: 0.6791 - val_loss: 0.6640 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6848 - accuracy: 0.5679 - f1_m: 0.6514 - precision_m: 0.6404 - recall_m: 0.7211 - val_loss: 0.6711 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6759 - accuracy: 0.5556 - f1_m: 0.6933 - precision_m: 0.6289 - recall_m: 0.7838 - val_loss: 0.6596 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6843 - accuracy: 0.5617 - f1_m: 0.6404 - precision_m: 0.6446 - recall_m: 0.7115 - val_loss: 0.6540 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6733 - accuracy: 0.5741 - f1_m: 0.7128 - precision_m: 0.6414 - recall_m: 0.8126 - val_loss: 0.6585 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6845 - accuracy: 0.5185 - f1_m: 0.5056 - precision_m: 0.4534 - recall_m: 0.5764 - val_loss: 0.6541 - val_accuracy: 0.7368 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6929 - accuracy: 0.5741 - f1_m: 0.6546 - precision_m: 0.6447 - recall_m: 0.7219 - val_loss: 0.6564 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6904 - accuracy: 0.5432 - f1_m: 0.5462 - precision_m: 0.4609 - recall_m: 0.6789 - val_loss: 0.6513 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6752 - accuracy: 0.5802 - f1_m: 0.5628 - precision_m: 0.4819 - recall_m: 0.6835 - val_loss: 0.6531 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6781 - accuracy: 0.6049 - f1_m: 0.7400 - precision_m: 0.6597 - recall_m: 0.8727 - val_loss: 0.6363 - val_accuracy: 0.5789 - val_f1_m: 0.6923 - val_precision_m: 0.5625 - val_recall_m: 0.9000\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6760 - accuracy: 0.5741 - f1_m: 0.6721 - precision_m: 0.5551 - recall_m: 0.8699 - val_loss: 0.6360 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6712 - accuracy: 0.5802 - f1_m: 0.7220 - precision_m: 0.6398 - recall_m: 0.8530 - val_loss: 0.6404 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6972 - accuracy: 0.5309 - f1_m: 0.6207 - precision_m: 0.6238 - recall_m: 0.7086 - val_loss: 0.6788 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6724 - accuracy: 0.5494 - f1_m: 0.6497 - precision_m: 0.6259 - recall_m: 0.7490 - val_loss: 0.6553 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6806 - accuracy: 0.5556 - f1_m: 0.7129 - precision_m: 0.6294 - recall_m: 0.8631 - val_loss: 0.6340 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6779 - accuracy: 0.5741 - f1_m: 0.5602 - precision_m: 0.4766 - recall_m: 0.6899 - val_loss: 0.6658 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6800 - accuracy: 0.5617 - f1_m: 0.6496 - precision_m: 0.6310 - recall_m: 0.7241 - val_loss: 0.6517 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6739 - accuracy: 0.5370 - f1_m: 0.5352 - precision_m: 0.4568 - recall_m: 0.6519 - val_loss: 0.6519 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6767 - accuracy: 0.5926 - f1_m: 0.5600 - precision_m: 0.4937 - recall_m: 0.6554 - val_loss: 0.6595 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6886 - accuracy: 0.5679 - f1_m: 0.7091 - precision_m: 0.6325 - recall_m: 0.8274 - val_loss: 0.6487 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6870 - accuracy: 0.5556 - f1_m: 0.6477 - precision_m: 0.5527 - recall_m: 0.8020 - val_loss: 0.6795 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6738 - accuracy: 0.5802 - f1_m: 0.7228 - precision_m: 0.6415 - recall_m: 0.8446 - val_loss: 0.6920 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6847 - accuracy: 0.5556 - f1_m: 0.5105 - precision_m: 0.4745 - recall_m: 0.5637 - val_loss: 0.6535 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6828 - accuracy: 0.5926 - f1_m: 0.5506 - precision_m: 0.4982 - recall_m: 0.6181 - val_loss: 0.6897 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6790 - accuracy: 0.5556 - f1_m: 0.6701 - precision_m: 0.6318 - recall_m: 0.7265 - val_loss: 0.7952 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6725 - accuracy: 0.5370 - f1_m: 0.6583 - precision_m: 0.6319 - recall_m: 0.7106 - val_loss: 0.6295 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6819 - accuracy: 0.5617 - f1_m: 0.5180 - precision_m: 0.4833 - recall_m: 0.5656 - val_loss: 0.6697 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6784 - accuracy: 0.5617 - f1_m: 0.6780 - precision_m: 0.6386 - recall_m: 0.7342 - val_loss: 0.7025 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6822 - accuracy: 0.5617 - f1_m: 0.6671 - precision_m: 0.6410 - recall_m: 0.7046 - val_loss: 0.7572 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6874 - accuracy: 0.5617 - f1_m: 0.6261 - precision_m: 0.6418 - recall_m: 0.6473 - val_loss: 0.8686 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6953 - accuracy: 0.5679 - f1_m: 0.6525 - precision_m: 0.5614 - recall_m: 0.7964 - val_loss: 0.7721 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6761 - accuracy: 0.5802 - f1_m: 0.6987 - precision_m: 0.6431 - recall_m: 0.7853 - val_loss: 0.8680 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6593 - accuracy: 0.6049 - f1_m: 0.7129 - precision_m: 0.6679 - recall_m: 0.7797 - val_loss: 0.7673 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6873 - accuracy: 0.6049 - f1_m: 0.7213 - precision_m: 0.6656 - recall_m: 0.8008 - val_loss: 0.6049 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.7084 - accuracy: 0.5864 - f1_m: 0.5376 - precision_m: 0.4852 - recall_m: 0.6109 - val_loss: 0.6309 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6737 - accuracy: 0.5679 - f1_m: 0.6919 - precision_m: 0.6404 - recall_m: 0.7597 - val_loss: 0.5985 - val_accuracy: 0.7895 - val_f1_m: 0.8182 - val_precision_m: 0.7500 - val_recall_m: 0.9000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6701 - accuracy: 0.5617 - f1_m: 0.5382 - precision_m: 0.4788 - recall_m: 0.6265 - val_loss: 0.6014 - val_accuracy: 0.8947 - val_f1_m: 0.8889 - val_precision_m: 1.0000 - val_recall_m: 0.8000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6912 - accuracy: 0.5432 - f1_m: 0.5126 - precision_m: 0.4630 - recall_m: 0.5768 - val_loss: 0.6062 - val_accuracy: 0.8947 - val_f1_m: 0.8889 - val_precision_m: 1.0000 - val_recall_m: 0.8000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6697 - accuracy: 0.5802 - f1_m: 0.5289 - precision_m: 0.4983 - recall_m: 0.5893 - val_loss: 0.6270 - val_accuracy: 0.6842 - val_f1_m: 0.7500 - val_precision_m: 0.6429 - val_recall_m: 0.9000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6796 - accuracy: 0.5802 - f1_m: 0.5361 - precision_m: 0.4958 - recall_m: 0.5893 - val_loss: 0.6207 - val_accuracy: 0.8947 - val_f1_m: 0.8889 - val_precision_m: 1.0000 - val_recall_m: 0.8000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6849 - accuracy: 0.5494 - f1_m: 0.6310 - precision_m: 0.6292 - recall_m: 0.6858 - val_loss: 0.6299 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6693 - accuracy: 0.5864 - f1_m: 0.5599 - precision_m: 0.4856 - recall_m: 0.6654 - val_loss: 0.6337 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6832 - accuracy: 0.5679 - f1_m: 0.6467 - precision_m: 0.6430 - recall_m: 0.7128 - val_loss: 0.6491 - val_accuracy: 0.8947 - val_f1_m: 0.9000 - val_precision_m: 0.9000 - val_recall_m: 0.9000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6722 - accuracy: 0.5864 - f1_m: 0.6634 - precision_m: 0.6473 - recall_m: 0.7392 - val_loss: 0.6349 - val_accuracy: 0.8421 - val_f1_m: 0.8235 - val_precision_m: 1.0000 - val_recall_m: 0.7000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6803 - accuracy: 0.5679 - f1_m: 0.6651 - precision_m: 0.6339 - recall_m: 0.7707 - val_loss: 0.6208 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6819 - accuracy: 0.5494 - f1_m: 0.6454 - precision_m: 0.6271 - recall_m: 0.7257 - val_loss: 0.6198 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6709 - accuracy: 0.5802 - f1_m: 0.5645 - precision_m: 0.4759 - recall_m: 0.7035 - val_loss: 0.6107 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6658 - accuracy: 0.5864 - f1_m: 0.6669 - precision_m: 0.6460 - recall_m: 0.7557 - val_loss: 0.6617 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6686 - accuracy: 0.5617 - f1_m: 0.6598 - precision_m: 0.6291 - recall_m: 0.7644 - val_loss: 0.6094 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 43886, 8)          72        \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 43886, 8)         32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 43886, 8)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_5   (None, 8)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357\n",
            "Trainable params: 305\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 97ms/step - loss: 0.8551 - accuracy: 0.4753 - f1_m: 0.3824 - precision_m: 0.4295 - recall_m: 0.3494 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.7496 - accuracy: 0.4938 - f1_m: 0.4145 - precision_m: 0.4470 - recall_m: 0.3914 - val_loss: 0.6917 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.7500 - accuracy: 0.4815 - f1_m: 0.3683 - precision_m: 0.4491 - recall_m: 0.3195 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.7515 - accuracy: 0.4815 - f1_m: 0.3805 - precision_m: 0.4342 - recall_m: 0.3427 - val_loss: 0.6921 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6695 - accuracy: 0.5926 - f1_m: 0.6303 - precision_m: 0.7108 - recall_m: 0.5739 - val_loss: 0.6925 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.7158 - accuracy: 0.5247 - f1_m: 0.4211 - precision_m: 0.4983 - recall_m: 0.3814 - val_loss: 0.6919 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.7054 - accuracy: 0.5123 - f1_m: 0.5171 - precision_m: 0.6222 - recall_m: 0.4562 - val_loss: 0.6923 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.7408 - accuracy: 0.4630 - f1_m: 0.3617 - precision_m: 0.4165 - recall_m: 0.3262 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6858 - accuracy: 0.5309 - f1_m: 0.5650 - precision_m: 0.6311 - recall_m: 0.5349 - val_loss: 0.6924 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6880 - accuracy: 0.5494 - f1_m: 0.6491 - precision_m: 0.6554 - recall_m: 0.6709 - val_loss: 0.6921 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6910 - accuracy: 0.5432 - f1_m: 0.6446 - precision_m: 0.6456 - recall_m: 0.6570 - val_loss: 0.6922 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6926 - accuracy: 0.5617 - f1_m: 0.4665 - precision_m: 0.5076 - recall_m: 0.4586 - val_loss: 0.6929 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6852 - accuracy: 0.5556 - f1_m: 0.4412 - precision_m: 0.4997 - recall_m: 0.3991 - val_loss: 0.6938 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6757 - accuracy: 0.5617 - f1_m: 0.5895 - precision_m: 0.6829 - recall_m: 0.5303 - val_loss: 0.6941 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6745 - accuracy: 0.5432 - f1_m: 0.5608 - precision_m: 0.6512 - recall_m: 0.5041 - val_loss: 0.6945 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6992 - accuracy: 0.5802 - f1_m: 0.5317 - precision_m: 0.7101 - recall_m: 0.4277 - val_loss: 0.6924 - val_accuracy: 0.6842 - val_f1_m: 0.7273 - val_precision_m: 0.6667 - val_recall_m: 0.8000\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6962 - accuracy: 0.5247 - f1_m: 0.5751 - precision_m: 0.5503 - recall_m: 0.6472 - val_loss: 0.6920 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6693 - accuracy: 0.5802 - f1_m: 0.5155 - precision_m: 0.5002 - recall_m: 0.5575 - val_loss: 0.6900 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6760 - accuracy: 0.5679 - f1_m: 0.4729 - precision_m: 0.5138 - recall_m: 0.4483 - val_loss: 0.6923 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6690 - accuracy: 0.5556 - f1_m: 0.5419 - precision_m: 0.6688 - recall_m: 0.4688 - val_loss: 0.6907 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6955 - accuracy: 0.5432 - f1_m: 0.5474 - precision_m: 0.6630 - recall_m: 0.4920 - val_loss: 0.6886 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6843 - accuracy: 0.5370 - f1_m: 0.6333 - precision_m: 0.6234 - recall_m: 0.6546 - val_loss: 0.6896 - val_accuracy: 0.6316 - val_f1_m: 0.6957 - val_precision_m: 0.6154 - val_recall_m: 0.8000\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6942 - accuracy: 0.6111 - f1_m: 0.6742 - precision_m: 0.6616 - recall_m: 0.7421 - val_loss: 0.6887 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6915 - accuracy: 0.5494 - f1_m: 0.6602 - precision_m: 0.6218 - recall_m: 0.7764 - val_loss: 0.6891 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6847 - accuracy: 0.5741 - f1_m: 0.5686 - precision_m: 0.4747 - recall_m: 0.7248 - val_loss: 0.6882 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6753 - accuracy: 0.5864 - f1_m: 0.5711 - precision_m: 0.4796 - recall_m: 0.7176 - val_loss: 0.6897 - val_accuracy: 0.5263 - val_f1_m: 0.6667 - val_precision_m: 0.5294 - val_recall_m: 0.9000\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6721 - accuracy: 0.5864 - f1_m: 0.7150 - precision_m: 0.6568 - recall_m: 0.8326 - val_loss: 0.6887 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6724 - accuracy: 0.5802 - f1_m: 0.5465 - precision_m: 0.4906 - recall_m: 0.6283 - val_loss: 0.6884 - val_accuracy: 0.5263 - val_f1_m: 0.6667 - val_precision_m: 0.5294 - val_recall_m: 0.9000\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6803 - accuracy: 0.5494 - f1_m: 0.6826 - precision_m: 0.6279 - recall_m: 0.7527 - val_loss: 0.6817 - val_accuracy: 0.6316 - val_f1_m: 0.6957 - val_precision_m: 0.6154 - val_recall_m: 0.8000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6794 - accuracy: 0.5370 - f1_m: 0.5978 - precision_m: 0.5559 - recall_m: 0.6949 - val_loss: 0.6845 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6596 - accuracy: 0.6235 - f1_m: 0.6743 - precision_m: 0.6064 - recall_m: 0.7931 - val_loss: 0.6878 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6811 - accuracy: 0.5741 - f1_m: 0.6610 - precision_m: 0.6410 - recall_m: 0.7484 - val_loss: 0.6797 - val_accuracy: 0.7368 - val_f1_m: 0.7059 - val_precision_m: 0.8571 - val_recall_m: 0.6000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6852 - accuracy: 0.5432 - f1_m: 0.5341 - precision_m: 0.4611 - recall_m: 0.6386 - val_loss: 0.6846 - val_accuracy: 0.6316 - val_f1_m: 0.5333 - val_precision_m: 0.8000 - val_recall_m: 0.4000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6665 - accuracy: 0.5802 - f1_m: 0.5780 - precision_m: 0.4801 - recall_m: 0.7287 - val_loss: 0.6854 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6712 - accuracy: 0.5864 - f1_m: 0.5576 - precision_m: 0.4914 - recall_m: 0.6517 - val_loss: 0.6968 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6635 - accuracy: 0.6173 - f1_m: 0.6699 - precision_m: 0.6747 - recall_m: 0.7076 - val_loss: 0.7008 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6754 - accuracy: 0.5926 - f1_m: 0.5579 - precision_m: 0.5020 - recall_m: 0.6619 - val_loss: 0.7377 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6940 - accuracy: 0.5247 - f1_m: 0.5064 - precision_m: 0.4531 - recall_m: 0.5769 - val_loss: 0.7231 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6820 - accuracy: 0.5988 - f1_m: 0.5401 - precision_m: 0.5057 - recall_m: 0.5940 - val_loss: 0.7281 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6831 - accuracy: 0.6111 - f1_m: 0.5405 - precision_m: 0.5251 - recall_m: 0.5591 - val_loss: 0.7244 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6923 - accuracy: 0.5494 - f1_m: 0.5106 - precision_m: 0.4712 - recall_m: 0.5665 - val_loss: 0.7177 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6689 - accuracy: 0.6173 - f1_m: 0.5509 - precision_m: 0.5257 - recall_m: 0.5812 - val_loss: 0.7422 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6787 - accuracy: 0.5741 - f1_m: 0.5139 - precision_m: 0.4966 - recall_m: 0.5374 - val_loss: 0.7773 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6825 - accuracy: 0.5123 - f1_m: 0.5459 - precision_m: 0.6151 - recall_m: 0.5160 - val_loss: 0.7581 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6877 - accuracy: 0.5247 - f1_m: 0.4800 - precision_m: 0.4536 - recall_m: 0.5210 - val_loss: 0.7018 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6863 - accuracy: 0.5432 - f1_m: 0.6655 - precision_m: 0.6499 - recall_m: 0.7273 - val_loss: 0.6981 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6842 - accuracy: 0.5432 - f1_m: 0.6750 - precision_m: 0.6284 - recall_m: 0.7394 - val_loss: 0.7095 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6735 - accuracy: 0.5556 - f1_m: 0.6857 - precision_m: 0.6365 - recall_m: 0.7587 - val_loss: 0.7674 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6688 - accuracy: 0.5988 - f1_m: 0.7189 - precision_m: 0.6602 - recall_m: 0.7981 - val_loss: 0.8383 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6934 - accuracy: 0.5370 - f1_m: 0.5105 - precision_m: 0.4634 - recall_m: 0.5758 - val_loss: 0.7687 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6656 - accuracy: 0.5988 - f1_m: 0.5720 - precision_m: 0.4994 - recall_m: 0.6828 - val_loss: 0.7064 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6653 - accuracy: 0.5802 - f1_m: 0.6409 - precision_m: 0.5724 - recall_m: 0.7570 - val_loss: 0.6680 - val_accuracy: 0.5789 - val_f1_m: 0.4286 - val_precision_m: 0.7500 - val_recall_m: 0.3000\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6802 - accuracy: 0.5309 - f1_m: 0.5956 - precision_m: 0.6235 - recall_m: 0.6081 - val_loss: 0.6679 - val_accuracy: 0.5789 - val_f1_m: 0.4286 - val_precision_m: 0.7500 - val_recall_m: 0.3000\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6720 - accuracy: 0.5432 - f1_m: 0.5234 - precision_m: 0.4650 - recall_m: 0.6004 - val_loss: 0.7105 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6801 - accuracy: 0.5370 - f1_m: 0.5606 - precision_m: 0.6371 - recall_m: 0.5277 - val_loss: 0.6817 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6746 - accuracy: 0.5741 - f1_m: 0.6846 - precision_m: 0.6424 - recall_m: 0.7386 - val_loss: 0.7752 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6918 - accuracy: 0.5741 - f1_m: 0.6949 - precision_m: 0.6478 - recall_m: 0.7548 - val_loss: 0.8086 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6718 - accuracy: 0.5802 - f1_m: 0.5501 - precision_m: 0.4875 - recall_m: 0.6344 - val_loss: 0.6697 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6736 - accuracy: 0.5741 - f1_m: 0.7086 - precision_m: 0.6421 - recall_m: 0.8014 - val_loss: 0.7233 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6700 - accuracy: 0.5494 - f1_m: 0.6814 - precision_m: 0.6327 - recall_m: 0.7492 - val_loss: 0.7208 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6731 - accuracy: 0.5741 - f1_m: 0.6481 - precision_m: 0.5701 - recall_m: 0.7852 - val_loss: 0.6895 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6774 - accuracy: 0.5926 - f1_m: 0.6541 - precision_m: 0.6566 - recall_m: 0.6969 - val_loss: 0.6865 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6857 - accuracy: 0.5741 - f1_m: 0.6473 - precision_m: 0.6443 - recall_m: 0.7013 - val_loss: 0.7018 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6828 - accuracy: 0.5494 - f1_m: 0.5244 - precision_m: 0.4689 - recall_m: 0.6068 - val_loss: 0.6947 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6686 - accuracy: 0.5679 - f1_m: 0.6553 - precision_m: 0.6390 - recall_m: 0.7308 - val_loss: 0.6555 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6716 - accuracy: 0.5679 - f1_m: 0.6604 - precision_m: 0.5559 - recall_m: 0.8239 - val_loss: 0.6406 - val_accuracy: 0.7368 - val_f1_m: 0.7059 - val_precision_m: 0.8571 - val_recall_m: 0.6000\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6767 - accuracy: 0.5494 - f1_m: 0.6455 - precision_m: 0.6260 - recall_m: 0.7374 - val_loss: 0.6507 - val_accuracy: 0.5789 - val_f1_m: 0.4286 - val_precision_m: 0.7500 - val_recall_m: 0.3000\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6696 - accuracy: 0.5741 - f1_m: 0.7200 - precision_m: 0.6366 - recall_m: 0.8424 - val_loss: 0.6225 - val_accuracy: 0.7368 - val_f1_m: 0.7619 - val_precision_m: 0.7273 - val_recall_m: 0.8000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6671 - accuracy: 0.5741 - f1_m: 0.6527 - precision_m: 0.6480 - recall_m: 0.7103 - val_loss: 0.6253 - val_accuracy: 0.5789 - val_f1_m: 0.6667 - val_precision_m: 0.5714 - val_recall_m: 0.8000\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6860 - accuracy: 0.5679 - f1_m: 0.6630 - precision_m: 0.6339 - recall_m: 0.7598 - val_loss: 0.6170 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6816 - accuracy: 0.5556 - f1_m: 0.5597 - precision_m: 0.4636 - recall_m: 0.7307 - val_loss: 0.6227 - val_accuracy: 0.7368 - val_f1_m: 0.7059 - val_precision_m: 0.8571 - val_recall_m: 0.6000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6687 - accuracy: 0.5864 - f1_m: 0.7353 - precision_m: 0.6434 - recall_m: 0.8882 - val_loss: 0.6189 - val_accuracy: 0.7368 - val_f1_m: 0.7368 - val_precision_m: 0.7778 - val_recall_m: 0.7000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6811 - accuracy: 0.5802 - f1_m: 0.5717 - precision_m: 0.4822 - recall_m: 0.7121 - val_loss: 0.6553 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6710 - accuracy: 0.5864 - f1_m: 0.5614 - precision_m: 0.4877 - recall_m: 0.6670 - val_loss: 0.6852 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6628 - accuracy: 0.6111 - f1_m: 0.7112 - precision_m: 0.6746 - recall_m: 0.7699 - val_loss: 0.6233 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6758 - accuracy: 0.6111 - f1_m: 0.6540 - precision_m: 0.6654 - recall_m: 0.6867 - val_loss: 0.6374 - val_accuracy: 0.7368 - val_f1_m: 0.7368 - val_precision_m: 0.7778 - val_recall_m: 0.7000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6881 - accuracy: 0.5679 - f1_m: 0.5462 - precision_m: 0.4749 - recall_m: 0.6475 - val_loss: 0.6543 - val_accuracy: 0.5789 - val_f1_m: 0.4286 - val_precision_m: 0.7500 - val_recall_m: 0.3000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6804 - accuracy: 0.5741 - f1_m: 0.5442 - precision_m: 0.4831 - recall_m: 0.6264 - val_loss: 0.6620 - val_accuracy: 0.5263 - val_f1_m: 0.6400 - val_precision_m: 0.5333 - val_recall_m: 0.8000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6867 - accuracy: 0.5617 - f1_m: 0.5382 - precision_m: 0.4790 - recall_m: 0.6354 - val_loss: 0.6631 - val_accuracy: 0.5789 - val_f1_m: 0.4286 - val_precision_m: 0.7500 - val_recall_m: 0.3000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6826 - accuracy: 0.5679 - f1_m: 0.6273 - precision_m: 0.6330 - recall_m: 0.6650 - val_loss: 0.6838 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6741 - accuracy: 0.5802 - f1_m: 0.7192 - precision_m: 0.6435 - recall_m: 0.8340 - val_loss: 0.7380 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6671 - accuracy: 0.5802 - f1_m: 0.5490 - precision_m: 0.4898 - recall_m: 0.6314 - val_loss: 0.7455 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6795 - accuracy: 0.5494 - f1_m: 0.6328 - precision_m: 0.6334 - recall_m: 0.6900 - val_loss: 0.7369 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6770 - accuracy: 0.5432 - f1_m: 0.6261 - precision_m: 0.6266 - recall_m: 0.6705 - val_loss: 0.6842 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6798 - accuracy: 0.5741 - f1_m: 0.6723 - precision_m: 0.6389 - recall_m: 0.7861 - val_loss: 0.6668 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6675 - accuracy: 0.5864 - f1_m: 0.6722 - precision_m: 0.5666 - recall_m: 0.8437 - val_loss: 0.6239 - val_accuracy: 0.6842 - val_f1_m: 0.6250 - val_precision_m: 0.8333 - val_recall_m: 0.5000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6729 - accuracy: 0.6111 - f1_m: 0.6916 - precision_m: 0.5783 - recall_m: 0.8781 - val_loss: 0.6193 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6566 - accuracy: 0.6481 - f1_m: 0.6015 - precision_m: 0.5268 - recall_m: 0.7115 - val_loss: 0.6146 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6809 - accuracy: 0.5802 - f1_m: 0.7078 - precision_m: 0.6469 - recall_m: 0.7920 - val_loss: 0.6180 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6827 - accuracy: 0.5802 - f1_m: 0.5549 - precision_m: 0.4858 - recall_m: 0.6528 - val_loss: 0.6290 - val_accuracy: 0.7368 - val_f1_m: 0.7368 - val_precision_m: 0.7778 - val_recall_m: 0.7000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6593 - accuracy: 0.6235 - f1_m: 0.6904 - precision_m: 0.5928 - recall_m: 0.8491 - val_loss: 0.6307 - val_accuracy: 0.6842 - val_f1_m: 0.7273 - val_precision_m: 0.6667 - val_recall_m: 0.8000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6800 - accuracy: 0.5617 - f1_m: 0.6914 - precision_m: 0.6371 - recall_m: 0.7657 - val_loss: 0.6383 - val_accuracy: 0.5789 - val_f1_m: 0.6923 - val_precision_m: 0.5625 - val_recall_m: 0.9000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6961 - accuracy: 0.5309 - f1_m: 0.5285 - precision_m: 0.4556 - recall_m: 0.6446 - val_loss: 0.6393 - val_accuracy: 0.7368 - val_f1_m: 0.7619 - val_precision_m: 0.7273 - val_recall_m: 0.8000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6850 - accuracy: 0.5556 - f1_m: 0.5396 - precision_m: 0.4720 - recall_m: 0.6385 - val_loss: 0.6500 - val_accuracy: 0.5789 - val_f1_m: 0.6667 - val_precision_m: 0.5714 - val_recall_m: 0.8000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6733 - accuracy: 0.5617 - f1_m: 0.6525 - precision_m: 0.6347 - recall_m: 0.7295 - val_loss: 0.6453 - val_accuracy: 0.6842 - val_f1_m: 0.7273 - val_precision_m: 0.6667 - val_recall_m: 0.8000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6659 - accuracy: 0.5864 - f1_m: 0.7246 - precision_m: 0.6400 - recall_m: 0.8540 - val_loss: 0.6235 - val_accuracy: 0.7368 - val_f1_m: 0.7368 - val_precision_m: 0.7778 - val_recall_m: 0.7000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6685 - accuracy: 0.6049 - f1_m: 0.5741 - precision_m: 0.4973 - recall_m: 0.6839 - val_loss: 0.6356 - val_accuracy: 0.6842 - val_f1_m: 0.7273 - val_precision_m: 0.6667 - val_recall_m: 0.8000\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6750 - accuracy: 0.5802 - f1_m: 0.7114 - precision_m: 0.6429 - recall_m: 0.8131 - val_loss: 0.6500 - val_accuracy: 0.5789 - val_f1_m: 0.7143 - val_precision_m: 0.5556 - val_recall_m: 1.0000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6653 - accuracy: 0.6111 - f1_m: 0.7309 - precision_m: 0.6661 - recall_m: 0.8258 - val_loss: 0.6202 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6693 - accuracy: 0.6049 - f1_m: 0.6558 - precision_m: 0.6555 - recall_m: 0.7028 - val_loss: 0.6121 - val_accuracy: 0.6842 - val_f1_m: 0.6667 - val_precision_m: 0.7500 - val_recall_m: 0.6000\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 43886, 8)          72        \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 43886, 8)         32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 43886, 8)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_6   (None, 8)                0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357\n",
            "Trainable params: 305\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 98ms/step - loss: 0.9569 - accuracy: 0.4815 - f1_m: 0.5497 - precision_m: 0.5832 - recall_m: 0.5223 - val_loss: 0.6995 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.8353 - accuracy: 0.4753 - f1_m: 0.5473 - precision_m: 0.5863 - recall_m: 0.5179 - val_loss: 0.6991 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.8328 - accuracy: 0.4691 - f1_m: 0.4915 - precision_m: 0.5676 - recall_m: 0.4486 - val_loss: 0.7022 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.8102 - accuracy: 0.5123 - f1_m: 0.6080 - precision_m: 0.6134 - recall_m: 0.6097 - val_loss: 0.6948 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.7851 - accuracy: 0.4877 - f1_m: 0.5199 - precision_m: 0.5949 - recall_m: 0.4866 - val_loss: 0.6943 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.7569 - accuracy: 0.4568 - f1_m: 0.4242 - precision_m: 0.4098 - recall_m: 0.4446 - val_loss: 0.6936 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.7307 - accuracy: 0.5494 - f1_m: 0.6288 - precision_m: 0.6418 - recall_m: 0.6246 - val_loss: 0.6927 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.7067 - accuracy: 0.5370 - f1_m: 0.5938 - precision_m: 0.5507 - recall_m: 0.6685 - val_loss: 0.6943 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6792 - accuracy: 0.5679 - f1_m: 0.6353 - precision_m: 0.6501 - recall_m: 0.6818 - val_loss: 0.6942 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.7075 - accuracy: 0.5247 - f1_m: 0.6188 - precision_m: 0.5336 - recall_m: 0.7576 - val_loss: 0.6982 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.7110 - accuracy: 0.5679 - f1_m: 0.6257 - precision_m: 0.6516 - recall_m: 0.6403 - val_loss: 0.6984 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6875 - accuracy: 0.5741 - f1_m: 0.6988 - precision_m: 0.6461 - recall_m: 0.7757 - val_loss: 0.6986 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7003 - accuracy: 0.5432 - f1_m: 0.6235 - precision_m: 0.5459 - recall_m: 0.7489 - val_loss: 0.6966 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.7108 - accuracy: 0.5185 - f1_m: 0.6001 - precision_m: 0.5378 - recall_m: 0.7168 - val_loss: 0.6986 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7026 - accuracy: 0.5494 - f1_m: 0.5075 - precision_m: 0.4749 - recall_m: 0.5774 - val_loss: 0.6983 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6892 - accuracy: 0.5494 - f1_m: 0.6627 - precision_m: 0.6470 - recall_m: 0.6974 - val_loss: 0.6962 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.7152 - accuracy: 0.5309 - f1_m: 0.4898 - precision_m: 0.4612 - recall_m: 0.5266 - val_loss: 0.6925 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7214 - accuracy: 0.5309 - f1_m: 0.6095 - precision_m: 0.5426 - recall_m: 0.7202 - val_loss: 0.6922 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6928 - accuracy: 0.5679 - f1_m: 0.6755 - precision_m: 0.6447 - recall_m: 0.7225 - val_loss: 0.6884 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6885 - accuracy: 0.5556 - f1_m: 0.5353 - precision_m: 0.4728 - recall_m: 0.6232 - val_loss: 0.6884 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6878 - accuracy: 0.5864 - f1_m: 0.6483 - precision_m: 0.5808 - recall_m: 0.7759 - val_loss: 0.6920 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6813 - accuracy: 0.5432 - f1_m: 0.5201 - precision_m: 0.4666 - recall_m: 0.6007 - val_loss: 0.6980 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.7110 - accuracy: 0.4938 - f1_m: 0.5643 - precision_m: 0.5170 - recall_m: 0.6505 - val_loss: 0.6950 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6674 - accuracy: 0.5864 - f1_m: 0.6471 - precision_m: 0.6537 - recall_m: 0.6913 - val_loss: 0.6883 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6785 - accuracy: 0.5741 - f1_m: 0.5430 - precision_m: 0.4824 - recall_m: 0.6274 - val_loss: 0.6866 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6603 - accuracy: 0.5988 - f1_m: 0.6543 - precision_m: 0.6681 - recall_m: 0.6815 - val_loss: 0.6847 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6883 - accuracy: 0.5494 - f1_m: 0.6180 - precision_m: 0.5545 - recall_m: 0.7189 - val_loss: 0.6836 - val_accuracy: 0.7895 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6776 - accuracy: 0.5741 - f1_m: 0.6963 - precision_m: 0.6383 - recall_m: 0.7758 - val_loss: 0.6806 - val_accuracy: 0.7895 - val_f1_m: 0.7500 - val_precision_m: 1.0000 - val_recall_m: 0.6000\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6858 - accuracy: 0.5556 - f1_m: 0.6875 - precision_m: 0.6210 - recall_m: 0.7809 - val_loss: 0.6819 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6782 - accuracy: 0.5679 - f1_m: 0.7076 - precision_m: 0.6344 - recall_m: 0.8172 - val_loss: 0.6815 - val_accuracy: 0.7895 - val_f1_m: 0.8333 - val_precision_m: 0.7143 - val_recall_m: 1.0000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6843 - accuracy: 0.5802 - f1_m: 0.6666 - precision_m: 0.5611 - recall_m: 0.8362 - val_loss: 0.6806 - val_accuracy: 0.7368 - val_f1_m: 0.7826 - val_precision_m: 0.6923 - val_recall_m: 0.9000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7054 - accuracy: 0.5185 - f1_m: 0.6880 - precision_m: 0.6076 - recall_m: 0.8068 - val_loss: 0.6818 - val_accuracy: 0.7895 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.7101 - accuracy: 0.5309 - f1_m: 0.5249 - precision_m: 0.4541 - recall_m: 0.6296 - val_loss: 0.6840 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6733 - accuracy: 0.6049 - f1_m: 0.7055 - precision_m: 0.6670 - recall_m: 0.7566 - val_loss: 0.6817 - val_accuracy: 0.5263 - val_f1_m: 0.1818 - val_precision_m: 1.0000 - val_recall_m: 0.1000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6840 - accuracy: 0.6049 - f1_m: 0.6803 - precision_m: 0.5810 - recall_m: 0.8356 - val_loss: 0.6815 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.7043 - accuracy: 0.5370 - f1_m: 0.6854 - precision_m: 0.6199 - recall_m: 0.7937 - val_loss: 0.6798 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6847 - accuracy: 0.5988 - f1_m: 0.5763 - precision_m: 0.4994 - recall_m: 0.6914 - val_loss: 0.6808 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6798 - accuracy: 0.5494 - f1_m: 0.6951 - precision_m: 0.6264 - recall_m: 0.7957 - val_loss: 0.6808 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6796 - accuracy: 0.5679 - f1_m: 0.6889 - precision_m: 0.6429 - recall_m: 0.7592 - val_loss: 0.6722 - val_accuracy: 0.7895 - val_f1_m: 0.8333 - val_precision_m: 0.7143 - val_recall_m: 1.0000\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6850 - accuracy: 0.5185 - f1_m: 0.6184 - precision_m: 0.5410 - recall_m: 0.7719 - val_loss: 0.6703 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6688 - accuracy: 0.6049 - f1_m: 0.7088 - precision_m: 0.6712 - recall_m: 0.7677 - val_loss: 0.6724 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6900 - accuracy: 0.5494 - f1_m: 0.5239 - precision_m: 0.4659 - recall_m: 0.6047 - val_loss: 0.6737 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6810 - accuracy: 0.5432 - f1_m: 0.6787 - precision_m: 0.6255 - recall_m: 0.7473 - val_loss: 0.6837 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6749 - accuracy: 0.5802 - f1_m: 0.7037 - precision_m: 0.6446 - recall_m: 0.7834 - val_loss: 0.6757 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6809 - accuracy: 0.5802 - f1_m: 0.6542 - precision_m: 0.6485 - recall_m: 0.7129 - val_loss: 0.6694 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6729 - accuracy: 0.5988 - f1_m: 0.5580 - precision_m: 0.5084 - recall_m: 0.6315 - val_loss: 0.6643 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6907 - accuracy: 0.5679 - f1_m: 0.5331 - precision_m: 0.4782 - recall_m: 0.6224 - val_loss: 0.6930 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6777 - accuracy: 0.5864 - f1_m: 0.7082 - precision_m: 0.6513 - recall_m: 0.7944 - val_loss: 0.6807 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6745 - accuracy: 0.5802 - f1_m: 0.7042 - precision_m: 0.6504 - recall_m: 0.7785 - val_loss: 0.6901 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6597 - accuracy: 0.5926 - f1_m: 0.7129 - precision_m: 0.6540 - recall_m: 0.7916 - val_loss: 0.6702 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6733 - accuracy: 0.5432 - f1_m: 0.6355 - precision_m: 0.5432 - recall_m: 0.7811 - val_loss: 0.6634 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6866 - accuracy: 0.5556 - f1_m: 0.5351 - precision_m: 0.4773 - recall_m: 0.6216 - val_loss: 0.6753 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6669 - accuracy: 0.5988 - f1_m: 0.7115 - precision_m: 0.6593 - recall_m: 0.7791 - val_loss: 0.6767 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6883 - accuracy: 0.5741 - f1_m: 0.5620 - precision_m: 0.4821 - recall_m: 0.6827 - val_loss: 0.7144 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6993 - accuracy: 0.5309 - f1_m: 0.5072 - precision_m: 0.4621 - recall_m: 0.5689 - val_loss: 0.7199 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6736 - accuracy: 0.5802 - f1_m: 0.6955 - precision_m: 0.6481 - recall_m: 0.7584 - val_loss: 0.7058 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6786 - accuracy: 0.5802 - f1_m: 0.6952 - precision_m: 0.6506 - recall_m: 0.7642 - val_loss: 0.6784 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6798 - accuracy: 0.6049 - f1_m: 0.5499 - precision_m: 0.5143 - recall_m: 0.5981 - val_loss: 0.6708 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6836 - accuracy: 0.5370 - f1_m: 0.5059 - precision_m: 0.4624 - recall_m: 0.5640 - val_loss: 0.6705 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6856 - accuracy: 0.5802 - f1_m: 0.5168 - precision_m: 0.5097 - recall_m: 0.5354 - val_loss: 0.6965 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6876 - accuracy: 0.5556 - f1_m: 0.6180 - precision_m: 0.6449 - recall_m: 0.6393 - val_loss: 0.6892 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6784 - accuracy: 0.6049 - f1_m: 0.7005 - precision_m: 0.6811 - recall_m: 0.7251 - val_loss: 0.6748 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6763 - accuracy: 0.5864 - f1_m: 0.6515 - precision_m: 0.5807 - recall_m: 0.7646 - val_loss: 0.6701 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6646 - accuracy: 0.5988 - f1_m: 0.6457 - precision_m: 0.6728 - recall_m: 0.6621 - val_loss: 0.6996 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6889 - accuracy: 0.5123 - f1_m: 0.6076 - precision_m: 0.6118 - recall_m: 0.6765 - val_loss: 0.6606 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6900 - accuracy: 0.5556 - f1_m: 0.7020 - precision_m: 0.6290 - recall_m: 0.8088 - val_loss: 0.6494 - val_accuracy: 0.7895 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6639 - accuracy: 0.5988 - f1_m: 0.5747 - precision_m: 0.4943 - recall_m: 0.6933 - val_loss: 0.6664 - val_accuracy: 0.7368 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6856 - accuracy: 0.5802 - f1_m: 0.5620 - precision_m: 0.4909 - recall_m: 0.6626 - val_loss: 0.6615 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6719 - accuracy: 0.5679 - f1_m: 0.6312 - precision_m: 0.6524 - recall_m: 0.6649 - val_loss: 0.6698 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6857 - accuracy: 0.5247 - f1_m: 0.5166 - precision_m: 0.4536 - recall_m: 0.6113 - val_loss: 0.6622 - val_accuracy: 0.4737 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6782 - accuracy: 0.5679 - f1_m: 0.5285 - precision_m: 0.4841 - recall_m: 0.5838 - val_loss: 0.6563 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.5679 - f1_m: 0.4917 - precision_m: 0.5050 - recall_m: 0.4941 - val_loss: 0.6529 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6775 - accuracy: 0.5185 - f1_m: 0.5686 - precision_m: 0.6151 - recall_m: 0.5662 - val_loss: 0.6521 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6871 - accuracy: 0.5864 - f1_m: 0.7079 - precision_m: 0.6559 - recall_m: 0.7810 - val_loss: 0.6442 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6739 - accuracy: 0.5926 - f1_m: 0.5463 - precision_m: 0.5022 - recall_m: 0.6118 - val_loss: 0.6488 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6687 - accuracy: 0.5617 - f1_m: 0.6697 - precision_m: 0.6389 - recall_m: 0.7086 - val_loss: 0.6310 - val_accuracy: 0.7895 - val_f1_m: 0.8333 - val_precision_m: 0.7143 - val_recall_m: 1.0000\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.6857 - accuracy: 0.5247 - f1_m: 0.6450 - precision_m: 0.6240 - recall_m: 0.6919 - val_loss: 0.6023 - val_accuracy: 0.7368 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6938 - accuracy: 0.5370 - f1_m: 0.6074 - precision_m: 0.6265 - recall_m: 0.6373 - val_loss: 0.6068 - val_accuracy: 0.8421 - val_f1_m: 0.8571 - val_precision_m: 0.8182 - val_recall_m: 0.9000\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6803 - accuracy: 0.5741 - f1_m: 0.5210 - precision_m: 0.4939 - recall_m: 0.5678 - val_loss: 0.6007 - val_accuracy: 0.6842 - val_f1_m: 0.6250 - val_precision_m: 0.8333 - val_recall_m: 0.5000\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6629 - accuracy: 0.5988 - f1_m: 0.6505 - precision_m: 0.5881 - recall_m: 0.7500 - val_loss: 0.6105 - val_accuracy: 0.7368 - val_f1_m: 0.8000 - val_precision_m: 0.6667 - val_recall_m: 1.0000\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6805 - accuracy: 0.5556 - f1_m: 0.5200 - precision_m: 0.4721 - recall_m: 0.5814 - val_loss: 0.6145 - val_accuracy: 0.6842 - val_f1_m: 0.5714 - val_precision_m: 1.0000 - val_recall_m: 0.4000\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6661 - accuracy: 0.5926 - f1_m: 0.7072 - precision_m: 0.6638 - recall_m: 0.7714 - val_loss: 0.6176 - val_accuracy: 0.7895 - val_f1_m: 0.7778 - val_precision_m: 0.8750 - val_recall_m: 0.7000\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6443 - accuracy: 0.6296 - f1_m: 0.7366 - precision_m: 0.6799 - recall_m: 0.8238 - val_loss: 0.6562 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.6695 - accuracy: 0.6049 - f1_m: 0.7299 - precision_m: 0.6604 - recall_m: 0.8421 - val_loss: 0.6624 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6883 - accuracy: 0.5494 - f1_m: 0.6790 - precision_m: 0.6304 - recall_m: 0.7489 - val_loss: 0.6712 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6698 - accuracy: 0.5988 - f1_m: 0.6505 - precision_m: 0.6666 - recall_m: 0.6752 - val_loss: 0.6578 - val_accuracy: 0.6316 - val_f1_m: 0.7407 - val_precision_m: 0.5882 - val_recall_m: 1.0000\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6577 - accuracy: 0.6049 - f1_m: 0.7227 - precision_m: 0.6622 - recall_m: 0.8026 - val_loss: 0.6592 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6763 - accuracy: 0.5988 - f1_m: 0.5476 - precision_m: 0.5036 - recall_m: 0.6048 - val_loss: 0.6259 - val_accuracy: 0.5789 - val_f1_m: 0.7143 - val_precision_m: 0.5556 - val_recall_m: 1.0000\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6688 - accuracy: 0.6173 - f1_m: 0.6722 - precision_m: 0.6721 - recall_m: 0.7245 - val_loss: 0.6120 - val_accuracy: 0.7895 - val_f1_m: 0.8182 - val_precision_m: 0.7500 - val_recall_m: 0.9000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6756 - accuracy: 0.5988 - f1_m: 0.5565 - precision_m: 0.5017 - recall_m: 0.6293 - val_loss: 0.6232 - val_accuracy: 0.7368 - val_f1_m: 0.8000 - val_precision_m: 0.6667 - val_recall_m: 1.0000\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6856 - accuracy: 0.5432 - f1_m: 0.6832 - precision_m: 0.6302 - recall_m: 0.7649 - val_loss: 0.6073 - val_accuracy: 0.7895 - val_f1_m: 0.8182 - val_precision_m: 0.7500 - val_recall_m: 0.9000\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6693 - accuracy: 0.5494 - f1_m: 0.6337 - precision_m: 0.6253 - recall_m: 0.6927 - val_loss: 0.6049 - val_accuracy: 0.7895 - val_f1_m: 0.8182 - val_precision_m: 0.7500 - val_recall_m: 0.9000\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6917 - accuracy: 0.5185 - f1_m: 0.6151 - precision_m: 0.6091 - recall_m: 0.6776 - val_loss: 0.6780 - val_accuracy: 0.5263 - val_f1_m: 0.6897 - val_precision_m: 0.5263 - val_recall_m: 1.0000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6832 - accuracy: 0.5370 - f1_m: 0.5232 - precision_m: 0.4574 - recall_m: 0.6178 - val_loss: 0.6097 - val_accuracy: 0.7368 - val_f1_m: 0.8000 - val_precision_m: 0.6667 - val_recall_m: 1.0000\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6506 - accuracy: 0.5926 - f1_m: 0.7049 - precision_m: 0.6578 - recall_m: 0.7776 - val_loss: 0.6220 - val_accuracy: 0.5789 - val_f1_m: 0.7143 - val_precision_m: 0.5556 - val_recall_m: 1.0000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6840 - accuracy: 0.5741 - f1_m: 0.6925 - precision_m: 0.6531 - recall_m: 0.7477 - val_loss: 0.5996 - val_accuracy: 0.7368 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.6975 - accuracy: 0.5309 - f1_m: 0.5155 - precision_m: 0.4648 - recall_m: 0.6070 - val_loss: 0.6058 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6764 - accuracy: 0.5926 - f1_m: 0.6349 - precision_m: 0.5980 - recall_m: 0.7118 - val_loss: 0.6526 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6822 - accuracy: 0.5741 - f1_m: 0.6670 - precision_m: 0.6492 - recall_m: 0.6979 - val_loss: 0.6529 - val_accuracy: 0.5789 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.6674 - accuracy: 0.6173 - f1_m: 0.6673 - precision_m: 0.6726 - recall_m: 0.7090 - val_loss: 0.6187 - val_accuracy: 0.6316 - val_f1_m: 0.4615 - val_precision_m: 1.0000 - val_recall_m: 0.3000\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  history = train_mnist(config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PXjVxSG4yt-o"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
