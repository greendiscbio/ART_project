{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjVxSG4yt-o"
      },
      "source": [
        "#Import libraies and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVA_ZA7c5BE0",
        "outputId": "529201f0-b215-4fa7-ee92-96397f94eb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.1.0-cp37-cp37m-manylinux2014_x86_64.whl (59.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.50.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.16.7-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray) (1.15.0)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (4.13.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray) (3.10.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Installing collected packages: platformdirs, distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 platformdirs-2.5.4 ray-2.1.0 virtualenv-20.16.7\n"
          ]
        }
      ],
      "source": [
        "pip install ray torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlaA55u5HNx",
        "outputId": "358c9dfe-3114-4f82-9390-bcd696f04a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.3.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU9kk9xU5K4-",
        "outputId": "6160a19f-966b-4294-a745-633cfbe405b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvgorDkMN429"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "dc5902d8-ab52-4854-9517-5d39e628ff44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUYbBj2yxpO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(43893, 1))\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block1_filters'], kernel_size=(8), strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv1D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv1D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(1,tf.keras.layers.Activation('sigmoid'))(x)\n",
        "    print(predictions)\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vViFfkzJTH"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "import random\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    recall = recall_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    precision = precision_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    f1 = f1_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oss9TBkZzMYA"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist(config):\n",
        "  path ='/content/drive/MyDrive/ART_Inv/CNN/Ray_Tune/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame.iloc[:,28:43921  ]   \n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      else:\n",
        "          Y.append(1)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, stratify = Y)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 43893 , 1)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 43893, 1)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # Create model\n",
        "  model = ConvNet(config)\n",
        "  # Compile model with losses and metrics\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =config['lr']),\n",
        "                # tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', f1_m, precision_m, recall_m], run_eagerly=True)\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      epochs=100,\n",
        "                      validation_data=(X_test, yTest))\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0],\n",
        "  \"val_f1_m\": history_m.history[\"val_f1_m\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QP5Zl8izRcd"
      },
      "source": [
        "# Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLNKDqS6irI5"
      },
      "outputs": [],
      "source": [
        "# config = {\n",
        "#  'conv_block1_filters': 8,\n",
        "#  'dropout_rate': 0.3,\n",
        "#  'fc1_units': 16,\n",
        "#  'fc_layer_type': 'dense',\n",
        "#  'lr': 0.01,\n",
        "#  'pool_type': 'average'}\n",
        "\n",
        "config = {\n",
        " 'conv_block1_filters': 16,\n",
        " 'dropout_rate': 0.6,\n",
        " 'fc1_units': 16,\n",
        " 'fc_layer_type': 'dense',\n",
        " 'lr': 0.0001,\n",
        " 'pool_type': 'max'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyV830YbioOZ",
        "outputId": "33b3d679-3d60-4726-d5c3-b19e32e6bd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/activation_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 43886, 16)         144       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 43886, 16)        64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 43886, 16)         0         \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 16)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16)               64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 2)                8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 589\n",
            "Trainable params: 521\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 13s 419ms/step - loss: 0.7280 - accuracy: 0.5486 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.6949 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.8616 - accuracy: 0.4792 - f1_m: 0.3183 - precision_m: 0.7592 - recall_m: 0.4812 - val_loss: 0.6960 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.8604 - accuracy: 0.4792 - f1_m: 0.3317 - precision_m: 0.7596 - recall_m: 0.4938 - val_loss: 0.6993 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7739 - accuracy: 0.5486 - f1_m: 0.3229 - precision_m: 0.7559 - recall_m: 0.4875 - val_loss: 0.7006 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8450 - accuracy: 0.4792 - f1_m: 0.3117 - precision_m: 0.7594 - recall_m: 0.4750 - val_loss: 0.6997 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.7513 - accuracy: 0.5208 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.6991 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8080 - accuracy: 0.5000 - f1_m: 0.2896 - precision_m: 0.7676 - recall_m: 0.4500 - val_loss: 0.6999 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8574 - accuracy: 0.4583 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.6992 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.7849 - accuracy: 0.5000 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7005 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.9034 - accuracy: 0.4722 - f1_m: 0.2992 - precision_m: 0.7621 - recall_m: 0.4625 - val_loss: 0.7023 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 3s 630ms/step - loss: 0.7850 - accuracy: 0.5208 - f1_m: 0.3274 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 0.7015 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.7866 - accuracy: 0.4861 - f1_m: 0.2938 - precision_m: 0.7646 - recall_m: 0.4563 - val_loss: 0.7016 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8608 - accuracy: 0.4653 - f1_m: 0.3097 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 0.7016 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7718 - accuracy: 0.5069 - f1_m: 0.3051 - precision_m: 0.7600 - recall_m: 0.4688 - val_loss: 0.7023 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.7170 - accuracy: 0.5625 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.7027 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.7414 - accuracy: 0.5694 - f1_m: 0.3276 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 0.7039 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8332 - accuracy: 0.4931 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7044 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.7812 - accuracy: 0.5417 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7053 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7631 - accuracy: 0.5347 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7056 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8483 - accuracy: 0.4653 - f1_m: 0.3076 - precision_m: 0.7531 - recall_m: 0.4750 - val_loss: 0.7057 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7324 - accuracy: 0.5764 - f1_m: 0.3178 - precision_m: 0.7580 - recall_m: 0.4812 - val_loss: 0.7060 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 381ms/step - loss: 0.8024 - accuracy: 0.5694 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750 - val_loss: 0.7060 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.8750 - accuracy: 0.4792 - f1_m: 0.2962 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.7063 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 382ms/step - loss: 0.9251 - accuracy: 0.4028 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563 - val_loss: 0.7066 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8537 - accuracy: 0.4792 - f1_m: 0.3169 - precision_m: 0.7572 - recall_m: 0.4812 - val_loss: 0.7068 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.7840 - accuracy: 0.5278 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.7076 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8418 - accuracy: 0.4514 - f1_m: 0.3359 - precision_m: 0.7662 - recall_m: 0.4938 - val_loss: 0.7078 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8129 - accuracy: 0.4861 - f1_m: 0.3359 - precision_m: 0.7658 - recall_m: 0.4938 - val_loss: 0.7077 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.8062 - accuracy: 0.4931 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.7081 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8666 - accuracy: 0.4722 - f1_m: 0.3192 - precision_m: 0.7604 - recall_m: 0.4812 - val_loss: 0.7081 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.8081 - accuracy: 0.5139 - f1_m: 0.3183 - precision_m: 0.7592 - recall_m: 0.4812 - val_loss: 0.7085 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8939 - accuracy: 0.4375 - f1_m: 0.2896 - precision_m: 0.7676 - recall_m: 0.4500 - val_loss: 0.7097 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 0.8448 - accuracy: 0.5139 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7101 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.8660 - accuracy: 0.4167 - f1_m: 0.2952 - precision_m: 0.7770 - recall_m: 0.4500 - val_loss: 0.7101 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.9274 - accuracy: 0.3958 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.7100 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 419ms/step - loss: 0.7600 - accuracy: 0.5000 - f1_m: 0.3270 - precision_m: 0.7621 - recall_m: 0.4875 - val_loss: 0.7112 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8393 - accuracy: 0.4583 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7104 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8184 - accuracy: 0.4931 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.7107 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 0.8543 - accuracy: 0.5000 - f1_m: 0.2976 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.7108 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 427ms/step - loss: 0.8557 - accuracy: 0.4514 - f1_m: 0.3023 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.7110 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.7324 - accuracy: 0.5278 - f1_m: 0.3244 - precision_m: 0.7582 - recall_m: 0.4875 - val_loss: 0.7113 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 381ms/step - loss: 0.8660 - accuracy: 0.4583 - f1_m: 0.3429 - precision_m: 0.7676 - recall_m: 0.5000 - val_loss: 0.7112 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.8418 - accuracy: 0.5208 - f1_m: 0.3234 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 0.7619 - accuracy: 0.5139 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8140 - accuracy: 0.5139 - f1_m: 0.3280 - precision_m: 0.7637 - recall_m: 0.4875 - val_loss: 0.7110 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8131 - accuracy: 0.5069 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.7104 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.7275 - accuracy: 0.5417 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7107 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.9291 - accuracy: 0.4375 - f1_m: 0.2971 - precision_m: 0.7590 - recall_m: 0.4625 - val_loss: 0.7118 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8766 - accuracy: 0.4514 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7116 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8472 - accuracy: 0.4861 - f1_m: 0.3266 - precision_m: 0.7613 - recall_m: 0.4875 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8282 - accuracy: 0.5000 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.8516 - accuracy: 0.4722 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.7124 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8912 - accuracy: 0.4236 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875 - val_loss: 0.7126 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.7700 - accuracy: 0.5069 - f1_m: 0.3199 - precision_m: 0.7615 - recall_m: 0.4812 - val_loss: 0.7117 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8022 - accuracy: 0.5556 - f1_m: 0.2959 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7113 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.7756 - accuracy: 0.5208 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7114 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.7595 - accuracy: 0.5417 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7118 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8434 - accuracy: 0.4583 - f1_m: 0.3026 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.7112 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8025 - accuracy: 0.4861 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7108 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.7927 - accuracy: 0.5139 - f1_m: 0.3257 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.7109 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.8635 - accuracy: 0.4236 - f1_m: 0.2883 - precision_m: 0.7652 - recall_m: 0.4500 - val_loss: 0.7109 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8036 - accuracy: 0.4653 - f1_m: 0.2898 - precision_m: 0.7576 - recall_m: 0.4563 - val_loss: 0.7110 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.8038 - accuracy: 0.5278 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7118 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8240 - accuracy: 0.4653 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 423ms/step - loss: 0.8780 - accuracy: 0.4444 - f1_m: 0.2986 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.7340 - accuracy: 0.5625 - f1_m: 0.2917 - precision_m: 0.7607 - recall_m: 0.4563 - val_loss: 0.7114 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8359 - accuracy: 0.4722 - f1_m: 0.2920 - precision_m: 0.7611 - recall_m: 0.4563 - val_loss: 0.7101 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8023 - accuracy: 0.5417 - f1_m: 0.2995 - precision_m: 0.7621 - recall_m: 0.4625 - val_loss: 0.7098 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8274 - accuracy: 0.4861 - f1_m: 0.3443 - precision_m: 0.7695 - recall_m: 0.5000 - val_loss: 0.7096 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 422ms/step - loss: 0.8201 - accuracy: 0.4792 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.7093 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 0.7204 - accuracy: 0.6042 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812 - val_loss: 0.7091 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8884 - accuracy: 0.4028 - f1_m: 0.3019 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.7095 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8239 - accuracy: 0.4861 - f1_m: 0.3013 - precision_m: 0.7645 - recall_m: 0.4625 - val_loss: 0.7090 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.8268 - accuracy: 0.4306 - f1_m: 0.3229 - precision_m: 0.7559 - recall_m: 0.4875 - val_loss: 0.7092 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.7261 - accuracy: 0.5278 - f1_m: 0.3205 - precision_m: 0.7627 - recall_m: 0.4812 - val_loss: 0.7086 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.7586 - accuracy: 0.5278 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7084 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8137 - accuracy: 0.4792 - f1_m: 0.3329 - precision_m: 0.7615 - recall_m: 0.4938 - val_loss: 0.7081 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.8711 - accuracy: 0.4236 - f1_m: 0.2977 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.7077 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8347 - accuracy: 0.4931 - f1_m: 0.3111 - precision_m: 0.7590 - recall_m: 0.4750 - val_loss: 0.7071 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 423ms/step - loss: 0.8336 - accuracy: 0.4792 - f1_m: 0.2897 - precision_m: 0.7676 - recall_m: 0.4500 - val_loss: 0.7060 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8422 - accuracy: 0.4722 - f1_m: 0.3166 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.7054 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.7296 - accuracy: 0.5139 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.7046 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 0.8279 - accuracy: 0.5417 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7050 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8048 - accuracy: 0.5000 - f1_m: 0.2869 - precision_m: 0.7629 - recall_m: 0.4500 - val_loss: 0.7060 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8416 - accuracy: 0.5000 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688 - val_loss: 0.7055 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7912 - accuracy: 0.4583 - f1_m: 0.3148 - precision_m: 0.7537 - recall_m: 0.4812 - val_loss: 0.7035 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.8317 - accuracy: 0.4792 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812 - val_loss: 0.7027 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7701 - accuracy: 0.5000 - f1_m: 0.3204 - precision_m: 0.7631 - recall_m: 0.4812 - val_loss: 0.7023 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8651 - accuracy: 0.4097 - f1_m: 0.3203 - precision_m: 0.7615 - recall_m: 0.4812 - val_loss: 0.7019 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8558 - accuracy: 0.4722 - f1_m: 0.3169 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.7015 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.7909 - accuracy: 0.5069 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7011 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8585 - accuracy: 0.4375 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875 - val_loss: 0.7010 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 0.8717 - accuracy: 0.4514 - f1_m: 0.3026 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.7007 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 0.7837 - accuracy: 0.5069 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625 - val_loss: 0.6992 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8368 - accuracy: 0.4583 - f1_m: 0.3082 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.6980 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 0.7887 - accuracy: 0.4722 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.6970 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.8146 - accuracy: 0.4792 - f1_m: 0.2927 - precision_m: 0.7623 - recall_m: 0.4563 - val_loss: 0.6964 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.7446 - accuracy: 0.5208 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812 - val_loss: 0.6956 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.7218 - accuracy: 0.5625 - f1_m: 0.2920 - precision_m: 0.7611 - recall_m: 0.4563 - val_loss: 0.6939 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8309 - accuracy: 0.5139 - f1_m: 0.3271 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 0.6933 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/activation_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 43886, 16)         144       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 43886, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 43886, 16)         0         \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 16)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16)               64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 2)                8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 589\n",
            "Trainable params: 521\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.7933 - accuracy: 0.5069 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.6955 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.8517 - accuracy: 0.5208 - f1_m: 0.2977 - precision_m: 0.7693 - recall_m: 0.4563 - val_loss: 0.6949 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.8818 - accuracy: 0.4583 - f1_m: 0.3178 - precision_m: 0.7584 - recall_m: 0.4812 - val_loss: 0.6955 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.7714 - accuracy: 0.5000 - f1_m: 0.3178 - precision_m: 0.7584 - recall_m: 0.4812 - val_loss: 0.6953 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8561 - accuracy: 0.4653 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6947 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8351 - accuracy: 0.5000 - f1_m: 0.3236 - precision_m: 0.7570 - recall_m: 0.4875 - val_loss: 0.6940 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.7971 - accuracy: 0.5694 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625 - val_loss: 0.6933 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.7914 - accuracy: 0.5972 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6927 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8675 - accuracy: 0.4792 - f1_m: 0.2910 - precision_m: 0.7596 - recall_m: 0.4563 - val_loss: 0.6929 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8204 - accuracy: 0.4931 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6928 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.7448 - accuracy: 0.5278 - f1_m: 0.2973 - precision_m: 0.7590 - recall_m: 0.4625 - val_loss: 0.6927 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8441 - accuracy: 0.4861 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.6920 - val_accuracy: 0.5676 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8863 - accuracy: 0.4306 - f1_m: 0.2925 - precision_m: 0.7619 - recall_m: 0.4563 - val_loss: 0.6919 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8069 - accuracy: 0.4792 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.6916 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.8586 - accuracy: 0.4931 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6918 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8060 - accuracy: 0.4861 - f1_m: 0.2887 - precision_m: 0.7660 - recall_m: 0.4500 - val_loss: 0.6917 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.7806 - accuracy: 0.4583 - f1_m: 0.3134 - precision_m: 0.7617 - recall_m: 0.4750 - val_loss: 0.6916 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 381ms/step - loss: 0.8373 - accuracy: 0.5278 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688 - val_loss: 0.6913 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8407 - accuracy: 0.5417 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 0.6912 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.7218 - accuracy: 0.5556 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6912 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8234 - accuracy: 0.4236 - f1_m: 0.3178 - precision_m: 0.7580 - recall_m: 0.4812 - val_loss: 0.6910 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8609 - accuracy: 0.5347 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750 - val_loss: 0.6910 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7316 - accuracy: 0.5486 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688 - val_loss: 0.6909 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8086 - accuracy: 0.4931 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8177 - accuracy: 0.4931 - f1_m: 0.2883 - precision_m: 0.7652 - recall_m: 0.4500 - val_loss: 0.6909 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8109 - accuracy: 0.5278 - f1_m: 0.3039 - precision_m: 0.7588 - recall_m: 0.4688 - val_loss: 0.6910 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.7661 - accuracy: 0.5278 - f1_m: 0.3178 - precision_m: 0.7584 - recall_m: 0.4812 - val_loss: 0.6910 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.8406 - accuracy: 0.5278 - f1_m: 0.3259 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.6906 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7698 - accuracy: 0.5694 - f1_m: 0.3266 - precision_m: 0.7617 - recall_m: 0.4875 - val_loss: 0.6907 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8383 - accuracy: 0.5069 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.7780 - accuracy: 0.5625 - f1_m: 0.2885 - precision_m: 0.7656 - recall_m: 0.4500 - val_loss: 0.6909 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.7727 - accuracy: 0.5208 - f1_m: 0.3045 - precision_m: 0.7596 - recall_m: 0.4688 - val_loss: 0.6911 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8412 - accuracy: 0.4931 - f1_m: 0.2931 - precision_m: 0.7631 - recall_m: 0.4563 - val_loss: 0.6909 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8018 - accuracy: 0.5069 - f1_m: 0.3325 - precision_m: 0.7607 - recall_m: 0.4938 - val_loss: 0.6909 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.7660 - accuracy: 0.4861 - f1_m: 0.2891 - precision_m: 0.7668 - recall_m: 0.4500 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8579 - accuracy: 0.4861 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6907 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8029 - accuracy: 0.5278 - f1_m: 0.2959 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.6907 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8068 - accuracy: 0.5069 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.6906 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.7419 - accuracy: 0.5833 - f1_m: 0.2971 - precision_m: 0.7590 - recall_m: 0.4625 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.7889 - accuracy: 0.4931 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6909 - val_accuracy: 0.5676 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8155 - accuracy: 0.4583 - f1_m: 0.2973 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.6909 - val_accuracy: 0.5676 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8814 - accuracy: 0.4931 - f1_m: 0.3033 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.6910 - val_accuracy: 0.5676 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8220 - accuracy: 0.4722 - f1_m: 0.2956 - precision_m: 0.7994 - recall_m: 0.4313 - val_loss: 0.6913 - val_accuracy: 0.5676 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.7614 - accuracy: 0.5556 - f1_m: 0.3138 - precision_m: 0.7521 - recall_m: 0.4812 - val_loss: 0.6914 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8532 - accuracy: 0.5625 - f1_m: 0.2946 - precision_m: 0.7654 - recall_m: 0.4563 - val_loss: 0.6917 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.9255 - accuracy: 0.4792 - f1_m: 0.3034 - precision_m: 0.7580 - recall_m: 0.4688 - val_loss: 0.6918 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.8057 - accuracy: 0.5000 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688 - val_loss: 0.6920 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8207 - accuracy: 0.5139 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.6925 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.7638 - accuracy: 0.5903 - f1_m: 0.2952 - precision_m: 0.7658 - recall_m: 0.4563 - val_loss: 0.6931 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7727 - accuracy: 0.5278 - f1_m: 0.3270 - precision_m: 0.7621 - recall_m: 0.4875 - val_loss: 0.6934 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8124 - accuracy: 0.5278 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.6936 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8046 - accuracy: 0.5417 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.6943 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.8032 - accuracy: 0.5486 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 0.6946 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8890 - accuracy: 0.5069 - f1_m: 0.3102 - precision_m: 0.7574 - recall_m: 0.4750 - val_loss: 0.6948 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.9173 - accuracy: 0.4722 - f1_m: 0.2981 - precision_m: 0.7701 - recall_m: 0.4563 - val_loss: 0.6952 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.8602 - accuracy: 0.4792 - f1_m: 0.3140 - precision_m: 0.7525 - recall_m: 0.4812 - val_loss: 0.6957 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.7027 - accuracy: 0.4722 - f1_m: 0.3053 - precision_m: 0.7607 - recall_m: 0.4688 - val_loss: 0.6964 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.7969 - accuracy: 0.5278 - f1_m: 0.2970 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.6974 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.7869 - accuracy: 0.5417 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.6978 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.7572 - accuracy: 0.5764 - f1_m: 0.3160 - precision_m: 0.7557 - recall_m: 0.4812 - val_loss: 0.6982 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8379 - accuracy: 0.4583 - f1_m: 0.3171 - precision_m: 0.7572 - recall_m: 0.4812 - val_loss: 0.6987 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8439 - accuracy: 0.5000 - f1_m: 0.2910 - precision_m: 0.7596 - recall_m: 0.4563 - val_loss: 0.6995 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8118 - accuracy: 0.5208 - f1_m: 0.2925 - precision_m: 0.7619 - recall_m: 0.4563 - val_loss: 0.7016 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.8721 - accuracy: 0.4722 - f1_m: 0.2954 - precision_m: 0.7559 - recall_m: 0.4625 - val_loss: 0.7016 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.6784 - accuracy: 0.5278 - f1_m: 0.3467 - precision_m: 0.7730 - recall_m: 0.5000 - val_loss: 0.7024 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.7904 - accuracy: 0.5069 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7030 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.7795 - accuracy: 0.5139 - f1_m: 0.3128 - precision_m: 0.7605 - recall_m: 0.4750 - val_loss: 0.7047 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.8245 - accuracy: 0.4583 - f1_m: 0.3181 - precision_m: 0.7584 - recall_m: 0.4812 - val_loss: 0.7049 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.7987 - accuracy: 0.4931 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7052 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8781 - accuracy: 0.4236 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7064 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8103 - accuracy: 0.4792 - f1_m: 0.2917 - precision_m: 0.7607 - recall_m: 0.4563 - val_loss: 0.7067 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8053 - accuracy: 0.5208 - f1_m: 0.3181 - precision_m: 0.7676 - recall_m: 0.4750 - val_loss: 0.7072 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8392 - accuracy: 0.4375 - f1_m: 0.3311 - precision_m: 0.7676 - recall_m: 0.4875 - val_loss: 0.7067 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8645 - accuracy: 0.5069 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7059 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.7656 - accuracy: 0.5069 - f1_m: 0.3151 - precision_m: 0.7541 - recall_m: 0.4812 - val_loss: 0.7057 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8183 - accuracy: 0.4792 - f1_m: 0.3427 - precision_m: 0.7672 - recall_m: 0.5000 - val_loss: 0.7055 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 427ms/step - loss: 0.7119 - accuracy: 0.5417 - f1_m: 0.3474 - precision_m: 0.7738 - recall_m: 0.5000 - val_loss: 0.7050 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.8440 - accuracy: 0.4861 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7053 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 379ms/step - loss: 0.8531 - accuracy: 0.4861 - f1_m: 0.2901 - precision_m: 0.7580 - recall_m: 0.4563 - val_loss: 0.7066 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8880 - accuracy: 0.4792 - f1_m: 0.3140 - precision_m: 0.7525 - recall_m: 0.4812 - val_loss: 0.7077 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.7626 - accuracy: 0.5208 - f1_m: 0.3364 - precision_m: 0.7666 - recall_m: 0.4938 - val_loss: 0.7083 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8295 - accuracy: 0.5139 - f1_m: 0.2971 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.7088 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.7968 - accuracy: 0.4722 - f1_m: 0.2982 - precision_m: 0.7605 - recall_m: 0.4625 - val_loss: 0.7083 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8319 - accuracy: 0.4792 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.7075 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.8199 - accuracy: 0.5347 - f1_m: 0.3057 - precision_m: 0.7611 - recall_m: 0.4688 - val_loss: 0.7078 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8054 - accuracy: 0.5000 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750 - val_loss: 0.7091 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 0.8403 - accuracy: 0.5278 - f1_m: 0.2922 - precision_m: 0.7615 - recall_m: 0.4563 - val_loss: 0.7092 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.7858 - accuracy: 0.5347 - f1_m: 0.3023 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.7093 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.8838 - accuracy: 0.4722 - f1_m: 0.3148 - precision_m: 0.7537 - recall_m: 0.4812 - val_loss: 0.7095 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7555 - accuracy: 0.5347 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.7099 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8035 - accuracy: 0.5278 - f1_m: 0.2979 - precision_m: 0.7602 - recall_m: 0.4625 - val_loss: 0.7127 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8445 - accuracy: 0.4931 - f1_m: 0.3237 - precision_m: 0.7570 - recall_m: 0.4875 - val_loss: 0.7143 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8485 - accuracy: 0.5000 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.7152 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.7852 - accuracy: 0.5417 - f1_m: 0.3138 - precision_m: 0.7521 - recall_m: 0.4812 - val_loss: 0.7140 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8128 - accuracy: 0.5069 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7120 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 3s 627ms/step - loss: 0.8587 - accuracy: 0.4861 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7106 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 3s 597ms/step - loss: 0.8492 - accuracy: 0.4653 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812 - val_loss: 0.7095 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.8276 - accuracy: 0.5278 - f1_m: 0.3023 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.7085 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.8087 - accuracy: 0.5208 - f1_m: 0.3080 - precision_m: 0.7539 - recall_m: 0.4750 - val_loss: 0.7066 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.7667 - accuracy: 0.5625 - f1_m: 0.3212 - precision_m: 0.7631 - recall_m: 0.4812 - val_loss: 0.7055 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_8/activation_8/Sigmoid:0', description=\"created by layer 'dense_8'\")\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 43886, 16)         144       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 43886, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 43886, 16)         0         \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 16)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 16)               64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 2)                8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 589\n",
            "Trainable params: 521\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.8168 - accuracy: 0.5278 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6892 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 1.0204 - accuracy: 0.3889 - f1_m: 0.2938 - precision_m: 0.7639 - recall_m: 0.4563 - val_loss: 0.6913 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.9159 - accuracy: 0.5000 - f1_m: 0.3248 - precision_m: 0.7590 - recall_m: 0.4875 - val_loss: 0.6929 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8936 - accuracy: 0.5000 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.6934 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.9912 - accuracy: 0.4097 - f1_m: 0.3148 - precision_m: 0.7537 - recall_m: 0.4812 - val_loss: 0.6944 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8494 - accuracy: 0.5278 - f1_m: 0.3687 - precision_m: 0.7902 - recall_m: 0.5125 - val_loss: 0.6950 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.8961 - accuracy: 0.5069 - f1_m: 0.2994 - precision_m: 0.7629 - recall_m: 0.4625 - val_loss: 0.6956 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.9148 - accuracy: 0.4931 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6960 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8300 - accuracy: 0.5139 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.6972 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.9834 - accuracy: 0.4097 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6976 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.7965 - accuracy: 0.5764 - f1_m: 0.2993 - precision_m: 0.7617 - recall_m: 0.4625 - val_loss: 0.6994 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 449ms/step - loss: 0.9742 - accuracy: 0.4514 - f1_m: 0.2994 - precision_m: 0.7740 - recall_m: 0.4563 - val_loss: 0.7001 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8026 - accuracy: 0.5694 - f1_m: 0.3233 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.7010 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 424ms/step - loss: 0.9559 - accuracy: 0.4375 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812 - val_loss: 0.7015 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.8463 - accuracy: 0.5069 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750 - val_loss: 0.7016 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.9034 - accuracy: 0.5139 - f1_m: 0.3138 - precision_m: 0.7521 - recall_m: 0.4812 - val_loss: 0.7026 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8773 - accuracy: 0.5347 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7039 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.9586 - accuracy: 0.4167 - f1_m: 0.3080 - precision_m: 0.7539 - recall_m: 0.4750 - val_loss: 0.7043 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8009 - accuracy: 0.5694 - f1_m: 0.3160 - precision_m: 0.7557 - recall_m: 0.4812 - val_loss: 0.7048 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.9510 - accuracy: 0.4514 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 - val_loss: 0.7051 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8033 - accuracy: 0.5208 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.7051 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9091 - accuracy: 0.4653 - f1_m: 0.3165 - precision_m: 0.7564 - recall_m: 0.4812 - val_loss: 0.7039 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8752 - accuracy: 0.5139 - f1_m: 0.2987 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 0.7054 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.8033 - accuracy: 0.5417 - f1_m: 0.3450 - precision_m: 0.7707 - recall_m: 0.5000 - val_loss: 0.7060 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8329 - accuracy: 0.5278 - f1_m: 0.2959 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7061 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.8694 - accuracy: 0.4861 - f1_m: 0.3012 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7067 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.8033 - accuracy: 0.5486 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.7073 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.8328 - accuracy: 0.5208 - f1_m: 0.3080 - precision_m: 0.7539 - recall_m: 0.4750 - val_loss: 0.7071 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.9397 - accuracy: 0.4653 - f1_m: 0.3138 - precision_m: 0.7521 - recall_m: 0.4812 - val_loss: 0.7078 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.8619 - accuracy: 0.4792 - f1_m: 0.2908 - precision_m: 0.7592 - recall_m: 0.4563 - val_loss: 0.7079 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 382ms/step - loss: 0.8937 - accuracy: 0.4722 - f1_m: 0.3160 - precision_m: 0.7664 - recall_m: 0.4750 - val_loss: 0.7091 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.9133 - accuracy: 0.5417 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7089 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8483 - accuracy: 0.5000 - f1_m: 0.3261 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.7096 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.7813 - accuracy: 0.5417 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.7098 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.9035 - accuracy: 0.4444 - f1_m: 0.3282 - precision_m: 0.7645 - recall_m: 0.4875 - val_loss: 0.7092 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.9014 - accuracy: 0.4722 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.7097 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.9600 - accuracy: 0.4236 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7105 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.8296 - accuracy: 0.5278 - f1_m: 0.2981 - precision_m: 0.7701 - recall_m: 0.4563 - val_loss: 0.7099 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.8522 - accuracy: 0.4722 - f1_m: 0.3080 - precision_m: 0.7539 - recall_m: 0.4750 - val_loss: 0.7091 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8193 - accuracy: 0.4931 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7087 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 1.0281 - accuracy: 0.3750 - f1_m: 0.3033 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7089 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.9792 - accuracy: 0.4097 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7083 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8828 - accuracy: 0.4722 - f1_m: 0.2988 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 0.7095 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.7700 - accuracy: 0.5417 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7102 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.8018 - accuracy: 0.5694 - f1_m: 0.3543 - precision_m: 0.7764 - recall_m: 0.5063 - val_loss: 0.7112 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.8665 - accuracy: 0.4861 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7119 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8311 - accuracy: 0.5278 - f1_m: 0.2913 - precision_m: 0.7699 - recall_m: 0.4500 - val_loss: 0.7129 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8910 - accuracy: 0.5000 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.7135 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8863 - accuracy: 0.4861 - f1_m: 0.2939 - precision_m: 0.7535 - recall_m: 0.4625 - val_loss: 0.7134 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8255 - accuracy: 0.5000 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.7132 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.9329 - accuracy: 0.4792 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7135 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.8383 - accuracy: 0.4931 - f1_m: 0.2982 - precision_m: 0.7713 - recall_m: 0.4563 - val_loss: 0.7132 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.7870 - accuracy: 0.5347 - f1_m: 0.3237 - precision_m: 0.7570 - recall_m: 0.4875 - val_loss: 0.7131 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.8841 - accuracy: 0.5000 - f1_m: 0.2954 - precision_m: 0.7559 - recall_m: 0.4625 - val_loss: 0.7133 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9146 - accuracy: 0.4167 - f1_m: 0.2896 - precision_m: 0.7676 - recall_m: 0.4500 - val_loss: 0.7157 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.9140 - accuracy: 0.4444 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.7178 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8808 - accuracy: 0.4861 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.7188 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8852 - accuracy: 0.4653 - f1_m: 0.2960 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.7199 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.8046 - accuracy: 0.5486 - f1_m: 0.2896 - precision_m: 0.7572 - recall_m: 0.4563 - val_loss: 0.7209 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8297 - accuracy: 0.4861 - f1_m: 0.2944 - precision_m: 0.7650 - recall_m: 0.4563 - val_loss: 0.7221 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 0.7814 - accuracy: 0.5764 - f1_m: 0.3157 - precision_m: 0.7553 - recall_m: 0.4812 - val_loss: 0.7234 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.8784 - accuracy: 0.4931 - f1_m: 0.3225 - precision_m: 0.7654 - recall_m: 0.4812 - val_loss: 0.7246 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 448ms/step - loss: 0.8642 - accuracy: 0.4792 - f1_m: 0.2921 - precision_m: 0.7611 - recall_m: 0.4563 - val_loss: 0.7256 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.8948 - accuracy: 0.5069 - f1_m: 0.3091 - precision_m: 0.7555 - recall_m: 0.4750 - val_loss: 0.7261 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8950 - accuracy: 0.4861 - f1_m: 0.3257 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.7262 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8999 - accuracy: 0.4792 - f1_m: 0.3110 - precision_m: 0.7586 - recall_m: 0.4750 - val_loss: 0.7277 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8784 - accuracy: 0.4722 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688 - val_loss: 0.7280 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.7836 - accuracy: 0.5417 - f1_m: 0.3043 - precision_m: 0.7592 - recall_m: 0.4688 - val_loss: 0.7285 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.9242 - accuracy: 0.4444 - f1_m: 0.2962 - precision_m: 0.7785 - recall_m: 0.4500 - val_loss: 0.7279 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8140 - accuracy: 0.4931 - f1_m: 0.3257 - precision_m: 0.7602 - recall_m: 0.4875 - val_loss: 0.7280 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8522 - accuracy: 0.4861 - f1_m: 0.2964 - precision_m: 0.7574 - recall_m: 0.4625 - val_loss: 0.7275 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8347 - accuracy: 0.4792 - f1_m: 0.2939 - precision_m: 0.7535 - recall_m: 0.4625 - val_loss: 0.7267 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8823 - accuracy: 0.5000 - f1_m: 0.3169 - precision_m: 0.7572 - recall_m: 0.4812 - val_loss: 0.7268 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.9338 - accuracy: 0.4514 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.7270 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.9054 - accuracy: 0.4583 - f1_m: 0.3199 - precision_m: 0.7615 - recall_m: 0.4812 - val_loss: 0.7272 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8693 - accuracy: 0.4722 - f1_m: 0.3140 - precision_m: 0.7525 - recall_m: 0.4812 - val_loss: 0.7270 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.8225 - accuracy: 0.5417 - f1_m: 0.3018 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 0.7281 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.9008 - accuracy: 0.4722 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.7298 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8948 - accuracy: 0.4792 - f1_m: 0.3553 - precision_m: 0.7779 - recall_m: 0.5063 - val_loss: 0.7309 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 444ms/step - loss: 0.8604 - accuracy: 0.5000 - f1_m: 0.3181 - precision_m: 0.7584 - recall_m: 0.4812 - val_loss: 0.7315 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8559 - accuracy: 0.5069 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7317 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.8086 - accuracy: 0.4722 - f1_m: 0.3055 - precision_m: 0.7615 - recall_m: 0.4688 - val_loss: 0.7309 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.9259 - accuracy: 0.4722 - f1_m: 0.3155 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.7318 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8244 - accuracy: 0.5208 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.7305 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8480 - accuracy: 0.4653 - f1_m: 0.3082 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.7305 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.9126 - accuracy: 0.4792 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 0.7300 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8794 - accuracy: 0.4653 - f1_m: 0.3259 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.7304 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.9080 - accuracy: 0.4792 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7303 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8868 - accuracy: 0.5000 - f1_m: 0.3077 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7306 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.9721 - accuracy: 0.4236 - f1_m: 0.2989 - precision_m: 0.7729 - recall_m: 0.4563 - val_loss: 0.7310 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8769 - accuracy: 0.4722 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7321 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.9646 - accuracy: 0.4028 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812 - val_loss: 0.7335 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.9565 - accuracy: 0.4028 - f1_m: 0.3250 - precision_m: 0.7590 - recall_m: 0.4875 - val_loss: 0.7349 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.8530 - accuracy: 0.4792 - f1_m: 0.3350 - precision_m: 0.7646 - recall_m: 0.4938 - val_loss: 0.7337 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.9445 - accuracy: 0.4583 - f1_m: 0.3166 - precision_m: 0.7568 - recall_m: 0.4812 - val_loss: 0.7338 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8684 - accuracy: 0.4861 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.7332 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.9505 - accuracy: 0.4583 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.7325 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9374 - accuracy: 0.4861 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.7337 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.9203 - accuracy: 0.4028 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7341 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 3s 596ms/step - loss: 0.8622 - accuracy: 0.5069 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7352 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_11/activation_11/Sigmoid:0', description=\"created by layer 'dense_11'\")\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 43886, 16)         144       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 43886, 16)        64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 43886, 16)         0         \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 16)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 589\n",
            "Trainable params: 521\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.7770 - accuracy: 0.5625 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7238 - val_accuracy: 0.4595 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.7899 - accuracy: 0.4931 - f1_m: 0.2882 - precision_m: 0.7652 - recall_m: 0.4500 - val_loss: 0.6999 - val_accuracy: 0.4595 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8147 - accuracy: 0.4375 - f1_m: 0.3207 - precision_m: 0.7623 - recall_m: 0.4812 - val_loss: 0.6932 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.9693 - accuracy: 0.4514 - f1_m: 0.3031 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8674 - accuracy: 0.5069 - f1_m: 0.3123 - precision_m: 0.7613 - recall_m: 0.4750 - val_loss: 0.6902 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8949 - accuracy: 0.4722 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.6905 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.7965 - accuracy: 0.5764 - f1_m: 0.3270 - precision_m: 0.7621 - recall_m: 0.4875 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8227 - accuracy: 0.5694 - f1_m: 0.2876 - precision_m: 0.7641 - recall_m: 0.4500 - val_loss: 0.6914 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8183 - accuracy: 0.5278 - f1_m: 0.2982 - precision_m: 0.7605 - recall_m: 0.4625 - val_loss: 0.6920 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.9294 - accuracy: 0.4583 - f1_m: 0.2977 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.6921 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8358 - accuracy: 0.5417 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.6928 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.9174 - accuracy: 0.5417 - f1_m: 0.2970 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.6937 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.7879 - accuracy: 0.5694 - f1_m: 0.2938 - precision_m: 0.7646 - recall_m: 0.4563 - val_loss: 0.6947 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.9196 - accuracy: 0.4583 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.6956 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8633 - accuracy: 0.5556 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.6957 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8996 - accuracy: 0.4653 - f1_m: 0.3233 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.6962 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.9001 - accuracy: 0.4375 - f1_m: 0.3054 - precision_m: 0.7738 - recall_m: 0.4625 - val_loss: 0.6964 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.9227 - accuracy: 0.4236 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.6963 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8439 - accuracy: 0.5833 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.6968 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.8893 - accuracy: 0.5347 - f1_m: 0.2869 - precision_m: 0.7629 - recall_m: 0.4500 - val_loss: 0.6963 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.9593 - accuracy: 0.4792 - f1_m: 0.3187 - precision_m: 0.7596 - recall_m: 0.4812 - val_loss: 0.6963 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8311 - accuracy: 0.4861 - f1_m: 0.3033 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.6960 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8167 - accuracy: 0.5347 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.6959 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8217 - accuracy: 0.4931 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6959 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8584 - accuracy: 0.5208 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875 - val_loss: 0.6960 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.8706 - accuracy: 0.5347 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6959 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.9542 - accuracy: 0.4306 - f1_m: 0.3089 - precision_m: 0.7551 - recall_m: 0.4750 - val_loss: 0.6958 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.9099 - accuracy: 0.4583 - f1_m: 0.3105 - precision_m: 0.7582 - recall_m: 0.4750 - val_loss: 0.6959 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.7988 - accuracy: 0.5278 - f1_m: 0.3023 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.6962 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.9175 - accuracy: 0.5000 - f1_m: 0.2869 - precision_m: 0.7721 - recall_m: 0.4437 - val_loss: 0.6963 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8657 - accuracy: 0.4931 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6964 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.7842 - accuracy: 0.5486 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.6957 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8665 - accuracy: 0.5000 - f1_m: 0.3030 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 0.6953 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.7868 - accuracy: 0.5208 - f1_m: 0.2909 - precision_m: 0.7699 - recall_m: 0.4500 - val_loss: 0.6947 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.9772 - accuracy: 0.5000 - f1_m: 0.3452 - precision_m: 0.7707 - recall_m: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8437 - accuracy: 0.4097 - f1_m: 0.3160 - precision_m: 0.7557 - recall_m: 0.4812 - val_loss: 0.6935 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.9000 - accuracy: 0.4514 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688 - val_loss: 0.6928 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8682 - accuracy: 0.5278 - f1_m: 0.3039 - precision_m: 0.7588 - recall_m: 0.4688 - val_loss: 0.6925 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8859 - accuracy: 0.5208 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.6925 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8662 - accuracy: 0.4722 - f1_m: 0.3143 - precision_m: 0.7529 - recall_m: 0.4812 - val_loss: 0.6924 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8621 - accuracy: 0.4792 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.6919 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8669 - accuracy: 0.5139 - f1_m: 0.3057 - precision_m: 0.7611 - recall_m: 0.4688 - val_loss: 0.6920 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.9153 - accuracy: 0.4931 - f1_m: 0.3092 - precision_m: 0.7559 - recall_m: 0.4750 - val_loss: 0.6917 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8347 - accuracy: 0.4722 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.6915 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.7644 - accuracy: 0.5556 - f1_m: 0.3129 - precision_m: 0.7613 - recall_m: 0.4750 - val_loss: 0.6916 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.8079 - accuracy: 0.4861 - f1_m: 0.3254 - precision_m: 0.7598 - recall_m: 0.4875 - val_loss: 0.6918 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.9405 - accuracy: 0.4792 - f1_m: 0.2901 - precision_m: 0.7580 - recall_m: 0.4563 - val_loss: 0.6924 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8420 - accuracy: 0.5000 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6928 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.9800 - accuracy: 0.4167 - f1_m: 0.3058 - precision_m: 0.7730 - recall_m: 0.4625 - val_loss: 0.6933 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8155 - accuracy: 0.4861 - f1_m: 0.2874 - precision_m: 0.7637 - recall_m: 0.4500 - val_loss: 0.6935 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8108 - accuracy: 0.4931 - f1_m: 0.3178 - precision_m: 0.7580 - recall_m: 0.4812 - val_loss: 0.6934 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.7953 - accuracy: 0.5278 - f1_m: 0.3050 - precision_m: 0.7607 - recall_m: 0.4688 - val_loss: 0.6934 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.7732 - accuracy: 0.5208 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.7637 - accuracy: 0.5278 - f1_m: 0.3148 - precision_m: 0.7537 - recall_m: 0.4812 - val_loss: 0.6939 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.8305 - accuracy: 0.5625 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.6938 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8023 - accuracy: 0.5694 - f1_m: 0.2911 - precision_m: 0.7699 - recall_m: 0.4500 - val_loss: 0.6944 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8220 - accuracy: 0.5764 - f1_m: 0.3332 - precision_m: 0.7619 - recall_m: 0.4938 - val_loss: 0.6948 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.8944 - accuracy: 0.4514 - f1_m: 0.2971 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 0.6946 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.7464 - accuracy: 0.5556 - f1_m: 0.2936 - precision_m: 0.7643 - recall_m: 0.4563 - val_loss: 0.6945 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.8515 - accuracy: 0.4792 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.6943 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.7624 - accuracy: 0.5278 - f1_m: 0.2881 - precision_m: 0.7648 - recall_m: 0.4500 - val_loss: 0.6943 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8416 - accuracy: 0.5208 - f1_m: 0.3519 - precision_m: 0.7816 - recall_m: 0.5000 - val_loss: 0.6946 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8359 - accuracy: 0.5278 - f1_m: 0.3006 - precision_m: 0.7533 - recall_m: 0.4688 - val_loss: 0.6946 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8763 - accuracy: 0.4792 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.6953 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.7953 - accuracy: 0.4861 - f1_m: 0.2994 - precision_m: 0.7629 - recall_m: 0.4625 - val_loss: 0.6961 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8774 - accuracy: 0.4861 - f1_m: 0.3435 - precision_m: 0.7684 - recall_m: 0.5000 - val_loss: 0.6960 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.6999 - accuracy: 0.6042 - f1_m: 0.3234 - precision_m: 0.7566 - recall_m: 0.4875 - val_loss: 0.6966 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.8953 - accuracy: 0.4514 - f1_m: 0.2960 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.6969 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.8623 - accuracy: 0.4653 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 0.6969 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.7201 - accuracy: 0.5625 - f1_m: 0.3004 - precision_m: 0.7529 - recall_m: 0.4688 - val_loss: 0.6969 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.7918 - accuracy: 0.5139 - f1_m: 0.3239 - precision_m: 0.7574 - recall_m: 0.4875 - val_loss: 0.6977 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.8375 - accuracy: 0.4722 - f1_m: 0.2898 - precision_m: 0.7576 - recall_m: 0.4563 - val_loss: 0.6978 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.8138 - accuracy: 0.5000 - f1_m: 0.3140 - precision_m: 0.7525 - recall_m: 0.4812 - val_loss: 0.6977 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.8974 - accuracy: 0.5278 - f1_m: 0.2979 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.6982 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.8619 - accuracy: 0.5278 - f1_m: 0.3160 - precision_m: 0.7557 - recall_m: 0.4812 - val_loss: 0.6982 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.8395 - accuracy: 0.5208 - f1_m: 0.2986 - precision_m: 0.7613 - recall_m: 0.4625 - val_loss: 0.6983 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.7597 - accuracy: 0.5625 - f1_m: 0.2976 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.6984 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8346 - accuracy: 0.5139 - f1_m: 0.3119 - precision_m: 0.7598 - recall_m: 0.4750 - val_loss: 0.6983 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.7777 - accuracy: 0.5556 - f1_m: 0.3045 - precision_m: 0.7596 - recall_m: 0.4688 - val_loss: 0.6980 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8116 - accuracy: 0.5347 - f1_m: 0.3156 - precision_m: 0.7549 - recall_m: 0.4812 - val_loss: 0.6983 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.8780 - accuracy: 0.4653 - f1_m: 0.3216 - precision_m: 0.7646 - recall_m: 0.4812 - val_loss: 0.6977 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8728 - accuracy: 0.5347 - f1_m: 0.3076 - precision_m: 0.7531 - recall_m: 0.4750 - val_loss: 0.6974 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 388ms/step - loss: 0.8544 - accuracy: 0.5069 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.6971 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8816 - accuracy: 0.4931 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.6970 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.8150 - accuracy: 0.5347 - f1_m: 0.2942 - precision_m: 0.7539 - recall_m: 0.4625 - val_loss: 0.6969 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.9117 - accuracy: 0.5278 - f1_m: 0.3141 - precision_m: 0.7645 - recall_m: 0.4750 - val_loss: 0.6969 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.7533 - accuracy: 0.6111 - f1_m: 0.2909 - precision_m: 0.7691 - recall_m: 0.4500 - val_loss: 0.6967 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.9650 - accuracy: 0.3889 - f1_m: 0.3098 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 0.6967 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8151 - accuracy: 0.5139 - f1_m: 0.3055 - precision_m: 0.7615 - recall_m: 0.4688 - val_loss: 0.6965 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.7174 - accuracy: 0.5139 - f1_m: 0.3183 - precision_m: 0.7588 - recall_m: 0.4812 - val_loss: 0.6964 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.8420 - accuracy: 0.5208 - f1_m: 0.2951 - precision_m: 0.7555 - recall_m: 0.4625 - val_loss: 0.6965 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8363 - accuracy: 0.5347 - f1_m: 0.3165 - precision_m: 0.7564 - recall_m: 0.4812 - val_loss: 0.6966 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.7749 - accuracy: 0.6181 - f1_m: 0.3000 - precision_m: 0.7629 - recall_m: 0.4625 - val_loss: 0.6966 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.7961 - accuracy: 0.5278 - f1_m: 0.3093 - precision_m: 0.7559 - recall_m: 0.4750 - val_loss: 0.6965 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.9207 - accuracy: 0.4792 - f1_m: 0.2988 - precision_m: 0.7732 - recall_m: 0.4563 - val_loss: 0.6967 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.7541 - accuracy: 0.5625 - f1_m: 0.3287 - precision_m: 0.7648 - recall_m: 0.4875 - val_loss: 0.6967 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.7713 - accuracy: 0.4722 - f1_m: 0.3140 - precision_m: 0.7637 - recall_m: 0.4750 - val_loss: 0.6966 - val_accuracy: 0.5405 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7739 - accuracy: 0.5694 - f1_m: 0.2994 - precision_m: 0.7514 - recall_m: 0.4688 - val_loss: 0.6967 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.7847 - accuracy: 0.5208 - f1_m: 0.2922 - precision_m: 0.7615 - recall_m: 0.4563 - val_loss: 0.6967 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 543ms/step - loss: 0.7718 - accuracy: 0.5764 - f1_m: 0.3163 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.6967 - val_accuracy: 0.5676 - val_f1_m: 0.2000 - val_precision_m: 0.7950 - val_recall_m: 0.3500\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_14/activation_14/Sigmoid:0', description=\"created by layer 'dense_14'\")\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 43886, 16)         144       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 43886, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 43886, 16)         0         \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 16)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 16)               64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 16)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 2)                8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 589\n",
            "Trainable params: 521\n",
            "Non-trainable params: 68\n",
            "_________________________________________________________________\n",
            "None\n",
            "Total number of layers: 13\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.8797 - accuracy: 0.5486 - f1_m: 0.3398 - precision_m: 0.7717 - recall_m: 0.4938 - val_loss: 0.6908 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.9885 - accuracy: 0.4722 - f1_m: 0.3102 - precision_m: 0.7574 - recall_m: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.9081 - accuracy: 0.5556 - f1_m: 0.3368 - precision_m: 0.7674 - recall_m: 0.4938 - val_loss: 0.6937 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.9707 - accuracy: 0.4583 - f1_m: 0.3029 - precision_m: 0.7572 - recall_m: 0.4688 - val_loss: 0.6954 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.9346 - accuracy: 0.4583 - f1_m: 0.3048 - precision_m: 0.7596 - recall_m: 0.4688 - val_loss: 0.6958 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.8917 - accuracy: 0.5000 - f1_m: 0.2910 - precision_m: 0.7596 - recall_m: 0.4563 - val_loss: 0.6971 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.9055 - accuracy: 0.5208 - f1_m: 0.3254 - precision_m: 0.7598 - recall_m: 0.4875 - val_loss: 0.6986 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 1.0034 - accuracy: 0.4167 - f1_m: 0.3553 - precision_m: 0.7779 - recall_m: 0.5063 - val_loss: 0.6991 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.9683 - accuracy: 0.4583 - f1_m: 0.3162 - precision_m: 0.7557 - recall_m: 0.4812 - val_loss: 0.7002 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.8664 - accuracy: 0.5139 - f1_m: 0.3153 - precision_m: 0.7545 - recall_m: 0.4812 - val_loss: 0.7023 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.8058 - accuracy: 0.4792 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7030 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.8557 - accuracy: 0.5347 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.7052 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.7562 - accuracy: 0.5764 - f1_m: 0.3002 - precision_m: 0.7525 - recall_m: 0.4688 - val_loss: 0.7066 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.9007 - accuracy: 0.5139 - f1_m: 0.2908 - precision_m: 0.7592 - recall_m: 0.4563 - val_loss: 0.7064 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.8920 - accuracy: 0.5000 - f1_m: 0.3216 - precision_m: 0.7646 - recall_m: 0.4812 - val_loss: 0.7072 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.9411 - accuracy: 0.4792 - f1_m: 0.3074 - precision_m: 0.7531 - recall_m: 0.4750 - val_loss: 0.7067 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.9077 - accuracy: 0.5069 - f1_m: 0.3132 - precision_m: 0.7613 - recall_m: 0.4750 - val_loss: 0.7068 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 393ms/step - loss: 0.8679 - accuracy: 0.4931 - f1_m: 0.3011 - precision_m: 0.7541 - recall_m: 0.4688 - val_loss: 0.7076 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.9192 - accuracy: 0.4792 - f1_m: 0.2869 - precision_m: 0.7629 - recall_m: 0.4500 - val_loss: 0.7080 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8678 - accuracy: 0.5417 - f1_m: 0.3085 - precision_m: 0.7547 - recall_m: 0.4750 - val_loss: 0.7086 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.9347 - accuracy: 0.4861 - f1_m: 0.3502 - precision_m: 0.7777 - recall_m: 0.5000 - val_loss: 0.7088 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.8553 - accuracy: 0.5208 - f1_m: 0.2925 - precision_m: 0.7619 - recall_m: 0.4563 - val_loss: 0.7085 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 1.0406 - accuracy: 0.4375 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7092 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.9018 - accuracy: 0.4722 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.7095 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.9952 - accuracy: 0.4028 - f1_m: 0.3419 - precision_m: 0.7660 - recall_m: 0.5000 - val_loss: 0.7104 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.8911 - accuracy: 0.4792 - f1_m: 0.2960 - precision_m: 0.7570 - recall_m: 0.4625 - val_loss: 0.7101 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.9057 - accuracy: 0.5278 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688 - val_loss: 0.7112 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.9117 - accuracy: 0.4861 - f1_m: 0.3178 - precision_m: 0.7584 - recall_m: 0.4812 - val_loss: 0.7113 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.9113 - accuracy: 0.5000 - f1_m: 0.2968 - precision_m: 0.7582 - recall_m: 0.4625 - val_loss: 0.7116 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 449ms/step - loss: 0.8879 - accuracy: 0.5208 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.9121 - accuracy: 0.5347 - f1_m: 0.2920 - precision_m: 0.7611 - recall_m: 0.4563 - val_loss: 0.7118 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8517 - accuracy: 0.5625 - f1_m: 0.3078 - precision_m: 0.7535 - recall_m: 0.4750 - val_loss: 0.7118 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.7841 - accuracy: 0.5694 - f1_m: 0.3092 - precision_m: 0.7559 - recall_m: 0.4750 - val_loss: 0.7115 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8103 - accuracy: 0.5417 - f1_m: 0.2912 - precision_m: 0.7600 - recall_m: 0.4563 - val_loss: 0.7106 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.8970 - accuracy: 0.4583 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688 - val_loss: 0.7119 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.9789 - accuracy: 0.4583 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.7121 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8171 - accuracy: 0.5833 - f1_m: 0.2953 - precision_m: 0.7670 - recall_m: 0.4563 - val_loss: 0.7135 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.8889 - accuracy: 0.5417 - f1_m: 0.3034 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7155 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8782 - accuracy: 0.5278 - f1_m: 0.2997 - precision_m: 0.7518 - recall_m: 0.4688 - val_loss: 0.7153 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.8979 - accuracy: 0.5417 - f1_m: 0.3626 - precision_m: 0.7885 - recall_m: 0.5063 - val_loss: 0.7160 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9017 - accuracy: 0.5417 - f1_m: 0.3259 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.7178 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.9462 - accuracy: 0.5764 - f1_m: 0.3065 - precision_m: 0.7516 - recall_m: 0.4750 - val_loss: 0.7182 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.9150 - accuracy: 0.4931 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7187 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.8992 - accuracy: 0.5417 - f1_m: 0.3100 - precision_m: 0.7570 - recall_m: 0.4750 - val_loss: 0.7187 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.9625 - accuracy: 0.4306 - f1_m: 0.3000 - precision_m: 0.7760 - recall_m: 0.4563 - val_loss: 0.7180 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9784 - accuracy: 0.4514 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7176 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.8437 - accuracy: 0.4722 - f1_m: 0.3246 - precision_m: 0.7586 - recall_m: 0.4875 - val_loss: 0.7183 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.9374 - accuracy: 0.5278 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7190 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8890 - accuracy: 0.5069 - f1_m: 0.3083 - precision_m: 0.7543 - recall_m: 0.4750 - val_loss: 0.7195 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 1.0152 - accuracy: 0.3819 - f1_m: 0.2973 - precision_m: 0.7590 - recall_m: 0.4625 - val_loss: 0.7201 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.9127 - accuracy: 0.4792 - f1_m: 0.3145 - precision_m: 0.7533 - recall_m: 0.4812 - val_loss: 0.7198 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.9479 - accuracy: 0.4792 - f1_m: 0.3140 - precision_m: 0.7525 - recall_m: 0.4812 - val_loss: 0.7201 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.8519 - accuracy: 0.4861 - f1_m: 0.3029 - precision_m: 0.7572 - recall_m: 0.4688 - val_loss: 0.7219 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.8464 - accuracy: 0.5417 - f1_m: 0.3080 - precision_m: 0.7539 - recall_m: 0.4750 - val_loss: 0.7232 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.9496 - accuracy: 0.4861 - f1_m: 0.2878 - precision_m: 0.7645 - recall_m: 0.4500 - val_loss: 0.7249 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.8778 - accuracy: 0.4931 - f1_m: 0.2999 - precision_m: 0.7521 - recall_m: 0.4688 - val_loss: 0.7263 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8856 - accuracy: 0.4722 - f1_m: 0.3329 - precision_m: 0.7615 - recall_m: 0.4938 - val_loss: 0.7280 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.9031 - accuracy: 0.5417 - f1_m: 0.3073 - precision_m: 0.7527 - recall_m: 0.4750 - val_loss: 0.7291 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 387ms/step - loss: 0.9112 - accuracy: 0.5069 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.7316 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 0.9511 - accuracy: 0.4514 - f1_m: 0.3172 - precision_m: 0.7576 - recall_m: 0.4812 - val_loss: 0.7314 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.9211 - accuracy: 0.4931 - f1_m: 0.3015 - precision_m: 0.7545 - recall_m: 0.4688 - val_loss: 0.7308 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.9331 - accuracy: 0.5139 - f1_m: 0.3039 - precision_m: 0.7584 - recall_m: 0.4688 - val_loss: 0.7307 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.9378 - accuracy: 0.4861 - f1_m: 0.2911 - precision_m: 0.7695 - recall_m: 0.4500 - val_loss: 0.7331 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8873 - accuracy: 0.5000 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563 - val_loss: 0.7391 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7828 - accuracy: 0.5347 - f1_m: 0.2933 - precision_m: 0.7635 - recall_m: 0.4563 - val_loss: 0.7468 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.8655 - accuracy: 0.5417 - f1_m: 0.3026 - precision_m: 0.7564 - recall_m: 0.4688 - val_loss: 0.7489 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.8697 - accuracy: 0.5208 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7517 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.9197 - accuracy: 0.4792 - f1_m: 0.3165 - precision_m: 0.7564 - recall_m: 0.4812 - val_loss: 0.7531 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 1.0268 - accuracy: 0.4236 - f1_m: 0.3026 - precision_m: 0.7561 - recall_m: 0.4688 - val_loss: 0.7519 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.8616 - accuracy: 0.5417 - f1_m: 0.3026 - precision_m: 0.7564 - recall_m: 0.4688 - val_loss: 0.7518 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8716 - accuracy: 0.4792 - f1_m: 0.3229 - precision_m: 0.7559 - recall_m: 0.4875 - val_loss: 0.7478 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 1.0458 - accuracy: 0.4583 - f1_m: 0.3244 - precision_m: 0.7582 - recall_m: 0.4875 - val_loss: 0.7463 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8409 - accuracy: 0.5139 - f1_m: 0.2949 - precision_m: 0.7551 - recall_m: 0.4625 - val_loss: 0.7453 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.9186 - accuracy: 0.5417 - f1_m: 0.3148 - precision_m: 0.7537 - recall_m: 0.4812 - val_loss: 0.7452 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.9102 - accuracy: 0.5208 - f1_m: 0.3070 - precision_m: 0.7523 - recall_m: 0.4750 - val_loss: 0.7418 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.9632 - accuracy: 0.4514 - f1_m: 0.2975 - precision_m: 0.7590 - recall_m: 0.4625 - val_loss: 0.7402 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.8087 - accuracy: 0.5903 - f1_m: 0.3046 - precision_m: 0.7596 - recall_m: 0.4688 - val_loss: 0.7391 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.9129 - accuracy: 0.4931 - f1_m: 0.3244 - precision_m: 0.7582 - recall_m: 0.4875 - val_loss: 0.7368 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9267 - accuracy: 0.5208 - f1_m: 0.3257 - precision_m: 0.7602 - recall_m: 0.4875 - val_loss: 0.7338 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.8287 - accuracy: 0.5208 - f1_m: 0.2903 - precision_m: 0.7584 - recall_m: 0.4563 - val_loss: 0.7292 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.8429 - accuracy: 0.5556 - f1_m: 0.3148 - precision_m: 0.7537 - recall_m: 0.4812 - val_loss: 0.7263 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.9290 - accuracy: 0.4722 - f1_m: 0.2968 - precision_m: 0.7582 - recall_m: 0.4625 - val_loss: 0.7238 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.9337 - accuracy: 0.4722 - f1_m: 0.3276 - precision_m: 0.7629 - recall_m: 0.4875 - val_loss: 0.7218 - val_accuracy: 0.3784 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.9426 - accuracy: 0.4583 - f1_m: 0.3092 - precision_m: 0.7559 - recall_m: 0.4750 - val_loss: 0.7202 - val_accuracy: 0.3784 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.8044 - accuracy: 0.5417 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7189 - val_accuracy: 0.3514 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.9456 - accuracy: 0.4931 - f1_m: 0.2976 - precision_m: 0.7598 - recall_m: 0.4625 - val_loss: 0.7170 - val_accuracy: 0.3514 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 1.0336 - accuracy: 0.4097 - f1_m: 0.3350 - precision_m: 0.7646 - recall_m: 0.4938 - val_loss: 0.7140 - val_accuracy: 0.4054 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8586 - accuracy: 0.4653 - f1_m: 0.2905 - precision_m: 0.7588 - recall_m: 0.4563 - val_loss: 0.7105 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 390ms/step - loss: 0.9093 - accuracy: 0.4722 - f1_m: 0.3164 - precision_m: 0.7561 - recall_m: 0.4812 - val_loss: 0.7076 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.9069 - accuracy: 0.5278 - f1_m: 0.2910 - precision_m: 0.7596 - recall_m: 0.4563 - val_loss: 0.7077 - val_accuracy: 0.4324 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.8274 - accuracy: 0.5694 - f1_m: 0.2958 - precision_m: 0.7566 - recall_m: 0.4625 - val_loss: 0.7071 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 417ms/step - loss: 0.7191 - accuracy: 0.6250 - f1_m: 0.2944 - precision_m: 0.7754 - recall_m: 0.4500 - val_loss: 0.7065 - val_accuracy: 0.4595 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.9717 - accuracy: 0.4306 - f1_m: 0.3026 - precision_m: 0.7564 - recall_m: 0.4688 - val_loss: 0.7057 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 395ms/step - loss: 0.9800 - accuracy: 0.4167 - f1_m: 0.3108 - precision_m: 0.7582 - recall_m: 0.4750 - val_loss: 0.7039 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.7803 - accuracy: 0.5347 - f1_m: 0.3261 - precision_m: 0.7605 - recall_m: 0.4875 - val_loss: 0.7028 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.7434 - accuracy: 0.4653 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 0.7024 - val_accuracy: 0.4865 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.8990 - accuracy: 0.5347 - f1_m: 0.3063 - precision_m: 0.7512 - recall_m: 0.4750 - val_loss: 0.7017 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.8828 - accuracy: 0.5069 - f1_m: 0.3068 - precision_m: 0.7520 - recall_m: 0.4750 - val_loss: 0.7012 - val_accuracy: 0.5405 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.8892 - accuracy: 0.5000 - f1_m: 0.3033 - precision_m: 0.7576 - recall_m: 0.4688 - val_loss: 0.7020 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.8649 - accuracy: 0.5347 - f1_m: 0.3327 - precision_m: 0.7611 - recall_m: 0.4938 - val_loss: 0.7023 - val_accuracy: 0.5135 - val_f1_m: 0.2639 - val_precision_m: 0.7555 - val_recall_m: 0.4344\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  history = train_mnist(config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PXjVxSG4yt-o"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
