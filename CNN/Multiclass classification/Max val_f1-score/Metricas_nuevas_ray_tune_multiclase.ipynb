{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjVxSG4yt-o"
      },
      "source": [
        "#Import libraies and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVA_ZA7c5BE0",
        "outputId": "cbd5caa0-7ba3-41c7-b423-f5f260db56b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.1.0-cp37-cp37m-manylinux2014_x86_64.whl (59.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.50.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.16.7-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray) (1.15.0)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray) (4.13.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray) (3.10.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.19.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.9.24)\n",
            "Installing collected packages: platformdirs, distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 platformdirs-2.5.4 ray-2.1.0 virtualenv-20.16.7\n"
          ]
        }
      ],
      "source": [
        "pip install ray torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlaA55u5HNx",
        "outputId": "e7698f7c-9d34-4b51-fe61-ffff100842c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.3.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU9kk9xU5K4-",
        "outputId": "029e978a-cbb3-4040-e6c0-f2c7bb350660"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: The module `ray.tune.suggest` has been moved to `ray.tune.search` and the old location will be deprecated soon. Please adjust your imports to point to the new location. Example: Do a global search and replace `ray.tune.suggest` with `ray.tune.search`.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvgorDkMN429"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtyQ06Iu5MP2",
        "outputId": "da4c12d6-ef26-4aa6-d0f9-2b128f72f825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoUYbBj2yxpO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmIVYXYN5Nv9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ConvNet(config, len_classes=2):\n",
        "    input = tf.keras.layers.Input(shape=(43893, 1))\n",
        "    x = input\n",
        "    x = tf.keras.layers.Conv1D(filters=config['conv_block1_filters'], kernel_size=(8), strides=1)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    if config['fc_layer_type'] == 'dense':\n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Dense(units=config['fc1_units'])(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Dense(units=len_classes)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(3,tf.keras.layers.Activation('softmax'))(x)\n",
        "\n",
        "    else:\n",
        "        # Fully connected layer 1\n",
        "        x = tf.keras.layers.Conv1D(filters=config['fc1_units'], kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "        # Fully connected layer 2\n",
        "        x = tf.keras.layers.Conv1D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
        "        x = tf.keras.layers.Dropout(config['dropout_rate'])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        \n",
        "        if config['pool_type'] == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "        else:\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        \n",
        "        predictions = tf.keras.layers.Dense(3,tf.keras.layers.Activation('softmax'))(x)\n",
        "    print(predictions)\n",
        "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
        "    \n",
        "    print(model.summary())\n",
        "    print(f'Total number of layers: {len(model.layers)}')\n",
        "\n",
        "    return model\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7vViFfkzJTH"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bJZCOYSB1qA"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "import random\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    recall = recall_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    precision = precision_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    y_true.numpy()\n",
        "    y_pred.numpy()\n",
        "    f1 = f1_score(y_true, np.argmax(y_pred, axis = 1), average='weighted', zero_division = 1)\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oss9TBkZzMYA"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSIMfshH5Qzx"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def train_mnist(config):\n",
        "  path ='/content/drive/MyDrive/ART_Inv/CNN/Ray_Tune/Clinical_data_and_RNA_total_Features_PFS.csv'\n",
        "  data_frame = pd.read_csv(path)\n",
        "  \n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X = data_frame.iloc[:,28:43921  ]   \n",
        "  Y=[]\n",
        "  for i in range (len(data_frame)):\n",
        "      if data_frame.PFS[i]<3: # If PFS is lower than 3 months, I will consider it as NonResponder (NR)\n",
        "          Y.append(0)\n",
        "      elif data_frame.PFS[i]<6:\n",
        "          Y.append(1)\n",
        "      else:\n",
        "          Y.append(2)# If PFS is over 3 months, I will consider it as Responder (R)\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  names = X.columns\n",
        "  d = scaler.fit_transform(X)\n",
        "  X = pd.DataFrame(d, columns=names)\n",
        "  XTrain, XTest, yTrain, yTest = train_test_split(X, Y, test_size=0.20, stratify = Y)\n",
        "  # Convert sets to arrays\n",
        "  XTrain = XTrain.values\n",
        "  XTest = XTest.values\n",
        "  # It is mandatory to transform Y list into array for trainning the model\n",
        "  yTrain=np.array(yTrain)\n",
        "  yTest=np.array(yTest)\n",
        "\n",
        "  X_train = XTrain.reshape(XTrain.shape[0], 43893 , 1)\n",
        "  X_test = XTest.reshape(XTest.shape[0], 43893, 1)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # Create model\n",
        "  model = ConvNet(config)\n",
        "  # Compile model with losses and metrics\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =config['lr']),\n",
        "                # tf.keras.optimizers.RMSprop(learning_rate =config['lr']),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy', f1_m, precision_m, recall_m], run_eagerly=True)\n",
        "  # Start model training\n",
        "  history_m = model.fit(X_train, yTrain,\n",
        "                      epochs=100,\n",
        "                      validation_data=(X_test, yTest))\n",
        "  history_m = {\n",
        "  \"loss\": history_m.history[\"loss\"][0],\n",
        "  \"val_loss\": history_m.history[\"val_loss\"][0],\n",
        "  \"accuracy\": history_m.history[\"accuracy\"][0],\n",
        "  \"val_accuracy\": history_m.history[\"val_accuracy\"][0],\n",
        "  \"val_f1_m\": history_m.history[\"val_f1_m\"][0]\n",
        "  }\n",
        "  return history_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QP5Zl8izRcd"
      },
      "source": [
        "# Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwt9luxAGLl",
        "outputId": "1e655902-de7a-460c-80ea-021d02eae37d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hpbandster\n",
            "  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 95 kB/s \n",
            "\u001b[?25hCollecting ConfigSpace\n",
            "  Downloading ConfigSpace-0.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting Pyro4\n",
            "  Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting serpent\n",
            "  Downloading serpent-1.41-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.21.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from hpbandster) (0.12.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.7.3)\n",
            "Collecting netifaces\n",
            "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (4.1.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (0.29.32)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (3.0.9)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (0.5.3)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels->hpbandster) (1.15.0)\n",
            "Building wheels for collected packages: hpbandster\n",
            "  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=80008 sha256=47a45d81707ed985bc82910e1d705d6de6f4f4f6f46e26ce39f35a4711e3ef20\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/88/fc/61ab6b9f386a386839668631c39a6dc3c2fb0ec7000d552faa\n",
            "Successfully built hpbandster\n",
            "Installing collected packages: serpent, Pyro4, netifaces, ConfigSpace, hpbandster\n",
            "Successfully installed ConfigSpace-0.6.0 Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n"
          ]
        }
      ],
      "source": [
        "pip install hpbandster ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCRd1vVu-GX5",
        "outputId": "7c737ad6-7b75-43a2-ed13-4536e925aa16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (0.29.32)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (4.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ConfigSpace) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "pip install ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoSc_LZj-PrU"
      },
      "outputs": [],
      "source": [
        "import ConfigSpace as CS\n",
        "config_space = CS.ConfigurationSpace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aagkiF3-Syc",
        "outputId": "de0ffa18-26ee-44fa-c62b-ca66259e4f4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fc1_units, Type: Categorical, Choices: {8, 16, 32, 64, 128}, Default: 8"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config_space = CS.ConfigurationSpace()\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"lr\", choices=[ 0.0001, 0.001, 0.01, 0.1]))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"dropout_rate\", choices=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"conv_block1_filters\", choices=[8, 16, 32, 64, 128]))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"fc_layer_type\", choices= ['dense', 'convolution']))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"pool_type\", choices= ['max', 'average']))\n",
        "config_space.add_hyperparameter(\n",
        "    CS.CategoricalHyperparameter(\n",
        "        name=\"fc1_units\", choices=[8, 16, 32, 64, 128]))\n",
        "\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"lr\", choices=[0.001]))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"dropout_rate\", choices=[ 0.3])) \n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"conv_block1_filters\", choices=[8]))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"fc_layer_type\", choices= ['dense']))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"pool_type\", choices= [ 'average']))\n",
        "# config_space.add_hyperparameter(\n",
        "#     CS.CategoricalHyperparameter(\n",
        "#         name=\"fc1_units\", choices=[16]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b5NabPB3_mlz",
        "outputId": "d9a89498-99e7-414d-891e-a16634872739"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-22 08:17:16,673\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2022-11-22 10:40:52</td></tr>\n",
              "<tr><td>Running for: </td><td>02:23:35.83        </td></tr>\n",
              "<tr><td>Memory:      </td><td>2.2/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using HyperBand: num_stopped=0 total_brackets=2<br>Round #0:<br>  Bracket(Max Size (n)=2, Milestone (r)=2, completed=100.0%): {TERMINATED: 3} <br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.28 GiB heap, 0.0/3.64 GiB objects\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  conv_block1_filters</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  fc1_units</th><th>fc_layer_type  </th><th style=\"text-align: right;\">    lr</th><th>pool_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_138c3eee</td><td>TERMINATED</td><td>172.28.0.2:840 </td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">        128</td><td>dense          </td><td style=\"text-align: right;\">0.1   </td><td>average    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3294.15</td><td style=\"text-align: right;\">1.09083</td><td style=\"text-align: right;\">   1.99308</td><td style=\"text-align: right;\">  0.458333</td></tr>\n",
              "<tr><td>train_mnist_c2e2b812</td><td>TERMINATED</td><td>172.28.0.2:3088</td><td style=\"text-align: right;\">                   32</td><td style=\"text-align: right;\">           0.7</td><td style=\"text-align: right;\">          8</td><td>convolution    </td><td style=\"text-align: right;\">0.0001</td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1487.66</td><td style=\"text-align: right;\">9.2704 </td><td style=\"text-align: right;\">   1.12447</td><td style=\"text-align: right;\">  0.173611</td></tr>\n",
              "<tr><td>train_mnist_416fcc76</td><td>TERMINATED</td><td>172.28.0.2:4599</td><td style=\"text-align: right;\">                  128</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">         64</td><td>dense          </td><td style=\"text-align: right;\">0.001 </td><td>max        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3805.74</td><td style=\"text-align: right;\">1.53145</td><td style=\"text-align: right;\">   1.08232</td><td style=\"text-align: right;\">  0.229167</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m 2022-11-22 08:17:36.526676: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense_2/activation_2/Softmax:0', description=\"created by layer 'dense_2'\")\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  conv1d (Conv1D)             (None, 43886, 128)        1152      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  batch_normalization (BatchN  (None, 43886, 128)       512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  activation (Activation)     (None, 43886, 128)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  global_average_pooling1d (G  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  lobalAveragePooling1D)                                          \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  dense (Dense)               (None, 128)               16512     \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  dropout (Dropout)           (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  batch_normalization_1 (Batc  (None, 128)              512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  activation_1 (Activation)   (None, 128)               0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  dense_1 (Dense)             (None, 2)                 258       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  batch_normalization_2 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m  dense_2 (Dense)             (None, 3)                 9         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Total params: 18,963\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Trainable params: 18,447\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Non-trainable params: 516\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Total number of layers: 13\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m 2022-11-22 08:17:36.842260: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 719028224 exceeds 10% of free system memory.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m 2022-11-22 08:17:37.357316: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 719028224 exceeds 10% of free system memory.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m 2022-11-22 08:17:37.966872: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 719028224 exceeds 10% of free system memory.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m 2022-11-22 08:17:38.672719: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 719028224 exceeds 10% of free system memory.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m 2022-11-22 08:17:39.047881: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 719028224 exceeds 10% of free system memory.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fb40f3cc050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fb40f3cc050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7fb40f3cc050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7fb40f3cc050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fb40f3d3830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fb40f3d3830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7fb40f3d3830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7fb40f3d3830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fb3b7737680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fb3b7737680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7fb3b7737680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7fb3b7737680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/5 [=====>........................] - ETA: 31s - loss: 1.1580 - accuracy: 0.3750 - f1_m: 0.3604 - precision_m: 0.3739 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.1489 - accuracy: 0.4062 - f1_m: 0.3830 - precision_m: 0.4249 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.1139 - accuracy: 0.4271 - f1_m: 0.3922 - precision_m: 0.4187 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0997 - accuracy: 0.4453 - f1_m: 0.4072 - precision_m: 0.4238 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0908 - accuracy: 0.4583 - f1_m: 0.4219 - precision_m: 0.4595 - recall_m: 0.4688\n",
            "5/5 [==============================] - 33s 6s/step - loss: 1.0908 - accuracy: 0.4583 - f1_m: 0.4219 - precision_m: 0.4595 - recall_m: 0.4688 - val_loss: 1.9931 - val_accuracy: 0.1622 - val_f1_m: 0.0544 - val_precision_m: 0.8541 - val_recall_m: 0.1781\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 2/100\n",
            "1/5 [=====>........................] - ETA: 22s - loss: 0.9705 - accuracy: 0.5312 - f1_m: 0.3763 - precision_m: 0.4163 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 0.9912 - accuracy: 0.5156 - f1_m: 0.3548 - precision_m: 0.5832 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0105 - accuracy: 0.5104 - f1_m: 0.3477 - precision_m: 0.6388 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0204 - accuracy: 0.4922 - f1_m: 0.3273 - precision_m: 0.6676 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0366 - accuracy: 0.4653 - f1_m: 0.2819 - precision_m: 0.6965 - recall_m: 0.4437\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0366 - accuracy: 0.4653 - f1_m: 0.2819 - precision_m: 0.6965 - recall_m: 0.4437 - val_loss: 2.4752 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 3/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.9128 - accuracy: 0.5938 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.0501 - accuracy: 0.4688 - f1_m: 0.3091 - precision_m: 0.7666 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0513 - accuracy: 0.4271 - f1_m: 0.2647 - precision_m: 0.7692 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0705 - accuracy: 0.4219 - f1_m: 0.2662 - precision_m: 0.6902 - recall_m: 0.4219 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0442 - accuracy: 0.4375 - f1_m: 0.3120 - precision_m: 0.6405 - recall_m: 0.4500\n",
            "5/5 [==============================] - 33s 6s/step - loss: 1.0442 - accuracy: 0.4375 - f1_m: 0.3120 - precision_m: 0.6405 - recall_m: 0.4500 - val_loss: 1.1452 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 4/100\n",
            "1/5 [=====>........................] - ETA: 27s - loss: 1.0095 - accuracy: 0.5312 - f1_m: 0.3686 - precision_m: 0.7510 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.0004 - accuracy: 0.4688 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0326 - accuracy: 0.4271 - f1_m: 0.2597 - precision_m: 0.7614 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0430 - accuracy: 0.4453 - f1_m: 0.2781 - precision_m: 0.7585 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0334 - accuracy: 0.4653 - f1_m: 0.3187 - precision_m: 0.7600 - recall_m: 0.4812\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0334 - accuracy: 0.4653 - f1_m: 0.3187 - precision_m: 0.7600 - recall_m: 0.4812 - val_loss: 1.0321 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 5/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0137 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.1035 - accuracy: 0.3906 - f1_m: 0.2240 - precision_m: 0.7681 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0474 - accuracy: 0.4479 - f1_m: 0.2843 - precision_m: 0.7633 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0230 - accuracy: 0.4688 - f1_m: 0.3054 - precision_m: 0.7603 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0302 - accuracy: 0.4653 - f1_m: 0.2976 - precision_m: 0.7590 - recall_m: 0.4625\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0302 - accuracy: 0.4653 - f1_m: 0.2976 - precision_m: 0.7590 - recall_m: 0.4625 - val_loss: 1.0412 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 6/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 0.9914 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 0.9868 - accuracy: 0.4531 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0128 - accuracy: 0.4688 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0113 - accuracy: 0.4766 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.4653 - f1_m: 0.2873 - precision_m: 0.7541 - recall_m: 0.4563\n",
            "5/5 [==============================] - 28s 6s/step - loss: 1.0296 - accuracy: 0.4653 - f1_m: 0.2873 - precision_m: 0.7541 - recall_m: 0.4563 - val_loss: 1.1675 - val_accuracy: 0.3514 - val_f1_m: 0.2022 - val_precision_m: 0.7672 - val_recall_m: 0.3719\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0226 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.0634 - accuracy: 0.4219 - f1_m: 0.2546 - precision_m: 0.7622 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0742 - accuracy: 0.4167 - f1_m: 0.2480 - precision_m: 0.7611 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0412 - accuracy: 0.4688 - f1_m: 0.3062 - precision_m: 0.7622 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0419 - accuracy: 0.4653 - f1_m: 0.2982 - precision_m: 0.7605 - recall_m: 0.4625\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0419 - accuracy: 0.4653 - f1_m: 0.2982 - precision_m: 0.7605 - recall_m: 0.4625 - val_loss: 1.3995 - val_accuracy: 0.1622 - val_f1_m: 0.0544 - val_precision_m: 0.8541 - val_recall_m: 0.1781\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 8/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 0.9574 - accuracy: 0.5938 - f1_m: 0.4424 - precision_m: 0.7588 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.0264 - accuracy: 0.5000 - f1_m: 0.3386 - precision_m: 0.7588 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0535 - accuracy: 0.4688 - f1_m: 0.3039 - precision_m: 0.7588 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0498 - accuracy: 0.4688 - f1_m: 0.3028 - precision_m: 0.7568 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0399 - accuracy: 0.4653 - f1_m: 0.2955 - precision_m: 0.7563 - recall_m: 0.4625\n",
            "5/5 [==============================] - 28s 6s/step - loss: 1.0399 - accuracy: 0.4653 - f1_m: 0.2955 - precision_m: 0.7563 - recall_m: 0.4625 - val_loss: 1.1274 - val_accuracy: 0.3514 - val_f1_m: 0.2022 - val_precision_m: 0.7672 - val_recall_m: 0.3719\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 9/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0443 - accuracy: 0.4062 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.0416 - accuracy: 0.4688 - f1_m: 0.3017 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0239 - accuracy: 0.4688 - f1_m: 0.3008 - precision_m: 0.7536 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0149 - accuracy: 0.4766 - f1_m: 0.3090 - precision_m: 0.7527 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0236 - accuracy: 0.4653 - f1_m: 0.2881 - precision_m: 0.7553 - recall_m: 0.4563\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.0236 - accuracy: 0.4653 - f1_m: 0.2881 - precision_m: 0.7553 - recall_m: 0.4563 - val_loss: 1.1069 - val_accuracy: 0.3514 - val_f1_m: 0.2022 - val_precision_m: 0.7672 - val_recall_m: 0.3719\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 10/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0886 - accuracy: 0.3750 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 29s - loss: 1.0419 - accuracy: 0.4062 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.0574 - accuracy: 0.4375 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0458 - accuracy: 0.4453 - f1_m: 0.2758 - precision_m: 0.7551 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0379 - accuracy: 0.4653 - f1_m: 0.3168 - precision_m: 0.7572 - recall_m: 0.4812\n",
            "5/5 [==============================] - 36s 8s/step - loss: 1.0379 - accuracy: 0.4653 - f1_m: 0.3168 - precision_m: 0.7572 - recall_m: 0.4812 - val_loss: 1.0397 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 11/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0203 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9830 - accuracy: 0.4844 - f1_m: 0.3175 - precision_m: 0.7524 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.9925 - accuracy: 0.4792 - f1_m: 0.3114 - precision_m: 0.7520 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0207 - accuracy: 0.4688 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0286 - accuracy: 0.4653 - f1_m: 0.2933 - precision_m: 0.7527 - recall_m: 0.4625\n",
            "5/5 [==============================] - 32s 7s/step - loss: 1.0286 - accuracy: 0.4653 - f1_m: 0.2933 - precision_m: 0.7527 - recall_m: 0.4625 - val_loss: 1.0136 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 12/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0295 - accuracy: 0.4062 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 0.9983 - accuracy: 0.5000 - f1_m: 0.3386 - precision_m: 0.7588 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0034 - accuracy: 0.4896 - f1_m: 0.3254 - precision_m: 0.7562 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0269 - accuracy: 0.4609 - f1_m: 0.2952 - precision_m: 0.7585 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0237 - accuracy: 0.4653 - f1_m: 0.3028 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0237 - accuracy: 0.4653 - f1_m: 0.3028 - precision_m: 0.7568 - recall_m: 0.4688 - val_loss: 1.0232 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 13/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0229 - accuracy: 0.4062 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0103 - accuracy: 0.4219 - f1_m: 0.2505 - precision_m: 0.7563 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0545 - accuracy: 0.4167 - f1_m: 0.2452 - precision_m: 0.7572 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0273 - accuracy: 0.4531 - f1_m: 0.2852 - precision_m: 0.7563 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0292 - accuracy: 0.4653 - f1_m: 0.3125 - precision_m: 0.7226 - recall_m: 0.4750\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0292 - accuracy: 0.4653 - f1_m: 0.3125 - precision_m: 0.7226 - recall_m: 0.4750 - val_loss: 1.0210 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 14/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9706 - accuracy: 0.4688 - f1_m: 0.3057 - precision_m: 0.2893 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0235 - accuracy: 0.4688 - f1_m: 0.3254 - precision_m: 0.4297 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0245 - accuracy: 0.4583 - f1_m: 0.3077 - precision_m: 0.4148 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0225 - accuracy: 0.4766 - f1_m: 0.3359 - precision_m: 0.4528 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0247 - accuracy: 0.4583 - f1_m: 0.3125 - precision_m: 0.5256 - recall_m: 0.4437\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0247 - accuracy: 0.4583 - f1_m: 0.3125 - precision_m: 0.5256 - recall_m: 0.4437 - val_loss: 1.0165 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 15/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9880 - accuracy: 0.5000 - f1_m: 0.4167 - precision_m: 0.6562 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0387 - accuracy: 0.3906 - f1_m: 0.2897 - precision_m: 0.4792 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0368 - accuracy: 0.4583 - f1_m: 0.3632 - precision_m: 0.5442 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0454 - accuracy: 0.4375 - f1_m: 0.3553 - precision_m: 0.5295 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0391 - accuracy: 0.4444 - f1_m: 0.3717 - precision_m: 0.5313 - recall_m: 0.4500\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0391 - accuracy: 0.4444 - f1_m: 0.3717 - precision_m: 0.5313 - recall_m: 0.4500 - val_loss: 1.0232 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 16/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0562 - accuracy: 0.4688 - f1_m: 0.3786 - precision_m: 0.5960 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0572 - accuracy: 0.4375 - f1_m: 0.3630 - precision_m: 0.5337 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0291 - accuracy: 0.4479 - f1_m: 0.3762 - precision_m: 0.5373 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0301 - accuracy: 0.4531 - f1_m: 0.3762 - precision_m: 0.5406 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0288 - accuracy: 0.4514 - f1_m: 0.3791 - precision_m: 0.5294 - recall_m: 0.4500\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0288 - accuracy: 0.4514 - f1_m: 0.3791 - precision_m: 0.5294 - recall_m: 0.4500 - val_loss: 1.1149 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 17/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9569 - accuracy: 0.5000 - f1_m: 0.4138 - precision_m: 0.5469 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0048 - accuracy: 0.4688 - f1_m: 0.3637 - precision_m: 0.5382 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0297 - accuracy: 0.4792 - f1_m: 0.3695 - precision_m: 0.5820 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0315 - accuracy: 0.4609 - f1_m: 0.3417 - precision_m: 0.5307 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.4792 - f1_m: 0.3792 - precision_m: 0.5796 - recall_m: 0.4938\n",
            "5/5 [==============================] - 32s 7s/step - loss: 1.0138 - accuracy: 0.4792 - f1_m: 0.3792 - precision_m: 0.5796 - recall_m: 0.4938 - val_loss: 1.2069 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 18/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0055 - accuracy: 0.5000 - f1_m: 0.3617 - precision_m: 0.4708 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 24s - loss: 1.0035 - accuracy: 0.4688 - f1_m: 0.3432 - precision_m: 0.5422 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0093 - accuracy: 0.5104 - f1_m: 0.3904 - precision_m: 0.5835 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0242 - accuracy: 0.4688 - f1_m: 0.3558 - precision_m: 0.5340 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0225 - accuracy: 0.4722 - f1_m: 0.3669 - precision_m: 0.5394 - recall_m: 0.4750\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0225 - accuracy: 0.4722 - f1_m: 0.3669 - precision_m: 0.5394 - recall_m: 0.4750 - val_loss: 1.4148 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 19/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9909 - accuracy: 0.4062 - f1_m: 0.3161 - precision_m: 0.4351 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 39s - loss: 0.9527 - accuracy: 0.4844 - f1_m: 0.4145 - precision_m: 0.4932 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 19s - loss: 0.9703 - accuracy: 0.4792 - f1_m: 0.4024 - precision_m: 0.5076 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9977 - accuracy: 0.4531 - f1_m: 0.3702 - precision_m: 0.5208 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0103 - accuracy: 0.4444 - f1_m: 0.3411 - precision_m: 0.5113 - recall_m: 0.4375\n",
            "5/5 [==============================] - 36s 8s/step - loss: 1.0103 - accuracy: 0.4444 - f1_m: 0.3411 - precision_m: 0.5113 - recall_m: 0.4375 - val_loss: 1.4659 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 20/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0138 - accuracy: 0.5312 - f1_m: 0.4495 - precision_m: 0.5831 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 16s - loss: 1.0446 - accuracy: 0.4688 - f1_m: 0.3851 - precision_m: 0.4837 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0699 - accuracy: 0.4688 - f1_m: 0.3837 - precision_m: 0.5322 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0425 - accuracy: 0.4766 - f1_m: 0.3949 - precision_m: 0.5359 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0371 - accuracy: 0.4931 - f1_m: 0.4233 - precision_m: 0.5694 - recall_m: 0.5063\n",
            "5/5 [==============================] - 28s 5s/step - loss: 1.0371 - accuracy: 0.4931 - f1_m: 0.4233 - precision_m: 0.5694 - recall_m: 0.5063 - val_loss: 1.1844 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 21/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 1.0198 - accuracy: 0.5625 - f1_m: 0.4597 - precision_m: 0.5884 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0226 - accuracy: 0.5000 - f1_m: 0.4059 - precision_m: 0.5893 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0228 - accuracy: 0.5000 - f1_m: 0.3891 - precision_m: 0.5682 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0142 - accuracy: 0.4609 - f1_m: 0.3492 - precision_m: 0.4925 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0141 - accuracy: 0.4583 - f1_m: 0.3579 - precision_m: 0.5029 - recall_m: 0.4563\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0141 - accuracy: 0.4583 - f1_m: 0.3579 - precision_m: 0.5029 - recall_m: 0.4563 - val_loss: 1.1548 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 22/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0203 - accuracy: 0.5312 - f1_m: 0.4547 - precision_m: 0.5974 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9817 - accuracy: 0.5469 - f1_m: 0.4550 - precision_m: 0.6056 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0059 - accuracy: 0.5208 - f1_m: 0.4164 - precision_m: 0.5444 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0287 - accuracy: 0.4688 - f1_m: 0.3587 - precision_m: 0.6084 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0294 - accuracy: 0.4792 - f1_m: 0.3713 - precision_m: 0.6167 - recall_m: 0.4875\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0294 - accuracy: 0.4792 - f1_m: 0.3713 - precision_m: 0.6167 - recall_m: 0.4875 - val_loss: 1.1311 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 23/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.9396 - accuracy: 0.5625 - f1_m: 0.4550 - precision_m: 0.5589 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 0.9868 - accuracy: 0.5156 - f1_m: 0.3928 - precision_m: 0.6595 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0227 - accuracy: 0.5000 - f1_m: 0.3715 - precision_m: 0.6930 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 5s - loss: 1.0269 - accuracy: 0.4922 - f1_m: 0.3551 - precision_m: 0.6312 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0240 - accuracy: 0.4792 - f1_m: 0.3250 - precision_m: 0.6581 - recall_m: 0.4688\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0240 - accuracy: 0.4792 - f1_m: 0.3250 - precision_m: 0.6581 - recall_m: 0.4688 - val_loss: 1.0794 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 24/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.1238 - accuracy: 0.4062 - f1_m: 0.2708 - precision_m: 0.4219 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 1.0567 - accuracy: 0.4688 - f1_m: 0.3452 - precision_m: 0.5353 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0666 - accuracy: 0.4375 - f1_m: 0.3174 - precision_m: 0.5072 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0479 - accuracy: 0.4219 - f1_m: 0.3076 - precision_m: 0.4761 - recall_m: 0.4219 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0403 - accuracy: 0.4444 - f1_m: 0.3563 - precision_m: 0.5380 - recall_m: 0.4625\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0403 - accuracy: 0.4444 - f1_m: 0.3563 - precision_m: 0.5380 - recall_m: 0.4625 - val_loss: 1.0249 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 25/100\n",
            "1/5 [=====>........................] - ETA: 33s - loss: 1.0016 - accuracy: 0.5000 - f1_m: 0.4039 - precision_m: 0.5139 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0359 - accuracy: 0.4062 - f1_m: 0.3220 - precision_m: 0.4696 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 11s - loss: 1.0462 - accuracy: 0.4062 - f1_m: 0.3133 - precision_m: 0.4771 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0434 - accuracy: 0.4219 - f1_m: 0.3233 - precision_m: 0.5027 - recall_m: 0.4219 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.4306 - f1_m: 0.3336 - precision_m: 0.4621 - recall_m: 0.4375\n",
            "5/5 [==============================] - 34s 6s/step - loss: 1.0271 - accuracy: 0.4306 - f1_m: 0.3336 - precision_m: 0.4621 - recall_m: 0.4375 - val_loss: 1.0177 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 26/100\n",
            "1/5 [=====>........................] - ETA: 23s - loss: 1.0051 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0059 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0313 - accuracy: 0.4271 - f1_m: 0.2699 - precision_m: 0.7634 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0298 - accuracy: 0.4609 - f1_m: 0.3106 - precision_m: 0.7626 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0264 - accuracy: 0.4792 - f1_m: 0.3446 - precision_m: 0.7632 - recall_m: 0.4938\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0264 - accuracy: 0.4792 - f1_m: 0.3446 - precision_m: 0.7632 - recall_m: 0.4938 - val_loss: 1.0242 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 27/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9180 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 0.9886 - accuracy: 0.4844 - f1_m: 0.3199 - precision_m: 0.7563 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0149 - accuracy: 0.4688 - f1_m: 0.3020 - precision_m: 0.7555 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0097 - accuracy: 0.4609 - f1_m: 0.2931 - precision_m: 0.7551 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0229 - accuracy: 0.4722 - f1_m: 0.3228 - precision_m: 0.7574 - recall_m: 0.4812\n",
            "5/5 [==============================] - 29s 6s/step - loss: 1.0229 - accuracy: 0.4722 - f1_m: 0.3228 - precision_m: 0.7574 - recall_m: 0.4812 - val_loss: 1.0927 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 28/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0053 - accuracy: 0.5000 - f1_m: 0.3404 - precision_m: 0.4456 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0439 - accuracy: 0.4375 - f1_m: 0.2810 - precision_m: 0.4264 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0328 - accuracy: 0.4479 - f1_m: 0.3128 - precision_m: 0.4431 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0340 - accuracy: 0.4531 - f1_m: 0.3285 - precision_m: 0.5274 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0178 - accuracy: 0.4792 - f1_m: 0.3866 - precision_m: 0.5817 - recall_m: 0.5000\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0178 - accuracy: 0.4792 - f1_m: 0.3866 - precision_m: 0.5817 - recall_m: 0.5000 - val_loss: 1.1399 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 29/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0835 - accuracy: 0.4688 - f1_m: 0.3469 - precision_m: 0.6261 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0515 - accuracy: 0.4688 - f1_m: 0.3688 - precision_m: 0.5937 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0070 - accuracy: 0.5208 - f1_m: 0.4358 - precision_m: 0.6198 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0211 - accuracy: 0.5000 - f1_m: 0.4089 - precision_m: 0.5773 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0338 - accuracy: 0.4931 - f1_m: 0.4014 - precision_m: 0.5763 - recall_m: 0.4875\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0338 - accuracy: 0.4931 - f1_m: 0.4014 - precision_m: 0.5763 - recall_m: 0.4875 - val_loss: 1.1642 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 30/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.0091 - accuracy: 0.5312 - f1_m: 0.4699 - precision_m: 0.6526 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0077 - accuracy: 0.5156 - f1_m: 0.4470 - precision_m: 0.5996 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9930 - accuracy: 0.5104 - f1_m: 0.4465 - precision_m: 0.5803 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0127 - accuracy: 0.4766 - f1_m: 0.4123 - precision_m: 0.5394 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0285 - accuracy: 0.4653 - f1_m: 0.3772 - precision_m: 0.5411 - recall_m: 0.4563\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0285 - accuracy: 0.4653 - f1_m: 0.3772 - precision_m: 0.5411 - recall_m: 0.4563 - val_loss: 1.0410 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 31/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9571 - accuracy: 0.5000 - f1_m: 0.4274 - precision_m: 0.5111 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 0.9764 - accuracy: 0.4531 - f1_m: 0.3558 - precision_m: 0.4802 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9980 - accuracy: 0.4479 - f1_m: 0.3260 - precision_m: 0.5715 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0251 - accuracy: 0.4453 - f1_m: 0.3111 - precision_m: 0.6171 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0207 - accuracy: 0.4444 - f1_m: 0.3021 - precision_m: 0.6444 - recall_m: 0.4437\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.0207 - accuracy: 0.4444 - f1_m: 0.3021 - precision_m: 0.6444 - recall_m: 0.4437 - val_loss: 1.0189 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 32/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9951 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 0.9981 - accuracy: 0.4531 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0096 - accuracy: 0.4688 - f1_m: 0.2996 - precision_m: 0.7516 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0265 - accuracy: 0.4766 - f1_m: 0.3080 - precision_m: 0.7512 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.4653 - f1_m: 0.2873 - precision_m: 0.7541 - recall_m: 0.4563\n",
            "5/5 [==============================] - 32s 7s/step - loss: 1.0270 - accuracy: 0.4653 - f1_m: 0.2873 - precision_m: 0.7541 - recall_m: 0.4563 - val_loss: 1.0263 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 33/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0508 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 26s - loss: 1.0115 - accuracy: 0.4688 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0328 - accuracy: 0.5000 - f1_m: 0.3349 - precision_m: 0.7526 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0231 - accuracy: 0.4766 - f1_m: 0.3098 - precision_m: 0.7542 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0241 - accuracy: 0.4653 - f1_m: 0.2888 - precision_m: 0.7564 - recall_m: 0.4563\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0241 - accuracy: 0.4653 - f1_m: 0.2888 - precision_m: 0.7564 - recall_m: 0.4563 - val_loss: 1.0168 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 34/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0799 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 24s - loss: 1.0219 - accuracy: 0.5000 - f1_m: 0.3339 - precision_m: 0.7510 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0476 - accuracy: 0.4479 - f1_m: 0.2919 - precision_m: 0.7634 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0221 - accuracy: 0.4453 - f1_m: 0.2915 - precision_m: 0.7636 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0119 - accuracy: 0.4722 - f1_m: 0.3554 - precision_m: 0.7334 - recall_m: 0.4938\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0119 - accuracy: 0.4722 - f1_m: 0.3554 - precision_m: 0.7334 - recall_m: 0.4938 - val_loss: 1.0202 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 35/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0568 - accuracy: 0.3438 - f1_m: 0.2371 - precision_m: 0.7279 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0453 - accuracy: 0.4219 - f1_m: 0.2888 - precision_m: 0.6024 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0551 - accuracy: 0.4792 - f1_m: 0.3477 - precision_m: 0.5918 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0322 - accuracy: 0.4766 - f1_m: 0.3441 - precision_m: 0.6157 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.4722 - f1_m: 0.3310 - precision_m: 0.6334 - recall_m: 0.4688\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0268 - accuracy: 0.4722 - f1_m: 0.3310 - precision_m: 0.6334 - recall_m: 0.4688 - val_loss: 1.0434 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 36/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9320 - accuracy: 0.5312 - f1_m: 0.3763 - precision_m: 0.6976 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 0.9105 - accuracy: 0.5312 - f1_m: 0.3725 - precision_m: 0.7243 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.9661 - accuracy: 0.5208 - f1_m: 0.3594 - precision_m: 0.7329 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0259 - accuracy: 0.4766 - f1_m: 0.3135 - precision_m: 0.7432 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0499 - accuracy: 0.4653 - f1_m: 0.2917 - precision_m: 0.7477 - recall_m: 0.4563\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0499 - accuracy: 0.4653 - f1_m: 0.2917 - precision_m: 0.7477 - recall_m: 0.4563 - val_loss: 1.0342 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 37/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.1315 - accuracy: 0.3125 - f1_m: 0.1637 - precision_m: 0.3296 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.1182 - accuracy: 0.3906 - f1_m: 0.2314 - precision_m: 0.5403 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0619 - accuracy: 0.4167 - f1_m: 0.2697 - precision_m: 0.5373 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0402 - accuracy: 0.4453 - f1_m: 0.3082 - precision_m: 0.5316 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0381 - accuracy: 0.4514 - f1_m: 0.3341 - precision_m: 0.5409 - recall_m: 0.4563\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.0381 - accuracy: 0.4514 - f1_m: 0.3341 - precision_m: 0.5409 - recall_m: 0.4563 - val_loss: 1.0030 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 38/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 1.0576 - accuracy: 0.4375 - f1_m: 0.3434 - precision_m: 0.5353 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 23s - loss: 1.0009 - accuracy: 0.4844 - f1_m: 0.3908 - precision_m: 0.5422 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0350 - accuracy: 0.4688 - f1_m: 0.3786 - precision_m: 0.5546 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0161 - accuracy: 0.5078 - f1_m: 0.4226 - precision_m: 0.6124 - recall_m: 0.5078 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0255 - accuracy: 0.4792 - f1_m: 0.3631 - precision_m: 0.5566 - recall_m: 0.4563\n",
            "5/5 [==============================] - 33s 6s/step - loss: 1.0255 - accuracy: 0.4792 - f1_m: 0.3631 - precision_m: 0.5566 - recall_m: 0.4563 - val_loss: 1.0007 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 39/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0058 - accuracy: 0.5312 - f1_m: 0.3903 - precision_m: 0.4647 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0581 - accuracy: 0.4375 - f1_m: 0.2934 - precision_m: 0.4417 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0517 - accuracy: 0.4167 - f1_m: 0.2794 - precision_m: 0.4705 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0339 - accuracy: 0.4531 - f1_m: 0.3179 - precision_m: 0.5429 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0255 - accuracy: 0.4583 - f1_m: 0.3210 - precision_m: 0.5843 - recall_m: 0.4625\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.0255 - accuracy: 0.4583 - f1_m: 0.3210 - precision_m: 0.5843 - recall_m: 0.4625 - val_loss: 1.0041 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 40/100\n",
            "1/5 [=====>........................] - ETA: 32s - loss: 1.0209 - accuracy: 0.4375 - f1_m: 0.3234 - precision_m: 0.4127 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0277 - accuracy: 0.4688 - f1_m: 0.3440 - precision_m: 0.5110 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0166 - accuracy: 0.4896 - f1_m: 0.3626 - precision_m: 0.5442 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0169 - accuracy: 0.4922 - f1_m: 0.3687 - precision_m: 0.5998 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0188 - accuracy: 0.4653 - f1_m: 0.3199 - precision_m: 0.5215 - recall_m: 0.4437\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.0188 - accuracy: 0.4653 - f1_m: 0.3199 - precision_m: 0.5215 - recall_m: 0.4437 - val_loss: 1.0352 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 41/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9301 - accuracy: 0.5938 - f1_m: 0.4835 - precision_m: 0.5882 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 0.9994 - accuracy: 0.4844 - f1_m: 0.3884 - precision_m: 0.5443 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9915 - accuracy: 0.4792 - f1_m: 0.3933 - precision_m: 0.5244 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9831 - accuracy: 0.4766 - f1_m: 0.3941 - precision_m: 0.5258 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0066 - accuracy: 0.4514 - f1_m: 0.3388 - precision_m: 0.5235 - recall_m: 0.4313\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0066 - accuracy: 0.4514 - f1_m: 0.3388 - precision_m: 0.5235 - recall_m: 0.4313 - val_loss: 1.1858 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 42/100\n",
            "1/5 [=====>........................] - ETA: 32s - loss: 0.9794 - accuracy: 0.5312 - f1_m: 0.4714 - precision_m: 0.5638 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0081 - accuracy: 0.5938 - f1_m: 0.5164 - precision_m: 0.6526 - recall_m: 0.5938\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9988 - accuracy: 0.5938 - f1_m: 0.5184 - precision_m: 0.6636 - recall_m: 0.5938\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0097 - accuracy: 0.5625 - f1_m: 0.4967 - precision_m: 0.6373 - recall_m: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0024 - accuracy: 0.5625 - f1_m: 0.5042 - precision_m: 0.6349 - recall_m: 0.5625\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0024 - accuracy: 0.5625 - f1_m: 0.5042 - precision_m: 0.6349 - recall_m: 0.5625 - val_loss: 1.4714 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 43/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9272 - accuracy: 0.4688 - f1_m: 0.4680 - precision_m: 0.5068 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9847 - accuracy: 0.4844 - f1_m: 0.4549 - precision_m: 0.5707 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0168 - accuracy: 0.4479 - f1_m: 0.4154 - precision_m: 0.5692 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0014 - accuracy: 0.4531 - f1_m: 0.4204 - precision_m: 0.5561 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0336 - accuracy: 0.4236 - f1_m: 0.3662 - precision_m: 0.5189 - recall_m: 0.4000\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0336 - accuracy: 0.4236 - f1_m: 0.3662 - precision_m: 0.5189 - recall_m: 0.4000 - val_loss: 1.4893 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 44/100\n",
            "1/5 [=====>........................] - ETA: 27s - loss: 0.9113 - accuracy: 0.5312 - f1_m: 0.4785 - precision_m: 0.5705 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0381 - accuracy: 0.4688 - f1_m: 0.4063 - precision_m: 0.5697 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0157 - accuracy: 0.4896 - f1_m: 0.4242 - precision_m: 0.5684 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0041 - accuracy: 0.5000 - f1_m: 0.4233 - precision_m: 0.6177 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0137 - accuracy: 0.4931 - f1_m: 0.3919 - precision_m: 0.6449 - recall_m: 0.4875\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0137 - accuracy: 0.4931 - f1_m: 0.3919 - precision_m: 0.6449 - recall_m: 0.4875 - val_loss: 1.0701 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 45/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 0.9729 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0212 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0129 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0254 - accuracy: 0.4609 - f1_m: 0.2940 - precision_m: 0.7561 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0261 - accuracy: 0.4653 - f1_m: 0.3018 - precision_m: 0.7549 - recall_m: 0.4688\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0261 - accuracy: 0.4653 - f1_m: 0.3018 - precision_m: 0.7549 - recall_m: 0.4688 - val_loss: 1.0306 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 46/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.2103 - accuracy: 0.3438 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.1168 - accuracy: 0.3906 - f1_m: 0.2211 - precision_m: 0.7642 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0670 - accuracy: 0.4583 - f1_m: 0.2949 - precision_m: 0.7624 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0485 - accuracy: 0.4453 - f1_m: 0.2798 - precision_m: 0.7615 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0331 - accuracy: 0.4653 - f1_m: 0.3200 - precision_m: 0.7623 - recall_m: 0.4812\n",
            "5/5 [==============================] - 30s 6s/step - loss: 1.0331 - accuracy: 0.4653 - f1_m: 0.3200 - precision_m: 0.7623 - recall_m: 0.4812 - val_loss: 1.0376 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 24s - loss: 1.0794 - accuracy: 0.3750 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0744 - accuracy: 0.4219 - f1_m: 0.2618 - precision_m: 0.6288 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0460 - accuracy: 0.4583 - f1_m: 0.2974 - precision_m: 0.6695 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0337 - accuracy: 0.4766 - f1_m: 0.3152 - precision_m: 0.6899 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0297 - accuracy: 0.4583 - f1_m: 0.2819 - precision_m: 0.7089 - recall_m: 0.4437\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0297 - accuracy: 0.4583 - f1_m: 0.2819 - precision_m: 0.7089 - recall_m: 0.4437 - val_loss: 1.0885 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 48/100\n",
            "1/5 [=====>........................] - ETA: 35s - loss: 1.0378 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 18s - loss: 1.0705 - accuracy: 0.4531 - f1_m: 0.2923 - precision_m: 0.6063 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0524 - accuracy: 0.4375 - f1_m: 0.2731 - precision_m: 0.6572 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0338 - accuracy: 0.4609 - f1_m: 0.3044 - precision_m: 0.6824 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0280 - accuracy: 0.4653 - f1_m: 0.3259 - precision_m: 0.6584 - recall_m: 0.4688\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.0280 - accuracy: 0.4653 - f1_m: 0.3259 - precision_m: 0.6584 - recall_m: 0.4688 - val_loss: 1.1118 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 49/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.1271 - accuracy: 0.4375 - f1_m: 0.3157 - precision_m: 0.6760 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0560 - accuracy: 0.5312 - f1_m: 0.4310 - precision_m: 0.6633 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0339 - accuracy: 0.4896 - f1_m: 0.3963 - precision_m: 0.6016 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0123 - accuracy: 0.4922 - f1_m: 0.4004 - precision_m: 0.5715 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0201 - accuracy: 0.4722 - f1_m: 0.3630 - precision_m: 0.5652 - recall_m: 0.4563\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0201 - accuracy: 0.4722 - f1_m: 0.3630 - precision_m: 0.5652 - recall_m: 0.4563 - val_loss: 1.1617 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 50/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9020 - accuracy: 0.5312 - f1_m: 0.4685 - precision_m: 0.4704 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9600 - accuracy: 0.5156 - f1_m: 0.4438 - precision_m: 0.5449 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9917 - accuracy: 0.5000 - f1_m: 0.4263 - precision_m: 0.6270 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0183 - accuracy: 0.4922 - f1_m: 0.4087 - precision_m: 0.6141 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.4792 - f1_m: 0.3839 - precision_m: 0.5993 - recall_m: 0.4688\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0219 - accuracy: 0.4792 - f1_m: 0.3839 - precision_m: 0.5993 - recall_m: 0.4688 - val_loss: 1.1438 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 51/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.8779 - accuracy: 0.6875 - f1_m: 0.6360 - precision_m: 0.6953 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9328 - accuracy: 0.5781 - f1_m: 0.5367 - precision_m: 0.6226 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.9474 - accuracy: 0.5521 - f1_m: 0.5158 - precision_m: 0.6085 - recall_m: 0.5521\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0392 - accuracy: 0.5000 - f1_m: 0.4513 - precision_m: 0.6130 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.4931 - f1_m: 0.4403 - precision_m: 0.5779 - recall_m: 0.4875\n",
            "5/5 [==============================] - 37s 8s/step - loss: 1.0290 - accuracy: 0.4931 - f1_m: 0.4403 - precision_m: 0.5779 - recall_m: 0.4875 - val_loss: 1.2253 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 52/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9390 - accuracy: 0.5312 - f1_m: 0.4714 - precision_m: 0.5875 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9324 - accuracy: 0.5312 - f1_m: 0.4920 - precision_m: 0.5744 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9848 - accuracy: 0.5104 - f1_m: 0.4530 - precision_m: 0.5743 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0175 - accuracy: 0.4844 - f1_m: 0.4069 - precision_m: 0.5685 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0096 - accuracy: 0.5000 - f1_m: 0.4318 - precision_m: 0.5868 - recall_m: 0.5125\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0096 - accuracy: 0.5000 - f1_m: 0.4318 - precision_m: 0.5868 - recall_m: 0.5125 - val_loss: 1.1816 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 53/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0595 - accuracy: 0.4375 - f1_m: 0.3297 - precision_m: 0.5681 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 23s - loss: 1.0362 - accuracy: 0.4531 - f1_m: 0.3450 - precision_m: 0.5401 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0385 - accuracy: 0.4583 - f1_m: 0.3509 - precision_m: 0.5320 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0209 - accuracy: 0.4844 - f1_m: 0.3805 - precision_m: 0.5491 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0318 - accuracy: 0.4514 - f1_m: 0.3253 - precision_m: 0.4787 - recall_m: 0.4250\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0318 - accuracy: 0.4514 - f1_m: 0.3253 - precision_m: 0.4787 - recall_m: 0.4250 - val_loss: 1.1670 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 54/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.8888 - accuracy: 0.5625 - f1_m: 0.4706 - precision_m: 0.5043 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 0.9671 - accuracy: 0.5312 - f1_m: 0.4335 - precision_m: 0.5718 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.9922 - accuracy: 0.4896 - f1_m: 0.3871 - precision_m: 0.5457 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0349 - accuracy: 0.4297 - f1_m: 0.3223 - precision_m: 0.5012 - recall_m: 0.4297 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.4514 - f1_m: 0.3735 - precision_m: 0.5336 - recall_m: 0.4688\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0271 - accuracy: 0.4514 - f1_m: 0.3735 - precision_m: 0.5336 - recall_m: 0.4688 - val_loss: 1.0298 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 55/100\n",
            "1/5 [=====>........................] - ETA: 31s - loss: 0.9725 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 33s - loss: 0.9838 - accuracy: 0.4844 - f1_m: 0.3163 - precision_m: 0.7505 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.9794 - accuracy: 0.5000 - f1_m: 0.3337 - precision_m: 0.7507 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0133 - accuracy: 0.4688 - f1_m: 0.3014 - precision_m: 0.7544 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0192 - accuracy: 0.4653 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.0192 - accuracy: 0.4653 - f1_m: 0.2944 - precision_m: 0.7543 - recall_m: 0.4625 - val_loss: 1.0227 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 56/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.1025 - accuracy: 0.4062 - f1_m: 0.2347 - precision_m: 0.7588 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0897 - accuracy: 0.3906 - f1_m: 0.2196 - precision_m: 0.7622 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0519 - accuracy: 0.4375 - f1_m: 0.2693 - precision_m: 0.7585 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0299 - accuracy: 0.4609 - f1_m: 0.2941 - precision_m: 0.7566 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0253 - accuracy: 0.4653 - f1_m: 0.3020 - precision_m: 0.7553 - recall_m: 0.4688\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0253 - accuracy: 0.4653 - f1_m: 0.3020 - precision_m: 0.7553 - recall_m: 0.4688 - val_loss: 1.0130 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 57/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 1.0529 - accuracy: 0.4688 - f1_m: 0.2992 - precision_m: 0.7510 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0685 - accuracy: 0.4375 - f1_m: 0.2670 - precision_m: 0.7549 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0383 - accuracy: 0.4688 - f1_m: 0.3107 - precision_m: 0.7559 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0280 - accuracy: 0.4844 - f1_m: 0.3252 - precision_m: 0.7547 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.4792 - f1_m: 0.3255 - precision_m: 0.7588 - recall_m: 0.4750\n",
            "5/5 [==============================] - 33s 6s/step - loss: 1.0175 - accuracy: 0.4792 - f1_m: 0.3255 - precision_m: 0.7588 - recall_m: 0.4750 - val_loss: 1.0126 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 58/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9008 - accuracy: 0.6250 - f1_m: 0.5125 - precision_m: 0.6260 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9662 - accuracy: 0.5312 - f1_m: 0.4283 - precision_m: 0.5584 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9801 - accuracy: 0.5104 - f1_m: 0.4112 - precision_m: 0.5594 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0009 - accuracy: 0.4844 - f1_m: 0.3808 - precision_m: 0.5666 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0066 - accuracy: 0.4861 - f1_m: 0.3885 - precision_m: 0.6104 - recall_m: 0.4875\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0066 - accuracy: 0.4861 - f1_m: 0.3885 - precision_m: 0.6104 - recall_m: 0.4875 - val_loss: 1.0747 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 59/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0422 - accuracy: 0.5000 - f1_m: 0.4081 - precision_m: 0.6014 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9690 - accuracy: 0.5625 - f1_m: 0.4883 - precision_m: 0.6308 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0090 - accuracy: 0.5208 - f1_m: 0.4440 - precision_m: 0.6141 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9928 - accuracy: 0.5312 - f1_m: 0.4686 - precision_m: 0.6073 - recall_m: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0333 - accuracy: 0.5000 - f1_m: 0.4170 - precision_m: 0.5847 - recall_m: 0.4750\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0333 - accuracy: 0.5000 - f1_m: 0.4170 - precision_m: 0.5847 - recall_m: 0.4750 - val_loss: 0.9893 - val_accuracy: 0.5676 - val_f1_m: 0.5142 - val_precision_m: 0.7273 - val_recall_m: 0.5813\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 60/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9375 - accuracy: 0.5312 - f1_m: 0.5118 - precision_m: 0.6934 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0232 - accuracy: 0.5312 - f1_m: 0.4878 - precision_m: 0.6639 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.9741 - accuracy: 0.5729 - f1_m: 0.5257 - precision_m: 0.6926 - recall_m: 0.5729\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9937 - accuracy: 0.5234 - f1_m: 0.4702 - precision_m: 0.6447 - recall_m: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.5000 - f1_m: 0.4199 - precision_m: 0.5869 - recall_m: 0.4812\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0073 - accuracy: 0.5000 - f1_m: 0.4199 - precision_m: 0.5869 - recall_m: 0.4812 - val_loss: 0.9995 - val_accuracy: 0.5405 - val_f1_m: 0.5021 - val_precision_m: 0.6958 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 61/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9519 - accuracy: 0.5938 - f1_m: 0.5294 - precision_m: 0.6965 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0077 - accuracy: 0.5156 - f1_m: 0.4325 - precision_m: 0.6397 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0040 - accuracy: 0.5417 - f1_m: 0.4628 - precision_m: 0.6452 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9965 - accuracy: 0.5078 - f1_m: 0.4142 - precision_m: 0.6765 - recall_m: 0.5078 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0179 - accuracy: 0.5000 - f1_m: 0.3846 - precision_m: 0.6920 - recall_m: 0.4938\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0179 - accuracy: 0.5000 - f1_m: 0.3846 - precision_m: 0.6920 - recall_m: 0.4938 - val_loss: 1.0156 - val_accuracy: 0.5676 - val_f1_m: 0.5142 - val_precision_m: 0.7273 - val_recall_m: 0.5813\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 62/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0153 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9912 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 18s - loss: 1.0225 - accuracy: 0.5000 - f1_m: 0.3382 - precision_m: 0.7578 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0344 - accuracy: 0.4688 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0273 - accuracy: 0.4653 - f1_m: 0.2971 - precision_m: 0.7586 - recall_m: 0.4625\n",
            "5/5 [==============================] - 37s 8s/step - loss: 1.0273 - accuracy: 0.4653 - f1_m: 0.2971 - precision_m: 0.7586 - recall_m: 0.4625 - val_loss: 1.0120 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 63/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0248 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0156 - accuracy: 0.4688 - f1_m: 0.2998 - precision_m: 0.7520 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0416 - accuracy: 0.4271 - f1_m: 0.2741 - precision_m: 0.6693 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0309 - accuracy: 0.4531 - f1_m: 0.3137 - precision_m: 0.6510 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0229 - accuracy: 0.4653 - f1_m: 0.3544 - precision_m: 0.6416 - recall_m: 0.4750\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0229 - accuracy: 0.4653 - f1_m: 0.3544 - precision_m: 0.6416 - recall_m: 0.4750 - val_loss: 1.0152 - val_accuracy: 0.5405 - val_f1_m: 0.5758 - val_precision_m: 0.7925 - val_recall_m: 0.6500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 64/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9762 - accuracy: 0.5000 - f1_m: 0.4266 - precision_m: 0.5625 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 1.0241 - accuracy: 0.4688 - f1_m: 0.3850 - precision_m: 0.5489 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0119 - accuracy: 0.4792 - f1_m: 0.3952 - precision_m: 0.5653 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0169 - accuracy: 0.4688 - f1_m: 0.3908 - precision_m: 0.5462 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.4583 - f1_m: 0.3652 - precision_m: 0.5398 - recall_m: 0.4500\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0296 - accuracy: 0.4583 - f1_m: 0.3652 - precision_m: 0.5398 - recall_m: 0.4500 - val_loss: 1.0111 - val_accuracy: 0.5405 - val_f1_m: 0.5758 - val_precision_m: 0.7925 - val_recall_m: 0.6500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 65/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9432 - accuracy: 0.5625 - f1_m: 0.4830 - precision_m: 0.7019 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9354 - accuracy: 0.5781 - f1_m: 0.4985 - precision_m: 0.6701 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 12s - loss: 0.9940 - accuracy: 0.5208 - f1_m: 0.4368 - precision_m: 0.6091 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9949 - accuracy: 0.5078 - f1_m: 0.4188 - precision_m: 0.6014 - recall_m: 0.5078 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0053 - accuracy: 0.5000 - f1_m: 0.4035 - precision_m: 0.5874 - recall_m: 0.4938\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0053 - accuracy: 0.5000 - f1_m: 0.4035 - precision_m: 0.5874 - recall_m: 0.4938 - val_loss: 1.0490 - val_accuracy: 0.4324 - val_f1_m: 0.4144 - val_precision_m: 0.7911 - val_recall_m: 0.5031\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 66/100\n",
            "1/5 [=====>........................] - ETA: 32s - loss: 1.0868 - accuracy: 0.4062 - f1_m: 0.3230 - precision_m: 0.5157 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 23s - loss: 1.0435 - accuracy: 0.4688 - f1_m: 0.3790 - precision_m: 0.5977 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0256 - accuracy: 0.5000 - f1_m: 0.4102 - precision_m: 0.5759 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0366 - accuracy: 0.4609 - f1_m: 0.3516 - precision_m: 0.6255 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0363 - accuracy: 0.4583 - f1_m: 0.3345 - precision_m: 0.6512 - recall_m: 0.4563\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0363 - accuracy: 0.4583 - f1_m: 0.3345 - precision_m: 0.6512 - recall_m: 0.4563 - val_loss: 1.0226 - val_accuracy: 0.5405 - val_f1_m: 0.5021 - val_precision_m: 0.6958 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 67/100\n",
            "1/5 [=====>........................] - ETA: 58s - loss: 1.0659 - accuracy: 0.3438 - f1_m: 0.1801 - precision_m: 0.3095 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0516 - accuracy: 0.4375 - f1_m: 0.2884 - precision_m: 0.5338 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0197 - accuracy: 0.4688 - f1_m: 0.3223 - precision_m: 0.4899 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0213 - accuracy: 0.4609 - f1_m: 0.3098 - precision_m: 0.4637 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0249 - accuracy: 0.4583 - f1_m: 0.3087 - precision_m: 0.4551 - recall_m: 0.4563\n",
            "5/5 [==============================] - 44s 7s/step - loss: 1.0249 - accuracy: 0.4583 - f1_m: 0.3087 - precision_m: 0.4551 - recall_m: 0.4563 - val_loss: 1.0189 - val_accuracy: 0.5405 - val_f1_m: 0.4824 - val_precision_m: 0.7220 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 68/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0003 - accuracy: 0.5312 - f1_m: 0.4120 - precision_m: 0.4927 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9786 - accuracy: 0.5781 - f1_m: 0.4464 - precision_m: 0.6292 - recall_m: 0.5781\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0209 - accuracy: 0.4792 - f1_m: 0.3387 - precision_m: 0.6854 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0347 - accuracy: 0.4453 - f1_m: 0.2980 - precision_m: 0.7076 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0234 - accuracy: 0.4514 - f1_m: 0.3051 - precision_m: 0.7161 - recall_m: 0.4563\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0234 - accuracy: 0.4514 - f1_m: 0.3051 - precision_m: 0.7161 - recall_m: 0.4563 - val_loss: 0.9986 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 69/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9630 - accuracy: 0.5625 - f1_m: 0.4050 - precision_m: 0.7539 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9932 - accuracy: 0.4844 - f1_m: 0.3199 - precision_m: 0.7563 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.9793 - accuracy: 0.5521 - f1_m: 0.4177 - precision_m: 0.7706 - recall_m: 0.5521\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9992 - accuracy: 0.5078 - f1_m: 0.3732 - precision_m: 0.7149 - recall_m: 0.5078 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0113 - accuracy: 0.4792 - f1_m: 0.3335 - precision_m: 0.6489 - recall_m: 0.4563\n",
            "5/5 [==============================] - 37s 8s/step - loss: 1.0113 - accuracy: 0.4792 - f1_m: 0.3335 - precision_m: 0.6489 - recall_m: 0.4563 - val_loss: 0.9856 - val_accuracy: 0.4865 - val_f1_m: 0.3038 - val_precision_m: 0.6691 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 70/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0725 - accuracy: 0.3750 - f1_m: 0.3381 - precision_m: 0.5290 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0857 - accuracy: 0.4688 - f1_m: 0.4113 - precision_m: 0.6038 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0626 - accuracy: 0.4583 - f1_m: 0.4096 - precision_m: 0.5942 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0230 - accuracy: 0.4922 - f1_m: 0.4483 - precision_m: 0.6091 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.4931 - f1_m: 0.4558 - precision_m: 0.5944 - recall_m: 0.4938\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0081 - accuracy: 0.4931 - f1_m: 0.4558 - precision_m: 0.5944 - recall_m: 0.4938 - val_loss: 0.9786 - val_accuracy: 0.5676 - val_f1_m: 0.5142 - val_precision_m: 0.7273 - val_recall_m: 0.5813\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 71/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.8999 - accuracy: 0.6250 - f1_m: 0.5779 - precision_m: 0.7299 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 0.9605 - accuracy: 0.5156 - f1_m: 0.4845 - precision_m: 0.5863 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.9829 - accuracy: 0.4896 - f1_m: 0.4571 - precision_m: 0.5823 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0244 - accuracy: 0.4766 - f1_m: 0.4400 - precision_m: 0.5871 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0329 - accuracy: 0.4653 - f1_m: 0.4073 - precision_m: 0.5759 - recall_m: 0.4563\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0329 - accuracy: 0.4653 - f1_m: 0.4073 - precision_m: 0.5759 - recall_m: 0.4563 - val_loss: 0.9806 - val_accuracy: 0.5676 - val_f1_m: 0.5142 - val_precision_m: 0.7273 - val_recall_m: 0.5813\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 72/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0345 - accuracy: 0.4688 - f1_m: 0.4089 - precision_m: 0.6003 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9906 - accuracy: 0.5312 - f1_m: 0.4689 - precision_m: 0.6096 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.9975 - accuracy: 0.5417 - f1_m: 0.4728 - precision_m: 0.6121 - recall_m: 0.5417\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0131 - accuracy: 0.5234 - f1_m: 0.4527 - precision_m: 0.6016 - recall_m: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0279 - accuracy: 0.4931 - f1_m: 0.3885 - precision_m: 0.5492 - recall_m: 0.4688\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0279 - accuracy: 0.4931 - f1_m: 0.3885 - precision_m: 0.5492 - recall_m: 0.4688 - val_loss: 1.0123 - val_accuracy: 0.5405 - val_f1_m: 0.5021 - val_precision_m: 0.6958 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 73/100\n",
            "1/5 [=====>........................] - ETA: 35s - loss: 1.0084 - accuracy: 0.4688 - f1_m: 0.3511 - precision_m: 0.5078 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 1.0254 - accuracy: 0.4531 - f1_m: 0.3516 - precision_m: 0.5490 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0243 - accuracy: 0.4792 - f1_m: 0.3820 - precision_m: 0.5926 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0206 - accuracy: 0.4844 - f1_m: 0.3861 - precision_m: 0.6026 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0235 - accuracy: 0.5069 - f1_m: 0.4276 - precision_m: 0.6404 - recall_m: 0.5250\n",
            "5/5 [==============================] - 35s 6s/step - loss: 1.0235 - accuracy: 0.5069 - f1_m: 0.4276 - precision_m: 0.6404 - recall_m: 0.5250 - val_loss: 1.0318 - val_accuracy: 0.5946 - val_f1_m: 0.6129 - val_precision_m: 0.7451 - val_recall_m: 0.6812\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 74/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9564 - accuracy: 0.5938 - f1_m: 0.4927 - precision_m: 0.6552 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0056 - accuracy: 0.5312 - f1_m: 0.4111 - precision_m: 0.7076 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0035 - accuracy: 0.5104 - f1_m: 0.3738 - precision_m: 0.7221 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9991 - accuracy: 0.5156 - f1_m: 0.3725 - precision_m: 0.7293 - recall_m: 0.5156 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0141 - accuracy: 0.4861 - f1_m: 0.3180 - precision_m: 0.7459 - recall_m: 0.4625\n",
            "5/5 [==============================] - 33s 7s/step - loss: 1.0141 - accuracy: 0.4861 - f1_m: 0.3180 - precision_m: 0.7459 - recall_m: 0.4625 - val_loss: 1.0341 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 75/100\n",
            "1/5 [=====>........................] - ETA: 32s - loss: 1.0989 - accuracy: 0.4375 - f1_m: 0.2973 - precision_m: 0.7641 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0327 - accuracy: 0.4844 - f1_m: 0.3368 - precision_m: 0.6215 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0364 - accuracy: 0.4375 - f1_m: 0.2916 - precision_m: 0.5242 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0151 - accuracy: 0.4766 - f1_m: 0.3431 - precision_m: 0.5244 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.4653 - f1_m: 0.3328 - precision_m: 0.5007 - recall_m: 0.4563\n",
            "5/5 [==============================] - 33s 6s/step - loss: 1.0081 - accuracy: 0.4653 - f1_m: 0.3328 - precision_m: 0.5007 - recall_m: 0.4563 - val_loss: 1.1062 - val_accuracy: 0.2432 - val_f1_m: 0.1629 - val_precision_m: 0.5481 - val_recall_m: 0.2250\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 76/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.0493 - accuracy: 0.3438 - f1_m: 0.2625 - precision_m: 0.3662 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9898 - accuracy: 0.4375 - f1_m: 0.3627 - precision_m: 0.4956 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0130 - accuracy: 0.4792 - f1_m: 0.4148 - precision_m: 0.5507 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0384 - accuracy: 0.4766 - f1_m: 0.4128 - precision_m: 0.5604 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0372 - accuracy: 0.4792 - f1_m: 0.4141 - precision_m: 0.5598 - recall_m: 0.4812\n",
            "5/5 [==============================] - 38s 8s/step - loss: 1.0372 - accuracy: 0.4792 - f1_m: 0.4141 - precision_m: 0.5598 - recall_m: 0.4812 - val_loss: 1.0920 - val_accuracy: 0.3784 - val_f1_m: 0.2337 - val_precision_m: 0.7691 - val_recall_m: 0.3875\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 77/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9874 - accuracy: 0.5938 - f1_m: 0.5233 - precision_m: 0.5480 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0595 - accuracy: 0.5000 - f1_m: 0.4212 - precision_m: 0.5783 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0772 - accuracy: 0.4688 - f1_m: 0.3988 - precision_m: 0.5678 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0458 - accuracy: 0.5000 - f1_m: 0.4255 - precision_m: 0.5816 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0389 - accuracy: 0.5000 - f1_m: 0.4227 - precision_m: 0.5774 - recall_m: 0.5000\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0389 - accuracy: 0.5000 - f1_m: 0.4227 - precision_m: 0.5774 - recall_m: 0.5000 - val_loss: 1.0138 - val_accuracy: 0.5405 - val_f1_m: 0.5896 - val_precision_m: 0.7240 - val_recall_m: 0.6500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 78/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.1075 - accuracy: 0.4375 - f1_m: 0.3498 - precision_m: 0.5761 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0203 - accuracy: 0.5156 - f1_m: 0.4326 - precision_m: 0.6432 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0063 - accuracy: 0.5000 - f1_m: 0.4152 - precision_m: 0.5999 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0036 - accuracy: 0.5234 - f1_m: 0.4358 - precision_m: 0.6268 - recall_m: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.5139 - f1_m: 0.4123 - precision_m: 0.5890 - recall_m: 0.5063\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0049 - accuracy: 0.5139 - f1_m: 0.4123 - precision_m: 0.5890 - recall_m: 0.5063 - val_loss: 1.0058 - val_accuracy: 0.5676 - val_f1_m: 0.6003 - val_precision_m: 0.7324 - val_recall_m: 0.6656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 79/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9415 - accuracy: 0.5312 - f1_m: 0.4610 - precision_m: 0.5968 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0019 - accuracy: 0.4688 - f1_m: 0.3863 - precision_m: 0.5655 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0372 - accuracy: 0.4375 - f1_m: 0.3514 - precision_m: 0.5461 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0157 - accuracy: 0.4766 - f1_m: 0.3980 - precision_m: 0.5723 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.4931 - f1_m: 0.4287 - precision_m: 0.5944 - recall_m: 0.5063\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0114 - accuracy: 0.4931 - f1_m: 0.4287 - precision_m: 0.5944 - recall_m: 0.5063 - val_loss: 0.9925 - val_accuracy: 0.5405 - val_f1_m: 0.5021 - val_precision_m: 0.6958 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 80/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0462 - accuracy: 0.5000 - f1_m: 0.4115 - precision_m: 0.5609 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0282 - accuracy: 0.4844 - f1_m: 0.3804 - precision_m: 0.5857 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.9787 - accuracy: 0.5625 - f1_m: 0.4846 - precision_m: 0.6465 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9918 - accuracy: 0.5391 - f1_m: 0.4586 - precision_m: 0.6138 - recall_m: 0.5391 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.5139 - f1_m: 0.4063 - precision_m: 0.5824 - recall_m: 0.4938\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0062 - accuracy: 0.5139 - f1_m: 0.4063 - precision_m: 0.5824 - recall_m: 0.4938 - val_loss: 0.9910 - val_accuracy: 0.5405 - val_f1_m: 0.5021 - val_precision_m: 0.6958 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 81/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 0.9711 - accuracy: 0.5625 - f1_m: 0.4697 - precision_m: 0.5961 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9384 - accuracy: 0.5625 - f1_m: 0.4710 - precision_m: 0.5867 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0016 - accuracy: 0.5208 - f1_m: 0.4402 - precision_m: 0.5956 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0074 - accuracy: 0.5000 - f1_m: 0.4137 - precision_m: 0.5350 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.4931 - f1_m: 0.4018 - precision_m: 0.5280 - recall_m: 0.4875\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0219 - accuracy: 0.4931 - f1_m: 0.4018 - precision_m: 0.5280 - recall_m: 0.4875 - val_loss: 1.0259 - val_accuracy: 0.5405 - val_f1_m: 0.5057 - val_precision_m: 0.6272 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 82/100\n",
            "1/5 [=====>........................] - ETA: 25s - loss: 1.1157 - accuracy: 0.3125 - f1_m: 0.2138 - precision_m: 0.3449 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 1.0510 - accuracy: 0.3750 - f1_m: 0.2856 - precision_m: 0.3482 - recall_m: 0.3750\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0548 - accuracy: 0.4167 - f1_m: 0.3294 - precision_m: 0.4254 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0605 - accuracy: 0.4141 - f1_m: 0.3148 - precision_m: 0.4323 - recall_m: 0.4141 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0500 - accuracy: 0.4167 - f1_m: 0.3051 - precision_m: 0.4966 - recall_m: 0.4187\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0500 - accuracy: 0.4167 - f1_m: 0.3051 - precision_m: 0.4966 - recall_m: 0.4187 - val_loss: 1.0239 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 83/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9933 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9886 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 12s - loss: 1.0010 - accuracy: 0.4688 - f1_m: 0.3005 - precision_m: 0.7529 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0389 - accuracy: 0.4688 - f1_m: 0.3001 - precision_m: 0.7524 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.4653 - f1_m: 0.2934 - precision_m: 0.7527 - recall_m: 0.4625\n",
            "5/5 [==============================] - 31s 6s/step - loss: 1.0340 - accuracy: 0.4653 - f1_m: 0.2934 - precision_m: 0.7527 - recall_m: 0.4625 - val_loss: 1.0138 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 84/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0653 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 23s - loss: 1.0318 - accuracy: 0.4062 - f1_m: 0.2354 - precision_m: 0.7598 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 18s - loss: 1.0340 - accuracy: 0.4375 - f1_m: 0.2681 - precision_m: 0.7565 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0344 - accuracy: 0.4375 - f1_m: 0.2724 - precision_m: 0.6672 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.4583 - f1_m: 0.3141 - precision_m: 0.6869 - recall_m: 0.4750\n",
            "5/5 [==============================] - 38s 8s/step - loss: 1.0268 - accuracy: 0.4583 - f1_m: 0.3141 - precision_m: 0.6869 - recall_m: 0.4750 - val_loss: 1.0087 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 85/100\n",
            "1/5 [=====>........................] - ETA: 55s - loss: 1.0061 - accuracy: 0.4375 - f1_m: 0.2853 - precision_m: 0.3679 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.9899 - accuracy: 0.5000 - f1_m: 0.3695 - precision_m: 0.5673 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0071 - accuracy: 0.4479 - f1_m: 0.3156 - precision_m: 0.4799 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0098 - accuracy: 0.4766 - f1_m: 0.3436 - precision_m: 0.5008 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.4514 - f1_m: 0.2949 - precision_m: 0.5632 - recall_m: 0.4313\n",
            "5/5 [==============================] - 40s 7s/step - loss: 1.0186 - accuracy: 0.4514 - f1_m: 0.2949 - precision_m: 0.5632 - recall_m: 0.4313 - val_loss: 0.9992 - val_accuracy: 0.4595 - val_f1_m: 0.2739 - val_precision_m: 0.5791 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 86/100\n",
            "1/5 [=====>........................] - ETA: 35s - loss: 0.9940 - accuracy: 0.4688 - f1_m: 0.3772 - precision_m: 0.5614 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 24s - loss: 1.0361 - accuracy: 0.4688 - f1_m: 0.3769 - precision_m: 0.6029 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0539 - accuracy: 0.3958 - f1_m: 0.3068 - precision_m: 0.5164 - recall_m: 0.3958\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0221 - accuracy: 0.4609 - f1_m: 0.3830 - precision_m: 0.5619 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0280 - accuracy: 0.4583 - f1_m: 0.3863 - precision_m: 0.5499 - recall_m: 0.4563\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0280 - accuracy: 0.4583 - f1_m: 0.3863 - precision_m: 0.5499 - recall_m: 0.4563 - val_loss: 1.0103 - val_accuracy: 0.5405 - val_f1_m: 0.5863 - val_precision_m: 0.7442 - val_recall_m: 0.6500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 87/100\n",
            "1/5 [=====>........................] - ETA: 27s - loss: 0.9983 - accuracy: 0.5312 - f1_m: 0.4630 - precision_m: 0.6080 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0558 - accuracy: 0.4531 - f1_m: 0.3933 - precision_m: 0.5647 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0802 - accuracy: 0.3854 - f1_m: 0.3363 - precision_m: 0.5160 - recall_m: 0.3854\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0515 - accuracy: 0.4141 - f1_m: 0.3692 - precision_m: 0.5282 - recall_m: 0.4141 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0401 - accuracy: 0.4236 - f1_m: 0.3937 - precision_m: 0.5335 - recall_m: 0.4313\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0401 - accuracy: 0.4236 - f1_m: 0.3937 - precision_m: 0.5335 - recall_m: 0.4313 - val_loss: 1.0169 - val_accuracy: 0.5405 - val_f1_m: 0.5021 - val_precision_m: 0.6958 - val_recall_m: 0.5656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 88/100\n",
            "1/5 [=====>........................] - ETA: 27s - loss: 1.0616 - accuracy: 0.4062 - f1_m: 0.3381 - precision_m: 0.6290 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0260 - accuracy: 0.4531 - f1_m: 0.3863 - precision_m: 0.5958 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0247 - accuracy: 0.4792 - f1_m: 0.3949 - precision_m: 0.5718 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0313 - accuracy: 0.4609 - f1_m: 0.3548 - precision_m: 0.6186 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0282 - accuracy: 0.4722 - f1_m: 0.3649 - precision_m: 0.6456 - recall_m: 0.4812\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0282 - accuracy: 0.4722 - f1_m: 0.3649 - precision_m: 0.6456 - recall_m: 0.4812 - val_loss: 1.0099 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 89/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0407 - accuracy: 0.4375 - f1_m: 0.2663 - precision_m: 0.7539 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0121 - accuracy: 0.4531 - f1_m: 0.2828 - precision_m: 0.7524 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0326 - accuracy: 0.4479 - f1_m: 0.2773 - precision_m: 0.7529 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0417 - accuracy: 0.4375 - f1_m: 0.2666 - precision_m: 0.7544 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0217 - accuracy: 0.4583 - f1_m: 0.3191 - precision_m: 0.7077 - recall_m: 0.4750\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.0217 - accuracy: 0.4583 - f1_m: 0.3191 - precision_m: 0.7077 - recall_m: 0.4750 - val_loss: 1.0055 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 90/100\n",
            "1/5 [=====>........................] - ETA: 27s - loss: 1.0600 - accuracy: 0.4688 - f1_m: 0.3438 - precision_m: 0.5938 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0590 - accuracy: 0.4375 - f1_m: 0.3058 - precision_m: 0.6820 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0183 - accuracy: 0.4896 - f1_m: 0.3606 - precision_m: 0.7093 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0039 - accuracy: 0.5000 - f1_m: 0.3757 - precision_m: 0.6916 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0147 - accuracy: 0.5069 - f1_m: 0.3904 - precision_m: 0.6962 - recall_m: 0.5125\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0147 - accuracy: 0.5069 - f1_m: 0.3904 - precision_m: 0.6962 - recall_m: 0.5125 - val_loss: 0.9949 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 91/100\n",
            "1/5 [=====>........................] - ETA: 41s - loss: 0.9849 - accuracy: 0.5625 - f1_m: 0.4672 - precision_m: 0.6417 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 1.0066 - accuracy: 0.5312 - f1_m: 0.4476 - precision_m: 0.6372 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.0100 - accuracy: 0.5104 - f1_m: 0.4293 - precision_m: 0.5905 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0137 - accuracy: 0.5234 - f1_m: 0.4443 - precision_m: 0.6091 - recall_m: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0271 - accuracy: 0.5208 - f1_m: 0.4317 - precision_m: 0.6113 - recall_m: 0.5188\n",
            "5/5 [==============================] - 39s 7s/step - loss: 1.0271 - accuracy: 0.5208 - f1_m: 0.4317 - precision_m: 0.6113 - recall_m: 0.5188 - val_loss: 0.9839 - val_accuracy: 0.4595 - val_f1_m: 0.2739 - val_precision_m: 0.5791 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 92/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 0.9902 - accuracy: 0.5312 - f1_m: 0.4851 - precision_m: 0.5764 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9821 - accuracy: 0.5469 - f1_m: 0.4952 - precision_m: 0.6159 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.9744 - accuracy: 0.5625 - f1_m: 0.5011 - precision_m: 0.6326 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9719 - accuracy: 0.5469 - f1_m: 0.4908 - precision_m: 0.6060 - recall_m: 0.5469 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0073 - accuracy: 0.5208 - f1_m: 0.4475 - precision_m: 0.6421 - recall_m: 0.5000\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0073 - accuracy: 0.5208 - f1_m: 0.4475 - precision_m: 0.6421 - recall_m: 0.5000 - val_loss: 1.0217 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 93/100\n",
            "1/5 [=====>........................] - ETA: 32s - loss: 1.1290 - accuracy: 0.4062 - f1_m: 0.3195 - precision_m: 0.5998 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0392 - accuracy: 0.4531 - f1_m: 0.3972 - precision_m: 0.5728 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0181 - accuracy: 0.4792 - f1_m: 0.4430 - precision_m: 0.5723 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0560 - accuracy: 0.4141 - f1_m: 0.3722 - precision_m: 0.5419 - recall_m: 0.4141 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0468 - accuracy: 0.4306 - f1_m: 0.3998 - precision_m: 0.5587 - recall_m: 0.4437\n",
            "5/5 [==============================] - 34s 6s/step - loss: 1.0468 - accuracy: 0.4306 - f1_m: 0.3998 - precision_m: 0.5587 - recall_m: 0.4437 - val_loss: 1.0068 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 94/100\n",
            "1/5 [=====>........................] - ETA: 31s - loss: 1.0161 - accuracy: 0.5000 - f1_m: 0.3988 - precision_m: 0.5190 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0051 - accuracy: 0.5312 - f1_m: 0.4454 - precision_m: 0.5612 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0242 - accuracy: 0.5000 - f1_m: 0.4056 - precision_m: 0.5449 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0377 - accuracy: 0.4688 - f1_m: 0.3554 - precision_m: 0.6000 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0395 - accuracy: 0.4583 - f1_m: 0.3252 - precision_m: 0.6332 - recall_m: 0.4500\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.0395 - accuracy: 0.4583 - f1_m: 0.3252 - precision_m: 0.6332 - recall_m: 0.4500 - val_loss: 1.0104 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 95/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0610 - accuracy: 0.3750 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0377 - accuracy: 0.4688 - f1_m: 0.3048 - precision_m: 0.7598 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0286 - accuracy: 0.4688 - f1_m: 0.3029 - precision_m: 0.7568 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0460 - accuracy: 0.4531 - f1_m: 0.2859 - precision_m: 0.7573 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0266 - accuracy: 0.4653 - f1_m: 0.3097 - precision_m: 0.7566 - recall_m: 0.4750\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0266 - accuracy: 0.4653 - f1_m: 0.3097 - precision_m: 0.7566 - recall_m: 0.4750 - val_loss: 1.0125 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 96/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0142 - accuracy: 0.5000 - f1_m: 0.3333 - precision_m: 0.7500 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0200 - accuracy: 0.5156 - f1_m: 0.3510 - precision_m: 0.7505 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0123 - accuracy: 0.4792 - f1_m: 0.3122 - precision_m: 0.7533 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0313 - accuracy: 0.4609 - f1_m: 0.2929 - precision_m: 0.7546 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0307 - accuracy: 0.4653 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0307 - accuracy: 0.4653 - f1_m: 0.3009 - precision_m: 0.7537 - recall_m: 0.4688 - val_loss: 1.0125 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 97/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0344 - accuracy: 0.3750 - f1_m: 0.2045 - precision_m: 0.7656 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0228 - accuracy: 0.5000 - f1_m: 0.3427 - precision_m: 0.7656 - recall_m: 0.5000\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0073 - accuracy: 0.4896 - f1_m: 0.3282 - precision_m: 0.7607 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0160 - accuracy: 0.4688 - f1_m: 0.3093 - precision_m: 0.6633 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0251 - accuracy: 0.4583 - f1_m: 0.2903 - precision_m: 0.6106 - recall_m: 0.4500\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0251 - accuracy: 0.4583 - f1_m: 0.2903 - precision_m: 0.6106 - recall_m: 0.4500 - val_loss: 1.0075 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 98/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.1177 - accuracy: 0.2500 - f1_m: 0.1500 - precision_m: 0.3259 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 26s - loss: 1.0504 - accuracy: 0.3906 - f1_m: 0.2978 - precision_m: 0.4511 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0504 - accuracy: 0.4062 - f1_m: 0.3160 - precision_m: 0.4756 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0238 - accuracy: 0.4375 - f1_m: 0.3503 - precision_m: 0.5034 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.4375 - f1_m: 0.3519 - precision_m: 0.5215 - recall_m: 0.4375\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0296 - accuracy: 0.4375 - f1_m: 0.3519 - precision_m: 0.5215 - recall_m: 0.4375 - val_loss: 1.0031 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 99/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.0811 - accuracy: 0.3125 - f1_m: 0.1829 - precision_m: 0.2856 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 1.0331 - accuracy: 0.4531 - f1_m: 0.3564 - precision_m: 0.4758 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0507 - accuracy: 0.4271 - f1_m: 0.3319 - precision_m: 0.4833 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 1.0428 - accuracy: 0.4375 - f1_m: 0.3441 - precision_m: 0.4914 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0348 - accuracy: 0.4653 - f1_m: 0.4015 - precision_m: 0.5547 - recall_m: 0.4875\n",
            "5/5 [==============================] - 32s 6s/step - loss: 1.0348 - accuracy: 0.4653 - f1_m: 0.4015 - precision_m: 0.5547 - recall_m: 0.4875 - val_loss: 1.0033 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m Epoch 100/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.9689 - accuracy: 0.5625 - f1_m: 0.4672 - precision_m: 0.6417 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 19s - loss: 0.9896 - accuracy: 0.5312 - f1_m: 0.4341 - precision_m: 0.6612 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.9942 - accuracy: 0.5312 - f1_m: 0.4460 - precision_m: 0.6405 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 6s - loss: 0.9851 - accuracy: 0.5312 - f1_m: 0.4549 - precision_m: 0.6265 - recall_m: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9998 - accuracy: 0.5069 - f1_m: 0.4034 - precision_m: 0.5926 - recall_m: 0.4875\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                                                                             </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip   </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  val_accuracy</th><th style=\"text-align: right;\">  val_f1_m</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_138c3eee</td><td style=\"text-align: right;\">  0.458333</td><td>2022-11-22_09-12-17</td><td>True  </td><td>                </td><td>c160da34ab6a49d984adfecf042a8870</td><td>1_conv_block1_filters=128,dropout_rate=0.3000,fc1_units=128,fc_layer_type=dense,lr=0.1000,pool_type=average</td><td>00cece75a9f1</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.09083</td><td>172.28.0.2</td><td style=\"text-align: right;\">  840</td><td style=\"text-align: right;\">             3294.15</td><td style=\"text-align: right;\">           3294.15</td><td style=\"text-align: right;\">       3294.15</td><td style=\"text-align: right;\"> 1669108337</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>138c3eee  </td><td style=\"text-align: right;\">      0.162162</td><td style=\"text-align: right;\"> 0.0544482</td><td style=\"text-align: right;\">   1.99308</td><td style=\"text-align: right;\">   0.00982666</td></tr>\n",
              "<tr><td>train_mnist_416fcc76</td><td style=\"text-align: right;\">  0.229167</td><td>2022-11-22_10-40-52</td><td>True  </td><td>                </td><td>805f52851fa842d38f8f4a9881d3246f</td><td>3_conv_block1_filters=128,dropout_rate=0.2000,fc1_units=64,fc_layer_type=dense,lr=0.0010,pool_type=max     </td><td>00cece75a9f1</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.53145</td><td>172.28.0.2</td><td style=\"text-align: right;\"> 4599</td><td style=\"text-align: right;\">             3805.74</td><td style=\"text-align: right;\">           3805.74</td><td style=\"text-align: right;\">       3805.74</td><td style=\"text-align: right;\"> 1669113652</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>416fcc76  </td><td style=\"text-align: right;\">      0.405405</td><td style=\"text-align: right;\"> 0.455758 </td><td style=\"text-align: right;\">   1.08232</td><td style=\"text-align: right;\">   0.0063529 </td></tr>\n",
              "<tr><td>train_mnist_c2e2b812</td><td style=\"text-align: right;\">  0.173611</td><td>2022-11-22_09-37-18</td><td>True  </td><td>                </td><td>6c770040324d478ca050e6b19e7cbfcc</td><td>2_conv_block1_filters=32,dropout_rate=0.7000,fc1_units=8,fc_layer_type=convolution,lr=0.0001,pool_type=max </td><td>00cece75a9f1</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">9.2704 </td><td>172.28.0.2</td><td style=\"text-align: right;\"> 3088</td><td style=\"text-align: right;\">             1487.66</td><td style=\"text-align: right;\">           1487.66</td><td style=\"text-align: right;\">       1487.66</td><td style=\"text-align: right;\"> 1669109838</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>c2e2b812  </td><td style=\"text-align: right;\">      0.162162</td><td style=\"text-align: right;\"> 0.128175 </td><td style=\"text-align: right;\">   1.12447</td><td style=\"text-align: right;\">   0.00944018</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=840)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 33s 6s/step - loss: 0.9998 - accuracy: 0.5069 - f1_m: 0.4034 - precision_m: 0.5926 - recall_m: 0.4875 - val_loss: 1.0050 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m 2022-11-22 09:12:44.627566: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense/activation_2/Softmax:0', description=\"created by layer 'dense'\")\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  conv1d (Conv1D)             (None, 43886, 32)         288       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  batch_normalization (BatchN  (None, 43886, 32)        128       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  activation (Activation)     (None, 43886, 32)         0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  conv1d_1 (Conv1D)           (None, 43886, 8)          264       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  dropout (Dropout)           (None, 43886, 8)          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  batch_normalization_1 (Batc  (None, 43886, 8)         32        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  activation_1 (Activation)   (None, 43886, 8)          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  conv1d_2 (Conv1D)           (None, 43886, 2)          18        \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  dropout_1 (Dropout)         (None, 43886, 2)          0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  batch_normalization_2 (Batc  (None, 43886, 2)         8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  global_max_pooling1d (Globa  (None, 2)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m  dense (Dense)               (None, 3)                 9         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Total params: 747\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Trainable params: 663\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Non-trainable params: 84\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Total number of layers: 13\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f043ed3c050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f043ed3c050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f043ed3c050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f043ed3c050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f043ed43830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f043ed43830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f043ed43830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f043ed43830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f03e70a7680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f03e70a7680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f03e70a7680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f03e70a7680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/5 [=====>........................] - ETA: 23s - loss: 8.4051 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.5252 - accuracy: 0.2188 - f1_m: 0.0796 - precision_m: 0.8301 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 8.9775 - accuracy: 0.1979 - f1_m: 0.0671 - precision_m: 0.8428 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 9.0580 - accuracy: 0.1875 - f1_m: 0.0609 - precision_m: 0.8491 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 9.2704 - accuracy: 0.1736 - f1_m: 0.0502 - precision_m: 0.8676 - recall_m: 0.1625\n",
            "5/5 [==============================] - 16s 3s/step - loss: 9.2704 - accuracy: 0.1736 - f1_m: 0.0502 - precision_m: 0.8676 - recall_m: 0.1625 - val_loss: 1.1245 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 2/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 9.0498 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.9479 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 8.9023 - accuracy: 0.1771 - f1_m: 0.0543 - precision_m: 0.8551 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 9.0321 - accuracy: 0.1719 - f1_m: 0.0513 - precision_m: 0.8584 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 8.9825 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8562 - recall_m: 0.1750\n",
            "5/5 [==============================] - 18s 4s/step - loss: 8.9825 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8562 - recall_m: 0.1750 - val_loss: 1.1308 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 3/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 8.2239 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.6547 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 9.0286 - accuracy: 0.1667 - f1_m: 0.0519 - precision_m: 0.8646 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 8.9794 - accuracy: 0.1562 - f1_m: 0.0458 - precision_m: 0.8711 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 8.7636 - accuracy: 0.1736 - f1_m: 0.0664 - precision_m: 0.8539 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 8.7636 - accuracy: 0.1736 - f1_m: 0.0664 - precision_m: 0.8539 - recall_m: 0.1875 - val_loss: 1.1396 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 4/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 8.5308 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.5336 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 8.3650 - accuracy: 0.1771 - f1_m: 0.0543 - precision_m: 0.8551 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 8.6007 - accuracy: 0.1719 - f1_m: 0.0513 - precision_m: 0.8584 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 8.4550 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8562 - recall_m: 0.1750\n",
            "5/5 [==============================] - 16s 3s/step - loss: 8.4550 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8562 - recall_m: 0.1750 - val_loss: 1.1492 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 5/100\n",
            "1/5 [=====>........................] - ETA: 14s - loss: 8.7293 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.2403 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 8.3369 - accuracy: 0.1458 - f1_m: 0.0392 - precision_m: 0.8770 - recall_m: 0.1458\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 8.1645 - accuracy: 0.1641 - f1_m: 0.0490 - precision_m: 0.8650 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 8.1603 - accuracy: 0.1736 - f1_m: 0.0592 - precision_m: 0.8545 - recall_m: 0.1813\n",
            "5/5 [==============================] - 14s 3s/step - loss: 8.1603 - accuracy: 0.1736 - f1_m: 0.0592 - precision_m: 0.8545 - recall_m: 0.1813 - val_loss: 1.1573 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 6/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 7.9997 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.4466 - accuracy: 0.1094 - f1_m: 0.0219 - precision_m: 0.9028 - recall_m: 0.1094 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 7.8893 - accuracy: 0.1562 - f1_m: 0.0479 - precision_m: 0.8727 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 8.1056 - accuracy: 0.1641 - f1_m: 0.0508 - precision_m: 0.8665 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 8.0561 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813\n",
            "5/5 [==============================] - 13s 3s/step - loss: 8.0561 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813 - val_loss: 1.1622 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 8.1337 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 7.5912 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 7.6782 - accuracy: 0.1667 - f1_m: 0.0519 - precision_m: 0.8646 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 8.0216 - accuracy: 0.1562 - f1_m: 0.0458 - precision_m: 0.8711 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 7.7995 - accuracy: 0.1736 - f1_m: 0.0664 - precision_m: 0.8539 - recall_m: 0.1875\n",
            "5/5 [==============================] - 15s 3s/step - loss: 7.7995 - accuracy: 0.1736 - f1_m: 0.0664 - precision_m: 0.8539 - recall_m: 0.1875 - val_loss: 1.1654 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 8/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 7.8986 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 7.9600 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 7.9948 - accuracy: 0.1562 - f1_m: 0.0447 - precision_m: 0.8701 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 7.6447 - accuracy: 0.1797 - f1_m: 0.0585 - precision_m: 0.8557 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 7.5579 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8627 - recall_m: 0.1688\n",
            "5/5 [==============================] - 17s 3s/step - loss: 7.5579 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8627 - recall_m: 0.1688 - val_loss: 1.1685 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 9/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 7.6426 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 7.0423 - accuracy: 0.2031 - f1_m: 0.0711 - precision_m: 0.8403 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 7.3428 - accuracy: 0.1771 - f1_m: 0.0567 - precision_m: 0.8571 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 7.3009 - accuracy: 0.1719 - f1_m: 0.0531 - precision_m: 0.8599 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 7.3340 - accuracy: 0.1736 - f1_m: 0.0543 - precision_m: 0.8574 - recall_m: 0.1750\n",
            "5/5 [==============================] - 15s 3s/step - loss: 7.3340 - accuracy: 0.1736 - f1_m: 0.0543 - precision_m: 0.8574 - recall_m: 0.1750 - val_loss: 1.1717 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 10/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 8.5197 - accuracy: 0.0625 - f1_m: 0.0074 - precision_m: 0.9414 - recall_m: 0.0625\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 8.0815 - accuracy: 0.0938 - f1_m: 0.0176 - precision_m: 0.9160 - recall_m: 0.0938 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 7.3802 - accuracy: 0.1562 - f1_m: 0.0529 - precision_m: 0.8766 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 7.2462 - accuracy: 0.1641 - f1_m: 0.0545 - precision_m: 0.8694 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 7.0802 - accuracy: 0.1736 - f1_m: 0.0636 - precision_m: 0.8580 - recall_m: 0.1813\n",
            "5/5 [==============================] - 14s 3s/step - loss: 7.0802 - accuracy: 0.1736 - f1_m: 0.0636 - precision_m: 0.8580 - recall_m: 0.1813 - val_loss: 1.1750 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 11/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.4701 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 6.9615 - accuracy: 0.2188 - f1_m: 0.0796 - precision_m: 0.8301 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 7.0300 - accuracy: 0.1979 - f1_m: 0.0671 - precision_m: 0.8428 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 7.1015 - accuracy: 0.1641 - f1_m: 0.0522 - precision_m: 0.8674 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 6.9354 - accuracy: 0.1736 - f1_m: 0.0618 - precision_m: 0.8564 - recall_m: 0.1813\n",
            "5/5 [==============================] - 14s 3s/step - loss: 6.9354 - accuracy: 0.1736 - f1_m: 0.0618 - precision_m: 0.8564 - recall_m: 0.1813 - val_loss: 1.1779 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 12/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.9965 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 7.5022 - accuracy: 0.1406 - f1_m: 0.0376 - precision_m: 0.8813 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 6.9195 - accuracy: 0.1875 - f1_m: 0.0663 - precision_m: 0.8535 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 6.6876 - accuracy: 0.1797 - f1_m: 0.0602 - precision_m: 0.8572 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 6.7482 - accuracy: 0.1736 - f1_m: 0.0538 - precision_m: 0.8639 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 6.7482 - accuracy: 0.1736 - f1_m: 0.0538 - precision_m: 0.8639 - recall_m: 0.1688 - val_loss: 1.1813 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 13/100\n",
            "1/5 [=====>........................] - ETA: 18s - loss: 6.7553 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 10s - loss: 6.4061 - accuracy: 0.2031 - f1_m: 0.0711 - precision_m: 0.8403 - recall_m: 0.2031\n",
            "3/5 [=================>............] - ETA: 6s - loss: 6.5438 - accuracy: 0.1667 - f1_m: 0.0528 - precision_m: 0.8652 - recall_m: 0.1667 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 6.5024 - accuracy: 0.1719 - f1_m: 0.0544 - precision_m: 0.8608 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 6.5897 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750\n",
            "5/5 [==============================] - 16s 3s/step - loss: 6.5897 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750 - val_loss: 1.1844 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 14/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.3243 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 6.1133 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 6.3376 - accuracy: 0.1667 - f1_m: 0.0495 - precision_m: 0.8626 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 6.3705 - accuracy: 0.1719 - f1_m: 0.0519 - precision_m: 0.8589 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 6.3611 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 6.3611 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750 - val_loss: 1.1876 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 15/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.1445 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 6.1630 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 6.0216 - accuracy: 0.1979 - f1_m: 0.0671 - precision_m: 0.8428 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 6.2615 - accuracy: 0.1797 - f1_m: 0.0573 - precision_m: 0.8547 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 6.2671 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 6.2671 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688 - val_loss: 1.1906 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 16/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.6032 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 6.3532 - accuracy: 0.1250 - f1_m: 0.0292 - precision_m: 0.8916 - recall_m: 0.1250 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 6.4059 - accuracy: 0.1354 - f1_m: 0.0335 - precision_m: 0.8838 - recall_m: 0.1354\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 6.1574 - accuracy: 0.1562 - f1_m: 0.0448 - precision_m: 0.8701 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 6.0244 - accuracy: 0.1736 - f1_m: 0.0656 - precision_m: 0.8531 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 6.0244 - accuracy: 0.1736 - f1_m: 0.0656 - precision_m: 0.8531 - recall_m: 0.1875 - val_loss: 1.1931 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 17/100\n",
            "1/5 [=====>........................] - ETA: 12s - loss: 5.9616 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 14s - loss: 5.8812 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875\n",
            "3/5 [=================>............] - ETA: 8s - loss: 6.0208 - accuracy: 0.1667 - f1_m: 0.0519 - precision_m: 0.8646 - recall_m: 0.1667 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 5.8784 - accuracy: 0.1719 - f1_m: 0.0537 - precision_m: 0.8604 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.8501 - accuracy: 0.1736 - f1_m: 0.0548 - precision_m: 0.8578 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 4s/step - loss: 5.8501 - accuracy: 0.1736 - f1_m: 0.0548 - precision_m: 0.8578 - recall_m: 0.1750 - val_loss: 1.1956 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 18/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.4369 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.5880 - accuracy: 0.2031 - f1_m: 0.0756 - precision_m: 0.8442 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 5.6110 - accuracy: 0.1875 - f1_m: 0.0645 - precision_m: 0.8522 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 5.6881 - accuracy: 0.1797 - f1_m: 0.0589 - precision_m: 0.8562 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.8004 - accuracy: 0.1736 - f1_m: 0.0527 - precision_m: 0.8631 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 5.8004 - accuracy: 0.1736 - f1_m: 0.0527 - precision_m: 0.8631 - recall_m: 0.1688 - val_loss: 1.1983 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 19/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 6.3628 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.8181 - accuracy: 0.1406 - f1_m: 0.0376 - precision_m: 0.8813 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 5.6637 - accuracy: 0.1562 - f1_m: 0.0448 - precision_m: 0.8701 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 5.8227 - accuracy: 0.1562 - f1_m: 0.0442 - precision_m: 0.8696 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.6720 - accuracy: 0.1736 - f1_m: 0.0651 - precision_m: 0.8527 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 5.6720 - accuracy: 0.1736 - f1_m: 0.0651 - precision_m: 0.8527 - recall_m: 0.1875 - val_loss: 1.2014 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 20/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 5.5862 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.8296 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 5.5995 - accuracy: 0.1771 - f1_m: 0.0543 - precision_m: 0.8551 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 5.4927 - accuracy: 0.1797 - f1_m: 0.0555 - precision_m: 0.8533 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.5051 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 5.5051 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688 - val_loss: 1.2045 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 21/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.7190 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.0169 - accuracy: 0.2188 - f1_m: 0.0796 - precision_m: 0.8301 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 7s - loss: 5.2966 - accuracy: 0.1875 - f1_m: 0.0623 - precision_m: 0.8503 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 5.5116 - accuracy: 0.1562 - f1_m: 0.0486 - precision_m: 0.8730 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.4395 - accuracy: 0.1736 - f1_m: 0.0686 - precision_m: 0.8555 - recall_m: 0.1875\n",
            "5/5 [==============================] - 17s 3s/step - loss: 5.4395 - accuracy: 0.1736 - f1_m: 0.0686 - precision_m: 0.8555 - recall_m: 0.1875 - val_loss: 1.2075 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 22/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.9787 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.2555 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 5.3952 - accuracy: 0.1771 - f1_m: 0.0543 - precision_m: 0.8551 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 5.3950 - accuracy: 0.1797 - f1_m: 0.0555 - precision_m: 0.8533 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.3518 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 5.3518 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688 - val_loss: 1.2104 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 23/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.6229 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.1266 - accuracy: 0.1719 - f1_m: 0.0580 - precision_m: 0.8638 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 5.1675 - accuracy: 0.1771 - f1_m: 0.0584 - precision_m: 0.8584 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 5.1932 - accuracy: 0.1719 - f1_m: 0.0544 - precision_m: 0.8608 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.1932 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 5.1932 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750 - val_loss: 1.2132 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 24/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 5.6161 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 9s - loss: 5.4674 - accuracy: 0.1250 - f1_m: 0.0292 - precision_m: 0.8916 - recall_m: 0.1250 \n",
            "3/5 [=================>............] - ETA: 7s - loss: 5.2342 - accuracy: 0.1667 - f1_m: 0.0528 - precision_m: 0.8652 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 5.2257 - accuracy: 0.1719 - f1_m: 0.0544 - precision_m: 0.8608 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 5.1505 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 5.1505 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750 - val_loss: 1.2160 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 25/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 5.0455 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.1295 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 4.9877 - accuracy: 0.1875 - f1_m: 0.0600 - precision_m: 0.8483 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 5.0311 - accuracy: 0.1719 - f1_m: 0.0519 - precision_m: 0.8589 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.9895 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 4.9895 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750 - val_loss: 1.2188 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 26/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.6831 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 5.1524 - accuracy: 0.1562 - f1_m: 0.0435 - precision_m: 0.8691 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.9097 - accuracy: 0.1875 - f1_m: 0.0623 - precision_m: 0.8503 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.8866 - accuracy: 0.1875 - f1_m: 0.0615 - precision_m: 0.8496 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.9182 - accuracy: 0.1736 - f1_m: 0.0507 - precision_m: 0.8680 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.9182 - accuracy: 0.1736 - f1_m: 0.0507 - precision_m: 0.8680 - recall_m: 0.1625 - val_loss: 1.2216 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 27/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.4004 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.9784 - accuracy: 0.1562 - f1_m: 0.0473 - precision_m: 0.8721 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.9159 - accuracy: 0.1562 - f1_m: 0.0456 - precision_m: 0.8708 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.8250 - accuracy: 0.1719 - f1_m: 0.0538 - precision_m: 0.8604 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.8437 - accuracy: 0.1736 - f1_m: 0.0549 - precision_m: 0.8578 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.8437 - accuracy: 0.1736 - f1_m: 0.0549 - precision_m: 0.8578 - recall_m: 0.1750 - val_loss: 1.2244 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 28/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.6946 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.9090 - accuracy: 0.1562 - f1_m: 0.0435 - precision_m: 0.8691 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.8041 - accuracy: 0.1771 - f1_m: 0.0552 - precision_m: 0.8558 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.7446 - accuracy: 0.1797 - f1_m: 0.0562 - precision_m: 0.8538 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.7199 - accuracy: 0.1736 - f1_m: 0.0505 - precision_m: 0.8611 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.7199 - accuracy: 0.1736 - f1_m: 0.0505 - precision_m: 0.8611 - recall_m: 0.1688 - val_loss: 1.2271 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 29/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 5.6009 - accuracy: 0.0625 - f1_m: 0.0074 - precision_m: 0.9414 - recall_m: 0.0625\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.7406 - accuracy: 0.1406 - f1_m: 0.0429 - precision_m: 0.8853 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.9410 - accuracy: 0.1458 - f1_m: 0.0427 - precision_m: 0.8796 - recall_m: 0.1458\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.7031 - accuracy: 0.1719 - f1_m: 0.0570 - precision_m: 0.8628 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.6529 - accuracy: 0.1736 - f1_m: 0.0575 - precision_m: 0.8598 - recall_m: 0.1750\n",
            "5/5 [==============================] - 15s 3s/step - loss: 4.6529 - accuracy: 0.1736 - f1_m: 0.0575 - precision_m: 0.8598 - recall_m: 0.1750 - val_loss: 1.2297 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 30/100\n",
            "1/5 [=====>........................] - ETA: 16s - loss: 5.1412 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.6930 - accuracy: 0.2188 - f1_m: 0.0883 - precision_m: 0.8379 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.7779 - accuracy: 0.1562 - f1_m: 0.0595 - precision_m: 0.8818 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.5924 - accuracy: 0.1797 - f1_m: 0.0696 - precision_m: 0.8645 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.5881 - accuracy: 0.1736 - f1_m: 0.0613 - precision_m: 0.8697 - recall_m: 0.1688\n",
            "5/5 [==============================] - 15s 3s/step - loss: 4.5881 - accuracy: 0.1736 - f1_m: 0.0613 - precision_m: 0.8697 - recall_m: 0.1688 - val_loss: 1.2323 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 31/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.2362 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.3392 - accuracy: 0.2188 - f1_m: 0.0796 - precision_m: 0.8301 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.5069 - accuracy: 0.1875 - f1_m: 0.0623 - precision_m: 0.8503 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.6233 - accuracy: 0.1641 - f1_m: 0.0508 - precision_m: 0.8665 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.5509 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.5509 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813 - val_loss: 1.2350 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 32/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.6445 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.4142 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.2934 - accuracy: 0.1979 - f1_m: 0.0664 - precision_m: 0.8421 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.3945 - accuracy: 0.1797 - f1_m: 0.0568 - precision_m: 0.8542 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.4750 - accuracy: 0.1736 - f1_m: 0.0510 - precision_m: 0.8615 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.4750 - accuracy: 0.1736 - f1_m: 0.0510 - precision_m: 0.8615 - recall_m: 0.1688 - val_loss: 1.2377 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 33/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.5262 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.5872 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.4995 - accuracy: 0.1771 - f1_m: 0.0543 - precision_m: 0.8551 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.3687 - accuracy: 0.1797 - f1_m: 0.0555 - precision_m: 0.8533 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.3896 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.3896 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688 - val_loss: 1.2403 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 34/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 4.9381 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 4.3780 - accuracy: 0.1875 - f1_m: 0.0698 - precision_m: 0.8564 - recall_m: 0.1875\n",
            "3/5 [=================>............] - ETA: 6s - loss: 4.3733 - accuracy: 0.1667 - f1_m: 0.0558 - precision_m: 0.8678 - recall_m: 0.1667 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 4.3537 - accuracy: 0.1719 - f1_m: 0.0566 - precision_m: 0.8628 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.3312 - accuracy: 0.1736 - f1_m: 0.0571 - precision_m: 0.8598 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 4.3312 - accuracy: 0.1736 - f1_m: 0.0571 - precision_m: 0.8598 - recall_m: 0.1750 - val_loss: 1.2429 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 35/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.4769 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.1666 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.3061 - accuracy: 0.1667 - f1_m: 0.0495 - precision_m: 0.8626 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.3784 - accuracy: 0.1641 - f1_m: 0.0477 - precision_m: 0.8640 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.2928 - accuracy: 0.1736 - f1_m: 0.0582 - precision_m: 0.8537 - recall_m: 0.1813\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.2928 - accuracy: 0.1736 - f1_m: 0.0582 - precision_m: 0.8537 - recall_m: 0.1813 - val_loss: 1.2455 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 36/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.0124 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.6393 - accuracy: 0.2656 - f1_m: 0.1137 - precision_m: 0.8071 - recall_m: 0.2656 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.0027 - accuracy: 0.1979 - f1_m: 0.0782 - precision_m: 0.8519 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.2093 - accuracy: 0.1719 - f1_m: 0.0627 - precision_m: 0.8677 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.2072 - accuracy: 0.1736 - f1_m: 0.0620 - precision_m: 0.8637 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.2072 - accuracy: 0.1736 - f1_m: 0.0620 - precision_m: 0.8637 - recall_m: 0.1750 - val_loss: 1.2482 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 37/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.0979 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.1117 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.1206 - accuracy: 0.1667 - f1_m: 0.0495 - precision_m: 0.8626 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.2096 - accuracy: 0.1562 - f1_m: 0.0441 - precision_m: 0.8696 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.1597 - accuracy: 0.1736 - f1_m: 0.0650 - precision_m: 0.8527 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.1597 - accuracy: 0.1736 - f1_m: 0.0650 - precision_m: 0.8527 - recall_m: 0.1875 - val_loss: 1.2507 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 38/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.6206 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 12s - loss: 4.3187 - accuracy: 0.1406 - f1_m: 0.0376 - precision_m: 0.8813 - recall_m: 0.1406\n",
            "3/5 [=================>............] - ETA: 8s - loss: 4.1389 - accuracy: 0.1667 - f1_m: 0.0513 - precision_m: 0.8639 - recall_m: 0.1667 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 4.1408 - accuracy: 0.1719 - f1_m: 0.0533 - precision_m: 0.8599 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.1018 - accuracy: 0.1736 - f1_m: 0.0544 - precision_m: 0.8574 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 4.1018 - accuracy: 0.1736 - f1_m: 0.0544 - precision_m: 0.8574 - recall_m: 0.1750 - val_loss: 1.2532 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 39/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.1380 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 4.1250 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.9854 - accuracy: 0.1875 - f1_m: 0.0600 - precision_m: 0.8483 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.9627 - accuracy: 0.1797 - f1_m: 0.0555 - precision_m: 0.8533 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.0612 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.0612 - accuracy: 0.1736 - f1_m: 0.0500 - precision_m: 0.8607 - recall_m: 0.1688 - val_loss: 1.2559 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 40/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.7244 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.9427 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 4.0660 - accuracy: 0.1875 - f1_m: 0.0616 - precision_m: 0.8496 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 4.0736 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.0507 - accuracy: 0.1736 - f1_m: 0.0544 - precision_m: 0.8574 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 4.0507 - accuracy: 0.1736 - f1_m: 0.0544 - precision_m: 0.8574 - recall_m: 0.1750 - val_loss: 1.2585 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 41/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 5.0226 - accuracy: 0.0312 - f1_m: 0.0019 - precision_m: 0.9697 - recall_m: 0.0312\n",
            "2/5 [===========>..................] - ETA: 13s - loss: 4.4612 - accuracy: 0.0938 - f1_m: 0.0221 - precision_m: 0.9189 - recall_m: 0.0938\n",
            "3/5 [=================>............] - ETA: 9s - loss: 4.2278 - accuracy: 0.1458 - f1_m: 0.0480 - precision_m: 0.8835 - recall_m: 0.1458 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 4.0275 - accuracy: 0.1719 - f1_m: 0.0610 - precision_m: 0.8657 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 4.0078 - accuracy: 0.1736 - f1_m: 0.0607 - precision_m: 0.8621 - recall_m: 0.1750\n",
            "5/5 [==============================] - 19s 4s/step - loss: 4.0078 - accuracy: 0.1736 - f1_m: 0.0607 - precision_m: 0.8621 - recall_m: 0.1750 - val_loss: 1.2613 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 42/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 3.9261 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 17s - loss: 3.8169 - accuracy: 0.1719 - f1_m: 0.0580 - precision_m: 0.8638 - recall_m: 0.1719\n",
            "3/5 [=================>............] - ETA: 10s - loss: 3.9292 - accuracy: 0.1667 - f1_m: 0.0528 - precision_m: 0.8652 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 4s - loss: 3.8421 - accuracy: 0.1797 - f1_m: 0.0592 - precision_m: 0.8562 - recall_m: 0.1797 \n",
            "5/5 [==============================] - ETA: 0s - loss: 3.9029 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8631 - recall_m: 0.1688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 3.9029 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8631 - recall_m: 0.1688 - val_loss: 1.2641 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 43/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 3.2786 - accuracy: 0.3125 - f1_m: 0.1488 - precision_m: 0.7852 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 9s - loss: 3.7726 - accuracy: 0.2344 - f1_m: 0.0955 - precision_m: 0.8267 - recall_m: 0.2344 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 3.7585 - accuracy: 0.2083 - f1_m: 0.0778 - precision_m: 0.8405 - recall_m: 0.2083\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 3.9195 - accuracy: 0.1719 - f1_m: 0.0602 - precision_m: 0.8657 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.8714 - accuracy: 0.1736 - f1_m: 0.0600 - precision_m: 0.8621 - recall_m: 0.1750\n",
            "5/5 [==============================] - 16s 3s/step - loss: 3.8714 - accuracy: 0.1736 - f1_m: 0.0600 - precision_m: 0.8621 - recall_m: 0.1750 - val_loss: 1.2668 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 44/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 3.3791 - accuracy: 0.2812 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 10s - loss: 3.5969 - accuracy: 0.2344 - f1_m: 0.0913 - precision_m: 0.8228 - recall_m: 0.2344\n",
            "3/5 [=================>............] - ETA: 6s - loss: 3.6280 - accuracy: 0.2188 - f1_m: 0.0806 - precision_m: 0.8311 - recall_m: 0.2188 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 3.8263 - accuracy: 0.1641 - f1_m: 0.0605 - precision_m: 0.8733 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.8407 - accuracy: 0.1736 - f1_m: 0.0684 - precision_m: 0.8611 - recall_m: 0.1813\n",
            "5/5 [==============================] - 15s 3s/step - loss: 3.8407 - accuracy: 0.1736 - f1_m: 0.0684 - precision_m: 0.8611 - recall_m: 0.1813 - val_loss: 1.2694 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 45/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.3363 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.6515 - accuracy: 0.2031 - f1_m: 0.0711 - precision_m: 0.8403 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.6058 - accuracy: 0.2083 - f1_m: 0.0736 - precision_m: 0.8366 - recall_m: 0.2083\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.6577 - accuracy: 0.1875 - f1_m: 0.0621 - precision_m: 0.8501 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.7672 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.7672 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625 - val_loss: 1.2721 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 46/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 4.2547 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 10s - loss: 4.2336 - accuracy: 0.1094 - f1_m: 0.0219 - precision_m: 0.9028 - recall_m: 0.1094\n",
            "3/5 [=================>............] - ETA: 6s - loss: 3.9066 - accuracy: 0.1562 - f1_m: 0.0479 - precision_m: 0.8727 - recall_m: 0.1562 \n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.7712 - accuracy: 0.1641 - f1_m: 0.0508 - precision_m: 0.8665 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.7401 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813\n",
            "5/5 [==============================] - 16s 3s/step - loss: 3.7401 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813 - val_loss: 1.2750 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.8478 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.9150 - accuracy: 0.1406 - f1_m: 0.0350 - precision_m: 0.8794 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.7461 - accuracy: 0.1562 - f1_m: 0.0431 - precision_m: 0.8688 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.6331 - accuracy: 0.1797 - f1_m: 0.0573 - precision_m: 0.8547 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.6852 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.6852 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688 - val_loss: 1.2780 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 48/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.1142 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.6488 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.5424 - accuracy: 0.2083 - f1_m: 0.0759 - precision_m: 0.8385 - recall_m: 0.2083\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.5950 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.6896 - accuracy: 0.1736 - f1_m: 0.0526 - precision_m: 0.8695 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.6896 - accuracy: 0.1736 - f1_m: 0.0526 - precision_m: 0.8695 - recall_m: 0.1625 - val_loss: 1.2813 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 49/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.8446 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.4499 - accuracy: 0.2344 - f1_m: 0.0893 - precision_m: 0.8208 - recall_m: 0.2344 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.4570 - accuracy: 0.1979 - f1_m: 0.0688 - precision_m: 0.8441 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.5484 - accuracy: 0.1875 - f1_m: 0.0621 - precision_m: 0.8501 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.6171 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.6171 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625 - val_loss: 1.2844 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 50/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 3.5870 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 13s - loss: 3.4945 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "3/5 [=================>............] - ETA: 8s - loss: 3.6305 - accuracy: 0.1354 - f1_m: 0.0326 - precision_m: 0.8831 - recall_m: 0.1354 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 3.5481 - accuracy: 0.1719 - f1_m: 0.0553 - precision_m: 0.8618 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.5602 - accuracy: 0.1736 - f1_m: 0.0561 - precision_m: 0.8590 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 3.5602 - accuracy: 0.1736 - f1_m: 0.0561 - precision_m: 0.8590 - recall_m: 0.1750 - val_loss: 1.2872 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 51/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 4.1451 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.7893 - accuracy: 0.1250 - f1_m: 0.0292 - precision_m: 0.8916 - recall_m: 0.1250 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.6720 - accuracy: 0.1458 - f1_m: 0.0392 - precision_m: 0.8770 - recall_m: 0.1458\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.4941 - accuracy: 0.1719 - f1_m: 0.0544 - precision_m: 0.8608 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.5158 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.5158 - accuracy: 0.1736 - f1_m: 0.0553 - precision_m: 0.8582 - recall_m: 0.1750 - val_loss: 1.2897 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 52/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.5552 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.5784 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.7111 - accuracy: 0.1562 - f1_m: 0.0479 - precision_m: 0.8727 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.5675 - accuracy: 0.1719 - f1_m: 0.0556 - precision_m: 0.8618 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.5132 - accuracy: 0.1736 - f1_m: 0.0563 - precision_m: 0.8590 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.5132 - accuracy: 0.1736 - f1_m: 0.0563 - precision_m: 0.8590 - recall_m: 0.1750 - val_loss: 1.2923 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 53/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.6134 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.6493 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.5779 - accuracy: 0.1562 - f1_m: 0.0431 - precision_m: 0.8688 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.4643 - accuracy: 0.1719 - f1_m: 0.0519 - precision_m: 0.8589 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.4466 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.4466 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750 - val_loss: 1.2948 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 54/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.5698 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.3803 - accuracy: 0.2031 - f1_m: 0.0689 - precision_m: 0.8384 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 7s - loss: 3.4842 - accuracy: 0.1771 - f1_m: 0.0552 - precision_m: 0.8558 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 3.3967 - accuracy: 0.1719 - f1_m: 0.0519 - precision_m: 0.8589 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.4084 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 3.4084 - accuracy: 0.1736 - f1_m: 0.0534 - precision_m: 0.8566 - recall_m: 0.1750 - val_loss: 1.2967 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 55/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.9144 - accuracy: 0.2812 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.2152 - accuracy: 0.2031 - f1_m: 0.0756 - precision_m: 0.8442 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.3549 - accuracy: 0.1771 - f1_m: 0.0597 - precision_m: 0.8597 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.3293 - accuracy: 0.1797 - f1_m: 0.0596 - precision_m: 0.8567 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.3707 - accuracy: 0.1736 - f1_m: 0.0532 - precision_m: 0.8635 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.3707 - accuracy: 0.1736 - f1_m: 0.0532 - precision_m: 0.8635 - recall_m: 0.1688 - val_loss: 1.2987 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 56/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.0389 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.1703 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.3858 - accuracy: 0.1562 - f1_m: 0.0431 - precision_m: 0.8688 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.3155 - accuracy: 0.1797 - f1_m: 0.0573 - precision_m: 0.8547 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.3165 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.3165 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688 - val_loss: 1.3007 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 57/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.0605 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.0708 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.1847 - accuracy: 0.1979 - f1_m: 0.0664 - precision_m: 0.8421 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.2669 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.2926 - accuracy: 0.1736 - f1_m: 0.0498 - precision_m: 0.8672 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.2926 - accuracy: 0.1736 - f1_m: 0.0498 - precision_m: 0.8672 - recall_m: 0.1625 - val_loss: 1.3024 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 58/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 2.9658 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 13s - loss: 2.9913 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719\n",
            "3/5 [=================>............] - ETA: 9s - loss: 2.9814 - accuracy: 0.2188 - f1_m: 0.0834 - precision_m: 0.8337 - recall_m: 0.2188 \n",
            "4/5 [=======================>......] - ETA: 4s - loss: 3.2563 - accuracy: 0.1797 - f1_m: 0.0644 - precision_m: 0.8606 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.2498 - accuracy: 0.1736 - f1_m: 0.0571 - precision_m: 0.8666 - recall_m: 0.1688\n",
            "5/5 [==============================] - 20s 4s/step - loss: 3.2498 - accuracy: 0.1736 - f1_m: 0.0571 - precision_m: 0.8666 - recall_m: 0.1688 - val_loss: 1.3038 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 59/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.3469 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.9754 - accuracy: 0.1875 - f1_m: 0.0698 - precision_m: 0.8564 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.1242 - accuracy: 0.1875 - f1_m: 0.0663 - precision_m: 0.8535 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.1732 - accuracy: 0.1797 - f1_m: 0.0602 - precision_m: 0.8572 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.1987 - accuracy: 0.1736 - f1_m: 0.0538 - precision_m: 0.8639 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.1987 - accuracy: 0.1736 - f1_m: 0.0538 - precision_m: 0.8639 - recall_m: 0.1688 - val_loss: 1.3049 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 60/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.9027 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.0682 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.1281 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.2347 - accuracy: 0.1797 - f1_m: 0.0550 - precision_m: 0.8528 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.1889 - accuracy: 0.1736 - f1_m: 0.0495 - precision_m: 0.8604 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.1889 - accuracy: 0.1736 - f1_m: 0.0495 - precision_m: 0.8604 - recall_m: 0.1688 - val_loss: 1.3059 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 61/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.1598 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.0442 - accuracy: 0.2031 - f1_m: 0.0689 - precision_m: 0.8384 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.2326 - accuracy: 0.1667 - f1_m: 0.0513 - precision_m: 0.8639 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.0573 - accuracy: 0.1875 - f1_m: 0.0635 - precision_m: 0.8511 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.1375 - accuracy: 0.1736 - f1_m: 0.0522 - precision_m: 0.8691 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.1375 - accuracy: 0.1736 - f1_m: 0.0522 - precision_m: 0.8691 - recall_m: 0.1625 - val_loss: 1.3064 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 62/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.1397 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.0971 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.0497 - accuracy: 0.1979 - f1_m: 0.0688 - precision_m: 0.8441 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.0551 - accuracy: 0.1797 - f1_m: 0.0585 - precision_m: 0.8557 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.1190 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8627 - recall_m: 0.1688\n",
            "5/5 [==============================] - 16s 3s/step - loss: 3.1190 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8627 - recall_m: 0.1688 - val_loss: 1.3066 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 63/100\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 3.3074 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.1354 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.0636 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.0543 - accuracy: 0.1641 - f1_m: 0.0465 - precision_m: 0.8630 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.0769 - accuracy: 0.1736 - f1_m: 0.0572 - precision_m: 0.8529 - recall_m: 0.1813\n",
            "5/5 [==============================] - 15s 3s/step - loss: 3.0769 - accuracy: 0.1736 - f1_m: 0.0572 - precision_m: 0.8529 - recall_m: 0.1813 - val_loss: 1.3070 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 64/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.1699 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.0714 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.9263 - accuracy: 0.2083 - f1_m: 0.0766 - precision_m: 0.8392 - recall_m: 0.2083\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.0263 - accuracy: 0.1875 - f1_m: 0.0644 - precision_m: 0.8521 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.0590 - accuracy: 0.1736 - f1_m: 0.0530 - precision_m: 0.8699 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.0590 - accuracy: 0.1736 - f1_m: 0.0530 - precision_m: 0.8699 - recall_m: 0.1625 - val_loss: 1.3075 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 65/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.0678 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 3.2418 - accuracy: 0.1406 - f1_m: 0.0429 - precision_m: 0.8853 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.2471 - accuracy: 0.1250 - f1_m: 0.0340 - precision_m: 0.8952 - recall_m: 0.1250\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 3.1116 - accuracy: 0.1562 - f1_m: 0.0505 - precision_m: 0.8745 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.0116 - accuracy: 0.1736 - f1_m: 0.0702 - precision_m: 0.8566 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 3.0116 - accuracy: 0.1736 - f1_m: 0.0702 - precision_m: 0.8566 - recall_m: 0.1875 - val_loss: 1.3076 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 66/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.6917 - accuracy: 0.2812 - f1_m: 0.1235 - precision_m: 0.7979 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.8128 - accuracy: 0.1875 - f1_m: 0.0698 - precision_m: 0.8564 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.8973 - accuracy: 0.1875 - f1_m: 0.0663 - precision_m: 0.8535 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.9164 - accuracy: 0.1875 - f1_m: 0.0645 - precision_m: 0.8521 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.9760 - accuracy: 0.1736 - f1_m: 0.0531 - precision_m: 0.8699 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.9760 - accuracy: 0.1736 - f1_m: 0.0531 - precision_m: 0.8699 - recall_m: 0.1625 - val_loss: 1.3082 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 67/100\n",
            "1/5 [=====>........................] - ETA: 17s - loss: 3.0965 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 11s - loss: 3.2017 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "3/5 [=================>............] - ETA: 6s - loss: 3.1086 - accuracy: 0.1250 - f1_m: 0.0305 - precision_m: 0.8926 - recall_m: 0.1250 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.9847 - accuracy: 0.1641 - f1_m: 0.0537 - precision_m: 0.8689 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.9218 - accuracy: 0.1736 - f1_m: 0.0630 - precision_m: 0.8576 - recall_m: 0.1813\n",
            "5/5 [==============================] - 16s 3s/step - loss: 2.9218 - accuracy: 0.1736 - f1_m: 0.0630 - precision_m: 0.8576 - recall_m: 0.1813 - val_loss: 1.3089 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 68/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.1435 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.9218 - accuracy: 0.1562 - f1_m: 0.0473 - precision_m: 0.8721 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 3.0431 - accuracy: 0.1354 - f1_m: 0.0369 - precision_m: 0.8864 - recall_m: 0.1354\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.9411 - accuracy: 0.1562 - f1_m: 0.0473 - precision_m: 0.8721 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.9061 - accuracy: 0.1736 - f1_m: 0.0676 - precision_m: 0.8547 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.9061 - accuracy: 0.1736 - f1_m: 0.0676 - precision_m: 0.8547 - recall_m: 0.1875 - val_loss: 1.3089 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 69/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.0641 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.9281 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.9295 - accuracy: 0.1771 - f1_m: 0.0567 - precision_m: 0.8571 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.8506 - accuracy: 0.1797 - f1_m: 0.0573 - precision_m: 0.8547 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.8737 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.8737 - accuracy: 0.1736 - f1_m: 0.0514 - precision_m: 0.8619 - recall_m: 0.1688 - val_loss: 1.3091 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 70/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 2.9742 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 2.6641 - accuracy: 0.2500 - f1_m: 0.1091 - precision_m: 0.8213 - recall_m: 0.2500 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.8345 - accuracy: 0.1979 - f1_m: 0.0781 - precision_m: 0.8525 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.8791 - accuracy: 0.1719 - f1_m: 0.0626 - precision_m: 0.8682 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.8298 - accuracy: 0.1736 - f1_m: 0.0619 - precision_m: 0.8641 - recall_m: 0.1750\n",
            "5/5 [==============================] - 13s 3s/step - loss: 2.8298 - accuracy: 0.1736 - f1_m: 0.0619 - precision_m: 0.8641 - recall_m: 0.1750 - val_loss: 1.3093 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 71/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 3.0842 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.8161 - accuracy: 0.1875 - f1_m: 0.0698 - precision_m: 0.8564 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 7s - loss: 2.9346 - accuracy: 0.1458 - f1_m: 0.0490 - precision_m: 0.8848 - recall_m: 0.1458\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.8614 - accuracy: 0.1641 - f1_m: 0.0564 - precision_m: 0.8708 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.8174 - accuracy: 0.1736 - f1_m: 0.0651 - precision_m: 0.8592 - recall_m: 0.1813\n",
            "5/5 [==============================] - 17s 3s/step - loss: 2.8174 - accuracy: 0.1736 - f1_m: 0.0651 - precision_m: 0.8592 - recall_m: 0.1813 - val_loss: 1.3094 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 72/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.5886 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.5840 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.8242 - accuracy: 0.1667 - f1_m: 0.0495 - precision_m: 0.8626 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.8736 - accuracy: 0.1562 - f1_m: 0.0441 - precision_m: 0.8696 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.7861 - accuracy: 0.1736 - f1_m: 0.0650 - precision_m: 0.8527 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.7861 - accuracy: 0.1736 - f1_m: 0.0650 - precision_m: 0.8527 - recall_m: 0.1875 - val_loss: 1.3092 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 73/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.5813 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6609 - accuracy: 0.2031 - f1_m: 0.0711 - precision_m: 0.8403 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.6719 - accuracy: 0.1875 - f1_m: 0.0615 - precision_m: 0.8496 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.7530 - accuracy: 0.1719 - f1_m: 0.0531 - precision_m: 0.8599 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.7600 - accuracy: 0.1736 - f1_m: 0.0543 - precision_m: 0.8574 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.7600 - accuracy: 0.1736 - f1_m: 0.0543 - precision_m: 0.8574 - recall_m: 0.1750 - val_loss: 1.3090 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 74/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.8839 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6622 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.7003 - accuracy: 0.1667 - f1_m: 0.0479 - precision_m: 0.8613 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.7253 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.7175 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8559 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.7175 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8559 - recall_m: 0.1750 - val_loss: 1.3088 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 75/100\n",
            "1/5 [=====>........................] - ETA: 18s - loss: 2.7396 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 9s - loss: 2.7998 - accuracy: 0.1562 - f1_m: 0.0435 - precision_m: 0.8691 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 2.7242 - accuracy: 0.1562 - f1_m: 0.0431 - precision_m: 0.8688 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.7447 - accuracy: 0.1484 - f1_m: 0.0392 - precision_m: 0.8743 - recall_m: 0.1484\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.6855 - accuracy: 0.1736 - f1_m: 0.0723 - precision_m: 0.8525 - recall_m: 0.1937\n",
            "5/5 [==============================] - 19s 4s/step - loss: 2.6855 - accuracy: 0.1736 - f1_m: 0.0723 - precision_m: 0.8525 - recall_m: 0.1937 - val_loss: 1.3087 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 76/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.5562 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.5653 - accuracy: 0.2188 - f1_m: 0.0796 - precision_m: 0.8301 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.5469 - accuracy: 0.2083 - f1_m: 0.0728 - precision_m: 0.8359 - recall_m: 0.2083\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.6491 - accuracy: 0.1875 - f1_m: 0.0615 - precision_m: 0.8496 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.6726 - accuracy: 0.1736 - f1_m: 0.0507 - precision_m: 0.8680 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.6726 - accuracy: 0.1736 - f1_m: 0.0507 - precision_m: 0.8680 - recall_m: 0.1625 - val_loss: 1.3087 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 77/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.7758 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.8118 - accuracy: 0.1250 - f1_m: 0.0292 - precision_m: 0.8916 - recall_m: 0.1250 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.7225 - accuracy: 0.1667 - f1_m: 0.0528 - precision_m: 0.8652 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.6154 - accuracy: 0.1797 - f1_m: 0.0592 - precision_m: 0.8562 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.6368 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8631 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.6368 - accuracy: 0.1736 - f1_m: 0.0529 - precision_m: 0.8631 - recall_m: 0.1688 - val_loss: 1.3087 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 78/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.5895 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6097 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.5639 - accuracy: 0.1771 - f1_m: 0.0536 - precision_m: 0.8545 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.5995 - accuracy: 0.1641 - f1_m: 0.0471 - precision_m: 0.8635 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.6094 - accuracy: 0.1736 - f1_m: 0.0577 - precision_m: 0.8533 - recall_m: 0.1813\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.6094 - accuracy: 0.1736 - f1_m: 0.0577 - precision_m: 0.8533 - recall_m: 0.1813 - val_loss: 1.3088 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 79/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.7532 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6135 - accuracy: 0.1406 - f1_m: 0.0350 - precision_m: 0.8794 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.5118 - accuracy: 0.1771 - f1_m: 0.0567 - precision_m: 0.8571 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.5422 - accuracy: 0.1875 - f1_m: 0.0621 - precision_m: 0.8501 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.5817 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625\n",
            "5/5 [==============================] - 15s 3s/step - loss: 2.5817 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625 - val_loss: 1.3086 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 80/100\n",
            "1/5 [=====>........................] - ETA: 18s - loss: 2.6247 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6574 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.4936 - accuracy: 0.1875 - f1_m: 0.0615 - precision_m: 0.8496 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.5576 - accuracy: 0.1719 - f1_m: 0.0531 - precision_m: 0.8599 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.5690 - accuracy: 0.1736 - f1_m: 0.0543 - precision_m: 0.8574 - recall_m: 0.1750\n",
            "5/5 [==============================] - 16s 3s/step - loss: 2.5690 - accuracy: 0.1736 - f1_m: 0.0543 - precision_m: 0.8574 - recall_m: 0.1750 - val_loss: 1.3084 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 81/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.6804 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6407 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.5234 - accuracy: 0.1771 - f1_m: 0.0543 - precision_m: 0.8551 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.5973 - accuracy: 0.1562 - f1_m: 0.0448 - precision_m: 0.8701 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.5219 - accuracy: 0.1736 - f1_m: 0.0656 - precision_m: 0.8531 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.5219 - accuracy: 0.1736 - f1_m: 0.0656 - precision_m: 0.8531 - recall_m: 0.1875 - val_loss: 1.3082 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 82/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.3188 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.6707 - accuracy: 0.1250 - f1_m: 0.0333 - precision_m: 0.8945 - recall_m: 0.1250 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.4817 - accuracy: 0.1875 - f1_m: 0.0718 - precision_m: 0.8581 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.4617 - accuracy: 0.1875 - f1_m: 0.0686 - precision_m: 0.8555 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.4866 - accuracy: 0.1736 - f1_m: 0.0564 - precision_m: 0.8727 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.4866 - accuracy: 0.1736 - f1_m: 0.0564 - precision_m: 0.8727 - recall_m: 0.1625 - val_loss: 1.3079 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 83/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.4804 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.4411 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.5694 - accuracy: 0.1458 - f1_m: 0.0392 - precision_m: 0.8770 - recall_m: 0.1458\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.5147 - accuracy: 0.1562 - f1_m: 0.0442 - precision_m: 0.8696 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.4784 - accuracy: 0.1736 - f1_m: 0.0651 - precision_m: 0.8527 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.4784 - accuracy: 0.1736 - f1_m: 0.0651 - precision_m: 0.8527 - recall_m: 0.1875 - val_loss: 1.3078 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 84/100\n",
            "1/5 [=====>........................] - ETA: 15s - loss: 2.6346 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 14s - loss: 2.6050 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "3/5 [=================>............] - ETA: 7s - loss: 2.5479 - accuracy: 0.1458 - f1_m: 0.0383 - precision_m: 0.8763 - recall_m: 0.1458 \n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.4794 - accuracy: 0.1719 - f1_m: 0.0537 - precision_m: 0.8604 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.4796 - accuracy: 0.1736 - f1_m: 0.0548 - precision_m: 0.8578 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 2.4796 - accuracy: 0.1736 - f1_m: 0.0548 - precision_m: 0.8578 - recall_m: 0.1750 - val_loss: 1.3077 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 85/100\n",
            "1/5 [=====>........................] - ETA: 10s - loss: 2.3510 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 7s - loss: 2.4529 - accuracy: 0.1562 - f1_m: 0.0435 - precision_m: 0.8691 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.4864 - accuracy: 0.1458 - f1_m: 0.0383 - precision_m: 0.8763 - recall_m: 0.1458\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.3552 - accuracy: 0.1875 - f1_m: 0.0659 - precision_m: 0.8535 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.4297 - accuracy: 0.1736 - f1_m: 0.0542 - precision_m: 0.8711 - recall_m: 0.1625\n",
            "5/5 [==============================] - 13s 3s/step - loss: 2.4297 - accuracy: 0.1736 - f1_m: 0.0542 - precision_m: 0.8711 - recall_m: 0.1625 - val_loss: 1.3076 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 86/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.2695 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.3909 - accuracy: 0.1875 - f1_m: 0.0639 - precision_m: 0.8516 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.4327 - accuracy: 0.1667 - f1_m: 0.0519 - precision_m: 0.8646 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.4460 - accuracy: 0.1562 - f1_m: 0.0458 - precision_m: 0.8711 - recall_m: 0.1562\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3907 - accuracy: 0.1736 - f1_m: 0.0664 - precision_m: 0.8539 - recall_m: 0.1875\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.3907 - accuracy: 0.1736 - f1_m: 0.0664 - precision_m: 0.8539 - recall_m: 0.1875 - val_loss: 1.3073 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 87/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.4358 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.5078 - accuracy: 0.1406 - f1_m: 0.0350 - precision_m: 0.8794 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.3995 - accuracy: 0.1771 - f1_m: 0.0567 - precision_m: 0.8571 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.3676 - accuracy: 0.1875 - f1_m: 0.0621 - precision_m: 0.8501 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3864 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.3864 - accuracy: 0.1736 - f1_m: 0.0512 - precision_m: 0.8684 - recall_m: 0.1625 - val_loss: 1.3071 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 88/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.2834 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.3843 - accuracy: 0.1562 - f1_m: 0.0435 - precision_m: 0.8691 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 7s - loss: 2.3289 - accuracy: 0.1875 - f1_m: 0.0623 - precision_m: 0.8503 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.3972 - accuracy: 0.1641 - f1_m: 0.0508 - precision_m: 0.8665 - recall_m: 0.1641\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3514 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813\n",
            "5/5 [==============================] - 17s 3s/step - loss: 2.3514 - accuracy: 0.1736 - f1_m: 0.0606 - precision_m: 0.8557 - recall_m: 0.1813 - val_loss: 1.3068 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 89/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.3901 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.3594 - accuracy: 0.1562 - f1_m: 0.0435 - precision_m: 0.8691 - recall_m: 0.1562 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.2932 - accuracy: 0.1875 - f1_m: 0.0623 - precision_m: 0.8503 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.2645 - accuracy: 0.1875 - f1_m: 0.0615 - precision_m: 0.8496 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3248 - accuracy: 0.1736 - f1_m: 0.0507 - precision_m: 0.8680 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.3248 - accuracy: 0.1736 - f1_m: 0.0507 - precision_m: 0.8680 - recall_m: 0.1625 - val_loss: 1.3066 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 90/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.3570 - accuracy: 0.2500 - f1_m: 0.1000 - precision_m: 0.8125 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.2425 - accuracy: 0.2344 - f1_m: 0.0893 - precision_m: 0.8208 - recall_m: 0.2344 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.2474 - accuracy: 0.2188 - f1_m: 0.0792 - precision_m: 0.8298 - recall_m: 0.2188\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.3418 - accuracy: 0.1797 - f1_m: 0.0613 - precision_m: 0.8577 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3341 - accuracy: 0.1736 - f1_m: 0.0546 - precision_m: 0.8643 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.3341 - accuracy: 0.1736 - f1_m: 0.0546 - precision_m: 0.8643 - recall_m: 0.1688 - val_loss: 1.3065 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 91/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.3253 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.1405 - accuracy: 0.2188 - f1_m: 0.0829 - precision_m: 0.8330 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.2420 - accuracy: 0.1875 - f1_m: 0.0645 - precision_m: 0.8522 - recall_m: 0.1875\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.2820 - accuracy: 0.1875 - f1_m: 0.0632 - precision_m: 0.8511 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.2924 - accuracy: 0.1736 - f1_m: 0.0520 - precision_m: 0.8691 - recall_m: 0.1625\n",
            "5/5 [==============================] - 16s 3s/step - loss: 2.2924 - accuracy: 0.1736 - f1_m: 0.0520 - precision_m: 0.8691 - recall_m: 0.1625 - val_loss: 1.3064 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 92/100\n",
            "1/5 [=====>........................] - ETA: 12s - loss: 2.5807 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.3813 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 6s - loss: 2.3071 - accuracy: 0.1562 - f1_m: 0.0447 - precision_m: 0.8701 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.2887 - accuracy: 0.1719 - f1_m: 0.0532 - precision_m: 0.8599 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.2662 - accuracy: 0.1736 - f1_m: 0.0544 - precision_m: 0.8574 - recall_m: 0.1750\n",
            "5/5 [==============================] - 17s 3s/step - loss: 2.2662 - accuracy: 0.1736 - f1_m: 0.0544 - precision_m: 0.8574 - recall_m: 0.1750 - val_loss: 1.3062 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 93/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.4575 - accuracy: 0.0938 - f1_m: 0.0161 - precision_m: 0.9150 - recall_m: 0.0938\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.4116 - accuracy: 0.1250 - f1_m: 0.0292 - precision_m: 0.8916 - recall_m: 0.1250 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.1943 - accuracy: 0.1771 - f1_m: 0.0606 - precision_m: 0.8604 - recall_m: 0.1771\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.1992 - accuracy: 0.1797 - f1_m: 0.0602 - precision_m: 0.8572 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.2223 - accuracy: 0.1736 - f1_m: 0.0538 - precision_m: 0.8639 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.2223 - accuracy: 0.1736 - f1_m: 0.0538 - precision_m: 0.8639 - recall_m: 0.1688 - val_loss: 1.3059 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 94/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.2899 - accuracy: 0.1562 - f1_m: 0.0422 - precision_m: 0.8682 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.2661 - accuracy: 0.1406 - f1_m: 0.0350 - precision_m: 0.8794 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.2758 - accuracy: 0.1146 - f1_m: 0.0258 - precision_m: 0.9001 - recall_m: 0.1146\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.1416 - accuracy: 0.1797 - f1_m: 0.0705 - precision_m: 0.8665 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.2226 - accuracy: 0.1736 - f1_m: 0.0619 - precision_m: 0.8713 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.2226 - accuracy: 0.1736 - f1_m: 0.0619 - precision_m: 0.8713 - recall_m: 0.1688 - val_loss: 1.3060 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 95/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.1292 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.1674 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.2024 - accuracy: 0.1667 - f1_m: 0.0479 - precision_m: 0.8613 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.1996 - accuracy: 0.1719 - f1_m: 0.0507 - precision_m: 0.8579 - recall_m: 0.1719\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1884 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8559 - recall_m: 0.1750\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.1884 - accuracy: 0.1736 - f1_m: 0.0524 - precision_m: 0.8559 - recall_m: 0.1750 - val_loss: 1.3061 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 96/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.2052 - accuracy: 0.1875 - f1_m: 0.0592 - precision_m: 0.8477 - recall_m: 0.1875\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.0933 - accuracy: 0.2188 - f1_m: 0.0796 - precision_m: 0.8301 - recall_m: 0.2188 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.0996 - accuracy: 0.1979 - f1_m: 0.0671 - precision_m: 0.8428 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 3s - loss: 2.0966 - accuracy: 0.1875 - f1_m: 0.0609 - precision_m: 0.8491 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1672 - accuracy: 0.1736 - f1_m: 0.0502 - precision_m: 0.8676 - recall_m: 0.1625\n",
            "5/5 [==============================] - 16s 3s/step - loss: 2.1672 - accuracy: 0.1736 - f1_m: 0.0502 - precision_m: 0.8676 - recall_m: 0.1625 - val_loss: 1.3064 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 97/100\n",
            "1/5 [=====>........................] - ETA: 13s - loss: 1.9754 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.2342 - accuracy: 0.1406 - f1_m: 0.0429 - precision_m: 0.8853 - recall_m: 0.1406 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.2070 - accuracy: 0.1562 - f1_m: 0.0484 - precision_m: 0.8727 - recall_m: 0.1562\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.1185 - accuracy: 0.1875 - f1_m: 0.0671 - precision_m: 0.8540 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1411 - accuracy: 0.1736 - f1_m: 0.0552 - precision_m: 0.8715 - recall_m: 0.1625\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.1411 - accuracy: 0.1736 - f1_m: 0.0552 - precision_m: 0.8715 - recall_m: 0.1625 - val_loss: 1.3065 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 98/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 2.4427 - accuracy: 0.1250 - f1_m: 0.0278 - precision_m: 0.8906 - recall_m: 0.1250\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.1013 - accuracy: 0.2031 - f1_m: 0.0756 - precision_m: 0.8442 - recall_m: 0.2031 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.1252 - accuracy: 0.1979 - f1_m: 0.0702 - precision_m: 0.8454 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.1277 - accuracy: 0.1797 - f1_m: 0.0596 - precision_m: 0.8567 - recall_m: 0.1797\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1555 - accuracy: 0.1736 - f1_m: 0.0532 - precision_m: 0.8635 - recall_m: 0.1688\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.1555 - accuracy: 0.1736 - f1_m: 0.0532 - precision_m: 0.8635 - recall_m: 0.1688 - val_loss: 1.3064 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 99/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 1.8211 - accuracy: 0.3438 - f1_m: 0.1759 - precision_m: 0.7744 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.0621 - accuracy: 0.1875 - f1_m: 0.0889 - precision_m: 0.8721 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.1726 - accuracy: 0.1667 - f1_m: 0.0685 - precision_m: 0.8783 - recall_m: 0.1667\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.1687 - accuracy: 0.1484 - f1_m: 0.0554 - precision_m: 0.8875 - recall_m: 0.1484\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1042 - accuracy: 0.1736 - f1_m: 0.0852 - precision_m: 0.8631 - recall_m: 0.1937\n",
            "5/5 [==============================] - 14s 3s/step - loss: 2.1042 - accuracy: 0.1736 - f1_m: 0.0852 - precision_m: 0.8631 - recall_m: 0.1937 - val_loss: 1.3064 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m Epoch 100/100\n",
            "1/5 [=====>........................] - ETA: 11s - loss: 1.9721 - accuracy: 0.2188 - f1_m: 0.0785 - precision_m: 0.8291 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 8s - loss: 2.0270 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875 \n",
            "3/5 [=================>............] - ETA: 5s - loss: 2.0357 - accuracy: 0.1979 - f1_m: 0.0664 - precision_m: 0.8421 - recall_m: 0.1979\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 2.0839 - accuracy: 0.1875 - f1_m: 0.0604 - precision_m: 0.8486 - recall_m: 0.1875\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.1177 - accuracy: 0.1736 - f1_m: 0.0498 - precision_m: 0.8672 - recall_m: 0.1625\n",
            "5/5 [==============================] - 15s 3s/step - loss: 2.1177 - accuracy: 0.1736 - f1_m: 0.0498 - precision_m: 0.8672 - recall_m: 0.1625 - val_loss: 1.3065 - val_accuracy: 0.1622 - val_f1_m: 0.1282 - val_precision_m: 0.8253 - val_recall_m: 0.2625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m 2022-11-22 09:37:40.589472: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='dense_2/activation_2/Softmax:0', description=\"created by layer 'dense_2'\")\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Model: \"model\"\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  Layer (type)                Output Shape              Param #   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  input_1 (InputLayer)        [(None, 43893, 1)]        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  conv1d (Conv1D)             (None, 43886, 128)        1152      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  batch_normalization (BatchN  (None, 43886, 128)       512       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  ormalization)                                                   \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  activation (Activation)     (None, 43886, 128)        0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  global_max_pooling1d (Globa  (None, 128)              0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  lMaxPooling1D)                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  dense (Dense)               (None, 64)                8256      \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  dropout (Dropout)           (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  batch_normalization_1 (Batc  (None, 64)               256       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  activation_1 (Activation)   (None, 64)                0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  dense_1 (Dense)             (None, 2)                 130       \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  dropout_1 (Dropout)         (None, 2)                 0         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  batch_normalization_2 (Batc  (None, 2)                8         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  hNormalization)                                                 \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m  dense_2 (Dense)             (None, 3)                 9         \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m                                                                  \n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m =================================================================\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Total params: 10,323\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Trainable params: 9,935\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Non-trainable params: 388\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m _________________________________________________________________\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m None\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Total number of layers: 13\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f91271a4050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f91271a4050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function f1_m at 0x7f91271a4050> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Cause: Unable to locate the source code of <function f1_m at 0x7f91271a4050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f91271ac830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f91271ac830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function precision_m at 0x7f91271ac830> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Cause: Unable to locate the source code of <function precision_m at 0x7f91271ac830>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f90cf50f680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f90cf50f680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m WARNING:tensorflow:AutoGraph could not transform <function recall_m at 0x7f90cf50f680> and will run it as-is.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Cause: Unable to locate the source code of <function recall_m at 0x7f90cf50f680>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/5 [=====>........................] - ETA: 46s - loss: 1.4929 - accuracy: 0.2188 - f1_m: 0.1504 - precision_m: 0.1189 - recall_m: 0.2188\n",
            "2/5 [===========>..................] - ETA: 36s - loss: 1.5502 - accuracy: 0.1875 - f1_m: 0.1518 - precision_m: 0.2378 - recall_m: 0.1875\n",
            "3/5 [=================>............] - ETA: 19s - loss: 1.4915 - accuracy: 0.2708 - f1_m: 0.2518 - precision_m: 0.3563 - recall_m: 0.2708\n",
            "4/5 [=======================>......] - ETA: 9s - loss: 1.5241 - accuracy: 0.2344 - f1_m: 0.2218 - precision_m: 0.3139 - recall_m: 0.2344 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.5314 - accuracy: 0.2292 - f1_m: 0.2150 - precision_m: 0.3622 - recall_m: 0.2250\n",
            "5/5 [==============================] - 47s 9s/step - loss: 1.5314 - accuracy: 0.2292 - f1_m: 0.2150 - precision_m: 0.3622 - recall_m: 0.2250 - val_loss: 1.0823 - val_accuracy: 0.4054 - val_f1_m: 0.4558 - val_precision_m: 0.5592 - val_recall_m: 0.4875\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 2/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.3784 - accuracy: 0.2812 - f1_m: 0.2523 - precision_m: 0.2770 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.3682 - accuracy: 0.2812 - f1_m: 0.2646 - precision_m: 0.3634 - recall_m: 0.2812\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.4584 - accuracy: 0.2604 - f1_m: 0.2507 - precision_m: 0.3829 - recall_m: 0.2604\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.3912 - accuracy: 0.2891 - f1_m: 0.2699 - precision_m: 0.4632 - recall_m: 0.2891 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3640 - accuracy: 0.3056 - f1_m: 0.3059 - precision_m: 0.5164 - recall_m: 0.3187\n",
            "5/5 [==============================] - 37s 8s/step - loss: 1.3640 - accuracy: 0.3056 - f1_m: 0.3059 - precision_m: 0.5164 - recall_m: 0.3187 - val_loss: 1.1074 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 3/100\n",
            "1/5 [=====>........................] - ETA: 36s - loss: 1.3410 - accuracy: 0.3438 - f1_m: 0.3114 - precision_m: 0.3924 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 29s - loss: 1.2386 - accuracy: 0.3438 - f1_m: 0.3135 - precision_m: 0.4643 - recall_m: 0.3438\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.2660 - accuracy: 0.3021 - f1_m: 0.2906 - precision_m: 0.4884 - recall_m: 0.3021\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.2983 - accuracy: 0.3203 - f1_m: 0.3090 - precision_m: 0.5421 - recall_m: 0.3203 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.3056 - accuracy: 0.3333 - f1_m: 0.3495 - precision_m: 0.5649 - recall_m: 0.3438\n",
            "5/5 [==============================] - 38s 7s/step - loss: 1.3056 - accuracy: 0.3333 - f1_m: 0.3495 - precision_m: 0.5649 - recall_m: 0.3438 - val_loss: 1.0978 - val_accuracy: 0.4595 - val_f1_m: 0.2531 - val_precision_m: 0.6781 - val_recall_m: 0.3500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 4/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.3617 - accuracy: 0.2500 - f1_m: 0.2143 - precision_m: 0.2946 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.3115 - accuracy: 0.3125 - f1_m: 0.2800 - precision_m: 0.3778 - recall_m: 0.3125\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.2837 - accuracy: 0.3438 - f1_m: 0.3135 - precision_m: 0.4340 - recall_m: 0.3438\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.2601 - accuracy: 0.3516 - f1_m: 0.3154 - precision_m: 0.4940 - recall_m: 0.3516 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2453 - accuracy: 0.3542 - f1_m: 0.3168 - precision_m: 0.5315 - recall_m: 0.3562\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.2453 - accuracy: 0.3542 - f1_m: 0.3168 - precision_m: 0.5315 - recall_m: 0.3562 - val_loss: 1.1062 - val_accuracy: 0.2703 - val_f1_m: 0.2202 - val_precision_m: 0.7409 - val_recall_m: 0.2406\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 5/100\n",
            "1/5 [=====>........................] - ETA: 40s - loss: 1.1752 - accuracy: 0.3750 - f1_m: 0.4064 - precision_m: 0.5698 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.3346 - accuracy: 0.2969 - f1_m: 0.3054 - precision_m: 0.4532 - recall_m: 0.2969\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.3103 - accuracy: 0.3021 - f1_m: 0.3111 - precision_m: 0.4883 - recall_m: 0.3021\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.2961 - accuracy: 0.3047 - f1_m: 0.2949 - precision_m: 0.4172 - recall_m: 0.3047 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2767 - accuracy: 0.3125 - f1_m: 0.3061 - precision_m: 0.4538 - recall_m: 0.3187\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.2767 - accuracy: 0.3125 - f1_m: 0.3061 - precision_m: 0.4538 - recall_m: 0.3187 - val_loss: 1.1127 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 6/100\n",
            "1/5 [=====>........................] - ETA: 26s - loss: 1.2996 - accuracy: 0.1562 - f1_m: 0.1418 - precision_m: 0.2335 - recall_m: 0.1562\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.2266 - accuracy: 0.1875 - f1_m: 0.1772 - precision_m: 0.2591 - recall_m: 0.1875\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.2384 - accuracy: 0.2083 - f1_m: 0.1901 - precision_m: 0.2999 - recall_m: 0.2083\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.2419 - accuracy: 0.2266 - f1_m: 0.2097 - precision_m: 0.3163 - recall_m: 0.2266 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2354 - accuracy: 0.2500 - f1_m: 0.2486 - precision_m: 0.3776 - recall_m: 0.2688\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.2354 - accuracy: 0.2500 - f1_m: 0.2486 - precision_m: 0.3776 - recall_m: 0.2688 - val_loss: 1.1189 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.1452 - accuracy: 0.3750 - f1_m: 0.3334 - precision_m: 0.4900 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.1592 - accuracy: 0.3750 - f1_m: 0.3446 - precision_m: 0.4978 - recall_m: 0.3750\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.1195 - accuracy: 0.3854 - f1_m: 0.3517 - precision_m: 0.4790 - recall_m: 0.3854\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.1247 - accuracy: 0.3750 - f1_m: 0.3413 - precision_m: 0.4660 - recall_m: 0.3750 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1151 - accuracy: 0.3819 - f1_m: 0.3534 - precision_m: 0.4594 - recall_m: 0.3875\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.1151 - accuracy: 0.3819 - f1_m: 0.3534 - precision_m: 0.4594 - recall_m: 0.3875 - val_loss: 1.1193 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 8/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.0794 - accuracy: 0.4062 - f1_m: 0.3620 - precision_m: 0.4231 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0748 - accuracy: 0.3906 - f1_m: 0.3447 - precision_m: 0.3824 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 17s - loss: 1.1670 - accuracy: 0.3542 - f1_m: 0.3288 - precision_m: 0.4080 - recall_m: 0.3542\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.1876 - accuracy: 0.3203 - f1_m: 0.3095 - precision_m: 0.4038 - recall_m: 0.3203 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1817 - accuracy: 0.3194 - f1_m: 0.3076 - precision_m: 0.3835 - recall_m: 0.3187\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.1817 - accuracy: 0.3194 - f1_m: 0.3076 - precision_m: 0.3835 - recall_m: 0.3187 - val_loss: 1.1289 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 9/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.4593 - accuracy: 0.2812 - f1_m: 0.3048 - precision_m: 0.6214 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.3253 - accuracy: 0.3438 - f1_m: 0.3420 - precision_m: 0.6372 - recall_m: 0.3438\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.2262 - accuracy: 0.3646 - f1_m: 0.3595 - precision_m: 0.5862 - recall_m: 0.3646\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.1944 - accuracy: 0.3750 - f1_m: 0.3802 - precision_m: 0.5952 - recall_m: 0.3750 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1805 - accuracy: 0.3681 - f1_m: 0.3646 - precision_m: 0.5724 - recall_m: 0.3625\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.1805 - accuracy: 0.3681 - f1_m: 0.3646 - precision_m: 0.5724 - recall_m: 0.3625 - val_loss: 1.1510 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 10/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.9671 - accuracy: 0.4375 - f1_m: 0.4293 - precision_m: 0.6175 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 25s - loss: 1.1024 - accuracy: 0.4375 - f1_m: 0.4131 - precision_m: 0.6046 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.1639 - accuracy: 0.3958 - f1_m: 0.3934 - precision_m: 0.5823 - recall_m: 0.3958\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.1716 - accuracy: 0.3672 - f1_m: 0.3826 - precision_m: 0.5592 - recall_m: 0.3672 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1492 - accuracy: 0.3681 - f1_m: 0.3686 - precision_m: 0.5036 - recall_m: 0.3688\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.1492 - accuracy: 0.3681 - f1_m: 0.3686 - precision_m: 0.5036 - recall_m: 0.3688 - val_loss: 1.1723 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 11/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.3197 - accuracy: 0.2812 - f1_m: 0.3179 - precision_m: 0.5605 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.2137 - accuracy: 0.3438 - f1_m: 0.3612 - precision_m: 0.5448 - recall_m: 0.3438\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.2422 - accuracy: 0.3438 - f1_m: 0.3457 - precision_m: 0.4901 - recall_m: 0.3438\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.2230 - accuracy: 0.3359 - f1_m: 0.3298 - precision_m: 0.4906 - recall_m: 0.3359 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2276 - accuracy: 0.3472 - f1_m: 0.3511 - precision_m: 0.4900 - recall_m: 0.3562\n",
            "5/5 [==============================] - 39s 8s/step - loss: 1.2276 - accuracy: 0.3472 - f1_m: 0.3511 - precision_m: 0.4900 - recall_m: 0.3562 - val_loss: 1.2073 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 12/100\n",
            "1/5 [=====>........................] - ETA: 31s - loss: 1.0529 - accuracy: 0.3750 - f1_m: 0.3349 - precision_m: 0.4060 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0931 - accuracy: 0.3125 - f1_m: 0.3127 - precision_m: 0.4261 - recall_m: 0.3125\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.1813 - accuracy: 0.2708 - f1_m: 0.2575 - precision_m: 0.4094 - recall_m: 0.2708\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.2018 - accuracy: 0.3047 - f1_m: 0.2958 - precision_m: 0.4272 - recall_m: 0.3047 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.2040 - accuracy: 0.3264 - f1_m: 0.3416 - precision_m: 0.4938 - recall_m: 0.3438\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.2040 - accuracy: 0.3264 - f1_m: 0.3416 - precision_m: 0.4938 - recall_m: 0.3438 - val_loss: 1.2169 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 13/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.1291 - accuracy: 0.2812 - f1_m: 0.2882 - precision_m: 0.4804 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.1809 - accuracy: 0.3125 - f1_m: 0.3138 - precision_m: 0.4214 - recall_m: 0.3125\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.1228 - accuracy: 0.3438 - f1_m: 0.3286 - precision_m: 0.4365 - recall_m: 0.3438\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.1183 - accuracy: 0.3906 - f1_m: 0.3868 - precision_m: 0.5169 - recall_m: 0.3906 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1324 - accuracy: 0.4097 - f1_m: 0.4243 - precision_m: 0.5475 - recall_m: 0.4250\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.1324 - accuracy: 0.4097 - f1_m: 0.4243 - precision_m: 0.5475 - recall_m: 0.4250 - val_loss: 1.1872 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 14/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.1211 - accuracy: 0.2500 - f1_m: 0.2622 - precision_m: 0.4904 - recall_m: 0.2500\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0605 - accuracy: 0.3125 - f1_m: 0.3043 - precision_m: 0.5774 - recall_m: 0.3125\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0139 - accuracy: 0.3750 - f1_m: 0.3773 - precision_m: 0.6338 - recall_m: 0.3750\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0289 - accuracy: 0.3984 - f1_m: 0.4044 - precision_m: 0.6377 - recall_m: 0.3984 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.4236 - f1_m: 0.4475 - precision_m: 0.6352 - recall_m: 0.4437\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0298 - accuracy: 0.4236 - f1_m: 0.4475 - precision_m: 0.6352 - recall_m: 0.4437 - val_loss: 1.1539 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 15/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.0482 - accuracy: 0.4375 - f1_m: 0.4650 - precision_m: 0.5641 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 29s - loss: 1.1154 - accuracy: 0.3906 - f1_m: 0.3885 - precision_m: 0.4829 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 17s - loss: 1.0739 - accuracy: 0.3854 - f1_m: 0.3603 - precision_m: 0.4136 - recall_m: 0.3854\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.1075 - accuracy: 0.3672 - f1_m: 0.3636 - precision_m: 0.4855 - recall_m: 0.3672 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1140 - accuracy: 0.3681 - f1_m: 0.3658 - precision_m: 0.4700 - recall_m: 0.3688\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.1140 - accuracy: 0.3681 - f1_m: 0.3658 - precision_m: 0.4700 - recall_m: 0.3688 - val_loss: 1.1417 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 16/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.1201 - accuracy: 0.3750 - f1_m: 0.3795 - precision_m: 0.4464 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0576 - accuracy: 0.4531 - f1_m: 0.4491 - precision_m: 0.5597 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.0901 - accuracy: 0.4167 - f1_m: 0.4153 - precision_m: 0.5343 - recall_m: 0.4167\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0815 - accuracy: 0.4141 - f1_m: 0.4056 - precision_m: 0.5389 - recall_m: 0.4141 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.3958 - f1_m: 0.3733 - precision_m: 0.5002 - recall_m: 0.3812\n",
            "5/5 [==============================] - 39s 8s/step - loss: 1.0868 - accuracy: 0.3958 - f1_m: 0.3733 - precision_m: 0.5002 - recall_m: 0.3812 - val_loss: 1.1569 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 17/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.2518 - accuracy: 0.4375 - f1_m: 0.4281 - precision_m: 0.4602 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.1043 - accuracy: 0.4531 - f1_m: 0.4466 - precision_m: 0.4775 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0852 - accuracy: 0.4271 - f1_m: 0.4234 - precision_m: 0.5079 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0793 - accuracy: 0.4531 - f1_m: 0.4574 - precision_m: 0.5771 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0948 - accuracy: 0.4375 - f1_m: 0.4273 - precision_m: 0.5230 - recall_m: 0.4250\n",
            "5/5 [==============================] - 40s 8s/step - loss: 1.0948 - accuracy: 0.4375 - f1_m: 0.4273 - precision_m: 0.5230 - recall_m: 0.4250 - val_loss: 1.1792 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 18/100\n",
            "1/5 [=====>........................] - ETA: 33s - loss: 1.0765 - accuracy: 0.2812 - f1_m: 0.2636 - precision_m: 0.2954 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 1.0351 - accuracy: 0.3906 - f1_m: 0.3808 - precision_m: 0.4485 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 17s - loss: 1.0327 - accuracy: 0.4062 - f1_m: 0.4017 - precision_m: 0.4827 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0387 - accuracy: 0.3906 - f1_m: 0.3860 - precision_m: 0.5072 - recall_m: 0.3906 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0443 - accuracy: 0.3889 - f1_m: 0.3759 - precision_m: 0.5224 - recall_m: 0.3875\n",
            "5/5 [==============================] - 39s 8s/step - loss: 1.0443 - accuracy: 0.3889 - f1_m: 0.3759 - precision_m: 0.5224 - recall_m: 0.3875 - val_loss: 1.2208 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 19/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 0.8871 - accuracy: 0.6562 - f1_m: 0.6497 - precision_m: 0.7428 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9377 - accuracy: 0.5625 - f1_m: 0.5369 - precision_m: 0.6028 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0080 - accuracy: 0.5000 - f1_m: 0.4817 - precision_m: 0.6310 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0245 - accuracy: 0.4922 - f1_m: 0.4754 - precision_m: 0.6307 - recall_m: 0.4922 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0170 - accuracy: 0.4861 - f1_m: 0.4679 - precision_m: 0.6686 - recall_m: 0.4812\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0170 - accuracy: 0.4861 - f1_m: 0.4679 - precision_m: 0.6686 - recall_m: 0.4812 - val_loss: 1.2515 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 20/100\n",
            "1/5 [=====>........................] - ETA: 36s - loss: 1.1606 - accuracy: 0.3438 - f1_m: 0.3613 - precision_m: 0.4570 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 24s - loss: 1.0300 - accuracy: 0.4375 - f1_m: 0.4555 - precision_m: 0.5866 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 15s - loss: 1.0246 - accuracy: 0.4271 - f1_m: 0.4324 - precision_m: 0.5574 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0161 - accuracy: 0.4609 - f1_m: 0.4629 - precision_m: 0.5675 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0167 - accuracy: 0.4792 - f1_m: 0.5003 - precision_m: 0.6311 - recall_m: 0.4938\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.0167 - accuracy: 0.4792 - f1_m: 0.5003 - precision_m: 0.6311 - recall_m: 0.4938 - val_loss: 1.2928 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 21/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.0649 - accuracy: 0.4375 - f1_m: 0.4257 - precision_m: 0.6769 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.1328 - accuracy: 0.3438 - f1_m: 0.3767 - precision_m: 0.5767 - recall_m: 0.3438\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.1497 - accuracy: 0.3542 - f1_m: 0.3900 - precision_m: 0.5634 - recall_m: 0.3542\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.1393 - accuracy: 0.3594 - f1_m: 0.3800 - precision_m: 0.5367 - recall_m: 0.3594 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1205 - accuracy: 0.3750 - f1_m: 0.3936 - precision_m: 0.5293 - recall_m: 0.3875\n",
            "5/5 [==============================] - 37s 8s/step - loss: 1.1205 - accuracy: 0.3750 - f1_m: 0.3936 - precision_m: 0.5293 - recall_m: 0.3875 - val_loss: 1.3205 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 22/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.0211 - accuracy: 0.3125 - f1_m: 0.2688 - precision_m: 0.3314 - recall_m: 0.3125\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0038 - accuracy: 0.3594 - f1_m: 0.3145 - precision_m: 0.3450 - recall_m: 0.3594\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0063 - accuracy: 0.4062 - f1_m: 0.3763 - precision_m: 0.4189 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0212 - accuracy: 0.4297 - f1_m: 0.3935 - precision_m: 0.4286 - recall_m: 0.4297 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0190 - accuracy: 0.4306 - f1_m: 0.4016 - precision_m: 0.4998 - recall_m: 0.4313\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0190 - accuracy: 0.4306 - f1_m: 0.4016 - precision_m: 0.4998 - recall_m: 0.4313 - val_loss: 1.3137 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 23/100\n",
            "1/5 [=====>........................] - ETA: 36s - loss: 1.0595 - accuracy: 0.3438 - f1_m: 0.3394 - precision_m: 0.5280 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0735 - accuracy: 0.4219 - f1_m: 0.4170 - precision_m: 0.5270 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 17s - loss: 1.0273 - accuracy: 0.4479 - f1_m: 0.4447 - precision_m: 0.5440 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0199 - accuracy: 0.4375 - f1_m: 0.4250 - precision_m: 0.5117 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.4306 - f1_m: 0.4207 - precision_m: 0.5633 - recall_m: 0.4250\n",
            "5/5 [==============================] - 39s 8s/step - loss: 1.0158 - accuracy: 0.4306 - f1_m: 0.4207 - precision_m: 0.5633 - recall_m: 0.4250 - val_loss: 1.3277 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 24/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.0309 - accuracy: 0.5312 - f1_m: 0.5135 - precision_m: 0.6323 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0109 - accuracy: 0.5312 - f1_m: 0.5095 - precision_m: 0.5798 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9809 - accuracy: 0.5312 - f1_m: 0.5164 - precision_m: 0.6429 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9996 - accuracy: 0.5000 - f1_m: 0.4928 - precision_m: 0.6067 - recall_m: 0.5000 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.4792 - f1_m: 0.4480 - precision_m: 0.5502 - recall_m: 0.4625\n",
            "5/5 [==============================] - 34s 7s/step - loss: 1.0143 - accuracy: 0.4792 - f1_m: 0.4480 - precision_m: 0.5502 - recall_m: 0.4625 - val_loss: 1.3352 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 25/100\n",
            "1/5 [=====>........................] - ETA: 33s - loss: 1.0377 - accuracy: 0.4688 - f1_m: 0.4778 - precision_m: 0.5404 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 1.0477 - accuracy: 0.4062 - f1_m: 0.4073 - precision_m: 0.5302 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.0522 - accuracy: 0.4271 - f1_m: 0.4235 - precision_m: 0.5256 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0062 - accuracy: 0.4688 - f1_m: 0.4572 - precision_m: 0.5537 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.4653 - f1_m: 0.4527 - precision_m: 0.5721 - recall_m: 0.4625\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.0268 - accuracy: 0.4653 - f1_m: 0.4527 - precision_m: 0.5721 - recall_m: 0.4625 - val_loss: 1.3444 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 26/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 0.9928 - accuracy: 0.4375 - f1_m: 0.4414 - precision_m: 0.4917 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9819 - accuracy: 0.5312 - f1_m: 0.5438 - precision_m: 0.6115 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0251 - accuracy: 0.5000 - f1_m: 0.5047 - precision_m: 0.5803 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0114 - accuracy: 0.5234 - f1_m: 0.5225 - precision_m: 0.6079 - recall_m: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9981 - accuracy: 0.5278 - f1_m: 0.5305 - precision_m: 0.6285 - recall_m: 0.5312\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.9981 - accuracy: 0.5278 - f1_m: 0.5305 - precision_m: 0.6285 - recall_m: 0.5312 - val_loss: 1.3462 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 27/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9376 - accuracy: 0.5000 - f1_m: 0.4833 - precision_m: 0.6399 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9247 - accuracy: 0.5469 - f1_m: 0.5314 - precision_m: 0.6853 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9701 - accuracy: 0.4792 - f1_m: 0.4885 - precision_m: 0.6466 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0165 - accuracy: 0.4375 - f1_m: 0.4330 - precision_m: 0.5569 - recall_m: 0.4375 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.4444 - f1_m: 0.4457 - precision_m: 0.5455 - recall_m: 0.4500\n",
            "5/5 [==============================] - 35s 7s/step - loss: 1.0063 - accuracy: 0.4444 - f1_m: 0.4457 - precision_m: 0.5455 - recall_m: 0.4500 - val_loss: 1.3130 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 28/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.1602 - accuracy: 0.2812 - f1_m: 0.2751 - precision_m: 0.3144 - recall_m: 0.2812\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0244 - accuracy: 0.4375 - f1_m: 0.4370 - precision_m: 0.5037 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 16s - loss: 1.0054 - accuracy: 0.4583 - f1_m: 0.4580 - precision_m: 0.5150 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0405 - accuracy: 0.4297 - f1_m: 0.4278 - precision_m: 0.4860 - recall_m: 0.4297 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0397 - accuracy: 0.4375 - f1_m: 0.4550 - precision_m: 0.5674 - recall_m: 0.4437\n",
            "5/5 [==============================] - 37s 7s/step - loss: 1.0397 - accuracy: 0.4375 - f1_m: 0.4550 - precision_m: 0.5674 - recall_m: 0.4437 - val_loss: 1.3051 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 29/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 0.9777 - accuracy: 0.5312 - f1_m: 0.5139 - precision_m: 0.5630 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0577 - accuracy: 0.4219 - f1_m: 0.4343 - precision_m: 0.6584 - recall_m: 0.4219\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0344 - accuracy: 0.4688 - f1_m: 0.4772 - precision_m: 0.6408 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0404 - accuracy: 0.4453 - f1_m: 0.4486 - precision_m: 0.6135 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.4514 - f1_m: 0.4556 - precision_m: 0.5924 - recall_m: 0.4563\n",
            "5/5 [==============================] - 37s 8s/step - loss: 1.0268 - accuracy: 0.4514 - f1_m: 0.4556 - precision_m: 0.5924 - recall_m: 0.4563 - val_loss: 1.3087 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 30/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 1.1075 - accuracy: 0.3438 - f1_m: 0.3236 - precision_m: 0.4578 - recall_m: 0.3438\n",
            "2/5 [===========>..................] - ETA: 30s - loss: 1.0204 - accuracy: 0.4062 - f1_m: 0.4038 - precision_m: 0.5871 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 17s - loss: 1.0361 - accuracy: 0.4062 - f1_m: 0.4016 - precision_m: 0.5418 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0312 - accuracy: 0.4453 - f1_m: 0.4424 - precision_m: 0.5800 - recall_m: 0.4453 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0530 - accuracy: 0.4375 - f1_m: 0.4283 - precision_m: 0.5452 - recall_m: 0.4313\n",
            "5/5 [==============================] - 38s 8s/step - loss: 1.0530 - accuracy: 0.4375 - f1_m: 0.4283 - precision_m: 0.5452 - recall_m: 0.4313 - val_loss: 1.3156 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 31/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.0906 - accuracy: 0.4062 - f1_m: 0.4228 - precision_m: 0.5521 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0830 - accuracy: 0.3594 - f1_m: 0.3638 - precision_m: 0.4395 - recall_m: 0.3594\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0608 - accuracy: 0.3854 - f1_m: 0.3890 - precision_m: 0.4705 - recall_m: 0.3854\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0398 - accuracy: 0.3828 - f1_m: 0.3855 - precision_m: 0.4704 - recall_m: 0.3828 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0282 - accuracy: 0.3889 - f1_m: 0.4060 - precision_m: 0.5011 - recall_m: 0.3938\n",
            "5/5 [==============================] - 38s 8s/step - loss: 1.0282 - accuracy: 0.3889 - f1_m: 0.4060 - precision_m: 0.5011 - recall_m: 0.3938 - val_loss: 1.3071 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 32/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 0.9635 - accuracy: 0.4688 - f1_m: 0.4440 - precision_m: 0.5248 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9811 - accuracy: 0.4844 - f1_m: 0.4624 - precision_m: 0.5085 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9356 - accuracy: 0.4896 - f1_m: 0.4540 - precision_m: 0.5550 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9462 - accuracy: 0.4844 - f1_m: 0.4649 - precision_m: 0.5637 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9619 - accuracy: 0.4861 - f1_m: 0.4697 - precision_m: 0.5611 - recall_m: 0.4875\n",
            "5/5 [==============================] - 34s 7s/step - loss: 0.9619 - accuracy: 0.4861 - f1_m: 0.4697 - precision_m: 0.5611 - recall_m: 0.4875 - val_loss: 1.3100 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 33/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 1.0146 - accuracy: 0.5312 - f1_m: 0.5347 - precision_m: 0.6051 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9904 - accuracy: 0.5469 - f1_m: 0.5386 - precision_m: 0.6085 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.9502 - accuracy: 0.5625 - f1_m: 0.5566 - precision_m: 0.6480 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9549 - accuracy: 0.5312 - f1_m: 0.5317 - precision_m: 0.6443 - recall_m: 0.5312 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9642 - accuracy: 0.5139 - f1_m: 0.4951 - precision_m: 0.5896 - recall_m: 0.5000\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.9642 - accuracy: 0.5139 - f1_m: 0.4951 - precision_m: 0.5896 - recall_m: 0.5000 - val_loss: 1.3109 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 34/100\n",
            "1/5 [=====>........................] - ETA: 28s - loss: 0.9846 - accuracy: 0.4062 - f1_m: 0.3775 - precision_m: 0.5365 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 33s - loss: 1.0514 - accuracy: 0.3438 - f1_m: 0.3467 - precision_m: 0.4557 - recall_m: 0.3438\n",
            "3/5 [=================>............] - ETA: 21s - loss: 1.0411 - accuracy: 0.3646 - f1_m: 0.3608 - precision_m: 0.4435 - recall_m: 0.3646\n",
            "4/5 [=======================>......] - ETA: 9s - loss: 1.0181 - accuracy: 0.4141 - f1_m: 0.4107 - precision_m: 0.5008 - recall_m: 0.4141 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.4097 - f1_m: 0.3806 - precision_m: 0.4407 - recall_m: 0.4062\n",
            "5/5 [==============================] - 41s 9s/step - loss: 1.0056 - accuracy: 0.4097 - f1_m: 0.3806 - precision_m: 0.4407 - recall_m: 0.4062 - val_loss: 1.3120 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 35/100\n",
            "1/5 [=====>........................] - ETA: 40s - loss: 0.9340 - accuracy: 0.5625 - f1_m: 0.5524 - precision_m: 0.5663 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0363 - accuracy: 0.4375 - f1_m: 0.4355 - precision_m: 0.4845 - recall_m: 0.4375\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9967 - accuracy: 0.4375 - f1_m: 0.4273 - precision_m: 0.4758 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0344 - accuracy: 0.4219 - f1_m: 0.4261 - precision_m: 0.5037 - recall_m: 0.4219 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0412 - accuracy: 0.4167 - f1_m: 0.4150 - precision_m: 0.5012 - recall_m: 0.4125\n",
            "5/5 [==============================] - 38s 7s/step - loss: 1.0412 - accuracy: 0.4167 - f1_m: 0.4150 - precision_m: 0.5012 - recall_m: 0.4125 - val_loss: 1.2891 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 36/100\n",
            "1/5 [=====>........................] - ETA: 40s - loss: 1.0117 - accuracy: 0.5625 - f1_m: 0.5756 - precision_m: 0.6286 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9892 - accuracy: 0.5469 - f1_m: 0.5627 - precision_m: 0.6143 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0508 - accuracy: 0.4792 - f1_m: 0.4879 - precision_m: 0.5640 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0357 - accuracy: 0.4531 - f1_m: 0.4578 - precision_m: 0.5476 - recall_m: 0.4531 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0281 - accuracy: 0.4444 - f1_m: 0.4468 - precision_m: 0.5773 - recall_m: 0.4375\n",
            "5/5 [==============================] - 41s 8s/step - loss: 1.0281 - accuracy: 0.4444 - f1_m: 0.4468 - precision_m: 0.5773 - recall_m: 0.4375 - val_loss: 1.2648 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 37/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.8342 - accuracy: 0.5938 - f1_m: 0.5836 - precision_m: 0.5938 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.9424 - accuracy: 0.4844 - f1_m: 0.4681 - precision_m: 0.5174 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9233 - accuracy: 0.4792 - f1_m: 0.4674 - precision_m: 0.5062 - recall_m: 0.4792\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9307 - accuracy: 0.4688 - f1_m: 0.4521 - precision_m: 0.5173 - recall_m: 0.4688 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9527 - accuracy: 0.4653 - f1_m: 0.4468 - precision_m: 0.4973 - recall_m: 0.4625\n",
            "5/5 [==============================] - 36s 7s/step - loss: 0.9527 - accuracy: 0.4653 - f1_m: 0.4468 - precision_m: 0.4973 - recall_m: 0.4625 - val_loss: 1.2432 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 38/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8959 - accuracy: 0.5938 - f1_m: 0.5954 - precision_m: 0.6335 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 28s - loss: 1.0271 - accuracy: 0.4688 - f1_m: 0.4683 - precision_m: 0.5201 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 17s - loss: 1.0289 - accuracy: 0.4688 - f1_m: 0.4809 - precision_m: 0.5488 - recall_m: 0.4688\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0261 - accuracy: 0.4766 - f1_m: 0.4939 - precision_m: 0.5651 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0092 - accuracy: 0.4861 - f1_m: 0.5077 - precision_m: 0.5813 - recall_m: 0.4938\n",
            "5/5 [==============================] - 38s 8s/step - loss: 1.0092 - accuracy: 0.4861 - f1_m: 0.5077 - precision_m: 0.5813 - recall_m: 0.4938 - val_loss: 1.2232 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 39/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.1833 - accuracy: 0.3750 - f1_m: 0.3580 - precision_m: 0.4466 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 1.1182 - accuracy: 0.3594 - f1_m: 0.3412 - precision_m: 0.4290 - recall_m: 0.3594\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0674 - accuracy: 0.3958 - f1_m: 0.3759 - precision_m: 0.4466 - recall_m: 0.3958\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0437 - accuracy: 0.4297 - f1_m: 0.4204 - precision_m: 0.4928 - recall_m: 0.4297 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0615 - accuracy: 0.4236 - f1_m: 0.4242 - precision_m: 0.5005 - recall_m: 0.4187\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.0615 - accuracy: 0.4236 - f1_m: 0.4242 - precision_m: 0.5005 - recall_m: 0.4187 - val_loss: 1.2150 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 40/100\n",
            "1/5 [=====>........................] - ETA: 36s - loss: 1.0297 - accuracy: 0.4375 - f1_m: 0.4415 - precision_m: 0.4771 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 1.0693 - accuracy: 0.4062 - f1_m: 0.3933 - precision_m: 0.4260 - recall_m: 0.4062\n",
            "3/5 [=================>............] - ETA: 13s - loss: 1.0604 - accuracy: 0.4271 - f1_m: 0.4204 - precision_m: 0.4903 - recall_m: 0.4271\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 1.0356 - accuracy: 0.4297 - f1_m: 0.4303 - precision_m: 0.5222 - recall_m: 0.4297 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0277 - accuracy: 0.4306 - f1_m: 0.4255 - precision_m: 0.5115 - recall_m: 0.4313\n",
            "5/5 [==============================] - 36s 7s/step - loss: 1.0277 - accuracy: 0.4306 - f1_m: 0.4255 - precision_m: 0.5115 - recall_m: 0.4313 - val_loss: 1.2147 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 41/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.0231 - accuracy: 0.3750 - f1_m: 0.3623 - precision_m: 0.3946 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 1.0541 - accuracy: 0.3906 - f1_m: 0.3961 - precision_m: 0.4408 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 14s - loss: 1.0272 - accuracy: 0.4062 - f1_m: 0.4293 - precision_m: 0.4992 - recall_m: 0.4062\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 1.0362 - accuracy: 0.3906 - f1_m: 0.4100 - precision_m: 0.4927 - recall_m: 0.3906 \n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0551 - accuracy: 0.3750 - f1_m: 0.3730 - precision_m: 0.5352 - recall_m: 0.3625\n",
            "5/5 [==============================] - 38s 8s/step - loss: 1.0551 - accuracy: 0.3750 - f1_m: 0.3730 - precision_m: 0.5352 - recall_m: 0.3625 - val_loss: 1.2324 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 42/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9923 - accuracy: 0.4062 - f1_m: 0.4550 - precision_m: 0.5180 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 1.0115 - accuracy: 0.3594 - f1_m: 0.3773 - precision_m: 0.4276 - recall_m: 0.3594\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.9890 - accuracy: 0.3750 - f1_m: 0.3960 - precision_m: 0.4456 - recall_m: 0.3750\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9922 - accuracy: 0.3750 - f1_m: 0.3892 - precision_m: 0.4384 - recall_m: 0.3750 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9858 - accuracy: 0.3889 - f1_m: 0.4140 - precision_m: 0.4882 - recall_m: 0.4000\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.9858 - accuracy: 0.3889 - f1_m: 0.4140 - precision_m: 0.4882 - recall_m: 0.4000 - val_loss: 1.2548 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 43/100\n",
            "1/5 [=====>........................] - ETA: 32s - loss: 0.8394 - accuracy: 0.5938 - f1_m: 0.5895 - precision_m: 0.6071 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 28s - loss: 0.9441 - accuracy: 0.4844 - f1_m: 0.4778 - precision_m: 0.5081 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.9648 - accuracy: 0.4479 - f1_m: 0.4519 - precision_m: 0.5363 - recall_m: 0.4479\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9496 - accuracy: 0.4609 - f1_m: 0.4624 - precision_m: 0.5287 - recall_m: 0.4609 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9322 - accuracy: 0.4861 - f1_m: 0.5116 - precision_m: 0.5742 - recall_m: 0.5063\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.9322 - accuracy: 0.4861 - f1_m: 0.5116 - precision_m: 0.5742 - recall_m: 0.5063 - val_loss: 1.2537 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 44/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.9017 - accuracy: 0.5938 - f1_m: 0.6019 - precision_m: 0.7219 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 29s - loss: 0.9266 - accuracy: 0.5625 - f1_m: 0.5547 - precision_m: 0.6703 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.9673 - accuracy: 0.5104 - f1_m: 0.5094 - precision_m: 0.6001 - recall_m: 0.5104\n",
            "4/5 [=======================>......] - ETA: 9s - loss: 0.9659 - accuracy: 0.5234 - f1_m: 0.5237 - precision_m: 0.6088 - recall_m: 0.5234 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9540 - accuracy: 0.5417 - f1_m: 0.5558 - precision_m: 0.6246 - recall_m: 0.5562\n",
            "5/5 [==============================] - 41s 8s/step - loss: 0.9540 - accuracy: 0.5417 - f1_m: 0.5558 - precision_m: 0.6246 - recall_m: 0.5562 - val_loss: 1.2532 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 45/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9859 - accuracy: 0.4688 - f1_m: 0.4903 - precision_m: 0.5513 - recall_m: 0.4688\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9792 - accuracy: 0.4688 - f1_m: 0.4964 - precision_m: 0.5716 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9628 - accuracy: 0.4896 - f1_m: 0.5155 - precision_m: 0.5897 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9837 - accuracy: 0.4844 - f1_m: 0.5015 - precision_m: 0.5735 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.5000 - f1_m: 0.5256 - precision_m: 0.6149 - recall_m: 0.5125\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.9714 - accuracy: 0.5000 - f1_m: 0.5256 - precision_m: 0.6149 - recall_m: 0.5125 - val_loss: 1.2643 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 46/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9179 - accuracy: 0.6250 - f1_m: 0.6253 - precision_m: 0.6414 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.9128 - accuracy: 0.5938 - f1_m: 0.5919 - precision_m: 0.6000 - recall_m: 0.5938\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.9533 - accuracy: 0.5000 - f1_m: 0.4865 - precision_m: 0.5174 - recall_m: 0.5000\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9538 - accuracy: 0.5078 - f1_m: 0.5013 - precision_m: 0.5318 - recall_m: 0.5078 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9613 - accuracy: 0.4931 - f1_m: 0.4738 - precision_m: 0.4984 - recall_m: 0.4812\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.9613 - accuracy: 0.4931 - f1_m: 0.4738 - precision_m: 0.4984 - recall_m: 0.4812 - val_loss: 1.2713 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 47/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.0432 - accuracy: 0.4062 - f1_m: 0.4027 - precision_m: 0.4622 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.9934 - accuracy: 0.4531 - f1_m: 0.4380 - precision_m: 0.4827 - recall_m: 0.4531\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9744 - accuracy: 0.4375 - f1_m: 0.4129 - precision_m: 0.4726 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9362 - accuracy: 0.4766 - f1_m: 0.4600 - precision_m: 0.5568 - recall_m: 0.4766 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9493 - accuracy: 0.4792 - f1_m: 0.4710 - precision_m: 0.5671 - recall_m: 0.4812\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.9493 - accuracy: 0.4792 - f1_m: 0.4710 - precision_m: 0.5671 - recall_m: 0.4812 - val_loss: 1.2431 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 48/100\n",
            "1/5 [=====>........................] - ETA: 36s - loss: 0.8799 - accuracy: 0.5938 - f1_m: 0.6056 - precision_m: 0.6508 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 26s - loss: 0.9382 - accuracy: 0.5312 - f1_m: 0.5401 - precision_m: 0.5801 - recall_m: 0.5312\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.9407 - accuracy: 0.5208 - f1_m: 0.5259 - precision_m: 0.5582 - recall_m: 0.5208\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9500 - accuracy: 0.5156 - f1_m: 0.5194 - precision_m: 0.5487 - recall_m: 0.5156 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.5208 - f1_m: 0.5341 - precision_m: 0.5768 - recall_m: 0.5250\n",
            "5/5 [==============================] - 38s 7s/step - loss: 0.9555 - accuracy: 0.5208 - f1_m: 0.5341 - precision_m: 0.5768 - recall_m: 0.5250 - val_loss: 1.2171 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 49/100\n",
            "1/5 [=====>........................] - ETA: 41s - loss: 0.8999 - accuracy: 0.5625 - f1_m: 0.5630 - precision_m: 0.5651 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8834 - accuracy: 0.5938 - f1_m: 0.5978 - precision_m: 0.6230 - recall_m: 0.5938\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9349 - accuracy: 0.5729 - f1_m: 0.5801 - precision_m: 0.6192 - recall_m: 0.5729\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9269 - accuracy: 0.5391 - f1_m: 0.5438 - precision_m: 0.5900 - recall_m: 0.5391 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9417 - accuracy: 0.5139 - f1_m: 0.4971 - precision_m: 0.5357 - recall_m: 0.4938\n",
            "5/5 [==============================] - 41s 8s/step - loss: 0.9417 - accuracy: 0.5139 - f1_m: 0.4971 - precision_m: 0.5357 - recall_m: 0.4938 - val_loss: 1.2218 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 50/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 1.0168 - accuracy: 0.4062 - f1_m: 0.4052 - precision_m: 0.4083 - recall_m: 0.4062\n",
            "2/5 [===========>..................] - ETA: 31s - loss: 0.9582 - accuracy: 0.3906 - f1_m: 0.3752 - precision_m: 0.4229 - recall_m: 0.3906\n",
            "3/5 [=================>............] - ETA: 21s - loss: 0.9722 - accuracy: 0.4375 - f1_m: 0.4249 - precision_m: 0.4654 - recall_m: 0.4375\n",
            "4/5 [=======================>......] - ETA: 9s - loss: 0.9555 - accuracy: 0.4844 - f1_m: 0.4793 - precision_m: 0.5196 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9616 - accuracy: 0.5069 - f1_m: 0.5239 - precision_m: 0.5755 - recall_m: 0.5250\n",
            "5/5 [==============================] - 42s 9s/step - loss: 0.9616 - accuracy: 0.5069 - f1_m: 0.5239 - precision_m: 0.5755 - recall_m: 0.5250 - val_loss: 1.2575 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 51/100\n",
            "1/5 [=====>........................] - ETA: 35s - loss: 0.9081 - accuracy: 0.4375 - f1_m: 0.4796 - precision_m: 0.5707 - recall_m: 0.4375\n",
            "2/5 [===========>..................] - ETA: 28s - loss: 0.8879 - accuracy: 0.4688 - f1_m: 0.4921 - precision_m: 0.5585 - recall_m: 0.4688\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.9243 - accuracy: 0.4583 - f1_m: 0.4746 - precision_m: 0.5244 - recall_m: 0.4583\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8968 - accuracy: 0.4844 - f1_m: 0.4955 - precision_m: 0.5388 - recall_m: 0.4844 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.4931 - f1_m: 0.5086 - precision_m: 0.5508 - recall_m: 0.5000\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.8853 - accuracy: 0.4931 - f1_m: 0.5086 - precision_m: 0.5508 - recall_m: 0.5000 - val_loss: 1.3005 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 52/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.8931 - accuracy: 0.6250 - f1_m: 0.6213 - precision_m: 0.6250 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8931 - accuracy: 0.5938 - f1_m: 0.6014 - precision_m: 0.6300 - recall_m: 0.5938\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.8896 - accuracy: 0.5833 - f1_m: 0.5894 - precision_m: 0.6100 - recall_m: 0.5833\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8824 - accuracy: 0.5703 - f1_m: 0.5761 - precision_m: 0.5952 - recall_m: 0.5703 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8804 - accuracy: 0.5625 - f1_m: 0.5654 - precision_m: 0.5862 - recall_m: 0.5562\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.8804 - accuracy: 0.5625 - f1_m: 0.5654 - precision_m: 0.5862 - recall_m: 0.5562 - val_loss: 1.3211 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 53/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9123 - accuracy: 0.6562 - f1_m: 0.6566 - precision_m: 0.6623 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.9031 - accuracy: 0.6562 - f1_m: 0.6637 - precision_m: 0.6781 - recall_m: 0.6562\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.9018 - accuracy: 0.6458 - f1_m: 0.6503 - precision_m: 0.6639 - recall_m: 0.6458\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.9075 - accuracy: 0.6094 - f1_m: 0.6132 - precision_m: 0.6281 - recall_m: 0.6094 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.5694 - f1_m: 0.5389 - precision_m: 0.5754 - recall_m: 0.5375\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.9244 - accuracy: 0.5694 - f1_m: 0.5389 - precision_m: 0.5754 - recall_m: 0.5375 - val_loss: 1.2927 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 54/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9124 - accuracy: 0.5000 - f1_m: 0.5093 - precision_m: 0.5655 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 25s - loss: 0.8986 - accuracy: 0.6094 - f1_m: 0.6098 - precision_m: 0.6377 - recall_m: 0.6094\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.9521 - accuracy: 0.5625 - f1_m: 0.5649 - precision_m: 0.5882 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.9066 - accuracy: 0.5859 - f1_m: 0.5877 - precision_m: 0.6338 - recall_m: 0.5859 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8911 - accuracy: 0.5764 - f1_m: 0.5600 - precision_m: 0.5981 - recall_m: 0.5688\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.8911 - accuracy: 0.5764 - f1_m: 0.5600 - precision_m: 0.5981 - recall_m: 0.5688 - val_loss: 1.2900 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 55/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8513 - accuracy: 0.5000 - f1_m: 0.4988 - precision_m: 0.5328 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 28s - loss: 0.8327 - accuracy: 0.6094 - f1_m: 0.6108 - precision_m: 0.6365 - recall_m: 0.6094\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.8944 - accuracy: 0.5521 - f1_m: 0.5512 - precision_m: 0.5707 - recall_m: 0.5521\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8833 - accuracy: 0.5859 - f1_m: 0.5853 - precision_m: 0.5999 - recall_m: 0.5859 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.5903 - f1_m: 0.6004 - precision_m: 0.6287 - recall_m: 0.5938\n",
            "5/5 [==============================] - 40s 8s/step - loss: 0.8756 - accuracy: 0.5903 - f1_m: 0.6004 - precision_m: 0.6287 - recall_m: 0.5938 - val_loss: 1.2597 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 56/100\n",
            "1/5 [=====>........................] - ETA: 33s - loss: 0.8949 - accuracy: 0.5000 - f1_m: 0.5104 - precision_m: 0.6612 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.8253 - accuracy: 0.5625 - f1_m: 0.5648 - precision_m: 0.6673 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.8316 - accuracy: 0.5625 - f1_m: 0.5698 - precision_m: 0.6472 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8560 - accuracy: 0.5469 - f1_m: 0.5557 - precision_m: 0.6220 - recall_m: 0.5469 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8431 - accuracy: 0.5694 - f1_m: 0.5924 - precision_m: 0.6452 - recall_m: 0.5875\n",
            "5/5 [==============================] - 36s 7s/step - loss: 0.8431 - accuracy: 0.5694 - f1_m: 0.5924 - precision_m: 0.6452 - recall_m: 0.5875 - val_loss: 1.2266 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 57/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7898 - accuracy: 0.6562 - f1_m: 0.6566 - precision_m: 0.6583 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.7943 - accuracy: 0.6562 - f1_m: 0.6579 - precision_m: 0.6616 - recall_m: 0.6562\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.8294 - accuracy: 0.5833 - f1_m: 0.5831 - precision_m: 0.6028 - recall_m: 0.5833\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8555 - accuracy: 0.5625 - f1_m: 0.5615 - precision_m: 0.5826 - recall_m: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8821 - accuracy: 0.5556 - f1_m: 0.5494 - precision_m: 0.5700 - recall_m: 0.5500\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.8821 - accuracy: 0.5556 - f1_m: 0.5494 - precision_m: 0.5700 - recall_m: 0.5500 - val_loss: 1.2362 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 58/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8198 - accuracy: 0.6250 - f1_m: 0.6342 - precision_m: 0.6750 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.9137 - accuracy: 0.4844 - f1_m: 0.4801 - precision_m: 0.5036 - recall_m: 0.4844\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.8684 - accuracy: 0.5729 - f1_m: 0.5690 - precision_m: 0.5885 - recall_m: 0.5729\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8411 - accuracy: 0.6094 - f1_m: 0.6095 - precision_m: 0.6334 - recall_m: 0.6094 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8569 - accuracy: 0.5903 - f1_m: 0.5758 - precision_m: 0.6099 - recall_m: 0.5750\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.8569 - accuracy: 0.5903 - f1_m: 0.5758 - precision_m: 0.6099 - recall_m: 0.5750 - val_loss: 1.2336 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 59/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9480 - accuracy: 0.5000 - f1_m: 0.5178 - precision_m: 0.5864 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 30s - loss: 0.8672 - accuracy: 0.5156 - f1_m: 0.5330 - precision_m: 0.5910 - recall_m: 0.5156\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.8958 - accuracy: 0.4896 - f1_m: 0.4977 - precision_m: 0.5340 - recall_m: 0.4896\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8687 - accuracy: 0.5078 - f1_m: 0.5161 - precision_m: 0.5489 - recall_m: 0.5078 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.5139 - f1_m: 0.5226 - precision_m: 0.5474 - recall_m: 0.5188\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.8623 - accuracy: 0.5139 - f1_m: 0.5226 - precision_m: 0.5474 - recall_m: 0.5188 - val_loss: 1.2386 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 60/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8467 - accuracy: 0.6562 - f1_m: 0.6589 - precision_m: 0.6762 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7886 - accuracy: 0.7344 - f1_m: 0.7359 - precision_m: 0.7459 - recall_m: 0.7344\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7707 - accuracy: 0.7188 - f1_m: 0.7219 - precision_m: 0.7382 - recall_m: 0.7188\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7856 - accuracy: 0.6875 - f1_m: 0.6900 - precision_m: 0.7074 - recall_m: 0.6875 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8036 - accuracy: 0.6667 - f1_m: 0.6532 - precision_m: 0.6696 - recall_m: 0.6500\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.8036 - accuracy: 0.6667 - f1_m: 0.6532 - precision_m: 0.6696 - recall_m: 0.6500 - val_loss: 1.2321 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 61/100\n",
            "1/5 [=====>........................] - ETA: 33s - loss: 0.8282 - accuracy: 0.6875 - f1_m: 0.6772 - precision_m: 0.6725 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8367 - accuracy: 0.6094 - f1_m: 0.6007 - precision_m: 0.6007 - recall_m: 0.6094\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.8593 - accuracy: 0.6146 - f1_m: 0.6099 - precision_m: 0.6146 - recall_m: 0.6146\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8541 - accuracy: 0.6406 - f1_m: 0.6383 - precision_m: 0.6463 - recall_m: 0.6406 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8612 - accuracy: 0.6458 - f1_m: 0.6561 - precision_m: 0.6827 - recall_m: 0.6500\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.8612 - accuracy: 0.6458 - f1_m: 0.6561 - precision_m: 0.6827 - recall_m: 0.6500 - val_loss: 1.2516 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 62/100\n",
            "1/5 [=====>........................] - ETA: 27s - loss: 0.7961 - accuracy: 0.7812 - f1_m: 0.7881 - precision_m: 0.7969 - recall_m: 0.7812\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 0.8139 - accuracy: 0.6562 - f1_m: 0.6566 - precision_m: 0.6589 - recall_m: 0.6562\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.8205 - accuracy: 0.6250 - f1_m: 0.6260 - precision_m: 0.6288 - recall_m: 0.6250\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8352 - accuracy: 0.5859 - f1_m: 0.5888 - precision_m: 0.5978 - recall_m: 0.5859 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8277 - accuracy: 0.5972 - f1_m: 0.6075 - precision_m: 0.6149 - recall_m: 0.6062\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.8277 - accuracy: 0.5972 - f1_m: 0.6075 - precision_m: 0.6149 - recall_m: 0.6062 - val_loss: 1.2149 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 63/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9342 - accuracy: 0.5000 - f1_m: 0.5275 - precision_m: 0.6254 - recall_m: 0.5000\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8642 - accuracy: 0.6250 - f1_m: 0.6381 - precision_m: 0.6902 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.8471 - accuracy: 0.6354 - f1_m: 0.6484 - precision_m: 0.6988 - recall_m: 0.6354\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8679 - accuracy: 0.6094 - f1_m: 0.6197 - precision_m: 0.6665 - recall_m: 0.6094 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.5833 - f1_m: 0.5812 - precision_m: 0.6359 - recall_m: 0.5625\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.8787 - accuracy: 0.5833 - f1_m: 0.5812 - precision_m: 0.6359 - recall_m: 0.5625 - val_loss: 1.1918 - val_accuracy: 0.1622 - val_f1_m: 0.0296 - val_precision_m: 0.9238 - val_recall_m: 0.0938\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 64/100\n",
            "1/5 [=====>........................] - ETA: 31s - loss: 1.0140 - accuracy: 0.3750 - f1_m: 0.3734 - precision_m: 0.3811 - recall_m: 0.3750\n",
            "2/5 [===========>..................] - ETA: 29s - loss: 0.8852 - accuracy: 0.5469 - f1_m: 0.5474 - precision_m: 0.5603 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.9004 - accuracy: 0.5312 - f1_m: 0.5293 - precision_m: 0.5385 - recall_m: 0.5312\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8881 - accuracy: 0.5547 - f1_m: 0.5530 - precision_m: 0.5601 - recall_m: 0.5547 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8728 - accuracy: 0.5764 - f1_m: 0.5951 - precision_m: 0.6106 - recall_m: 0.5938\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.8728 - accuracy: 0.5764 - f1_m: 0.5951 - precision_m: 0.6106 - recall_m: 0.5938 - val_loss: 1.1421 - val_accuracy: 0.4595 - val_f1_m: 0.2542 - val_precision_m: 0.6668 - val_recall_m: 0.3500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 65/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7904 - accuracy: 0.5938 - f1_m: 0.6017 - precision_m: 0.6445 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 21s - loss: 0.8284 - accuracy: 0.5625 - f1_m: 0.5713 - precision_m: 0.6121 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.8103 - accuracy: 0.5625 - f1_m: 0.5643 - precision_m: 0.5911 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8240 - accuracy: 0.5625 - f1_m: 0.5658 - precision_m: 0.5891 - recall_m: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8142 - accuracy: 0.5833 - f1_m: 0.6045 - precision_m: 0.6374 - recall_m: 0.6000\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.8142 - accuracy: 0.5833 - f1_m: 0.6045 - precision_m: 0.6374 - recall_m: 0.6000 - val_loss: 1.0980 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 66/100\n",
            "1/5 [=====>........................] - ETA: 31s - loss: 0.7575 - accuracy: 0.6875 - f1_m: 0.6906 - precision_m: 0.6999 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8659 - accuracy: 0.6250 - f1_m: 0.6273 - precision_m: 0.6407 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 22s - loss: 0.8499 - accuracy: 0.6250 - f1_m: 0.6251 - precision_m: 0.6480 - recall_m: 0.6250\n",
            "4/5 [=======================>......] - ETA: 10s - loss: 0.8425 - accuracy: 0.6328 - f1_m: 0.6321 - precision_m: 0.6524 - recall_m: 0.6328\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8350 - accuracy: 0.6319 - f1_m: 0.6351 - precision_m: 0.6761 - recall_m: 0.6313 \n",
            "5/5 [==============================] - 45s 9s/step - loss: 0.8350 - accuracy: 0.6319 - f1_m: 0.6351 - precision_m: 0.6761 - recall_m: 0.6313 - val_loss: 1.0734 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 67/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.9092 - accuracy: 0.5625 - f1_m: 0.5643 - precision_m: 0.5843 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 28s - loss: 0.8814 - accuracy: 0.5469 - f1_m: 0.5491 - precision_m: 0.5658 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 18s - loss: 0.8384 - accuracy: 0.5938 - f1_m: 0.5910 - precision_m: 0.6012 - recall_m: 0.5938\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.8383 - accuracy: 0.5859 - f1_m: 0.5872 - precision_m: 0.6032 - recall_m: 0.5859 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8298 - accuracy: 0.5764 - f1_m: 0.5677 - precision_m: 0.5819 - recall_m: 0.5688\n",
            "5/5 [==============================] - 40s 8s/step - loss: 0.8298 - accuracy: 0.5764 - f1_m: 0.5677 - precision_m: 0.5819 - recall_m: 0.5688 - val_loss: 1.0723 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 68/100\n",
            "1/5 [=====>........................] - ETA: 39s - loss: 0.8229 - accuracy: 0.6250 - f1_m: 0.6161 - precision_m: 0.6215 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 0.8049 - accuracy: 0.6719 - f1_m: 0.6656 - precision_m: 0.6787 - recall_m: 0.6719\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.8026 - accuracy: 0.6458 - f1_m: 0.6485 - precision_m: 0.6700 - recall_m: 0.6458\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7997 - accuracy: 0.6641 - f1_m: 0.6662 - precision_m: 0.6885 - recall_m: 0.6641 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7992 - accuracy: 0.6667 - f1_m: 0.6710 - precision_m: 0.6910 - recall_m: 0.6687\n",
            "5/5 [==============================] - 39s 7s/step - loss: 0.7992 - accuracy: 0.6667 - f1_m: 0.6710 - precision_m: 0.6910 - recall_m: 0.6687 - val_loss: 1.0830 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 69/100\n",
            "1/5 [=====>........................] - ETA: 31s - loss: 0.8351 - accuracy: 0.5312 - f1_m: 0.5363 - precision_m: 0.5469 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.9019 - accuracy: 0.5469 - f1_m: 0.5508 - precision_m: 0.5632 - recall_m: 0.5469\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.8562 - accuracy: 0.5625 - f1_m: 0.5678 - precision_m: 0.5884 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8067 - accuracy: 0.6328 - f1_m: 0.6361 - precision_m: 0.6581 - recall_m: 0.6328 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8316 - accuracy: 0.6181 - f1_m: 0.6073 - precision_m: 0.6327 - recall_m: 0.6062\n",
            "5/5 [==============================] - 36s 7s/step - loss: 0.8316 - accuracy: 0.6181 - f1_m: 0.6073 - precision_m: 0.6327 - recall_m: 0.6062 - val_loss: 1.0900 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 70/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7888 - accuracy: 0.6875 - f1_m: 0.6875 - precision_m: 0.6939 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8027 - accuracy: 0.6719 - f1_m: 0.6719 - precision_m: 0.6751 - recall_m: 0.6719\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.7691 - accuracy: 0.6875 - f1_m: 0.6884 - precision_m: 0.6990 - recall_m: 0.6875\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7906 - accuracy: 0.6641 - f1_m: 0.6635 - precision_m: 0.6716 - recall_m: 0.6641 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.6597 - f1_m: 0.6548 - precision_m: 0.6644 - recall_m: 0.6562\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7881 - accuracy: 0.6597 - f1_m: 0.6548 - precision_m: 0.6644 - recall_m: 0.6562 - val_loss: 1.0940 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 71/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7466 - accuracy: 0.7812 - f1_m: 0.7843 - precision_m: 0.7896 - recall_m: 0.7812\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7862 - accuracy: 0.6562 - f1_m: 0.6509 - precision_m: 0.6500 - recall_m: 0.6562\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7553 - accuracy: 0.7083 - f1_m: 0.7043 - precision_m: 0.7057 - recall_m: 0.7083\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8373 - accuracy: 0.6328 - f1_m: 0.6293 - precision_m: 0.6304 - recall_m: 0.6328 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8212 - accuracy: 0.6389 - f1_m: 0.6406 - precision_m: 0.6424 - recall_m: 0.6438\n",
            "5/5 [==============================] - 36s 7s/step - loss: 0.8212 - accuracy: 0.6389 - f1_m: 0.6406 - precision_m: 0.6424 - recall_m: 0.6438 - val_loss: 1.0841 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 72/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.7917 - accuracy: 0.6562 - f1_m: 0.6737 - precision_m: 0.7297 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 28s - loss: 0.8286 - accuracy: 0.6250 - f1_m: 0.6294 - precision_m: 0.6590 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.7848 - accuracy: 0.6562 - f1_m: 0.6593 - precision_m: 0.6801 - recall_m: 0.6562\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7974 - accuracy: 0.6328 - f1_m: 0.6362 - precision_m: 0.6533 - recall_m: 0.6328 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7844 - accuracy: 0.6458 - f1_m: 0.6589 - precision_m: 0.6757 - recall_m: 0.6562\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.7844 - accuracy: 0.6458 - f1_m: 0.6589 - precision_m: 0.6757 - recall_m: 0.6562 - val_loss: 1.0114 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 73/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7654 - accuracy: 0.6875 - f1_m: 0.6875 - precision_m: 0.7001 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7705 - accuracy: 0.7031 - f1_m: 0.7022 - precision_m: 0.7152 - recall_m: 0.7031\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7444 - accuracy: 0.7188 - f1_m: 0.7182 - precision_m: 0.7326 - recall_m: 0.7188\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8010 - accuracy: 0.6875 - f1_m: 0.6847 - precision_m: 0.7096 - recall_m: 0.6875 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.6806 - f1_m: 0.6707 - precision_m: 0.6906 - recall_m: 0.6750\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7965 - accuracy: 0.6806 - f1_m: 0.6707 - precision_m: 0.6906 - recall_m: 0.6750 - val_loss: 1.0090 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 74/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8115 - accuracy: 0.6875 - f1_m: 0.6824 - precision_m: 0.6840 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7653 - accuracy: 0.6875 - f1_m: 0.6839 - precision_m: 0.6870 - recall_m: 0.6875\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.7789 - accuracy: 0.6979 - f1_m: 0.6883 - precision_m: 0.7219 - recall_m: 0.6979\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7938 - accuracy: 0.6875 - f1_m: 0.6790 - precision_m: 0.7035 - recall_m: 0.6875 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.6736 - f1_m: 0.6680 - precision_m: 0.7033 - recall_m: 0.6625\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.8038 - accuracy: 0.6736 - f1_m: 0.6680 - precision_m: 0.7033 - recall_m: 0.6625 - val_loss: 1.0315 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 75/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.8492 - accuracy: 0.5625 - f1_m: 0.5547 - precision_m: 0.5525 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 24s - loss: 0.8208 - accuracy: 0.6250 - f1_m: 0.6246 - precision_m: 0.6345 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 18s - loss: 0.7836 - accuracy: 0.6771 - f1_m: 0.6770 - precision_m: 0.6893 - recall_m: 0.6771\n",
            "4/5 [=======================>......] - ETA: 9s - loss: 0.7976 - accuracy: 0.6797 - f1_m: 0.6790 - precision_m: 0.6881 - recall_m: 0.6797 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7910 - accuracy: 0.6875 - f1_m: 0.6969 - precision_m: 0.7172 - recall_m: 0.6938\n",
            "5/5 [==============================] - 43s 9s/step - loss: 0.7910 - accuracy: 0.6875 - f1_m: 0.6969 - precision_m: 0.7172 - recall_m: 0.6938 - val_loss: 1.0187 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 76/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.6979 - accuracy: 0.7188 - f1_m: 0.7218 - precision_m: 0.7314 - recall_m: 0.7188\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8076 - accuracy: 0.6406 - f1_m: 0.6432 - precision_m: 0.6503 - recall_m: 0.6406\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.8010 - accuracy: 0.6042 - f1_m: 0.6049 - precision_m: 0.6096 - recall_m: 0.6042\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8538 - accuracy: 0.5625 - f1_m: 0.5679 - precision_m: 0.5818 - recall_m: 0.5625 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8304 - accuracy: 0.5903 - f1_m: 0.6170 - precision_m: 0.6305 - recall_m: 0.6125\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.8304 - accuracy: 0.5903 - f1_m: 0.6170 - precision_m: 0.6305 - recall_m: 0.6125 - val_loss: 1.0384 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 77/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.7952 - accuracy: 0.7500 - f1_m: 0.7548 - precision_m: 0.7866 - recall_m: 0.7500\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7906 - accuracy: 0.6406 - f1_m: 0.6489 - precision_m: 0.6752 - recall_m: 0.6406\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.7794 - accuracy: 0.6771 - f1_m: 0.6798 - precision_m: 0.7142 - recall_m: 0.6771\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7702 - accuracy: 0.6953 - f1_m: 0.6989 - precision_m: 0.7327 - recall_m: 0.6953 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7878 - accuracy: 0.6806 - f1_m: 0.6679 - precision_m: 0.6917 - recall_m: 0.6687\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.7878 - accuracy: 0.6806 - f1_m: 0.6679 - precision_m: 0.6917 - recall_m: 0.6687 - val_loss: 1.0498 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 78/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7571 - accuracy: 0.6562 - f1_m: 0.6633 - precision_m: 0.6911 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7876 - accuracy: 0.6406 - f1_m: 0.6448 - precision_m: 0.6775 - recall_m: 0.6406\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.7729 - accuracy: 0.6562 - f1_m: 0.6602 - precision_m: 0.6882 - recall_m: 0.6562\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7913 - accuracy: 0.6641 - f1_m: 0.6682 - precision_m: 0.6967 - recall_m: 0.6641 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.6667 - f1_m: 0.6709 - precision_m: 0.6942 - recall_m: 0.6687\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7832 - accuracy: 0.6667 - f1_m: 0.6709 - precision_m: 0.6942 - recall_m: 0.6687 - val_loss: 1.0373 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 79/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.6739 - accuracy: 0.7812 - f1_m: 0.7800 - precision_m: 0.7806 - recall_m: 0.7812\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7467 - accuracy: 0.7500 - f1_m: 0.7472 - precision_m: 0.7570 - recall_m: 0.7500\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7431 - accuracy: 0.7396 - f1_m: 0.7374 - precision_m: 0.7553 - recall_m: 0.7396\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7178 - accuracy: 0.7734 - f1_m: 0.7718 - precision_m: 0.7852 - recall_m: 0.7734 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.7500 - f1_m: 0.7300 - precision_m: 0.7407 - recall_m: 0.7312\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.7308 - accuracy: 0.7500 - f1_m: 0.7300 - precision_m: 0.7407 - recall_m: 0.7312 - val_loss: 1.0009 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 80/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.6425 - accuracy: 0.7500 - f1_m: 0.7495 - precision_m: 0.7520 - recall_m: 0.7500\n",
            "2/5 [===========>..................] - ETA: 30s - loss: 0.6486 - accuracy: 0.7656 - f1_m: 0.7653 - precision_m: 0.7675 - recall_m: 0.7656\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.6860 - accuracy: 0.7188 - f1_m: 0.7186 - precision_m: 0.7200 - recall_m: 0.7188\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7081 - accuracy: 0.6953 - f1_m: 0.6949 - precision_m: 0.7010 - recall_m: 0.6953 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7001 - accuracy: 0.7083 - f1_m: 0.7173 - precision_m: 0.7255 - recall_m: 0.7188\n",
            "5/5 [==============================] - 41s 8s/step - loss: 0.7001 - accuracy: 0.7083 - f1_m: 0.7173 - precision_m: 0.7255 - recall_m: 0.7188 - val_loss: 1.0639 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 81/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7178 - accuracy: 0.6875 - f1_m: 0.6901 - precision_m: 0.7109 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7212 - accuracy: 0.7344 - f1_m: 0.7369 - precision_m: 0.7555 - recall_m: 0.7344\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7610 - accuracy: 0.6979 - f1_m: 0.6980 - precision_m: 0.7124 - recall_m: 0.6979\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7593 - accuracy: 0.6875 - f1_m: 0.6878 - precision_m: 0.6995 - recall_m: 0.6875 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7644 - accuracy: 0.6875 - f1_m: 0.6874 - precision_m: 0.7080 - recall_m: 0.6875\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7644 - accuracy: 0.6875 - f1_m: 0.6874 - precision_m: 0.7080 - recall_m: 0.6875 - val_loss: 1.0124 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 82/100\n",
            "1/5 [=====>........................] - ETA: 45s - loss: 0.7382 - accuracy: 0.6875 - f1_m: 0.6720 - precision_m: 0.6873 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 35s - loss: 0.7997 - accuracy: 0.6719 - f1_m: 0.6582 - precision_m: 0.6804 - recall_m: 0.6719\n",
            "3/5 [=================>............] - ETA: 19s - loss: 0.7819 - accuracy: 0.6562 - f1_m: 0.6528 - precision_m: 0.6802 - recall_m: 0.6562\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7566 - accuracy: 0.6719 - f1_m: 0.6689 - precision_m: 0.6896 - recall_m: 0.6719 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.6806 - f1_m: 0.6862 - precision_m: 0.7142 - recall_m: 0.6875\n",
            "5/5 [==============================] - 44s 8s/step - loss: 0.7608 - accuracy: 0.6806 - f1_m: 0.6862 - precision_m: 0.7142 - recall_m: 0.6875 - val_loss: 1.0680 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 83/100\n",
            "1/5 [=====>........................] - ETA: 37s - loss: 0.7437 - accuracy: 0.7812 - f1_m: 0.7804 - precision_m: 0.8073 - recall_m: 0.7812\n",
            "2/5 [===========>..................] - ETA: 25s - loss: 0.7730 - accuracy: 0.7031 - f1_m: 0.7043 - precision_m: 0.7203 - recall_m: 0.7031\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.8179 - accuracy: 0.6667 - f1_m: 0.6667 - precision_m: 0.6867 - recall_m: 0.6667\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7926 - accuracy: 0.6797 - f1_m: 0.6804 - precision_m: 0.7010 - recall_m: 0.6797 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.7083 - f1_m: 0.7317 - precision_m: 0.7499 - recall_m: 0.7312\n",
            "5/5 [==============================] - 39s 7s/step - loss: 0.7637 - accuracy: 0.7083 - f1_m: 0.7317 - precision_m: 0.7499 - recall_m: 0.7312 - val_loss: 1.0359 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 84/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8194 - accuracy: 0.5625 - f1_m: 0.5572 - precision_m: 0.5646 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8033 - accuracy: 0.5938 - f1_m: 0.5897 - precision_m: 0.5933 - recall_m: 0.5938\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7654 - accuracy: 0.6354 - f1_m: 0.6324 - precision_m: 0.6406 - recall_m: 0.6354\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7574 - accuracy: 0.6562 - f1_m: 0.6539 - precision_m: 0.6705 - recall_m: 0.6562 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7558 - accuracy: 0.6458 - f1_m: 0.6340 - precision_m: 0.6507 - recall_m: 0.6375\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.7558 - accuracy: 0.6458 - f1_m: 0.6340 - precision_m: 0.6507 - recall_m: 0.6375 - val_loss: 1.0269 - val_accuracy: 0.3514 - val_f1_m: 0.2773 - val_precision_m: 0.4208 - val_recall_m: 0.3719\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 85/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.7801 - accuracy: 0.5938 - f1_m: 0.6135 - precision_m: 0.7491 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7981 - accuracy: 0.5625 - f1_m: 0.5740 - precision_m: 0.6441 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7466 - accuracy: 0.6354 - f1_m: 0.6442 - precision_m: 0.6995 - recall_m: 0.6354\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7657 - accuracy: 0.6406 - f1_m: 0.6459 - precision_m: 0.6890 - recall_m: 0.6406 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7885 - accuracy: 0.6181 - f1_m: 0.5938 - precision_m: 0.6207 - recall_m: 0.6000\n",
            "5/5 [==============================] - 36s 7s/step - loss: 0.7885 - accuracy: 0.6181 - f1_m: 0.5938 - precision_m: 0.6207 - recall_m: 0.6000 - val_loss: 1.0664 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 86/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.6525 - accuracy: 0.6875 - f1_m: 0.6899 - precision_m: 0.7521 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.6736 - accuracy: 0.7031 - f1_m: 0.7106 - precision_m: 0.7566 - recall_m: 0.7031\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.6891 - accuracy: 0.7292 - f1_m: 0.7350 - precision_m: 0.7672 - recall_m: 0.7292\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.6818 - accuracy: 0.7500 - f1_m: 0.7525 - precision_m: 0.7777 - recall_m: 0.7500 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7361 - f1_m: 0.7251 - precision_m: 0.7597 - recall_m: 0.7250\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7060 - accuracy: 0.7361 - f1_m: 0.7251 - precision_m: 0.7597 - recall_m: 0.7250 - val_loss: 1.1380 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 87/100\n",
            "1/5 [=====>........................] - ETA: 39s - loss: 0.8130 - accuracy: 0.6250 - f1_m: 0.6250 - precision_m: 0.6250 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 23s - loss: 0.8143 - accuracy: 0.6406 - f1_m: 0.6369 - precision_m: 0.6433 - recall_m: 0.6406\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.7795 - accuracy: 0.6250 - f1_m: 0.6250 - precision_m: 0.6394 - recall_m: 0.6250\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7843 - accuracy: 0.6328 - f1_m: 0.6319 - precision_m: 0.6439 - recall_m: 0.6328 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7686 - accuracy: 0.6528 - f1_m: 0.6657 - precision_m: 0.6829 - recall_m: 0.6687\n",
            "5/5 [==============================] - 40s 8s/step - loss: 0.7686 - accuracy: 0.6528 - f1_m: 0.6657 - precision_m: 0.6829 - recall_m: 0.6687 - val_loss: 1.0059 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 88/100\n",
            "1/5 [=====>........................] - ETA: 33s - loss: 0.7531 - accuracy: 0.6562 - f1_m: 0.6614 - precision_m: 0.6992 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 0.7258 - accuracy: 0.7188 - f1_m: 0.7190 - precision_m: 0.7418 - recall_m: 0.7188\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.7040 - accuracy: 0.7188 - f1_m: 0.7204 - precision_m: 0.7427 - recall_m: 0.7188\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7081 - accuracy: 0.7031 - f1_m: 0.7043 - precision_m: 0.7211 - recall_m: 0.7031 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.7083 - f1_m: 0.7135 - precision_m: 0.7319 - recall_m: 0.7125\n",
            "5/5 [==============================] - 36s 7s/step - loss: 0.7028 - accuracy: 0.7083 - f1_m: 0.7135 - precision_m: 0.7319 - recall_m: 0.7125 - val_loss: 0.9926 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 89/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7327 - accuracy: 0.6875 - f1_m: 0.7083 - precision_m: 0.7734 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7396 - accuracy: 0.7031 - f1_m: 0.7117 - precision_m: 0.7459 - recall_m: 0.7031\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.7638 - accuracy: 0.6562 - f1_m: 0.6637 - precision_m: 0.6896 - recall_m: 0.6562\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7399 - accuracy: 0.6875 - f1_m: 0.6931 - precision_m: 0.7164 - recall_m: 0.6875 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7233 - accuracy: 0.7014 - f1_m: 0.7160 - precision_m: 0.7353 - recall_m: 0.7125\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7233 - accuracy: 0.7014 - f1_m: 0.7160 - precision_m: 0.7353 - recall_m: 0.7125 - val_loss: 1.0206 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 90/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7078 - accuracy: 0.6562 - f1_m: 0.6566 - precision_m: 0.7097 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.6922 - accuracy: 0.7344 - f1_m: 0.7346 - precision_m: 0.7677 - recall_m: 0.7344\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.6851 - accuracy: 0.7396 - f1_m: 0.7387 - precision_m: 0.7785 - recall_m: 0.7396\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.6946 - accuracy: 0.7188 - f1_m: 0.7183 - precision_m: 0.7500 - recall_m: 0.7188 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.7153 - f1_m: 0.7224 - precision_m: 0.7656 - recall_m: 0.7125\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.6986 - accuracy: 0.7153 - f1_m: 0.7224 - precision_m: 0.7656 - recall_m: 0.7125 - val_loss: 1.0050 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 91/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7739 - accuracy: 0.6250 - f1_m: 0.6330 - precision_m: 0.6638 - recall_m: 0.6250\n",
            "2/5 [===========>..................] - ETA: 30s - loss: 0.7298 - accuracy: 0.6875 - f1_m: 0.6912 - precision_m: 0.7326 - recall_m: 0.6875\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.7477 - accuracy: 0.6667 - f1_m: 0.6657 - precision_m: 0.7123 - recall_m: 0.6667\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7324 - accuracy: 0.6875 - f1_m: 0.6867 - precision_m: 0.7217 - recall_m: 0.6875 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.7083 - f1_m: 0.7256 - precision_m: 0.7607 - recall_m: 0.7250\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7085 - accuracy: 0.7083 - f1_m: 0.7256 - precision_m: 0.7607 - recall_m: 0.7250 - val_loss: 1.0643 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 92/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8580 - accuracy: 0.5938 - f1_m: 0.6438 - precision_m: 0.7188 - recall_m: 0.5938\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.8031 - accuracy: 0.6250 - f1_m: 0.6451 - precision_m: 0.7195 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 15s - loss: 0.8209 - accuracy: 0.6146 - f1_m: 0.6273 - precision_m: 0.6863 - recall_m: 0.6146\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7931 - accuracy: 0.6250 - f1_m: 0.6355 - precision_m: 0.6900 - recall_m: 0.6250 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8069 - accuracy: 0.6042 - f1_m: 0.6061 - precision_m: 0.6770 - recall_m: 0.5875\n",
            "5/5 [==============================] - 37s 7s/step - loss: 0.8069 - accuracy: 0.6042 - f1_m: 0.6061 - precision_m: 0.6770 - recall_m: 0.5875 - val_loss: 1.0703 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 93/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.7229 - accuracy: 0.6875 - f1_m: 0.6877 - precision_m: 0.6938 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 20s - loss: 0.6645 - accuracy: 0.7500 - f1_m: 0.7486 - precision_m: 0.7553 - recall_m: 0.7500\n",
            "3/5 [=================>............] - ETA: 13s - loss: 0.6967 - accuracy: 0.7188 - f1_m: 0.7195 - precision_m: 0.7431 - recall_m: 0.7188\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7166 - accuracy: 0.7188 - f1_m: 0.7232 - precision_m: 0.7518 - recall_m: 0.7188 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.7083 - f1_m: 0.6949 - precision_m: 0.7139 - recall_m: 0.7000\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.7315 - accuracy: 0.7083 - f1_m: 0.6949 - precision_m: 0.7139 - recall_m: 0.7000 - val_loss: 1.0773 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 94/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.8603 - accuracy: 0.5625 - f1_m: 0.5629 - precision_m: 0.6120 - recall_m: 0.5625\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7552 - accuracy: 0.6875 - f1_m: 0.6871 - precision_m: 0.7248 - recall_m: 0.6875\n",
            "3/5 [=================>............] - ETA: 17s - loss: 0.7600 - accuracy: 0.6667 - f1_m: 0.6685 - precision_m: 0.7065 - recall_m: 0.6667\n",
            "4/5 [=======================>......] - ETA: 8s - loss: 0.7640 - accuracy: 0.6719 - f1_m: 0.6722 - precision_m: 0.7146 - recall_m: 0.6719 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7555 - accuracy: 0.6736 - f1_m: 0.6753 - precision_m: 0.7106 - recall_m: 0.6750\n",
            "5/5 [==============================] - 39s 8s/step - loss: 0.7555 - accuracy: 0.6736 - f1_m: 0.6753 - precision_m: 0.7106 - recall_m: 0.6750 - val_loss: 1.0142 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 95/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7762 - accuracy: 0.6875 - f1_m: 0.6891 - precision_m: 0.6969 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7839 - accuracy: 0.6250 - f1_m: 0.6249 - precision_m: 0.6328 - recall_m: 0.6250\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7554 - accuracy: 0.6667 - f1_m: 0.6648 - precision_m: 0.6722 - recall_m: 0.6667\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7467 - accuracy: 0.6641 - f1_m: 0.6629 - precision_m: 0.6770 - recall_m: 0.6641 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7748 - accuracy: 0.6458 - f1_m: 0.6321 - precision_m: 0.6574 - recall_m: 0.6313\n",
            "5/5 [==============================] - 35s 7s/step - loss: 0.7748 - accuracy: 0.6458 - f1_m: 0.6321 - precision_m: 0.6574 - recall_m: 0.6313 - val_loss: 1.2773 - val_accuracy: 0.4865 - val_f1_m: 0.3329 - val_precision_m: 0.7230 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 96/100\n",
            "1/5 [=====>........................] - ETA: 34s - loss: 0.8855 - accuracy: 0.5312 - f1_m: 0.5390 - precision_m: 0.5516 - recall_m: 0.5312\n",
            "2/5 [===========>..................] - ETA: 27s - loss: 0.8592 - accuracy: 0.5625 - f1_m: 0.5698 - precision_m: 0.6121 - recall_m: 0.5625\n",
            "3/5 [=================>............] - ETA: 16s - loss: 0.8611 - accuracy: 0.5625 - f1_m: 0.5629 - precision_m: 0.5942 - recall_m: 0.5625\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.8454 - accuracy: 0.5547 - f1_m: 0.5552 - precision_m: 0.5853 - recall_m: 0.5547 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.5764 - f1_m: 0.5942 - precision_m: 0.6183 - recall_m: 0.5938\n",
            "5/5 [==============================] - 38s 7s/step - loss: 0.8223 - accuracy: 0.5764 - f1_m: 0.5942 - precision_m: 0.6183 - recall_m: 0.5938 - val_loss: 1.0491 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 97/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.7612 - accuracy: 0.6562 - f1_m: 0.6656 - precision_m: 0.7156 - recall_m: 0.6562\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7608 - accuracy: 0.6406 - f1_m: 0.6453 - precision_m: 0.6890 - recall_m: 0.6406\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7728 - accuracy: 0.6667 - f1_m: 0.6733 - precision_m: 0.7104 - recall_m: 0.6667\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7704 - accuracy: 0.6250 - f1_m: 0.6328 - precision_m: 0.6651 - recall_m: 0.6250 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7624 - accuracy: 0.6181 - f1_m: 0.6203 - precision_m: 0.6571 - recall_m: 0.6125\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7624 - accuracy: 0.6181 - f1_m: 0.6203 - precision_m: 0.6571 - recall_m: 0.6125 - val_loss: 1.1162 - val_accuracy: 0.4595 - val_f1_m: 0.2739 - val_precision_m: 0.6572 - val_recall_m: 0.4344\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 98/100\n",
            "1/5 [=====>........................] - ETA: 30s - loss: 0.6407 - accuracy: 0.7812 - f1_m: 0.7844 - precision_m: 0.7909 - recall_m: 0.7812\n",
            "2/5 [===========>..................] - ETA: 46s - loss: 0.6903 - accuracy: 0.7188 - f1_m: 0.7194 - precision_m: 0.7228 - recall_m: 0.7188\n",
            "3/5 [=================>............] - ETA: 23s - loss: 0.7154 - accuracy: 0.6875 - f1_m: 0.6971 - precision_m: 0.7174 - recall_m: 0.6875\n",
            "4/5 [=======================>......] - ETA: 10s - loss: 0.7069 - accuracy: 0.7031 - f1_m: 0.7078 - precision_m: 0.7281 - recall_m: 0.7031\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.7222 - f1_m: 0.7414 - precision_m: 0.7606 - recall_m: 0.7375 \n",
            "5/5 [==============================] - 44s 9s/step - loss: 0.6945 - accuracy: 0.7222 - f1_m: 0.7414 - precision_m: 0.7606 - recall_m: 0.7375 - val_loss: 1.1964 - val_accuracy: 0.4865 - val_f1_m: 0.2810 - val_precision_m: 0.7550 - val_recall_m: 0.4500\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 99/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.6358 - accuracy: 0.7500 - f1_m: 0.7563 - precision_m: 0.7656 - recall_m: 0.7500\n",
            "2/5 [===========>..................] - ETA: 32s - loss: 0.8064 - accuracy: 0.6719 - f1_m: 0.6717 - precision_m: 0.7219 - recall_m: 0.6719\n",
            "3/5 [=================>............] - ETA: 18s - loss: 0.7620 - accuracy: 0.7083 - f1_m: 0.7080 - precision_m: 0.7422 - recall_m: 0.7083\n",
            "4/5 [=======================>......] - ETA: 9s - loss: 0.7771 - accuracy: 0.6719 - f1_m: 0.6702 - precision_m: 0.6971 - recall_m: 0.6719 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7948 - accuracy: 0.6736 - f1_m: 0.6750 - precision_m: 0.7092 - recall_m: 0.6750\n",
            "5/5 [==============================] - 42s 9s/step - loss: 0.7948 - accuracy: 0.6736 - f1_m: 0.6750 - precision_m: 0.7092 - recall_m: 0.6750 - val_loss: 1.0092 - val_accuracy: 0.5135 - val_f1_m: 0.3129 - val_precision_m: 0.7590 - val_recall_m: 0.4656\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4599)\u001b[0m Epoch 100/100\n",
            "1/5 [=====>........................] - ETA: 29s - loss: 0.8070 - accuracy: 0.6875 - f1_m: 0.6942 - precision_m: 0.7250 - recall_m: 0.6875\n",
            "2/5 [===========>..................] - ETA: 22s - loss: 0.7386 - accuracy: 0.7500 - f1_m: 0.7551 - precision_m: 0.7795 - recall_m: 0.7500\n",
            "3/5 [=================>............] - ETA: 14s - loss: 0.7703 - accuracy: 0.7292 - f1_m: 0.7300 - precision_m: 0.7646 - recall_m: 0.7292\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.7683 - accuracy: 0.7188 - f1_m: 0.7193 - precision_m: 0.7489 - recall_m: 0.7188 \n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7851 - accuracy: 0.6806 - f1_m: 0.6495 - precision_m: 0.7003 - recall_m: 0.6500\n",
            "5/5 [==============================] - 38s 8s/step - loss: 0.7851 - accuracy: 0.6806 - f1_m: 0.6495 - precision_m: 0.7003 - recall_m: 0.6500 - val_loss: 1.4886 - val_accuracy: 0.3514 - val_f1_m: 0.2994 - val_precision_m: 0.7726 - val_recall_m: 0.4563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-22 10:40:52,626\tINFO tune.py:778 -- Total run time: 8616.00 seconds (8615.80 seconds for the tuning loop).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f604d668050>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
        "from ray.tune.suggest.bohb import TuneBOHB\n",
        "algo = TuneBOHB(\n",
        "    config_space, metric=\"val_f1_m\", mode=\"max\", max_concurrent=1)\n",
        "bohb = HyperBandForBOHB(\n",
        "    time_attr=\"training_iteration\",\n",
        "    metric=\"val_f1_m\",\n",
        "      mode=\"max\",\n",
        "      max_t=2)\n",
        "tune.run(train_mnist, scheduler=bohb, num_samples=3, search_alg=algo)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb15f1e0f376981e7b6e1fc44ae8b8146823f10f258bcd6e448b0230b889fc06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
